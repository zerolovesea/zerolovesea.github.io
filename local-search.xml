<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>重温统计学习方法：极大似然估计与贝叶斯估计</title>
    <link href="/2025/01/19/%E9%87%8D%E8%AF%BB%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BC%9A%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/"/>
    <url>/2025/01/19/%E9%87%8D%E8%AF%BB%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BC%9A%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<p>最近在重温统计机器学习，发现很多概念都已经很模糊了，一些算法的推导公式和原理都不记得了，因此决定重新整理一下。这次先从最开始的两大统计学派：频率学派和贝叶斯学派开始。</p><hr><h2 id="极大似然估计-MLE"><a href="#极大似然估计-MLE" class="headerlink" title="极大似然估计 (MLE)"></a><strong>极大似然估计 (MLE)</strong></h2><p>极大似然的基本思想是通过已有的观测到的数据，找到使观测数据出现的可能性最大的模型参数。</p><p><strong>原理</strong></p><ol><li>假设数据来自某一概率分布 $P(x|\theta)$ ，其中 $\theta$ 是待估计的参数。</li><li>给定一组观测数据${x_1, x_2, \ldots, x_n}$，似然函数定义为： $L(\theta) &#x3D; P(x_1, x_2, \ldots, x_n | \theta)$ </li><li>我们假设数据独立同分布（i.i.d.），这样就变成了多个样本的联合概率，可以直接写成多个概率的乘积： $L(\theta) &#x3D; \prod_{i&#x3D;1}^n P(x_i|\theta)$</li><li>取对数简化计算： $\ell(\theta) &#x3D; \log L(\theta) &#x3D; \sum_{i&#x3D;1}^n \log P(x_i|\theta)$</li><li>找到使对数似然函数最大的参数 $\theta$，即： $\theta_{MLE} &#x3D; \arg\max_{\theta} \ell(\theta)$</li></ol><p>MLE体现了传统频率学派的观点：只基于数据，不依赖先验分布。当样本量足够大的时候，它的期望等于实际参数。而在样本量不够，或者参数量过大的时候，又会导致过拟合。</p><hr><h2 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a><strong>贝叶斯估计</strong></h2><p>和MLE对应的是贝叶斯估计。贝叶斯估计基于贝叶斯定理，将先验知识和观测数据相结合，得到参数的后验分布，并以此进行参数估计。</p><p><strong>原理</strong></p><ol><li><p>贝叶斯定理公式为：</p><p>$P(\theta | x) &#x3D; \frac{P(x | \theta) P(\theta)}{P(x)}$</p><ul><li>$P(\theta)$：先验分布，表示对参数 $\theta$ 的先验知识。</li><li>$P(x|\theta)$：似然函数，表示在参数 $\theta$ 下观测数据 $x$ 的概率。</li><li>$P(x)$：归一化常数，通常不直接关心。</li><li>$P(\theta|x)$：后验分布，结合了先验知识和观测数据后的参数分布。</li></ul></li><li><p>根据后验分布进行估计：</p><ul><li><strong>最大后验估计（MAP）</strong>：取后验分布的最大值作为参数估计值： $\theta_{MAP} &#x3D; \arg\max_{\theta} P(\theta | x)$</li><li><strong>后验均值估计</strong>：计算后验分布的期望值： ${\theta}_{Bayes} &#x3D; \int \theta P(\theta|x) d\theta$</li></ul></li></ol><p>贝叶斯估计体现了贝叶斯学派的观点：结合先验分布与观测数据。由于存在了一些先验的信息，在样本量不够的情况下比MLE效果更好。</p><hr><h2 id="极大似然估计与贝叶斯估计的区别"><a href="#极大似然估计与贝叶斯估计的区别" class="headerlink" title="极大似然估计与贝叶斯估计的区别"></a><strong>极大似然估计与贝叶斯估计的区别</strong></h2><table><thead><tr><th>特点</th><th>极大似然估计 (MLE)</th><th>贝叶斯估计</th></tr></thead><tbody><tr><td><strong>理论基础</strong></td><td>频率学派，关注观测数据</td><td>贝叶斯学派，结合先验与数据</td></tr><tr><td><strong>输入信息</strong></td><td>仅使用观测数据</td><td>使用观测数据和先验分布</td></tr><tr><td><strong>目标</strong></td><td>最大化似然函数</td><td>最大化后验分布</td></tr><tr><td><strong>适用场景</strong></td><td>样本量大，先验信息不足或无先验信息</td><td>样本量小，存在可靠的先验信息</td></tr><tr><td><strong>计算复杂度</strong></td><td>较低，解析解常常可用</td><td>较高，可能需要数值积分或近似</td></tr><tr><td><strong>估计结果</strong></td><td>点估计（一个确定值）</td><td>分布估计（后验分布）或点估计</td></tr></tbody></table><hr><h2 id="更具象的解释"><a href="#更具象的解释" class="headerlink" title="更具象的解释"></a><strong>更具象的解释</strong></h2><p>但从理论解释可能还有一些混乱，用一个机器学习调参的任务来对比一下他们的区别。</p><p>对于一个机器学习模型，极大似然估计任务模型参数是一个固定值，需要对数据最大化似然来得到这个模型参数。而贝叶斯估计认为模型参数是随机的，先拥有一个先验的分布，随后根据数据，计算参数的后验分布。</p><ol><li><p>极大似然估计里，我们直接最大化对数似然函数，就能找到这个参数。</p></li><li><p>在贝叶斯估计里，我们先对参数$\theta$有一个先验知识，我们假定权重参数都是0，并且认为这些参数符合正态分布，那么正态分布就是参数$\theta$的先验分布：$P(\theta) &#x3D; \prod_{j&#x3D;1}^d N(\theta_j; 0, \tau^2)$</p></li><li><p>这时根据贝叶斯公式，后验分布就是先验分布和似然函数的乘积，对这个乘积求最大值已得到参数：$\theta_{\text{MAP}} &#x3D; \arg\max_{\theta} \left( \log P(y \mid x; \theta) + \log P(\theta) \right)$</p></li></ol><p>对比最大后验估计和极大似然估计，两者在取对数的时候，只相差了一个先验项$\log P(\theta) $。</p><h2 id="个人疑问"><a href="#个人疑问" class="headerlink" title="个人疑问"></a>个人疑问</h2><p>个人的疑问在于：当用多个batch训练模型的时候，每个batch中的模型，是否都拥有了前一个batch的先验知识，包括模型和数据。</p><p>对于这个问题，我直接复制GPT的答案：</p><p>在极大似然估计（MLE）中，多个 batch 的数据和模型的更新并不能被称为“先验知识”，这是因为<strong>MLE 本身没有引入先验概率的概念</strong>。让我们详细分析这个问题：</p><hr><h3 id="极大似然估计的性质"><a href="#极大似然估计的性质" class="headerlink" title="极大似然估计的性质"></a><strong>极大似然估计的性质</strong></h3><ol><li><p><strong>没有先验知识</strong>： 在 MLE 中，参数 $\theta$ 被认为是一个固定但未知的值。MLE 的目标是找到一个使数据的似然 $)P(x|\theta)$最大的 $\theta$。这里不涉及任何关于 $\theta$ 的先验分布或假设。</p></li><li><p><strong>每个 batch 的数据贡献</strong>： 在使用多个 batch 的数据时，MLE 的思想是逐步更新参数，使得所有数据的对数似然总和最大化：</p><p>$\ell(\theta) &#x3D; \sum_{i&#x3D;1}^n \log P(x_i | \theta)$</p><p>在批量训练中，每个 batch 的数据只是全量数据的一个子集，对总对数似然做局部贡献。<strong>这些数据只影响参数的更新，并不影响对 $\theta$ 的先验假设</strong>。</p></li><li><p><strong>批次模型的状态</strong>： 在 MLE 中，每个 batch 的训练结果仅仅是当前模型参数的更新，反映的是如何让模型更好地拟合已有数据，而不是引入任何“先验知识”。</p></li></ol><hr><h3 id="贝叶斯估计的视角"><a href="#贝叶斯估计的视角" class="headerlink" title="贝叶斯估计的视角"></a><strong>贝叶斯估计的视角</strong></h3><p>相比之下，贝叶斯估计明确区分了<strong>先验知识</strong>和<strong>数据贡献</strong>：</p><ol><li>**先验分布$P(\theta)$**：<ul><li>贝叶斯估计在更新参数时，会显式考虑 $\theta$ 的先验分布，先验分布反映了在看到数据之前我们对参数的主观认识。</li><li>先验分布是模型的“初始信念”，不依赖观测数据。</li></ul></li><li><strong>后验更新</strong>：<ul><li>贝叶斯方法结合先验分布和批量数据 $x_{batch}$ 计算后验分布： $P(θ)P(\theta | x_{batch}) \propto P(x_{batch}|\theta) P(\theta)$</li><li>每一批数据 $x_{batch}$ 更新后，新的后验分布 $P(\theta|x_{batch})$就成了下一批数据的先验分布。</li><li>这种“动态更新”明确体现了贝叶斯的先验和后验的关系。</li></ul></li></ol><hr><h3 id="MLE-与批量训练的关系"><a href="#MLE-与批量训练的关系" class="headerlink" title="MLE 与批量训练的关系"></a><strong>MLE 与批量训练的关系</strong></h3><p>在 MLE 中：</p><ul><li>批量训练时，每个 batch 的数据只是对总似然的一个部分贡献，并不会改变对参数的任何“先验假设”，因为 MLE 没有先验假设。</li><li>批次之间的模型状态只是参数更新的结果，并不能被视为先验分布的动态更新。</li></ul><hr><h3 id="为什么-MLE-的批量训练不等于先验知识？"><a href="#为什么-MLE-的批量训练不等于先验知识？" class="headerlink" title="为什么 MLE 的批量训练不等于先验知识？"></a><strong>为什么 MLE 的批量训练不等于先验知识？</strong></h3><p>可以用以下几点来解释：</p><ol><li><strong>先验知识的定义</strong>：<ul><li>贝叶斯统计中的先验知识指的是在没有观察数据之前，对参数 $\theta$ 的主观信念或背景信息。</li><li>MLE 没有先验知识的概念，它的参数估计完全基于观测数据。</li></ul></li><li><strong>批次间的独立性</strong>：<ul><li>在 MLE 中，每个 batch 的数据对模型的贡献是独立的，并没有继承“先验到后验再成为新先验”的动态过程。</li></ul></li><li><strong>更新过程的本质</strong>：<ul><li>批量训练的参数更新（如梯度下降）是逐步逼近全数据最大似然解的一种数值优化方法，目的是最大化全数据的似然，而不是动态调整对参数的信念。</li></ul></li></ol><hr><h3 id="类比说明"><a href="#类比说明" class="headerlink" title="类比说明"></a><strong>类比说明</strong></h3><ul><li><strong>MLE 的批量训练</strong>： 像是用分段的方法计算总和，每一批次的数据只是整个总量的一部分贡献，目的是找到能最大化全量数据似然的参数值。</li><li><strong>贝叶斯方法</strong>： 像是分步更新信念的过程，每一批数据都会更新对参数的信念（后验分布），并在下一批数据中用新的信念作为起点。</li></ul><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>在 MLE 中，批次间的模型状态或数据贡献只是逐步逼近全数据最优解的过程，不能被称为“先验知识”。只有在贝叶斯估计中，才有明确的先验分布和动态更新的概念。批量训练在 MLE 和贝叶斯估计中的作用是完全不同的：</p><ul><li><strong>MLE</strong>：所有数据共同构造一个似然函数，逐步优化其最大值。</li><li><strong>贝叶斯估计</strong>：每一批数据更新后验分布，后验分布成为下一步的先验分布，明确体现了“先验知识”的动态演化。</li></ul><p>2025&#x2F;1&#x2F;24 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>统计机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>统计机器学习</tag>
      
      <tag>MLE</tag>
      
      <tag>贝叶斯估计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>写在2024的最后一天</title>
    <link href="/2024/12/31/%E5%86%99%E5%9C%A82024%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%A4%A9/"/>
    <url>/2024/12/31/%E5%86%99%E5%9C%A82024%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%A4%A9/</url>
    
    <content type="html"><![CDATA[<p>今天是2024年的12月31日，按照惯例，写点东西总结一下今年。毕业后工作的第一年，奔跑，离别和改变，这是我对这匆匆一年的简单概括。</p><h2 id="短暂的算法开发生涯"><a href="#短暂的算法开发生涯" class="headerlink" title="短暂的算法开发生涯"></a>短暂的算法开发生涯</h2><p>23年的12月25日，圣诞节的晚上十一点，我刚刚从驻场项目的工厂里出来，虽然12月的苏州天气已冷，但是我一点没有感到寒意。彼时我刚在毕业后的第一家公司转正不久，顶着算法开发的头衔，加上工作初期时常接触到工程代码，学习到很多代码规范，尽管工资不高，但是着实让我很有干劲。</p><p>当时同时在做好几个项目，一个是将一个视觉检测系统部署到工厂里，另一个则是将一个语言模型深度集成到软件当中。同时接触到深度学习领域的两大课题非常让人兴奋。当时我可以每天花三四个小时，在下班后看视频，复现代码。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/250101-1.jpeg"></div><div class="group-image-wrap"><img src="/images/250101-2.jpg"></div></div></div><h3 id="猝不及防的裁员潮"><a href="#猝不及防的裁员潮" class="headerlink" title="猝不及防的裁员潮"></a>猝不及防的裁员潮</h3><p>24年初，我们接连交付了两个项目。尽管其中一个项目拿到了项目奖金，但是很遗憾，其中被寄予厚望，投入大量人力物力的另一个产品并没有被甲方认可。连锁反应很快就降临了。先是降薪，很快裁员就开始了。</p><p>有意识的同事很快主动提了离职，更多的人则猝不及防的被离开了公司。公司的桌椅很快被清理了，本就不算大的公司变得冷冷清清。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/250101-5.jpeg" alt="拿到了职业生涯的第一个奖金"></div><div class="group-image-wrap"><img src="/images/250101-3.jpeg" alt="清空的办公桌"></div></div></div><p>这是我第一次感受到裁员的残酷，前一天还在一起吃饭的同事，第二天就在办公室和HR大声争吵。感受到前景并不令人期待，从4月开始，我就开始陆陆续续向外投简历了，很快锁定了下家。6月，我跟相处不久的同事道了别，走向了下一个阶段的起点。</p><h2 id="短暂的团聚"><a href="#短暂的团聚" class="headerlink" title="短暂的团聚"></a>短暂的团聚</h2><p>2月的时候，芳芳也回了国，我去福建见了她的家人。不久，我俩一起回到苏州，希望能为她在国内找到心仪的工作。我们在工业园区租了一间房，花了很长一段时间把屋子打理的尽可能温馨舒适。</p><p>这段时间也是24年最轻松快乐的一段时间。平时下班以后，我们会一起在家做饭吃，然后在饭后在附近的夜市溜达。周末的时候，我们会买个冰糖葫芦去园林溜达，偶尔去金鸡湖骑自行车。我们还去了杭州见了共同的朋友，听了演唱会和音乐节。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/250101-4.jpeg" alt="三坊七巷的爱心树"></div><div class="group-image-wrap"><img src="/images/250101-7.jpeg" alt="音乐节"></div><div class="group-image-wrap"><img src="/images/250101-8.jpeg" alt="某个网红蛋糕"></div></div></div><p>快乐的日子没有持续很久。一直听闻国内建筑行业不景气，当实际求职的时候才切实的体会到行业的衰落，这是可能这两年计算机行业难以想象的。哪怕是拥有注册建筑师头衔的硕士毕业生，在国内也只能获得8千的起薪，这成为了国内国外的一道鸿沟。这段时间，我对赚钱的意愿愈发强烈，这也是我离开前司的重要原因。</p><p>7月，芳芳离开了苏州，回到了马德里。我搬出了我们共同收拾的屋子，又恢复了7小时时差的异国恋。</p><p><img src="/images/250101-9.jpeg" alt="空落落的家"></p><h2 id="下一个起点和压力"><a href="#下一个起点和压力" class="headerlink" title="下一个起点和压力"></a>下一个起点和压力</h2><p>在无数面试之后，最终锁定了两家，阿里云和讯飞。我甚至都做完了阿里的体检，但是在写花名的时候还是犹豫了。考虑再三，还是去了讯飞。一是离家近，二是还是想做一些跟技术更近的内容。</p><p>在讯飞的工作之前已经提过很多次。在很长一段时间里，产品的表现都不尽如人意，确实给自己带来了不少压力。因此技术博客基本上停了，更多的时间都花在业务分析和报表上。</p><p>跌跌撞撞的六个月之后，还是顺利转正了。</p><p><img src="/images/250101-20.png"></p><h2 id="云南之行"><a href="#云南之行" class="headerlink" title="云南之行"></a>云南之行</h2><p>10月的时候，公司团建去了云南，这是我第一次去云南。云南的景色和食物都很对我胃口，尤其是菌菇火锅。短短几天里，我们去了大理古城，丽江，洱海，爬了玉龙雪山。我一向不爱出去旅游，不过这次出行确实让我紧绷已久的神经稍稍放松了一些。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/250101-10.jpeg" alt="丽江古城"></div><div class="group-image-wrap"><img src="/images/250101-11.jpeg" alt="菌菇火锅"></div><div class="group-image-wrap"><img src="/images/250101-12.jpeg" alt="登顶玉龙"></div></div></div><h2 id="关于技术"><a href="#关于技术" class="headerlink" title="关于技术"></a>关于技术</h2><p>今年一共写了66篇技术博客，上半年的技术主题由Python开发，到语言模型和Yolo，到Docker，再到分布式训练和搜索系统。到了下半年入职讯飞以后，主题转向了Pyspark，机器学习和推荐系统。</p><p>关于推荐系统，其实和我的工作没有那么强相关，不过其中确实有一些可借鉴的思想，例如Item维度的特征，其实是可以融入在模型中的。</p><p>明年的工作大致围绕在风控算法，Pyspark，统计机器学习方面，偶尔会穿插一些新的东西，例如最近的Modern Bert，我有点想琢磨一下。</p><h2 id="恢复打球"><a href="#恢复打球" class="headerlink" title="恢复打球"></a>恢复打球</h2><p>在回来以前，已经有很长时间没有接触篮球了。搬家之后，小区楼下就是一个球场，于是很快恢复了打球的习惯。复健的开始非常难熬，长时间没有好好运动导致我刚跑几步就眼前发黑。好在很快和小区的一帮球友混熟了，所以适应之后，逐渐恢复了每天下班打球一小时的习惯，这是今年比较重要的收获之一。</p><h2 id="游戏与观影"><a href="#游戏与观影" class="headerlink" title="游戏与观影"></a>游戏与观影</h2><p>今年通关了两款大作，最后生还者1和2的重制版。这两款游戏无论是从游戏性还是剧情深度上，都远超今年出的一众游戏大作。从故事角度出发，这两款作品都无愧于年度最佳剧本。</p><p>艾莉和乔尔之前的故事在第一部里还没有那么让我触动，反倒是在第二部里，有关乔尔的几处零星片段让我更加感动。剩下的一些游戏浅尝辄止，诸如死亡空间，战神云云，都没有动力玩下去。除此之外，国庆假期里，我还通关了一个国产RPG，大侠立志传。作为一个画风无比朴素的像素2D游戏，这个游戏的系统，主线，支线，玩法都很让人上头。</p><h2 id="关于近视和飞秒"><a href="#关于近视和飞秒" class="headerlink" title="关于近视和飞秒"></a>关于近视和飞秒</h2><p>今年做了半飞秒，这可能是我近十年来最大的一次手术，摘掉了我从小学就开始带的眼镜。这一步没有我想象的那么曲折，某一个周日的下午，突然就想到了近视眼手术，于是预约，检查，隔了两周就去做了手术。由于角膜太薄，只能做半飞秒。手术本身已经很成熟，躺在机器里，能感觉到激光切除角膜时发出的焦糊味。刚做完的那个下午，眼睛奇痛无比，过了两天不适感才逐渐缓解。</p><p><img src="/images/250101-16.jpeg"></p><h2 id="设备的更新"><a href="#设备的更新" class="headerlink" title="设备的更新"></a>设备的更新</h2><p>今年最大的几个设备更新：4K HDR显示器，哈曼卡顿音响和Macbook Pro。前两者都是心仪已久的产品，而Macbook则完全是在M4发布之后被种草的。适应Mac OS的程度超出了我的想象，我原以为会比较难用，没想到除了快捷键和滚轮需要适应，其他的操作逻辑跟ipad和iphone如出一辙，因此很快顺利上手了苹果生态。</p><p>从三星+Windows转到全苹果生态，花了大概五年时间，不得不说苹果的驯化能力实在是强。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/250101-15.jpg" alt="曾经的生态全家桶"></div><div class="group-image-wrap"><img src="/images/241221-3.jpeg" alt="更新Macbook"></div></div></div><h2 id="关于展望"><a href="#关于展望" class="headerlink" title="关于展望"></a>关于展望</h2><p>正如我前面所说，2024年是奔跑，离别和改变的一年。对于2025，没有特别细致的愿望，只希望一切能够顺利，无论是工作还是生活。</p><p>2024&#x2F;12&#x2F;31 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>What goes up must come down</title>
    <link href="/2024/12/14/What-goes-up-must-come-down/"/>
    <url>/2024/12/14/What-goes-up-must-come-down/</url>
    
    <content type="html"><![CDATA[<p>距离上次写东西又过去了两个月，想不到工作以后的更新速度愈发迟缓了，也不知道是我的生活更充实了还是没有写东西的欲望。不过昨天入手了心心念念很久的macbook pro，今天迁移了一整天数据，末了忽然想更新一下尘封许久的博客，遂有此文。</p><h2 id="依旧是产品与内耗"><a href="#依旧是产品与内耗" class="headerlink" title="依旧是产品与内耗"></a>依旧是产品与内耗</h2><p>上次写博客的时候，刚好是接手另一个大产品的时候，刚接手一个月，数据很好看，时至十月国庆，更是风头无两，当时觉得自己已经顺利上岸了，想不到写完博客没过几天，情况急转直下。先是两个产品的竞争对手双双崛起，从单量上碾压了自己，又过了几天，效果直线下滑，以前稳定的策略又失效了。情况到了十一月更加严重，哪怕是有同事跟我一起分担压力，也只是稍微稳住了阵脚，十二月的时候，又碰到了一些市场整体的波动，压力就更大了。答辩之际，实在不想看到这种局面。</p><p>BTW，附上公司发的积木人：</p><p><img src="/images/241221-6.jpeg"></p><p><img src="/images/241221-5.jpeg"></p><h2 id="团聚和离别"><a href="#团聚和离别" class="headerlink" title="团聚和离别"></a>团聚和离别</h2><p>十一月底的时候，芳芳来国内出差，我申请了异地办公来找她，也差不多时隔半年没见，我们去吃了火锅日料，逛了逛潮人云集的上海（太潮了，风湿病要犯了），吃了某个米其林推荐的麻酱拌面，感觉又回到了以前在马村的感觉。这样的日子差不多过了一周，她就要回去了。下次见面又要隔半年，实属无奈，希望下次见面的时候能稳定一点。</p><p><img src="/images/241221-1.jpeg"></p><p><img src="/images/241221-2.jpeg"></p><h2 id="新电脑到手"><a href="#新电脑到手" class="headerlink" title="新电脑到手"></a>新电脑到手</h2><p>苹果刚发布M4的时候，我就一下子被圈中，又恰逢国家补贴，一下子就顶不住了。双十一的时候一度想要下单mac mini，但是还是忍住了。这几天晚上睡不着觉，B站和抖音轮番给我轰炸各种mac视频，终于某一天晚上忍不住了，下单了macbook pro m4 pro 24+512。昨天拿到手的一刹那真是非常激动，记得以前还嘲笑过mac os的系统反人类，想不到真香定律会平等的发生在每个人身上。屏幕音响都是非常顶级，虽然我以前的雷蛇也不差，但是比起macbook，从性能上还是差了一点，配置一下午，电脑的风扇都没转，真是太香了。</p><p><img src="/images/241221-3.jpeg"></p><p><img src="/images/241221-4.jpeg"></p><p>2024&#x2F;12&#x2F;14 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统：NeuralCF的实现</title>
    <link href="/2024/10/03/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9ANeuralCF%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <url>/2024/10/03/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9ANeuralCF%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>在Github上看到一张不错的思维导图，摘录至此：</p><p><img src="/images/neuralcf.png"></p><p>这张图概述了整个推荐系统的学习框架。这次要学习的NeuralCF正属于协同过滤家族下，属于深度学习运用协同过滤的思想诞生的产物。</p><p>原论文地址：<a href="https://arxiv.org/abs/1708.05031">Neural Collaborative Filtering</a></p><p>翻译论文地址：<a href="https://www.cnblogs.com/HolyShine/p/6728999.html">【翻译】Neural Collaborative Filtering–神经协同过滤</a></p><h1 id="论文思想"><a href="#论文思想" class="headerlink" title="论文思想"></a>论文思想</h1><p>原论文发表于2017年，作者的观点是：传统矩阵分解使用隐向量的内积来计算特征交互，这种计算方式可以用神经网络来替代，因为理论上DNN能拟合所有函数，它的表达能力比单纯内积要更好。</p><blockquote><p>简单地将潜在特征的乘积线性组合的内积可能不足以捕捉用户交互数据的复杂结构。</p></blockquote><p>因此作者提出了NCF，名字是神经协同过滤，核心思想是通过一个多层MLP来学习User-Item的交互。</p><p>原文用配图展示了共现矩阵对比隐向量（Latent space）的表现能力不足。具体而言是用了一个热门用户，表现为该用户什么都喜欢，使用内积会导致他的相似用户和真实情况有偏差，这实际上是因为只考虑点击的单个维度导致的。现在为了解决这个问题，可以扩大隐向量维度来增加信息。</p><p>论文中的实现方式是将输入分成两个部分，GMF和MLP部分。</p><p><img src="/images/neuralcf1.png"></p><p>GMF可以视作传统的MF，MLP对User&#x2F;Item进行更深层的特征提取。</p><p>细看一下MLP部分，输入是用户和商品的One Hot编码，经过嵌入后直接Concat后输入网络，得到用户购买商品的概率。<br><img src="/images/neuralcf2.png"></p><p>GMF部分的输入也是用户和商品的One Hot编码，经过嵌入后得到User&#x2F;Item向量$p_{u},q_{i}$。GMF模型的输出则为$\hat y_{ui}&#x3D;a_{out}(h^{T}(p_{u}\odot q_{i}))$。其中$a_{out}$是激活函数，$h^{T}$是边权重。当激活函数是一个恒等函数，并且权重为1时，GMF就退化为MF模型。</p><p>两边其实都用了嵌入层，不过作者将两边分开学习独立的Embedding，并通过连接最后一个隐藏层来组合模型，实际上就是融合了两个模型。在实际融合的时候，使用了一个超参数来权衡两个模型的权重。</p><h1 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h1><p>模型的输入只有User和Item ID，显然又丢失了很多其他特征，核心还是从共现关系中挖掘更多的信息。完全利用嵌入导致可解释性远远不如特征更多的LR以及各种树模型。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>使用经典数据集MovieLens作为测试数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, Dataset<br></code></pre></td></tr></table></figure><p>读一下文件，然后需要做一些预处理。MovieLens的用户&#x2F;物品Index是从1开始计数的，我们需要调整到从0开始。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">data_root = <span class="hljs-string">r&#x27;C:\Users\ZeroLoveSeA\Desktop\Datasets\ml-1m&#x27;</span><br>ml1m_dir = data_root + <span class="hljs-string">r&#x27;\ratings.dat&#x27;</span><br>ml1m_rating = pd.read_csv(ml1m_dir, sep=<span class="hljs-string">&#x27;::&#x27;</span>, header=<span class="hljs-literal">None</span>, names=[<span class="hljs-string">&#x27;uid&#x27;</span>, <span class="hljs-string">&#x27;mid&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;timestamp&#x27;</span>], engine=<span class="hljs-string">&#x27;python&#x27;</span>)<br><br>ml1m_rating[<span class="hljs-string">&#x27;userId&#x27;</span>], _ = pd.factorize(ml1m_rating[<span class="hljs-string">&#x27;uid&#x27;</span>])<br>ml1m_rating[<span class="hljs-string">&#x27;itemId&#x27;</span>], _ = pd.factorize(ml1m_rating[<span class="hljs-string">&#x27;mid&#x27;</span>])<br><br>ml1m_rating = ml1m_rating[[<span class="hljs-string">&#x27;userId&#x27;</span>, <span class="hljs-string">&#x27;itemId&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;timestamp&#x27;</span>]]<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Range of userId is [&#123;&#125;, &#123;&#125;]&#x27;</span>.<span class="hljs-built_in">format</span>(ml1m_rating.userId.<span class="hljs-built_in">min</span>(), ml1m_rating.userId.<span class="hljs-built_in">max</span>()))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Range of itemId is [&#123;&#125;, &#123;&#125;]&#x27;</span>.<span class="hljs-built_in">format</span>(ml1m_rating.itemId.<span class="hljs-built_in">min</span>(), ml1m_rating.itemId.<span class="hljs-built_in">max</span>()))<br><br><span class="hljs-comment"># Range of userId is [0, 6039]</span><br><span class="hljs-comment"># Range of itemId is [0, 3705]</span><br></code></pre></td></tr></table></figure><p>写一下Dataset：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NCFData</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, user_tensor, item_tensor, rating_tensor</span>):<br>        self.user_tensor = user_tensor<br>        self.item_tensor = item_tensor<br>        self.target_tensor = rating_tensor<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.user_tensor)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> self.user_tensor[idx], self.item_tensor[idx], self.target_tensor[idx]<br></code></pre></td></tr></table></figure><p>然后是DataLoader，我们为每个正样本分配一定数量的负样本，并且需要对评分进行二值化。除此之外，再写一个验证数据集的属性，可以在eval的时候直接调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SampleGenerator</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SampleGenerator</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, ratings</span>):<br>        self.ratings = ratings<br>        self.preprocess_ratings = self._binarize(self.ratings)<br>        self.user_pool = <span class="hljs-built_in">set</span>(self.ratings[<span class="hljs-string">&#x27;userId&#x27;</span>].unique()) <br>        self.item_pool = <span class="hljs-built_in">set</span>(self.ratings[<span class="hljs-string">&#x27;itemId&#x27;</span>].unique())<br><br>        self.negatives = self._sample_negative(self.ratings)<br>        self.train_ratings, self.test_ratings = self._split_loo(self.preprocess_ratings)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_binarize</span>(<span class="hljs-params">self, ratings</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;将评分二值化，大于0的评分映射为1&#x27;&#x27;&#x27;</span><br>        ratings[<span class="hljs-string">&#x27;rating&#x27;</span>] = (ratings[<span class="hljs-string">&#x27;rating&#x27;</span>] &gt; <span class="hljs-number">0</span>).astype(<span class="hljs-built_in">float</span>)<br>        <span class="hljs-keyword">return</span> ratings<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_sample_negative</span>(<span class="hljs-params">self, ratings</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;负采样&#x27;&#x27;&#x27;</span><br>        interact_status = ratings.groupby(<span class="hljs-string">&#x27;userId&#x27;</span>)[<span class="hljs-string">&#x27;itemId&#x27;</span>].apply(<span class="hljs-built_in">set</span>).reset_index().rename(<br>            columns=&#123;<span class="hljs-string">&#x27;itemId&#x27;</span>: <span class="hljs-string">&#x27;interacted_items&#x27;</span>&#125;)<br>        <span class="hljs-comment"># 将用户没有交互过的物品作为负样本</span><br>        interact_status[<span class="hljs-string">&#x27;negative_items&#x27;</span>] = interact_status[<span class="hljs-string">&#x27;interacted_items&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: self.item_pool - x)<br>        <span class="hljs-comment"># 从负样本中随机采样99个</span><br>        interact_status[<span class="hljs-string">&#x27;negative_samples&#x27;</span>] = interact_status[<span class="hljs-string">&#x27;negative_items&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: random.sample(<span class="hljs-built_in">list</span>(x), <span class="hljs-number">99</span>))<br>        <span class="hljs-keyword">return</span> interact_status[[<span class="hljs-string">&#x27;userId&#x27;</span>, <span class="hljs-string">&#x27;negative_items&#x27;</span>, <span class="hljs-string">&#x27;negative_samples&#x27;</span>]]        <br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_loo</span>(<span class="hljs-params">self, ratings</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Leave-One-Out evaluation&quot;&quot;&quot;</span><br>        ratings[<span class="hljs-string">&#x27;rank_latest&#x27;</span>] = ratings.groupby([<span class="hljs-string">&#x27;userId&#x27;</span>])[<span class="hljs-string">&#x27;timestamp&#x27;</span>].rank(method=<span class="hljs-string">&#x27;first&#x27;</span>, ascending=<span class="hljs-literal">False</span>)<br>        test = ratings[ratings[<span class="hljs-string">&#x27;rank_latest&#x27;</span>] == <span class="hljs-number">1</span>]<br>        train = ratings[ratings[<span class="hljs-string">&#x27;rank_latest&#x27;</span>] &gt; <span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">assert</span> train[<span class="hljs-string">&#x27;userId&#x27;</span>].nunique() == test[<span class="hljs-string">&#x27;userId&#x27;</span>].nunique(), <span class="hljs-string">&#x27;Not Match Train User with Test User&#x27;</span><br>        <span class="hljs-keyword">return</span> train[[<span class="hljs-string">&#x27;userId&#x27;</span>, <span class="hljs-string">&#x27;itemId&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>]], test[[<span class="hljs-string">&#x27;userId&#x27;</span>, <span class="hljs-string">&#x27;itemId&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>]]<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">instance_a_train_loader</span>(<span class="hljs-params">self, num_negatives, batch_size</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;构建训练数据集&#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Load train data&#x27;</span>)<br>        users, items, ratings = [], [], []<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Sample negative items&#x27;</span>)<br>        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> self.train_ratings.itertuples():<br>            users.append(<span class="hljs-built_in">int</span>(row.userId))<br>            items.append(<span class="hljs-built_in">int</span>(row.itemId))<br>            ratings.append(<span class="hljs-built_in">float</span>(row.rating))<br><br>            negatives = random.sample(self.negatives[self.negatives[<span class="hljs-string">&#x27;userId&#x27;</span>] == row.userId][<span class="hljs-string">&#x27;negative_samples&#x27;</span>].iloc[<span class="hljs-number">0</span>], num_negatives)<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_negatives):<br>                users.append(row.userId)<br>                items.append(negatives[i])<br>                ratings.append(<span class="hljs-number">0</span>) <span class="hljs-comment"># 负样本的评分为0</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Construct DataLoader&#x27;</span>)<br>        dataset = NCFData(user_tensor=torch.tensor(users), item_tensor=torch.tensor(items), rating_tensor=torch.tensor(ratings))<br>        <span class="hljs-keyword">return</span> DataLoader(dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    <br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_data</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;构建测试数据集&#x27;&#x27;&#x27;</span><br>        test_ratings = self.test_ratings.merge(self.negatives[[<span class="hljs-string">&#x27;userId&#x27;</span>, <span class="hljs-string">&#x27;negative_samples&#x27;</span>]], on=<span class="hljs-string">&#x27;userId&#x27;</span>)<br>        test_users, test_items, negative_users, negative_items = [], [], [], []<br>        <br>        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> test_ratings.itertuples():<br>            test_users.append(row.userId)<br>            test_items.append(row.itemId)<br>            negative_users.extend([row.userId] * <span class="hljs-built_in">len</span>(row.negative_samples))<br>            negative_items.extend(row.negative_samples)<br>        <br>        <span class="hljs-keyword">return</span> [torch.tensor(test_users), torch.tensor(test_items),<br>                torch.tensor(negative_users), torch.tensor(negative_items)]<br></code></pre></td></tr></table></figure><p>实例化一下Dataloader和验证数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">sample_generator = SampleGenerator(ml1m_rating)<br>evaluate_data = sample_generator.evaluate_data<br></code></pre></td></tr></table></figure><p>接下来写模型，包括forward，train和evaluate。模型架构本身没什么说的，基本上就是Embedding进两个网络，最后Concat后进Sigmoid得到一个Logit。</p><p>训练包括了训练单个batch和一个epoch的部分。验证时计算命中率和NDCG。命中率的计算方式是，只要预测的正样本在排名Top k中，则分子+1，分母为所有预测数。NDCG是DCG的归一化，每个样本单独计算其贡献度，即分子为当前样本是否为正样本，是则为1。分母是对样本的index+1取log，也就是当前样本越靠后，分母越大，样本的整体得分越小，相当于一个加权计算。最后将每个样本的贡献度求和，就是DCG。</p><p>要求得NDCG，需要对DCG除以一个标准化的系数，IDCG，IDCG和DCG基本一致，只不过分子是理想下的DCG值，即样本真实的DCG值。最终，如果预测和理想完全一致，NDCG的值为1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">NeuMF</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_users, num_items, latent_dim_mf, latent_dim_mlp, config_layers, learning_rate</span>):<br>        <span class="hljs-built_in">super</span>(NeuMF, self).__init__()<br>        self.num_users = num_users<br>        self.num_items = num_items<br>        self.latent_dim_mf = latent_dim_mf<br>        self.latent_dim_mlp = latent_dim_mlp<br>        self.config_layers = config_layers<br>        self.learning_rate = learning_rate<br>        self._writer = SummaryWriter(log_dir=<span class="hljs-string">&#x27;logs&#x27;</span>)<br><br>        <span class="hljs-comment"># 嵌入层</span><br>        self.embedding_user_mlp = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim_mlp)<br>        self.embedding_item_mlp = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim_mlp)<br>        self.embedding_user_mf = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim_mf)<br>        self.embedding_item_mf = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim_mf)<br><br>        <span class="hljs-comment"># MLP layers: 输入层是用户和物品的嵌入向量，输出层是一个数值</span><br>        self.fc_layers = nn.ModuleList()<br>        input_size = self.latent_dim_mlp * <span class="hljs-number">2</span>  <span class="hljs-comment"># 合并用户和物品的嵌入向量</span><br>        <span class="hljs-keyword">for</span> output_size <span class="hljs-keyword">in</span> self.config_layers:<br>            self.fc_layers.append(nn.Linear(input_size, output_size))<br>            input_size = output_size<br><br>        <span class="hljs-comment"># Output layer: 输出层的输入是MLP的输出和MF的输出</span><br>        self.output_layer = nn.Linear(self.config_layers[-<span class="hljs-number">1</span>] + self.latent_dim_mf, <span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 损失函数和优化器</span><br>        self.loss = nn.BCELoss()<br>        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)<br>        <br>        <span class="hljs-comment"># 评估指标</span><br>        self._metrics = Metrics(top_k=<span class="hljs-number">10</span>)<br>        <br>        <span class="hljs-comment"># 初始化权重</span><br>        self._init_weight_()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_weight_</span>(<span class="hljs-params">self</span>):<br>        nn.init.normal_(self.embedding_user_mlp.weight, std=<span class="hljs-number">0.01</span>)<br>        nn.init.normal_(self.embedding_item_mlp.weight, std=<span class="hljs-number">0.01</span>)<br>        nn.init.normal_(self.embedding_user_mf.weight, std=<span class="hljs-number">0.01</span>)<br>        nn.init.normal_(self.embedding_item_mf.weight, std=<span class="hljs-number">0.01</span>)<br><br>        <span class="hljs-keyword">for</span> fc <span class="hljs-keyword">in</span> self.fc_layers:<br>            nn.init.xavier_uniform_(fc.weight)<br>            nn.init.zeros_(fc.bias)<br><br>        nn.init.kaiming_uniform_(self.output_layer.weight, nonlinearity=<span class="hljs-string">&#x27;sigmoid&#x27;</span>)<br>        nn.init.zeros_(self.output_layer.bias)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, user, item</span>):<br>        <span class="hljs-comment"># MLP part</span><br>        user_mlp = self.embedding_user_mlp(user)<br>        item_mlp = self.embedding_item_mlp(item)<br>        mlp_vector = torch.cat([user_mlp, item_mlp], dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">for</span> fc <span class="hljs-keyword">in</span> self.fc_layers:<br>            mlp_vector = torch.relu(fc(mlp_vector))<br><br>        <span class="hljs-comment"># MF part</span><br>        user_mf = self.embedding_user_mf(user)<br>        item_mf = self.embedding_item_mf(item)<br>        mf_vector = torch.mul(user_mf, item_mf)<br><br>        <span class="hljs-comment"># 合并MLP和MF的输出</span><br>        output_vector = torch.cat([mlp_vector, mf_vector], dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 最终输出</span><br>        rating_logit = torch.sigmoid(self.output_layer(output_vector))<br>        <span class="hljs-keyword">return</span> rating_logit<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_single_batch</span>(<span class="hljs-params">self, users, items, ratings</span>):<br>        <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>            users, items, ratings = users.cuda(), items.cuda(), ratings.cuda()<br><br>        self.train()<br>        self.optimizer.zero_grad()<br>        ratings_pred = self.forward(users, items)<br>        loss = self.loss(ratings_pred.view(-<span class="hljs-number">1</span>), ratings)<br>        loss.backward()<br>        self.optimizer.step()<br>        <span class="hljs-keyword">return</span> loss.item()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_single_epoch</span>(<span class="hljs-params">self, train_loader, epoch_id</span>):<br>        self.train()<br>        total_loss = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> batch_id, (users, items, ratings) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>            loss = self.train_single_batch(users, items, ratings)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch &#123;&#125; Batch &#123;&#125; Loss &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch_id, batch_id, loss))<br>            total_loss += loss<br>        self._writer.add_scalar(<span class="hljs-string">&#x27;model/loss&#x27;</span>, total_loss, epoch_id)<br>        <span class="hljs-keyword">return</span> total_loss<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">self, evaluate_data</span>):<br>        self.<span class="hljs-built_in">eval</span>()<br>        test_users, test_items, negative_users, negative_items = evaluate_data<br>        <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>            test_users, test_items, negative_users, negative_items = test_users.cuda(), test_items.cuda(), negative_users.cuda(), negative_items.cuda()<br><br>        <span class="hljs-comment"># 计算测试样本和负样本的预测分数</span><br>        test_scores = self.forward(test_users, test_items)<br>        negative_scores = self.forward(negative_users, negative_items)<br><br>        <span class="hljs-comment"># 设置 metrics 中的 subjects</span><br>        self._metrics.set_subjects(<br>            test_users=test_users.cpu(),<br>            test_items=test_items.cpu(),<br>            test_scores=test_scores.cpu(),<br>            negative_users=negative_users.cpu(),<br>            negative_items=negative_items.cpu(),<br>            negative_scores=negative_scores.cpu()<br>        )<br><br>        <span class="hljs-comment"># 计算命中率和NDCG</span><br>        hit_ratio = self._metrics.cal_hit_ratio()<br>        ndcg = self._metrics.cal_ndcg()<br><br>        self._writer.add_scalar(<span class="hljs-string">&#x27;model/hit_ratio&#x27;</span>, hit_ratio, <span class="hljs-number">0</span>)<br>        self._writer.add_scalar(<span class="hljs-string">&#x27;model/ndcg&#x27;</span>, ndcg, <span class="hljs-number">0</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Hit Ratio is &#123;:.6f&#125;, NDCG is &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(hit_ratio, ndcg))<br>        <span class="hljs-keyword">return</span> hit_ratio, ndcg<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Metrics</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, top_k</span>):<br>        self._top_k = top_k<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_subjects</span>(<span class="hljs-params">self, test_users, test_items, test_scores, negative_users, negative_items, negative_scores</span>):<br>        self._subjects = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(test_users)):<br>            user = test_users[i].item()<br>            test_item = test_items[i].item()<br>            <span class="hljs-comment"># test_score 是一维的</span><br>            test_score = test_scores[i].view(-<span class="hljs-number">1</span>).item()  <span class="hljs-comment"># 确保 test_score 是标量</span><br>            <span class="hljs-comment"># neg_items 是负样本的物品ID</span><br>            neg_items = negative_items[i*<span class="hljs-number">99</span>:(i+<span class="hljs-number">1</span>)*<span class="hljs-number">99</span>].detach().numpy()<br>            <span class="hljs-comment"># neg_scores 是针对负样本的评分，需展平为一维</span><br>            neg_scores = negative_scores[i*<span class="hljs-number">99</span>:(i+<span class="hljs-number">1</span>)*<span class="hljs-number">99</span>].view(-<span class="hljs-number">1</span>).detach().numpy()<br><br>            <span class="hljs-comment"># 合并正样本和负样本的物品及其对应分数</span><br>            items = np.concatenate(([test_item], neg_items))<br>            scores = np.concatenate(([test_score], neg_scores))<br><br>            <span class="hljs-comment"># 按得分排序</span><br>            ranked_idx = np.argsort(-scores)<br>            ranked_items = items[ranked_idx]<br>            <br>            self._subjects.append(&#123;<br>                <span class="hljs-string">&#x27;user&#x27;</span>: user,<br>                <span class="hljs-string">&#x27;ranked_items&#x27;</span>: ranked_items,<br>                <span class="hljs-string">&#x27;test_item&#x27;</span>: test_item<br>            &#125;)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">cal_hit_ratio</span>(<span class="hljs-params">self</span>):<br>        hits = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> subject <span class="hljs-keyword">in</span> self._subjects:<br>            <span class="hljs-comment"># 如果正样本的物品在排名前top_k之内，则命中</span><br>            <span class="hljs-keyword">if</span> subject[<span class="hljs-string">&#x27;test_item&#x27;</span>] <span class="hljs-keyword">in</span> subject[<span class="hljs-string">&#x27;ranked_items&#x27;</span>][:self._top_k]:<br>                hits += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> hits / <span class="hljs-built_in">len</span>(self._subjects)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">cal_ndcg</span>(<span class="hljs-params">self</span>):<br>        total_ndcg = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> subject <span class="hljs-keyword">in</span> self._subjects:<br>            <span class="hljs-keyword">try</span>:<br>                rank = np.where(subject[<span class="hljs-string">&#x27;ranked_items&#x27;</span>] == subject[<span class="hljs-string">&#x27;test_item&#x27;</span>])[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] + <span class="hljs-number">1</span><br>                total_ndcg += math.log(<span class="hljs-number">2</span>) / math.log(<span class="hljs-number">1</span> + rank)<br>            <span class="hljs-keyword">except</span> IndexError:<br>                <span class="hljs-keyword">continue</span><br>        <span class="hljs-keyword">return</span> total_ndcg / <span class="hljs-built_in">len</span>(self._subjects)<br><br></code></pre></td></tr></table></figure><p>我们训练一个Epoch试一下，设置MF和MLP的隐向量维度都为8，BS为64：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python">num_users = ml1m_rating[<span class="hljs-string">&#x27;userId&#x27;</span>].nunique()<br>num_items = ml1m_rating[<span class="hljs-string">&#x27;itemId&#x27;</span>].nunique()<br>num_factors_mf = <span class="hljs-number">8</span><br>num_factors_mlp = <span class="hljs-number">8</span><br>layers = [<span class="hljs-number">16</span>, <span class="hljs-number">64</span>, <span class="hljs-number">32</span>, <span class="hljs-number">16</span>, <span class="hljs-number">8</span>]<br>learning_rate = <span class="hljs-number">0.001</span><br>batch_size = <span class="hljs-number">64</span><br><br>num_negatives = <span class="hljs-number">4</span><br><br>neumf = NeuMF(num_users=num_users, <br>              num_items=num_items, <br>              latent_dim_mf=num_factors_mf, <br>              latent_dim_mlp=num_factors_mlp, <br>              config_layers=layers, <br>              learning_rate=learning_rate)<br><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    neumf = neumf.cuda()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>    train_loader = sample_generator.instance_a_train_loader(num_negatives, batch_size)<br>    loss = neumf.train_single_epoch(train_loader, epoch)<br>    hit_ratio, ndcg = neumf.evaluate(evaluate_data)<br>    <br><span class="hljs-comment"># Epoch 0 Batch 24 Loss 0.6258940696716309</span><br>...<br><span class="hljs-comment"># Epoch 0 Batch 77667 Loss 0.38616734743118286</span><br><span class="hljs-comment"># Epoch 0 Batch 77668 Loss 0.2662082016468048</span><br><span class="hljs-comment"># Epoch 0 Batch 77669 Loss 0.12284557521343231</span><br><span class="hljs-comment"># Hit Ratio is 0.617384, NDCG is 0.464588</span><br></code></pre></td></tr></table></figure><p>2024&#x2F;10&#x2F;3 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>特征工程</tag>
      
      <tag>推荐系统</tag>
      
      <tag>机器学习</tag>
      
      <tag>NeuralCF</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>有些忙碌的近期</title>
    <link href="/2024/09/30/%E6%9C%89%E4%BA%9B%E5%BF%99%E7%A2%8C%E7%9A%84%E8%BF%91%E6%9C%9F/"/>
    <url>/2024/09/30/%E6%9C%89%E4%BA%9B%E5%BF%99%E7%A2%8C%E7%9A%84%E8%BF%91%E6%9C%9F/</url>
    
    <content type="html"><![CDATA[<p>最近两个月都没有更新博客，一方面确实是忙起来了，另一方面也有一些无从下笔。</p><h2 id="试用期与内耗"><a href="#试用期与内耗" class="headerlink" title="试用期与内耗"></a>试用期与内耗</h2><p>试用期刚满三个月，内心还是比较焦虑的，有点担心自己能不能顺利通过最后的答辩。入职的前两个月，手上的产品实在是表现太差，测试了上百个策略，花了无数冤枉钱，结果毛利还是在连连下降，内心焦虑无可言说。最焦虑的那几天，每天上班就是调模型，看报表，然后抓头发。</p><p>还好在第三个月接手了第二个大产品，才勉强稳住了业绩。数据好看了以后，最重要的是，没有那么内耗了，也有精力去思考一些新的建模思路了。</p><h2 id="推荐系统的怪圈"><a href="#推荐系统的怪圈" class="headerlink" title="推荐系统的怪圈"></a>推荐系统的怪圈</h2><p>我发现一个奇怪的现象，之前关注的很多推荐系统相关博主，除开最顶尖的大厂算法，往往都没有很follow更新最新的模型，一般分享了一段时间的经典架构，就停止了内容更新。</p><blockquote><p>相比高质量数据，模型远远没有那么重要。</p></blockquote><p>我猜测百分之80以上的公司都没有那么细致的特征，能让高参数模型真正发挥自己的作用。这可能是做学术和做业务的差距，实际场景里实在很少有那么高质量的数据，至少在召回领域，有限的特征下树模型架构足矣应对大部分场景。</p><p>与想象中不同的另一点是，工作中写代码越来越少了，反而是SQL越写越多。系统架构早已搭好，剩下的就是如何正确高效的调用算法。为了保证自己还能有一定的代码能力，过去两个月一直在写小项目。</p><h2 id="最近接触的东西"><a href="#最近接触的东西" class="headerlink" title="最近接触的东西"></a>最近接触的东西</h2><p>Github没有以前刷的那么频繁了，不过还是找到一些比较有趣的东西。</p><p>一个是Mac OS的Docker镜像，项目名是Docker-OSX。基于KVM，也就是基于内核层面的虚拟机实现，性能损耗有点大，但是足够让我在wsl里尝尝鲜。</p><p><img src="/images/macosx.png"></p><p><img src="/images/macosx2.png"></p><p>另一个是deep live cam，用CPU就能跑的换脸项目。效果一般般，但是胜在运行要求低。</p><p>之前挂了Bing的SEO，想不到写的Deepspeed的帖子被推到了搜索第一名，阅读量还挺高，哈哈哈哈哈。</p><p>2024&#x2F;9&#x2F;30 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统：Deep Crossing设计理念及实现</title>
    <link href="/2024/08/17/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9ADeep-Crossing%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5%E5%8F%8A%E5%AE%9E%E7%8E%B0/"/>
    <url>/2024/08/17/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9ADeep-Crossing%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5%E5%8F%8A%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>在推荐系统中，特征交叉和特征筛选是一个永恒不灭的话题。从逻辑回归时代的人工特征交互，到poly2的完全特征交互，到FM的隐向量特征交互，再到GDBT+LR的自动特征交互，都是在深度学习方法开始之前的特征工程的发展历史。</p><p>在14年Resnet解决了层数过深导致的梯度消失问题后，深度神经网络被广泛运用到工业界。2016年微软发布了Deep Crossing模型，用于CTR等二分类任务，原论文链接如下：<a href="https://www.kdd.org/kdd2016/papers/files/adf0975-shanA.pdf">Deep Crossing: Web-Scale Modeling without<br>Manually Crafted Combinatorial Features<br></a></p><h1>论文解读</h1><p>看名字就知道它要解决的是人工组合特征的问题。通过构建网络来实现特征的深度交叉。在Deep Crossing中，支持文本，分类，ID，数值这样的特征。</p><p>Deep Crossing的网络架构如下：</p><p><img src="/images/deepcrossing.png" alt=""></p><p>核心是四个部分：Embedding层用于嵌入特征，Stacking层用于将嵌入层简单的concat在一起，随后通过多个Residual模块提取特征。最后利用一个Scoring层来进行打分，也就是最后得到的logit值。通过对logit值进行排序，实现投放广告的排序。</p><p>原文中，微软使用的特征如下所示：</p><p><img src="/images/deepcrossing2.png" alt=""></p><p>对于一些关键的概念也进行了解释：</p><table><thead><tr><th>特征</th><th>含义</th></tr></thead><tbody><tr><td>搜索词</td><td>用户在搜索框中输入的搜索词</td></tr><tr><td>广告关键词</td><td>广告主为广告添加的描述其产品的关键词</td></tr><tr><td>广告标题</td><td>广告标题</td></tr><tr><td>落地页</td><td>点击广告后的落地页面</td></tr><tr><td>匹配类型 Match Type</td><td>广告主选择的广告-搜索词匹配类型（精准，模糊，语义等）</td></tr><tr><td>点击率</td><td>广告历史点击率</td></tr><tr><td>预估点击率</td><td>另一个CTR模型的CTR预估值</td></tr><tr><td>广告计划 Campaign</td><td>广告主创建的广告投放计划，包括预算，定向条件等</td></tr><tr><td>曝光样例</td><td>一个广告曝光的例子，记录了广告在实际曝光场景的相关信息</td></tr><tr><td>点击样例</td><td>一个广告点击的例子，记录了广告在实际点击场景的相关信息</td></tr></tbody></table><p>每个单独的特征都被转为向量，例如对于Query等文本特征，将转为49292维的向量。例如匹配类型的低基数分类输入进行one hot处理。对于一些高基数的特征，例如Campaign ID特征，它表示的是不同的广告计划，通常会有数百万个ID，原作者的思路是根据CampaignID的历史点击率，选择Top10000个，编号从0到9999，将剩余的ID统一编号为10001。同时构建其衍生特征，将所有ID对应的历史点击率组合成10001维的稠密矩阵，各个元素分别为对应ID的历史CTR，最后一个元素为剩余ID的平均CTR。通过降维引入衍生特征的方式，可以有效的减少高基数特征带来的参数量剧增问题。</p><p>这也是原图中展示的Campaign ID 10001维度的由来。</p><p>文章对特征嵌入没有讲的很明确，翻阅了很多网上的解释，我对这一部分依旧不是很理解。原文针对自己的场景有一些tricks，整体的思想就是将高维稀疏矩阵嵌入为低维稠密矩阵。</p><p>嵌入层之后经过Stacking层的拼接，直接传到残差层。</p><p><img src="/images/deepcrossing3.png" alt=""></p><p>针对ResNet中的残差模块，将原本的卷积核替换为了普通的MLP层。经过多层残差后，输出一个score，用于评估用户是否会点击对应的广告。</p><h1>代码实现</h1><p>用pytorch实现一下代码，假设特征工程和预处理已经结束，我们需要实现数据集类，模型，训练/预测代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, X, y=<span class="hljs-literal">None</span></span>):<br>        self.X = X  <span class="hljs-comment"># Dataframe</span><br>        self.y = y<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.X)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        X_item = torch.tensor(self.X.iloc[index].values, dtype=torch.float32)<br>        <span class="hljs-keyword">if</span> self.y <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            y_item = torch.tensor(self.y.iloc[index], dtype=torch.float32)<br>            <span class="hljs-keyword">return</span> X_item, y_item<br>        <span class="hljs-keyword">return</span> X_item<br>        <br>        <br>train_dataset = CustomDataset(X_train, y_train)<br>test_dataset = CustomDataset(X_test, y_test)<br><br>train_loader = DataLoader(train_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>)<br>test_loader = DataLoader(test_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>定义模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DeepCrossing</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dims, embedding_dim, residual_dims, output_dim=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>(DeepCrossing, self).__init__()<br>        <br>        <span class="hljs-comment"># 对每维特征进行嵌入</span><br>        self.embeddings = nn.ModuleList([<br>            nn.Linear(input_dim, embedding_dim) <span class="hljs-keyword">if</span> input_dim &gt; embedding_dim <span class="hljs-keyword">else</span> nn.Identity()<br>            <span class="hljs-keyword">for</span> input_dim <span class="hljs-keyword">in</span> input_dims<br>        ])<br>        <br>        <span class="hljs-comment"># Stacking layer</span><br>        self.stack_dim = <span class="hljs-built_in">sum</span>(embedding_dim <span class="hljs-keyword">if</span> input_dim &gt; embedding_dim <span class="hljs-keyword">else</span> input_dim <span class="hljs-keyword">for</span> input_dim <span class="hljs-keyword">in</span> input_dims)<br>        <br>        <span class="hljs-comment"># 残差块</span><br>        self.residual_units = nn.Sequential(<br>            *[ResidualUnit(self.stack_dim, dim) <span class="hljs-keyword">for</span> dim <span class="hljs-keyword">in</span> residual_dims]<br>        )<br>        <br>        <span class="hljs-comment"># 评分层</span><br>        self.scoring_layer = nn.Linear(self.stack_dim, output_dim)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs</span>):<br>        embedded = [embedding(<span class="hljs-built_in">input</span>) <span class="hljs-keyword">for</span> embedding, <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.embeddings, inputs)]<br>        <span class="hljs-comment"># 直接concat特征</span><br>        stacked = torch.cat(embedded, dim=<span class="hljs-number">1</span>)<br>        <br>        out = self.residual_units(stacked)<br>        out = torch.sigmoid(self.scoring_layer(out))<br>        <span class="hljs-keyword">return</span> out<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResidualUnit</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, hidden_dim</span>):<br>        <span class="hljs-built_in">super</span>(ResidualUnit, self).__init__()<br>        self.fc1 = nn.Linear(input_dim, hidden_dim)<br>        self.fc2 = nn.Linear(hidden_dim, input_dim)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        residual = x<br>        out = F.relu(self.fc1(x))<br>        out = self.fc2(out)<br>        out += residual<br>        <span class="hljs-keyword">return</span> F.relu(out)<br></code></pre></td></tr></table></figure><p>下面就是训练部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 假设输入维度是10</span><br>input_dims = <span class="hljs-number">10</span><br><br>embedding_dim = <span class="hljs-number">8</span><br>residual_dims = [<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">64</span>, <span class="hljs-number">32</span>]<br><br>model = DeepCrossing(input_dims, embedding_dim, residual_dims)<br><br><span class="hljs-comment"># 4. 训练模型</span><br>criterion = nn.BCELoss()<br>optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model, train_loader, criterion, optimizer, num_epochs=<span class="hljs-number">10</span></span>):<br>    model.train()<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        running_loss = <span class="hljs-number">0.0</span><br>        <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> train_loader:<br>            inputs = [inputs[:, i].unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(inputs.shape[<span class="hljs-number">1</span>])]<br>            <br>            optimizer.zero_grad()<br>            outputs = model(inputs).squeeze()<br>            loss = criterion(outputs, labels)<br>            loss.backward()<br>            optimizer.step()<br>            running_loss += loss.item() * inputs[<span class="hljs-number">0</span>].size(<span class="hljs-number">0</span>)<br>        <br>        epoch_loss = running_loss / <span class="hljs-built_in">len</span>(train_loader.dataset)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_epochs&#125;</span>, Loss: <span class="hljs-subst">&#123;epoch_loss:<span class="hljs-number">.4</span>f&#125;</span>&#x27;</span>)<br><br>train(model, train_loader, criterion, optimizer)<br></code></pre></td></tr></table></figure><p>模型评估：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model, test_loader</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    predictions = []<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> test_loader:<br>            inputs = [inputs[:, i].unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(inputs.shape[<span class="hljs-number">1</span>])]<br>            outputs = model(inputs).squeeze()<br>            predictions.extend(outputs.tolist())<br>    <span class="hljs-keyword">return</span> predictions<br><br>predictions = evaluate(model, test_loader)<br>predictions = np.array(predictions) &gt; <span class="hljs-number">0.5</span>  <span class="hljs-comment"># 将输出转换为二分类预测</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Predictions: &quot;</span>, predictions)<br></code></pre></td></tr></table></figure><p>2024/8/18 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>特征工程</tag>
      
      <tag>推荐系统</tag>
      
      <tag>机器学习</tag>
      
      <tag>Deep Crossing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统：从FM到FFM</title>
    <link href="/2024/08/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%BB%8EFM%E5%88%B0FFM/"/>
    <url>/2024/08/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%BB%8EFM%E5%88%B0FFM/</url>
    
    <content type="html"><![CDATA[<h1 id="从MF到FM"><a href="#从MF到FM" class="headerlink" title="从MF到FM"></a>从MF到FM</h1><p>前面讲过了MF模型，它基于用户ID和物品ID的共现矩阵进行矩阵分解，用隐向量来表示物品和用户，并通过内积的形式计算得到预估评分。它比协同过滤的优势在于泛化能力，使用嵌入能够表达一些训练集不存在的特例，但是损失了一定的记忆能力。</p><p>MF是协同过滤的一大改进，然而它无法将一些物品及用户的信息作为特征。为了解决这个问题，逻辑回归以其可解释性和易于工业计算的优点，在工业推荐算法中非常流行。</p><p>逻辑回归的优点在于特征可解释性非常强，能够通过权重直观的反应特征重要性，然而实际应用中需要进行人工特征组合，这一过程非常耗时耗力。这里的特征组合通常是特征交叉，也就是特征两两之间进行计算。</p><p>由于推荐系统天生拥有的稀疏性问题，本就稀疏的特征在进行交叉之后，维度大幅提高的同时，稀疏性也大大提高，由于很难出现两个特征同时出现的情况，要求极大的数据量才能让模型收敛。</p><p>这个问题似乎有些似曾相识，在FM模型中，我们也提到它解决了共现矩阵的稀疏问题。现在，为了解决特征的稀疏问题，我们同样能够将他们变为低维稠密向量，这时它们之间两两交互就不会有太多0出现了。</p><h1 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h1><h2 id="FM的公式"><a href="#FM的公式" class="headerlink" title="FM的公式"></a>FM的公式</h2><p>FM的公式是对逻辑回归的改进，在原本一次项的基础上增加了二次项，即特征之间的两两内积。类别特征被OneHot之后，转换为了$k$维向量。</p><p>FM 模型的基本形式是：</p><p>$\hat{y}(x) &#x3D; w_0 + \sum_{i&#x3D;1}^{n} w_i x_i + \sum_{i&#x3D;1}^{n} \sum_{j&#x3D;i+1}^{n} \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j$</p><p>其中：</p><ul><li>$\hat{y}(x)$ 表示对目标变量的预测值。</li><li>$w_0$是全局偏置（全局截距）。</li><li>$w_i$是特征 $x_i$的权重。</li><li>$x_i$ 和 $x_j$是输入特征。</li><li>$\mathbf{v}_i$和 $\mathbf{v}_j$是对应于特征$x_i$和 $x_j$ 的嵌入隐向量。</li><li>$\langle \mathbf{v}_i, \mathbf{v}_j \rangle $表示$\mathbf{v}$ 和$\mathbf{v}_j$的内积，计算特征$x_i$和 $x_j$之间的交互作用。</li></ul><p>原公式的计算复杂度是$n^2 k$，内积部分进一步展开后可以进一步降低到$nk$，FM 模型的预测公式可以写成：</p><p>$\hat{y}(x) &#x3D; w_0 + \sum_{i&#x3D;1}^{n} w_i x_i + \sum_{i&#x3D;1}^{n} \sum_{j&#x3D;i+1}^{n} \left( \sum_{f&#x3D;1}^{k} v_{i,f} \cdot v_{j,f} \right) x_i x_j$</p><p>FM 可以高效地捕捉特征之间的二阶交互作用，并通过隐向量 $\mathbf{v}_i$和$\mathbf{v}_j$对这些交互进行建模。</p><p>由于计算复杂度和空间复杂度的权衡，FM通常使用二阶特征交叉。</p><h2 id="FM和MF的关系"><a href="#FM和MF的关系" class="headerlink" title="FM和MF的关系"></a>FM和MF的关系</h2><p>从本质上来看，MF是FM的一个特例。MF可以被认作是只有用户ID和物品ID的FM模型。</p><p>从公式来看，MF的公式：</p><p>$r&#x3D; \mathbf{p}_u \cdot \mathbf{q}_i^T$</p><p>​        $ &#x3D; \sum_{f&#x3D;1}^{k} p_{u,f} \cdot q_{i,f}$</p><p>和FM的公式：</p><p>$\hat{y}(x) &#x3D; w_0 + \sum_{i&#x3D;1}^{n} w_i x_i + \sum_{i&#x3D;1}^{n} \sum_{j&#x3D;i+1}^{n} \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j$</p><p>在 MF 模型中，只有两个特征：用户和物品。在 FM 模型中，如果忽略一阶项，只选择用户特征$u$和物品特征$i$进行二阶交互项，仅考虑用户和物品的交互项，即 $\langle \mathbf{v}_u, \mathbf{v}_i \rangle$，其中$x_u$和$x_i$是用户和物品的特征值，由于我们只关注用户和物品的交互，因此将它们设置为1。</p><p>此时，FM 公式中的二阶交互项可以简化为：$\hat{y}(x) &#x3D; \langle \mathbf{v}_u, \mathbf{v}_i \rangle x_u x_j$。</p><p>在MF中，我们同样只关注用户和物品的交互项，因此将 $x_u$和$x_i$都设置为1。此时公式变为：$\hat{y}(x) &#x3D; \langle \mathbf{v}_u, \mathbf{v}_i \rangle$。</p><p>这实际上与 MF 中的 $\mathbf{p}_u \cdot \mathbf{q}_i^T$的内积是等价的。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>使用numpy实现FM模型，首先需要初始化几个关键参数：特征数和隐向量维度以生成隐向量矩阵，全局偏置和一次项权重。偏置和权重可以随机初始化。</p><p>在预测时，只需要将全局截距与一次项和二次项求和即可。一次项部分是输入特征向量和一次项权重的点积。二次项在经过展开后，变换为以下形式：</p><p>$\frac{1}{2} \sum_{f&#x3D;1}^{k} \left( \left( \sum_{i&#x3D;1}^{n} v_{i,f} x_i \right)^2 - \sum_{i&#x3D;1}^{n} v_{i,f}^2 x_i^2 \right)$</p><p>在训练过程中根据均方误差，手动计算梯度并进行更新。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FM</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_features, k=<span class="hljs-number">5</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化FM模型</span><br><span class="hljs-string">        :param n_features: 特征数量</span><br><span class="hljs-string">        :param k: 隐向量的维度</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.n_features = n_features<br>        self.k = k<br>        self.w0 = <span class="hljs-number">0</span>  <span class="hljs-comment"># 全局偏置</span><br>        self.w = np.zeros(n_features)  <span class="hljs-comment"># 一次项权重</span><br>        self.V = np.random.normal(scale=<span class="hljs-number">0.1</span>, size=(n_features, k))  <span class="hljs-comment"># 隐向量矩阵</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        预测函数</span><br><span class="hljs-string">        :param X: 输入样本矩阵，形状为 (m_samples, n_features)</span><br><span class="hljs-string">        :return: 预测值</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        linear_terms = np.dot(X, self.w)  <span class="hljs-comment"># 线性部分</span><br>        interactions = np.<span class="hljs-built_in">sum</span>(np.dot(X, self.V)**<span class="hljs-number">2</span> - np.dot(X**<span class="hljs-number">2</span>, self.V**<span class="hljs-number">2</span>), axis=<span class="hljs-number">1</span>) / <span class="hljs-number">2</span><br>        <span class="hljs-keyword">return</span> self.w0 + linear_terms + interactions<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, X, y, epochs=<span class="hljs-number">10</span>, lr=<span class="hljs-number">0.01</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        训练FM模型</span><br><span class="hljs-string">        :param X: 输入样本矩阵，形状为 (m_samples, n_features)</span><br><span class="hljs-string">        :param y: 标签</span><br><span class="hljs-string">        :param epochs: 训练轮数</span><br><span class="hljs-string">        :param lr: 学习率</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        m_samples = X.shape[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m_samples):<br>                xi = X[i]<br>                yi = y[i]<br>                y_pred = self.predict(xi.reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>))<br>                error = yi - y_pred<br><br>                <span class="hljs-comment"># 更新参数</span><br>                self.w0 += lr * error<br>                self.w += lr * error * xi<br>                <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.k):<br>                    self.V[:, f] += lr * error * (<br>                        xi * np.dot(xi, self.V[:, f]) - self.V[:, f] * xi**<span class="hljs-number">2</span><br>                    )<br><br>            <span class="hljs-comment"># 输出当前轮次的误差</span><br>            y_preds = self.predict(X)<br>            mse = np.mean((y - y_preds)**<span class="hljs-number">2</span>)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>, MSE: <span class="hljs-subst">&#123;mse&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment"># 预测集，行为用户，列为OneHot特征</span><br>    X = np.array([<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<br>    ])<br><br>    y = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])  <span class="hljs-comment"># 目标值</span><br><br>    <span class="hljs-comment"># 初始化并训练FM模型</span><br>    fm = FM(n_features=X.shape[<span class="hljs-number">1</span>], k=<span class="hljs-number">2</span>)<br>    fm.fit(X, y, epochs=<span class="hljs-number">20</span>, lr=<span class="hljs-number">0.01</span>)<br><br>    <span class="hljs-comment"># 预测</span><br>    predictions = fm.predict(X)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Predictions:&quot;</span>, predictions)<br></code></pre></td></tr></table></figure><p>也可以用pytorch实现更方便一点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FactorizationMachine</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_features, k</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化FM模型</span><br><span class="hljs-string">        :param n_features: 特征数量</span><br><span class="hljs-string">        :param k: 隐向量的维度</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(FactorizationMachine, self).__init__()<br>        self.n_features = n_features<br>        self.k = k<br><br>        <span class="hljs-comment"># 初始化参数</span><br>        self.w0 = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>))  <span class="hljs-comment"># 全局偏置</span><br>        self.w = nn.Parameter(torch.zeros(n_features))  <span class="hljs-comment"># 线性项权重</span><br>        self.V = nn.Parameter(torch.randn(n_features, k) * <span class="hljs-number">0.01</span>)  <span class="hljs-comment"># 隐向量矩阵</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        前向传播</span><br><span class="hljs-string">        :param X: 输入样本矩阵，形状为 (m_samples, n_features)</span><br><span class="hljs-string">        :return: 预测值</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        linear_terms = torch.matmul(X, self.w)  <span class="hljs-comment"># 线性部分</span><br>        interactions = <span class="hljs-number">0.5</span> * torch.<span class="hljs-built_in">sum</span>(<br>            torch.<span class="hljs-built_in">pow</span>(torch.matmul(X, self.V), <span class="hljs-number">2</span>) -<br>            torch.matmul(torch.<span class="hljs-built_in">pow</span>(X, <span class="hljs-number">2</span>), torch.<span class="hljs-built_in">pow</span>(self.V, <span class="hljs-number">2</span>)),<br>            dim=<span class="hljs-number">1</span><br>        )<br>        <span class="hljs-keyword">return</span> self.w0 + linear_terms + interactions<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>(<span class="hljs-params">model, X, y, epochs=<span class="hljs-number">10</span>, lr=<span class="hljs-number">0.01</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    训练FM模型</span><br><span class="hljs-string">    :param model: FM模型</span><br><span class="hljs-string">    :param X: 输入样本矩阵，形状为 (m_samples, n_features)</span><br><span class="hljs-string">    :param y: 标签</span><br><span class="hljs-string">    :param epochs: 训练轮数</span><br><span class="hljs-string">    :param lr: 学习率</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    criterion = nn.MSELoss()<br>    optimizer = optim.SGD(model.parameters(), lr=lr)<br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        model.train()<br>        optimizer.zero_grad()<br><br>        y_pred = model(X)<br>        loss = criterion(y_pred, y)<br>        loss.backward()<br>        optimizer.step()<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;epochs&#125;</span>, Loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    X = torch.tensor([<br>        [<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>],<br>        [<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>],<br>        [<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>],<br>        [<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>]<br>    ])<br><br>    y = torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>]) <br><br>    <span class="hljs-comment"># 初始化并训练FM模型</span><br>    fm = FactorizationMachine(n_features=X.shape[<span class="hljs-number">1</span>], k=<span class="hljs-number">2</span>)<br>    train_model(fm, X, y, epochs=<span class="hljs-number">20</span>, lr=<span class="hljs-number">0.01</span>)<br><br>    <span class="hljs-comment"># 预测</span><br>    fm.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        predictions = fm(X)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Predictions:&quot;</span>, predictions.numpy())<br><br></code></pre></td></tr></table></figure><h1 id="FFM"><a href="#FFM" class="headerlink" title="FFM"></a>FFM</h1><p>在原版FM的基础上，后续又研究出了FFM（Field-aware Factorization Machines），意味感知域的因子分解机。它引入了域的概念。所谓域的概念就是为每个特征分配了一个特征域，用于指示特征所从属的类别。</p><p>例如假如我们有以下特征：</p><table><thead><tr><th>User</th><th>Movie</th><th>Genre</th><th>Price</th></tr></thead><tbody><tr><td>YangZhou</td><td>Alien</td><td>Horror, Sci-fi</td><td>$9.9</td></tr></tbody></table><p>其中User，Movie，Genre就是特征域。当我们将特征进行OneHot编码后，每个特征就会被分配一个特征域：</p><table><thead><tr><th>Field Name</th><th>Field Index</th><th>Feature Name</th><th>Feature Index</th></tr></thead><tbody><tr><td>User</td><td>1</td><td>User&#x3D;YangZhou</td><td>1</td></tr><tr><td>Movie</td><td>2</td><td>Moive&#x3D;Alien</td><td>2</td></tr><tr><td>Genre</td><td>3</td><td>Genre&#x3D;Horror</td><td>3</td></tr><tr><td>Price</td><td>4</td><td>Genre&#x3D;Sci-fi</td><td>4</td></tr><tr><td></td><td></td><td>Price</td><td>5</td></tr></tbody></table><p>FFM的思想可以用一个例子来解释：假设我们有两个二阶交叉特征，<code>男性#45岁</code>，<code>男性#初中学历</code>。可以看到这两个交叉特征中都出现了<code>男性</code>这个特征，在FM中，这个特征被一个嵌入隐向量所表示，那么在计算内积的时候，<code>男性#45岁</code>，<code>男性#初中学历</code>中使用的都是同一个代表<code>男性</code>的向量。</p><p>现在在FFM中，认为<code>男性#45岁</code>，<code>男性#初中学历</code>这两个交叉特征中，<code>男性</code>的含义可能是不一样的，因为在考虑年龄和考虑学历的时候，<code>男性</code>特征可能会有不同的意义。因此，FFM中提出需要为每个特征交互时，考虑特征所处的特征域。</p><p>拿我们上面的例子为例，当Movie&#x3D;Alien和Genre&#x3D;Horror进行交互时，将采用Movie&#x3D;Alien对应Genere域的隐向量，而当Movie&#x3D;Alien和User&#x3D;YangZhou进行交互时，将采用Movie&#x3D;Alien对应User域的隐向量。换言之，经过OneHot编码的特征将会为每个特征域单独分配一个向量，这样在两两交互的时候就能够使用更加精确且具有针对性的向量。</p><p>2024&#x2F;8&#x2F;12 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>推荐系统</tag>
      
      <tag>机器学习</tag>
      
      <tag>FM</tag>
      
      <tag>FFM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统：逻辑回归-工业特征融合的中流砥柱</title>
    <link href="/2024/08/04/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-%E5%B7%A5%E4%B8%9A%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E4%B8%AD%E6%B5%81%E7%A0%A5%E6%9F%B1/"/>
    <url>/2024/08/04/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-%E5%B7%A5%E4%B8%9A%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E4%B8%AD%E6%B5%81%E7%A0%A5%E6%9F%B1/</url>
    
    <content type="html"><![CDATA[<p>逻辑回归可以算得上是机器学习入门前几课必接触的内容了，作为线性回归的映射，它具有可解释性非常强的优点，并且在推荐算法工业界非常流行。</p><p>在推荐算法中，逻辑回归将推荐任务转换为一个二分类任务，即判断用户是否会点击。这也和CTR任务不谋而合。</p><p>逻辑回归的公式人尽皆知：</p><p>$P(y&#x3D;1 \mid \mathbf{x}) &#x3D; \frac{1}{1 + e^{-\mathbf{w}^T \mathbf{x} - b}}$</p><p>其中$w$是权重向量，$\mathbf{x}$ 是特征向量，$b$ 是偏置项。损失函数是交叉熵损失。</p><p>逻辑回归基于输入特征的线性组合，将线性组合的输出映射到[0,1]区间的一个实数，这里的映射就是一个sigmoid函数。由于它的值域落在0-1区间，符合概率的意义，因此很早就被用在广告算法的CTR模型中。</p><p>Sigmoid函数之所以流行，不光是它的值域在0-1区间，而且它的导数非常好计算，是$f(x)(1-f(x))$。</p><h1 id="为什么用逻辑回归"><a href="#为什么用逻辑回归" class="headerlink" title="为什么用逻辑回归"></a>为什么用逻辑回归</h1><p>相比更具有数学之美的SVM和各种树模型，逻辑回归在推荐系统发展史上的地位举足轻重。</p><p>用它的理由主要有三点：</p><ul><li>数学支持：逻辑回归基于广义线性模型，假设因变量服从伯努利分布，这和CTR任务相似。</li><li>可解释性强：每个特征都有对应的权重，无论是特征交叉还是单独特征，都可以通过权重大小直观的看到对于最终结果的贡献度</li><li>训练开销小：能够在不同机器上并行计算</li></ul><p>逻辑回归的讲解，公式推导及梯度下降，网上有很多，在此不赘述。在非常早期的推荐系统中，往往需要人工构建特征，这导致诸多不便，尤其是需要考虑到特征交叉的情况。为了解决这个问题，出现了GBDT+LR的架构，以实现特征自动组合。这个先码住，下次再写。</p><p>2024&#x2F;8&#x2F;4 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>推荐系统</tag>
      
      <tag>机器学习</tag>
      
      <tag>逻辑回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统：从MF看SVD</title>
    <link href="/2024/08/03/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%BB%8EMF%E7%9C%8BSVD/"/>
    <url>/2024/08/03/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%BB%8EMF%E7%9C%8BSVD/</url>
    
    <content type="html"><![CDATA[<p>前面提到了协同过滤类模型，基于用户-物体共现矩阵，通过相似度计算为用户推荐物品。它的缺点在于无法利用更多的物品和用户的信息，并且无法将单个物品的信息扩展到其他物品上。</p><p>用户对多个物品的打分可能代表了用户本身的一些爱好偏向，而不同物品向量之间本身也存在特征信息。如果只使用协同过滤，就损失了这些信息。为了解决这个问题，矩阵分解算法被提出。</p><p>这个算法在06年Netflix Prize Challenge中表现出众，解决了稀疏矩阵的问题。</p><p>通过将矩阵分解为$P$矩阵和$Q$矩阵，每一个物品和每一个用户都用一个隐向量表示。</p><p>公式如下：$ R \approx P \times Q^T $</p><p>矩阵分解的优势在于以下几点：</p><ul><li>泛化能力强，且隐向量基于全局的共线矩阵拟合，能够使用全局信息</li><li>空间复杂度低，不用存储大量的稀疏矩阵</li><li>隐向量的表达能力更强，其实和Embedding的思想是类似的</li></ul><p>不过，矩阵分解依旧无法使用到一些其他的特征，例如用户和物品自身的一些特征。隐向量的构建还是基于共现矩阵，而共现矩阵并无法体现一些上下文信息。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>基于pytorch简单实现矩阵分解算法。首先写一个FM的网络。完整的训练过程中，我们需要初始化两个矩阵，让两个矩阵的点积拟合评分矩阵。</p><p>我们使用torch的Embedding类实例化两个矩阵。</p><blockquote><ul><li>nn.Embedding和nn.Linear的区别在于，前者相当于一个查找表，其中根据每个index，可以获取对应index的嵌入向量。而Linear是用于前向和反向传播的向量。</li><li>Embedding的作用相当于将n个词转换为m维向量，例如当我们使用<code>emb = Embedding(num_embeddings=3, embedding_dim=5)</code>时，相当于我们给三个词生成了5维的向量。</li><li>当我们实际在输入一个词时，通过Embedding产生的5维向量才是真正参与模型训练并更新的向量。</li><li>参考链接：<a href="https://blog.csdn.net/qq_43391414/article/details/120783887">https://blog.csdn.net/qq_43391414/article/details/120783887</a><br><a href="https://www.zhihu.com/question/436748480">https://www.zhihu.com/question/436748480</a></li></ul></blockquote><p>前向传播时，只需要两个矩阵计算内积，并拟合用户-物体共现矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MatrixFactorization</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_users, num_items, embedding_size=<span class="hljs-number">20</span></span>):<br>        <span class="hljs-built_in">super</span>(MatrixFactorization, self).__init__()<br>        self.user_embeddings = nn.Embedding(num_users, embedding_size)<br>        self.item_embeddings = nn.Embedding(num_items, embedding_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, user_indices, item_indices</span>):<br>        user_embedding = self.user_embeddings(user_indices)<br>        item_embedding = self.item_embeddings(item_indices)<br>        <span class="hljs-keyword">return</span> (user_embedding * item_embedding).<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>我们生成一些数据。我们假设有5个用户和5个产品，并且隐向量维度是10维，此外还需要生成一些评分。</p><p>user_indices对应的是用户对不同物品的打分。一个用户可以为多个物品进行打分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">num_users = <span class="hljs-number">5</span>  <span class="hljs-comment"># 5个用户</span><br>num_items = <span class="hljs-number">5</span>  <span class="hljs-comment"># 5个物品</span><br>embedding_size = <span class="hljs-number">10</span>  <span class="hljs-comment"># 隐向量维度10</span><br><br>user_indices = torch.tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>])<br>item_indices = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>])<br>ratings = torch.tensor([<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">3.5</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">1.5</span>])<br></code></pre></td></tr></table></figure><p>定义模型，损失函数和优化器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">model = MatrixFactorization(num_users, num_items, embedding_size)<br><br>criterion = nn.MSELoss()  <br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.1</span>) <br></code></pre></td></tr></table></figure><p>训练模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">num_epochs = <span class="hljs-number">100</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    optimizer.zero_grad()<br>    predictions = model(user_indices, item_indices)<br>    loss = criterion(predictions, ratings)<br>    loss.backward()<br>    optimizer.step()<br><br>    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch&#125;</span>: Loss = <span class="hljs-subst">&#123;loss.item()&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure><p>训练完成后，我们假设需要预测用户0对物品1的打分，预测代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">user_id = torch.tensor([<span class="hljs-number">0</span>])<br>item_id = torch.tensor([<span class="hljs-number">1</span>])<br>prediction = model(user_id, item_id)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Predicted rating for user 0 on item 1: <span class="hljs-subst">&#123;prediction.item()&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="特征值分解"><a href="#特征值分解" class="headerlink" title="特征值分解"></a>特征值分解</h1><p>可以注意到，虽然名字叫矩阵分解，但是我们在构建模型的时候，实际上并没有使用传统意义的奇异值分解，而是一种经过改良的方法，这种方法由Simon Punk在其博客中公开，通过梯度下降拟合P, Q矩阵，这种方法被称为Latent Factor Model，也称为LFM。</p><p>之所以没有使用原版的SVD，其中很大程度上是因为计算量过大，而且共现矩阵过于稀疏。不过我想在矩阵分解这个话题上再更进一步，研究一下奇异值分解。</p><p>在此之前，需要了解一下特征值分解。</p><p>一个方阵的信息由特征值和特征向量表示。具体定义是$Ax&#x3D;λx$。</p><p>其中 A 是一个$n\times n$的方阵， $x$ 是一个 n 维向量，则 $\lambda$是矩阵 A 的一个特征值，而 $x$  是矩阵 A 的特征值 $\lambda$所对应的特征向量。</p><p><strong>换言之，方阵A可以被转换为$A&#x3D;Q\lambda Q^{-1}$。其中$\lambda$是对角阵，对角阵上的每个元素都是特征值。特征值的大小说明了对应特征向量的重要性。</strong></p><p>当我们求出了A的n个特征值，我们也拥有了这n个特征值对应的特征向量。</p><p>特征值$\lambda$体现的是矩阵被拉伸的强度，这和秩有一点点的关联，秩体现的是矩阵所包含信息的维度。由于特征值代表了在某一个方向上拉伸的方向，当特征值为0时，意味着在某一方向上没有提供信息。</p><p>两者的关联是：</p><ul><li><p>非零特征值的个数即矩阵的秩。这是因为矩阵的特征值决定了它在特征向量所在方向上的行为，而这些非零特征向量是线性独立的，因此贡献于矩阵的秩。</p></li><li><p>秩提供了关于矩阵如何填充其所在空间的结构信息，而特征值则提供了关于矩阵作用强度和方向的信息。</p></li></ul><p>总结来说，特征值体现的是拉伸属性，秩体现的是矩阵的维度信息。</p><p>特征向量$x$通过特征值作为缩放因子进行线性变换后，就会得到最初的方阵。既然只是缩放因子，特征向量的方向是不会变的，变的只是特征向量的数值大小。</p><p>特征值分解后得到的两个东西，特征向量代表了特征是什么，而特征值则代表了特征的重要性，也就是拉伸的程度。</p><h1 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h1><p>参考链接：</p><p><a href="https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html">机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用 - LeftNotEasy - 博客园 (cnblogs.com)</a></p><p><a href="https://www.zhihu.com/question/22237507">奇异值的物理意义是什么？ - 知乎 (zhihu.com)</a></p><p>特征值分解对于数理分析非常有用，但是存在局限，即原矩阵必须是方阵，因为一旦不是方阵，就出现了维度的变化，那么特征向量只乘一个标量就无法改变维度变成原矩阵。作为替代，可以使用奇异值分解来分解任意形状的矩阵。对于一个 $m \times n$ 矩阵A，奇异值分解表示为：</p><p>$A &#x3D; U \Sigma V^T$</p><p>其中：</p><ul><li>$U$ 是一个$m \times m$的单位正交矩阵，其列向量称为左奇异向量。</li><li>$V$ 是一个$n \times n$的单位正交矩阵，其列向量称为右奇异向量。</li><li>$\Sigma$是一个$m \times n$的对角矩阵，对角线上的元素是$A$的奇异值，且这些值非负且按降序排列。</li><li>$U^TU&#x3D;I$,$V^TV&#x3D;I$。</li></ul><p>类似的，奇异值也代表着矩阵在特定方向的拉伸程度，也是矩阵$A^TA$或 $A^TA$的特征值的平方根。当方阵$A$对称且正定时，$A^TA$就是一个方阵，它的奇异值是特征值的绝对值。</p><p><img src="/images/svd1.png"></p><p>知乎上有个对奇异值很好的描述：</p><blockquote><p>奇异值分解是一个有着很明显的物理意义的一种方法，它可以将一个比较复杂的矩阵用更小更简单的几个子矩阵的相乘来表示，这些小矩阵描述的是矩阵的重要的特性。</p><p>就像是描述一个人一样，给别人描述说这个人长得浓眉大眼，方脸，络腮胡，而且带个黑框的眼镜，这样寥寥的几个特征，就让别人脑海里面就有一个较为清楚的认识，实际上，人脸上的特征是有着无数种的，之所以能这么描述，是因为人天生就有着非常好的抽取重要特征的能力，让机器学会抽取重要的特征，SVD是一个重要的方法。</p></blockquote><p>代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># 使用ml-100k数据集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;data.txt&#x27;</span>, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, header=<span class="hljs-literal">None</span>)<br>df.drop(<span class="hljs-number">3</span>, inplace=<span class="hljs-literal">True</span>, axis=<span class="hljs-number">1</span>) <span class="hljs-comment"># 去掉时间戳</span><br>df.columns = [<span class="hljs-string">&#x27;uid&#x27;</span>, <span class="hljs-string">&#x27;iid&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>]<br><br>df = df.sample(frac=<span class="hljs-number">1</span>, random_state=<span class="hljs-number">0</span>)<br>train_set = df.iloc[:<span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(df)*<span class="hljs-number">0.75</span>)]<br>test_set = df.iloc[<span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(df)*<span class="hljs-number">0.75</span>):]<br><br>n_users = <span class="hljs-built_in">max</span>(df.uid)+<span class="hljs-number">1</span> <span class="hljs-comment"># uid最小从1开始</span><br>n_items = <span class="hljs-built_in">max</span>(df.iid)+<span class="hljs-number">1</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Funk_SVD</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_epochs, n_users, n_items, n_factors, lr, reg_rate, random_seed=<span class="hljs-number">0</span></span>):<br>        self.n_epochs = n_epochs<br>        self.lr = lr<br>        self.reg_rate = reg_rate<br>        np.random.seed(random_seed)<br>        self.pu = np.random.randn(n_users, n_factors) / np.sqrt(n_factors) <span class="hljs-comment"># 参数初始化不能太大</span><br>        self.qi = np.random.randn(n_items, n_factors) / np.sqrt(n_factors)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, u, i</span>):<br>        <span class="hljs-keyword">return</span> np.dot(self.qi[i], self.pu[u])<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, train_set, verbose=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n_epochs):<br>            mse = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> train_set.iterrows():<br>                u, i, r = row.uid, row.iid, row.rating<br>                error = r - self.predict(u, i)<br>                mse += error**<span class="hljs-number">2</span><br>                tmp = self.pu[u]<br>                self.pu[u] += self.lr * (error * self.qi[i] - self.reg_rate * self.pu[u])<br>                self.qi[i] += self.lr * (error * tmp - self.reg_rate * self.qi[i])<br>            <span class="hljs-keyword">if</span> verbose == <span class="hljs-literal">True</span>:<br>                rmse = np.sqrt(mse / <span class="hljs-built_in">len</span>(train_set))<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch: %d, rmse: %.4f&#x27;</span> % (epoch, rmse))<br>        <span class="hljs-keyword">return</span> self<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">self, test_set</span>):<br>        predictions = test_set.apply(<span class="hljs-keyword">lambda</span> x: self.predict(x.uid, x.iid), axis=<span class="hljs-number">1</span>)<br>        rmse = np.sqrt(np.<span class="hljs-built_in">sum</span>((test_set.rating - predictions)**<span class="hljs-number">2</span>) / <span class="hljs-built_in">len</span>(test_set))<br>        <span class="hljs-keyword">return</span> rmse<br>    <br>funk_svd = Funk_SVD(n_epochs=<span class="hljs-number">20</span>, n_users=n_users, n_items=n_items, n_factors=<span class="hljs-number">35</span>, lr=<span class="hljs-number">0.005</span>, reg_rate=<span class="hljs-number">0.02</span>)<br>funk_svd.fit(train_set, verbose=<span class="hljs-literal">True</span>)<br>funk_svd.test(test_set)<br><span class="hljs-comment"># 0.9872467462373891</span><br>funk_svd.predict(<span class="hljs-number">120</span>, <span class="hljs-number">282</span>) <br><span class="hljs-comment"># 测试集中的某一条数据，真实评分为4，预测为3.233268069895416</span><br></code></pre></td></tr></table></figure><h1 id="基于SVD的改进"><a href="#基于SVD的改进" class="headerlink" title="基于SVD的改进"></a>基于SVD的改进</h1><p>前面提到的LFM，是06年的Netflix Prize冠军方案，不过正如之前提到的一些不足，使得后续有很多基于该模型的发展。</p><h2 id="加入Bias的LFM"><a href="#加入Bias的LFM" class="headerlink" title="加入Bias的LFM"></a>加入Bias的LFM</h2><p>原版的LFM公式在开头已经给出，不过我们可以加入偏置项，这是为了平衡一些物品和用户的偏好。公式如下：</p><p>$R \approx \mu + b_u + b_i + P \times Q^T$</p><p>其中，$\mu$是全局平均评分，$b_u$是用户偏置向量，通常用当前用户打出的所有得分的均分，$b_i$是物品偏置向量，为当前物品收到的所有得分的均分。</p><p>这解决的问题是用户的一些属性和物品没有关系，只是自身的独立属性，同样的，物品也存在独立的属性。例如用户可能由于自己的原因，偏向打低分，而一些物品本来的的质量就不佳，因此本身得分就很低。</p><p>除此之外，还能够加上L2正则项来防止过拟合。</p><p>代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Bias_SVD</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_epochs, n_users, n_items, n_factors, lr, reg_rate, random_seed=<span class="hljs-number">0</span></span>):<br>        self.n_epochs = n_epochs<br>        self.lr = lr<br>        self.reg_rate = reg_rate<br>        np.random.seed(random_seed)<br>        self.pu = np.random.randn(n_users, n_factors) / np.sqrt(n_factors)<br>        self.qi = np.random.randn(n_items, n_factors) / np.sqrt(n_factors)<br>        self.bu = np.zeros(n_users, np.double)<br>        self.bi = np.zeros(n_items, np.double)<br>        self.global_bias = <span class="hljs-number">0</span><br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, u, i</span>):<br>        <span class="hljs-keyword">return</span> self.global_bias + self.bu[u] + self.bi[i] + np.dot(self.qi[i], self.pu[u])<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, train_set, verbose=<span class="hljs-literal">True</span></span>):<br>        self.global_bias = np.mean(train_set.rating)<br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n_epochs):<br>            mse = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> train_set.iterrows():<br>                u, i, r = row.uid, row.iid, row.rating<br>                error = r - self.predict(u, i)<br>                mse += error**<span class="hljs-number">2</span><br>                self.bu[u] += self.lr * (error - self.reg_rate * self.bu[u])<br>                self.bi[i] += self.lr * (error - self.reg_rate * self.bi[i])<br>                tmp = self.pu[u]<br>                self.pu[u] += self.lr * (error * self.qi[i] - self.reg_rate * self.pu[u])<br>                self.qi[i] += self.lr * (error * tmp - self.reg_rate * self.qi[i])<br>            <span class="hljs-keyword">if</span> verbose == <span class="hljs-literal">True</span>:<br>                rmse = np.sqrt(mse / <span class="hljs-built_in">len</span>(train_set))<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch: %d, rmse: %.4f&#x27;</span> % (epoch, rmse))<br>        <span class="hljs-keyword">return</span> self<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">self, test_set</span>):<br>        predictions = test_set.apply(<span class="hljs-keyword">lambda</span> x: self.predict(x.uid, x.iid), axis=<span class="hljs-number">1</span>)<br>        rmse = np.sqrt(np.<span class="hljs-built_in">sum</span>((test_set.rating - predictions)**<span class="hljs-number">2</span>) / <span class="hljs-built_in">len</span>(test_set))<br>        <span class="hljs-keyword">return</span> rmse<br><br>bias_svd = Bias_SVD(n_epochs=<span class="hljs-number">20</span>, n_users=n_users, n_items=n_items, n_factors=<span class="hljs-number">35</span>, lr=<span class="hljs-number">0.005</span>, reg_rate=<span class="hljs-number">0.02</span>)<br>bias_svd.fit(train_set, verbose=<span class="hljs-literal">True</span>)<br>bias_svd.test(test_set)<br><span class="hljs-comment"># 0.9642304425644652</span><br>bias_svd.predict(<span class="hljs-number">120</span>, <span class="hljs-number">282</span>) <br><span class="hljs-comment"># 真实评分为4，预测为3.495711940570076</span><br></code></pre></td></tr></table></figure><h2 id="加入用户历史行为的SVD"><a href="#加入用户历史行为的SVD" class="headerlink" title="加入用户历史行为的SVD++"></a>加入用户历史行为的SVD++</h2><p>在前者的基础上，后续又提出SVD++，该模型将用户历史评分的物品加入到LFM模型中。</p><p>公式如下：</p><p>$m_{ui} &#x3D; \mu + b_u + b_i + q_i^T \left( p_u + |I_u|^{-1&#x2F;2} \sum_{j \in I_u} y_j \right)$</p><p>和上面的不同在于将原本的物品P矩阵做了扩充，增加了的部分是用户操作过的物品的特性。</p><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SVDpp</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_epochs, n_users, n_items, n_factors, lr, reg_rate, random_seed=<span class="hljs-number">0</span></span>):<br>        self.n_epochs = n_epochs<br>        self.lr = lr<br>        self.reg_rate = reg_rate<br>        self.n_factors = n_factors<br>        np.random.seed(random_seed)<br>        self.pu = np.random.randn(n_users, n_factors) / np.sqrt(n_factors)<br>        self.qi = np.random.randn(n_items, n_factors) / np.sqrt(n_factors)<br>        self.yj = np.random.randn(n_items, n_factors) / np.sqrt(n_factors)<br>        self.bu = np.zeros(n_users, np.double)<br>        self.bi = np.zeros(n_items, np.double)<br>        self.global_bias = <span class="hljs-number">0</span><br>        self.Iu = <span class="hljs-built_in">dict</span>()<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reg_sum_yj</span>(<span class="hljs-params">self, u, i</span>):<br>        sum_yj = np.zeros(self.n_factors, np.double)<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> self.Iu[u]:<br>            sum_yj += self.yj[j]<br>        <span class="hljs-keyword">return</span> sum_yj / np.sqrt(<span class="hljs-built_in">len</span>(self.Iu[u]))<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, u, i, feedback_vec_reg</span>):<br>        <span class="hljs-keyword">return</span> self.global_bias + self.bu[u] + self.bi[i] + np.dot(self.qi[i], self.pu[u] + feedback_vec_reg)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, train_set, verbose=<span class="hljs-literal">True</span></span>):<br>        self.global_bias = np.mean(train_set.rating)<br>        <span class="hljs-comment"># 将用户打过分的记录到Iu字典中，key为uid，value为打过分的iid的list</span><br>        g = train_set.groupby([<span class="hljs-string">&#x27;uid&#x27;</span>])<br>        <span class="hljs-keyword">for</span> uid, df_uid <span class="hljs-keyword">in</span> g:<br>            self.Iu[uid] = <span class="hljs-built_in">list</span>(df_uid.iid)<br>        <br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n_epochs):<br>            square_err = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> train_set.iterrows():<br>                u, i, r = row.uid, row.iid, row.rating<br>                feedback_vec_reg = self.reg_sum_yj(u, i)<br>                error = r - self.predict(u, i, feedback_vec_reg)<br>                square_err += error**<span class="hljs-number">2</span><br>                self.bu[u] += self.lr * (error - self.reg_rate * self.bu[u])<br>                self.bi[i] += self.lr * (error - self.reg_rate * self.bi[i])<br>                tmp_pu = self.pu[u]<br>                tmp_qi = self.qi[i]<br>                self.pu[u] += self.lr * (error * self.qi[i] - self.reg_rate * self.pu[u])<br>                self.qi[i] += self.lr * (error * (tmp_pu + feedback_vec_reg) - self.reg_rate * self.qi[i])<br>                <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> self.Iu[u]:<br>                    self.yj[j] += self.lr * (error / np.sqrt(<span class="hljs-built_in">len</span>(self.Iu[u])) * tmp_qi - self.reg_rate * self.yj[j])<br>            <span class="hljs-keyword">if</span> verbose == <span class="hljs-literal">True</span>:<br>                rmse = np.sqrt(square_err / <span class="hljs-built_in">len</span>(train_set))<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch: %d, rmse: %.4f&#x27;</span> % (epoch, rmse))<br>        <span class="hljs-keyword">return</span> self<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">self, test_set</span>):<br>        predictions = test_set.apply(<span class="hljs-keyword">lambda</span> x: self.predict(x.uid, x.iid, self.reg_sum_yj(x.uid, x.iid)), axis=<span class="hljs-number">1</span>)<br>        rmse = np.sqrt(np.<span class="hljs-built_in">sum</span>((test_set.rating - predictions)**<span class="hljs-number">2</span>) / <span class="hljs-built_in">len</span>(test_set))<br>        <span class="hljs-keyword">return</span> rmse<br><br>svdpp = SVDpp(n_epochs=<span class="hljs-number">20</span>, n_users=n_users, n_items=n_items, n_factors=<span class="hljs-number">35</span>, lr=<span class="hljs-number">0.005</span>, reg_rate=<span class="hljs-number">0.02</span>)<br>svdpp.fit(train_set, verbose=<span class="hljs-literal">True</span>)<br>svdpp.test(test_set)<br><span class="hljs-comment"># 0.9510302683304096</span><br>svdpp.predict(<span class="hljs-number">120</span>, <span class="hljs-number">282</span>, svdpp.reg_sum_yj(<span class="hljs-number">120</span>, <span class="hljs-number">282</span>)) <br><span class="hljs-comment"># 真实评分为4，预测为3.5370712737668204</span><br></code></pre></td></tr></table></figure><h2 id="加入时序信息的timeSVD"><a href="#加入时序信息的timeSVD" class="headerlink" title="加入时序信息的timeSVD++"></a>加入时序信息的timeSVD++</h2><p>通过引入时间信息，原本的共现矩阵现在变为了三维矩阵。对它进行分解后，增加了一项用于计算用户兴趣随时间影响的效应。</p><h1 id="SVD在其他领域的应用"><a href="#SVD在其他领域的应用" class="headerlink" title="SVD在其他领域的应用"></a>SVD在其他领域的应用</h1><h2 id="潜在语义索引LSA"><a href="#潜在语义索引LSA" class="headerlink" title="潜在语义索引LSA"></a>潜在语义索引LSA</h2><p>LSA用于获取潜在的语义信息，这和矩阵分解有点类似。以下例子来源于以下链接：<a href="https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html">机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用 - LeftNotEasy - 博客园 (cnblogs.com)</a></p><p>假设我们有多个文章标题和索引的单词，我们想知道这些标题的特征性质以及单词的特征性质。</p><p><img src="/images/svd2.png"></p><p>我们对这个矩阵进行SVD，会得到以下三个矩阵：</p><p><img src="/images/svd3.png"></p><p>其中， 左奇异向量表示词的一些特性，右奇异向量表示文档的一些特性，中间的奇异值矩阵表示左奇异向量的一行与右奇异向量的一列的重要程序，也是拉伸的程度。</p><p>从这里就能看出它和矩阵分解的思路是一样的，只不过MF采用了另一种方法实现。</p><p>在吴军老师的数据之美中这样解释：</p><blockquote><p>“三个矩阵有非常清楚的物理含义。</p><p>第一个矩阵X中的每一行表示意思相关的一类词，其中的每个非零元素表示这类词中每个词的重要性（或者说相关性），数值越大越相关。</p><p>最后一个矩阵Y中的每一列表示同一主题一类文章，其中每个元素表示这类文章中每篇文章的相关性。</p><p>中间的矩阵则表示类词和文章之间的相关性。因此，我们只要对关联矩阵A进行一次奇异值分解，我们就可以同时完成了近义词分类和文章的分类。（同时得到每类文章和每类词的相关性）。”</p></blockquote><h2 id="SVD用于图像压缩"><a href="#SVD用于图像压缩" class="headerlink" title="SVD用于图像压缩"></a>SVD用于图像压缩</h2><p>SVD同样用于图像领域，由于图像本身就是矩阵，通过SVD后，能找到对于原图更重要的特征，去除不重要的特征，已达到图像压缩的效果。</p><p><img src="/images/svd7.png"></p><p>同样摘抄来自知乎的一个例子：</p><p>原图如下：</p><p><img src="/images/svd4.png"></p><p>原图视为矩阵$A$，奇异值分解后将矩阵分解为多个秩一矩阵之和。其实就是将特征单独剥离出来。拆解后得到：</p><p>$A &#x3D; \sigma_1 u_1 v_1^T + \sigma_2 u_2 v_2^T + \ldots + \sigma_r u_r v_r^T$</p><p>可以理解为，将SVD分解后，中间的那个对角矩阵$\lambda$每个奇异值拆出来，作为对应奇异向量的乘积。所有的乘积之和组成了这张完整的照片。我们将其按照奇异值大小排序，并保留前5项，这时的图片就变成了：</p><p><img src="/images/svd5.jpg"></p><p>当保留20项时，图片变为了：</p><p><img src="/images/svd6.jpg"></p><p>原图是一个$450×333的矩阵，需要保存$450×333&#x3D;149850$个元素的值。而如果我们只保留奇异值分解后的前50项，那存储量仅为原图的26%。</p><p>同样的，这也可以用在图像去噪上，我们将一些较小的奇异值认为是噪音，将它们变为0，这时图像就达到了降噪的效果。</p><p>记录一下示例代码，使用numpy就能进行SVD分解：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> cv2<br> <br>img = cv2.imread(<span class="hljs-string">&#x27;harden.jpg&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;origin image shape is &#x27;</span>, img.shape)<br><span class="hljs-comment"># 表示 RGB 中各有一个矩阵，都为300*532</span><br><span class="hljs-comment">#  origin image shape is  (300, 532, 3)</span><br> <br> <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">svd_compression</span>(<span class="hljs-params">img, k</span>):<br>    res_image = np.zeros_like(img)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(img.shape[<span class="hljs-number">2</span>]):<br>        <span class="hljs-comment"># 进行奇异值分解, 从svd函数中得到的奇异值sigma 是从大到小排列的</span><br>        U, Sigma, VT = np.linalg.svd(img[:,:,i])<br>        res_image[:, :, i] = U[:,:k].dot(np.diag(Sigma[:k])).dot(VT[:k,:])<br> <br>    <span class="hljs-keyword">return</span> res_image<br> <br> <br><span class="hljs-comment"># 保留前 k 个奇异值</span><br>res1 = svd_compression(img, k=<span class="hljs-number">300</span>)<br>res2 = svd_compression(img, k=<span class="hljs-number">200</span>)<br>res3 = svd_compression(img, k=<span class="hljs-number">100</span>)<br>res4 = svd_compression(img, k=<span class="hljs-number">50</span>)<br> <br>row11 = np.hstack((res1, res2))<br>row22 = np.hstack((res3, res4))<br>res = np.vstack((row11, row22))<br> <br>cv2.imshow(<span class="hljs-string">&#x27;img&#x27;</span>, res)<br>cv2.waitKey(<span class="hljs-number">0</span>)<br>cv2.destroyAllWindows()<br></code></pre></td></tr></table></figure><p>分别提取了前300， 200， 100， 50 的奇异值，结果图如下：</p><p><img src="/images/svd8.png"></p><p>可以看到，当我们取到前面300个奇异值来重构图片时，基本与原图看不出来差别。</p><p>2024&#x2F;8&#x2F;4 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>推荐系统</tag>
      
      <tag>机器学习</tag>
      
      <tag>SVD</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>摘录：召回算法超详细讲解[演化、主流算法、召回路径、多路召回融合]</title>
    <link href="/2024/08/01/%E6%91%98%E5%BD%95%EF%BC%9A%E5%8F%AC%E5%9B%9E%E7%AE%97%E6%B3%95%E8%B6%85%E8%AF%A6%E7%BB%86%E8%AE%B2%E8%A7%A3%5B%E6%BC%94%E5%8C%96%E3%80%81%E4%B8%BB%E6%B5%81%E7%AE%97%E6%B3%95%E3%80%81%E5%8F%AC%E5%9B%9E%E8%B7%AF%E5%BE%84%E3%80%81%E5%A4%9A%E8%B7%AF%E5%8F%AC%E5%9B%9E%E8%9E%8D%E5%90%88%5D/"/>
    <url>/2024/08/01/%E6%91%98%E5%BD%95%EF%BC%9A%E5%8F%AC%E5%9B%9E%E7%AE%97%E6%B3%95%E8%B6%85%E8%AF%A6%E7%BB%86%E8%AE%B2%E8%A7%A3%5B%E6%BC%94%E5%8C%96%E3%80%81%E4%B8%BB%E6%B5%81%E7%AE%97%E6%B3%95%E3%80%81%E5%8F%AC%E5%9B%9E%E8%B7%AF%E5%BE%84%E3%80%81%E5%A4%9A%E8%B7%AF%E5%8F%AC%E5%9B%9E%E8%9E%8D%E5%90%88%5D/</url>
    
    <content type="html"><![CDATA[<p>原文链接：</p><p>[人工智能 - 推荐系统<a href="https://segmentfault.com/a/1190000043454134#item-2">二]：召回算法超详细讲解[召回模型演化过程、召回模型主流常见算法、召回路径简介、多路召回融合] - 汀NLP - SegmentFault 思否</a></p><p>看到一篇非常不错的对召回算法的介绍，故摘抄至此，并做了一些排版的优化。</p><hr><h2 id="1-前言：召回排序流程策略算法简介">1.前言：召回排序流程策略算法简介</h2><p><img src="/images/recall1.png" alt=""><br>推荐可分为以下四个流程，分别是召回、粗排、精排以及重排：</p><ol><li>召回是源头，在某种意义上决定着整个推荐的天花板；</li><li>粗排是初筛，一般不会上复杂模型；</li><li>精排是整个推荐环节的重中之重，在特征和模型上都会做的比较复杂；</li><li>重排，一般是做打散或满足业务运营的特定强插需求，同样不会使用复杂模型；</li></ol><ul><li><p><strong>召回层</strong>：召回解决的是从海量候选item中召回千级别的item问题</p><ul><li>基于规则的统计类，热度，LBS；</li><li>协同过滤类，UserCF、ItemCF；</li><li>u2Tag2i，如基于user Tag的召回；</li><li>i2i类，如Embedding（Word2Vec、FastText），GraphEmbedding（Node2Vec、DeepWalk、EGES）；</li><li>u2i类，如DSSM、YouTube DNN、Sentence Bert；</li></ul></li></ul><p><img src="/images/recall2.png" alt=""></p><ul><li><p><strong>模型类</strong>：模型类的模式是将用户和item分别映射到一个向量空间，然后用向量召回，这类有itemcf，usercf，embedding（word2vec），Graph embedding（node2vec等），DNN（如DSSM双塔召回，YouTubeDNN等），RNN（预测下一个点击的item得到用户emb和item emb）；向量检索可以用Annoy（基于LSH），FAISS（基于矢量量化）。此外还见过用逻辑回归搞个预估模型，把权重大的交叉特征拿出来构建索引做召回</p></li><li><p><strong>排序策略</strong>：learning to rank 流程三大模式（pointwise、pairwise、listwise），主要是特征工程和CTR模型预估；</p><ul><li><strong>粗排层</strong>：本质上跟精排类似，只是特征和模型复杂度上会精简，此外也有将精排模型通过蒸馏得到简化版模型来做粗排<ul><li>常见的特征挖掘（user、item、context，以及相互交叉）；</li></ul></li><li><strong>精排层</strong>：精排解决的是从千级别item到几十这个级别的问题<ul><li><strong>CTR预估</strong>：LR，GBDT，FM及其变种（FM是一个工程团队不太强又对算法精度有一定要求时比较好的选择），WideDeep，DeepFm，NCF各种交叉，DIN，BERT，RNN</li><li><strong>多目标</strong>：MOE，MMOE，MTL（多任务学习）</li><li><strong>打分公式融合</strong>: 随机搜索，CEM（性价比比较高的方法），在线贝叶斯优化（高斯过程），带模型CEM，强化学习等</li></ul></li></ul></li></ul><p><img src="/images/recall3.png" alt=""></p><ul><li><p><strong>重排层</strong>：重排层解决的是展示列表总体最优，模型有 MMR，DPP，RNN系列（参考阿里的global rerank系列）</p></li><li><p><strong>展示层</strong>：</p><ul><li><strong>推荐理由</strong>：统计规则、行为规则、抽取式（一般从评论和内容中抽取）、生成式；排序可以用汤普森采样（简单有效），融合到精排模型排等等</li><li><strong>首图优选</strong>：CNN抽特征，汤普森采样</li></ul></li><li><p><strong>探索与利用</strong>：随机策略（简单有效），汤普森采样，bandit，强化学习（Q-Learning、DQN）等</p></li><li><p><strong>产品层</strong>：交互式推荐、分Tab、多种类型物料融合</p></li></ul><h2 id="2-召回算法简介">2.召回算法简介</h2><p>召回区分主路和旁路，主路的作用是个性化+向上管理，而旁路的作用是查缺补漏。</p><p>推荐系统的前几个操作可能就决定了整个系统的走向，在初期一定要三思而后行。</p><p>做自媒体，打广告，漏斗的入口有多大很重要。<br><img src="/images/recall4.png" alt=""></p><p>召回这里稍微有些复杂，因为召回是多路的。</p><p>首先我们要解释主路和旁路的差别，主路的意义和粗排类似，可以看作是一个入口更大，但模型更加简单的粗排。</p><p>主路的意义是为粗排分担压力。但是旁路却不是这样的，旁路出现的时机往往是当主路存在某种机制上的问题，而单靠现在的这个模型很难解决的时候。</p><p>举个例子，主路召回学的不错，但是它可能由于某种原因，特别讨厌影视剧片段这一类内容，导致了这类视频无法上升到粗排上。那这样的话整个系统推不出影视剧片段就是一个问题。从多路召回的角度来讲，我们可能需要单加一路专门召回影视剧的，并且规定：主路召回只能出3000个，这一路新加的固定出500个，两边合并起来进入到粗排中去。这个例子，是出现旁路的一个动机。</p><h3 id="2-1-召回路径介绍">2.1 召回路径介绍</h3><p><strong>推荐系统中的i2i、u2i、u2i2i、u2u2i、u2Tag2i，都是指推荐系统的召回路径。</strong></p><ul><li>第一种召回，是非个性化的。比如对于新用户，我们要确保用最高质量的视频把他们留住，那么我们可以划一个“精品池”出来，根据他们的某种热度排序，作为一路召回。做法就是新用户的每次请求我们都把这些精品池的内容当做结果送给粗排。这样的召回做起来最容易，用sql就可以搞定。</li><li>第二种召回，是i2i，i指的是item，严格意义上应该叫u2i2i。指的是用用户的历史item，来找相似的item。比如说我们把用户过去点过赞的视频拿出来，去找画面上，BGM上，或者用户行为结构上相似的视频。等于说我们就认为用户还会喜欢看同样类型的视频。这种召回，既可以从内容上建立相似关系（利用深度学习），也可以用现在比较火的graph来构建关系。这种召回负担也比较小，图像上谁和谁相似完全可以离线计算，甚至都不会随着时间变化。</li><li>第三种召回是u2i，即纯粹从user和item的关系出发。我们所说的双塔就是一个典型的u2i。在用户请求过来的时候，计算出user的embedding，然后去一个实现存好的item embedding的空间，寻找最相似的一批拿出来。由于要实时计算user特征，它的负担要大于前面两者，但这种召回个性化程度最高，实践中效果也是非常好的。</li></ul><p><img src="/images/recall5.png" alt=""></p><p>通过上图理解什么是召回路径：</p><ul><li>u、i、Tag是指图中的节点</li><li>2是指图中的线(关系)</li></ul><p><strong>i2i：指从一个物品到达另外一个物品，item 到 item</strong></p><ul><li>应用：头条，在下方列出相似的、相关的文章；</li><li>算法：<ul><li>内容相似，eg：文章的相似，取标题的关键字，内容相似</li><li>协同过滤</li><li>关联规则挖掘等</li></ul></li><li>两个物品被同时看的可能性很大，当一个物品被查看，就给他推荐另一个物品</li></ul><p><strong>u2i：指从一个用户到达一个物品，user 到item</strong></p><ul><li>一般指用户的直接行为，比如播放、点击、购买等；</li><li>用户查看了一个物品，就会再次给它推荐这个物品</li><li>结合i2i一起使用，就是用户查看以合物品，就会给他推荐另一个相似的物品，就是u2i2i路径；</li></ul><p><strong>u2i2i：从一个用户，通过一个物品，到达另一个物品</strong></p><ul><li>用户查看了一个耳机（u2i），找出和这个耳机相似或者相关的产品（i2i）并推荐给用户</li><li>对路径的使用，已经从一条线变成两条线</li><li>方法：就是把两种算法结合起来，先得到u2i的数据，再利用i2i的数据进行扩展，就可以从第一个节点，越过一个节点，到达第三个节点，实现推荐</li><li>中间的桥梁是item</li></ul><p><strong>u2u2i：从一个用户，到达另一个用户，到达一个物品</strong></p><ul><li>先计算u2u：两种方法<ul><li>一是：取用户的性别、年龄、职业等人工属性的信息，计算相似性，得到u2u；</li><li>一是：从行为数据中进行挖掘，比如看的内容和视频大部分很相似，就可以看作一类人；</li><li>也可以使用聚类的方法进行u2u计算</li><li>u2u一般用在社交里，比如微博、Facebook，推荐感兴趣的人</li></ul></li><li>UserB和UserC相似，如果UserB查看了某个商品，就把这个商品推荐给UserC；</li><li>中间的桥梁是User</li></ul><p><strong>u2Tag2i：中间节点是Tag标签，而不是 u 或者 i</strong></p><ul><li>京东，豆瓣，物品的标签非常丰富、非常详细；比如统计一个用户历史查看过的书籍，就可以计算标签偏好的向量：标签+喜欢的强度。</li><li>用户就达到了Tag的节点，而商品本身带有标签，这就可以互通，进行推荐</li><li>先算出用户的Tag偏好，然后匹配item列表</li><li>这种方法的泛化性能比较好（推荐的内容不那么狭窄，比如喜欢科幻，那么会推荐科幻的所有内容）</li><li>今日头条就大量使用标签推荐</li></ul><p><strong>基于图的算法：u2*2i</strong></p><ul><li>起始于U，结束于I，中间跨越很多的U、很多的I，可以在图中不停的游走</li><li>例如：PersonalRank，不限制一条还是两条线，在图中到处的游走，游走带着概率，可以达到很多的item；但是相比前面一条、两条边的路径，性能不是很好</li></ul><h3 id="2-2-多路召回融合排序">2.2 多路召回融合排序</h3><h4 id="2-2-1-多路召回">2.2.1 多路召回</h4><p>推荐服务一般有多个环节（召回、粗排序、精排序），一般会使用多个召回策略，互相弥补不足，效果更好。比如说：</p><ul><li>实时召回- u2i2i，<ul><li>几秒之内根据行为更新推荐列表。</li><li>用u2i得到你实时的行为对象列表，再根据I2I得到可能喜欢的其他的物品</li><li>这个是实时召回，剩下3个是提前算好的</li></ul></li><li>基于内容 - u2Tag2i<ul><li>先算好用户的偏好Tag，然后对Tag计算相似度，获取可能感兴趣的item</li></ul></li><li>矩阵分解 - u2i<ul><li>先算好User和Item的Tag矩阵，然后叉乘，给每个user推荐item</li><li>提前存储好进行推荐</li></ul></li><li>聚类推荐 - u2u2i<ul><li>根据用户信息对用户进行聚类，然后找到最相似的user，推荐最相似user喜欢的物品；或者找到聚类中大家喜欢的物品，进行推荐</li></ul></li></ul><p>写程序时，每个策略之间毫不相关，所以：</p><blockquote><p>1、一般可以编写并发多线程同时执行<br>2、每一种策略输出结果，都有一个顺序，但最后要的结果只有一个列表，这就需要融合排序</p></blockquote><h4 id="2-2-2-融合排序">2.2.2 融合排序</h4><p>多种召回策略的内容，取TOP N合并成一个新的列表。这个新的列表，可以直接返回给前端，进行展示；也可以发给精排，进行排序。</p><p>精排模型非常耗时，所以召回的内容，会经过粗排之后，把少量的数据给精排进行排序</p><h5 id="几种多路召回结果融合的方法"><strong>几种多路召回结果融合的方法</strong></h5><p>举个例子：几种召回策略返回的列表（Item-id，权重）分别为：</p><table><thead><tr><th>召回策略</th><th>返回列表</th><th></th><th></th></tr></thead><tbody><tr><td>召回策略X</td><td>A：0.9</td><td>B：0.8</td><td>C：0.7</td></tr><tr><td>召回策略Y</td><td>B：0.6</td><td>C：0.5</td><td>D：0.4</td></tr><tr><td>召回策略Z</td><td>C：0.3</td><td>D：0.2</td><td>E：0.1</td></tr></tbody></table><p><strong>融合策略：</strong><br><strong>1、按顺序展示</strong></p><ul><li>比如说实时 &gt; 购买数据召回 &gt; 播放数据召回，则直接展示A、B、C、D、E</li></ul><p><strong>2、平均法</strong></p><ul><li>分母为召回策略个数，分子为权重加和。</li><li>C为(0.7+0.5+0.3)/3，B为(0.8+0.6)/3</li></ul><p><strong>3、加权平均</strong></p><ul><li>比如三种策略自己指定权重为0.4、0.3、0.3，则B的权重为(0.40.8 + 0.60.3 + 0*0.2)/ (0.4+0.3+0.2)，这个方法有个问题就是，每个策略的权重是自己设置的，并不准确，所以，有动态加权法。</li></ul><p><strong>4、动态加权法</strong></p><ul><li>计算XYZ三种召回策略的CTR，作为每天更新的动态加权。</li><li>只考虑了点击率，并不全面。</li><li>每种召回源CTR计算方法：<ul><li>展现日志-带召回源：X，Y，Z，X，Y，Z</li><li>点击日志-带召回源：点击X</li><li>则每种召回的CTR = 点击数/展现数</li></ul></li></ul><p><strong>5、机器学习权重法</strong></p><ul><li>逻辑回归LR分类模型预先离线算好各种召回的权重，然后做加权召回。</li><li>考虑更多的特征以及环境因素，会更准确。</li></ul><p>以上融合排序的方法，成本逐渐增大，效果依次变好，按照成本进行选择。</p><h2 id="3-推荐场景中召回模型的演化过程">3.推荐场景中召回模型的演化过程</h2><h3 id="3-1-传统方法：基于协同过滤">3.1 传统方法：基于协同过滤</h3><p>更多内容参考：<a href="https://link.segmentfault.com/?enc=avx9BQAEPblrF0AsG83k3g%3D%3D.Tc9Cv%2F77Pzpf6ubVt5fy1xtUtiPTdpdo54d3cG%2Bkg0oylz5IoQTDiP2h83YWi2sjqMYywq9usU%2FNqZEIojrRSw%3D%3D">https://blog.csdn.net/sinat_39620217/article/details/129119611</a></p><h3 id="3-2-单-Embedding-向量召回">3.2 单 Embedding 向量召回</h3><ul><li><p>Youtube DNN 召回</p></li><li><p>双塔模型召回</p></li></ul><h3 id="3-2-多-Embedding-向量召回-用户多兴趣表达">3.2 多 Embedding 向量召回-用户多兴趣表达</h3><ul><li>Multi-Interest Network with Dynamic Routing 模型</li></ul><h3 id="3-3-Graph-Embedding">3.3 Graph Embedding</h3><ul><li><p>阿里 Graph Embedding with Side information</p></li><li><p>GraphSAGE：Inductive representation learning on large graphs</p></li></ul><h3 id="3-4-结合用户长期和短期兴趣建模">3.4 结合用户长期和短期兴趣建模</h3><ul><li>Next Item Recommendation with Self-Attention</li></ul><p>更多内容参考：<a href="https://link.segmentfault.com/?enc=RYZu21e1f0TQRcgvkqda3w%3D%3D.09dRHSJ%2BrzhG2PB0S4ljav4Q1EuqsL6MGhrmDezWJ8384I5joPo7VPx8N%2FPIk7eFAGAz2CqmEwcfzBVeaxbpXQ%3D%3D">https://blog.csdn.net/sinat_39620217/article/details/129119611</a></p><h3 id="3-5-TDM-深度树匹配召回">3.5 TDM 深度树匹配召回</h3><p>TDM 是为大规模推荐系统设计的、能够承载任意先进模型 ( 也就是可以通过任何深度学习推荐模型来训练树 ) 来高效检索用户兴趣的推荐算法解决方案。</p><p>TDM 基于树结构，提出了一套对用户兴趣度量进行层次化建模与检索的方法论，使得系统能直接利高级深度学习模型在全库范围内检索用户兴趣。</p><p>其基本原理是使用树结构对全库 item 进行索引，然后训练深度模型以支持树上的逐层检索，从而将大规模推荐中全库检索的复杂度由 O(n) ( n 为所有 item 的量级 ) 下降至 O(log n)。</p><h2 id="4-当前业界的主流召回算法综述">4.当前业界的主流召回算法综述</h2><h3 id="4-1-Youtube-DNN">4.1 Youtube DNN</h3><p><img src="/images/recall6.png" alt=""></p><p>当前的<strong>主流方法的通用思路就是对于use和item的embedding的学习, 这也被称为表示学习</strong>; YoutbeDNN是经典的将深度学习模型引入推荐系统中，可以看到网络模型并不复杂，但是文中有很多工程上的技巧，比如说 word2vec对 video 和 search token做embedding后做为video初始embedding，对模型训练中训练时间和采集日志时间之间“position bias”的处理，以及对大规模多分类问题的负采样softmax。</p><h3 id="4-2-DeepMF">4.2 DeepMF</h3><h3 id="4-3-DSSM">4.3 DSSM</h3><p>更多内容参考：<a href="https://link.segmentfault.com/?enc=9VE2qCPRyCXvGOC7f8igDg%3D%3D.U5njn1Vyf0bN1Z%2BMcUv0FVVTe5My4lxmiagsPFZLeuKmv4%2FZfTTawm%2BeQc84KmZBbg6VWbwOTx3irux5ZHbgww%3D%3D">https://blog.csdn.net/sinat_39620217/article/details/129119611</a></p><h3 id="4-4-Item2vec">4.4.Item2vec</h3><h3 id="4-5-Airbnb-Embedding">4.5.Airbnb Embedding</h3><h3 id="4-6-DeepWalk">4.6.DeepWalk</h3><p><img src="/images/recall7.png" alt=""></p><h3 id="4-7-Node2Vec">4.7 Node2Vec</h3><h3 id="4-8-EGES">4.8.EGES</h3><h3 id="4-9-LINE">4.9.LINE</h3><p>更多内容参考：<a href="https://link.segmentfault.com/?enc=H1Sy1LhP29sGHnoDSiNqsA%3D%3D.SL%2B6UPlymbfxPh1o4jozreHyvPc3DmLLdFrVsaaG7WlqCxB4ryH%2FqQckyVlHHtFtG2ge3hMPoENxluaEiWKsoA%3D%3D">https://blog.csdn.net/sinat_39620217/article/details/129119611</a></p><h3 id="4-10-SDNE">4.10.SDNE</h3><h3 id="4-11-GraphSAGE">4.11.GraphSAGE</h3><h3 id="4-12-MIND">4.12 MIND</h3><h3 id="4-13-SDM">4.13.SDM</h3><h3 id="4-14-DeepFM">4.14.DeepFM</h3><h3 id="4-15-NCF">4.15.NCF</h3><h3 id="4-16-TDM">4.16.TDM</h3><p>更多内容参考：<a href="https://link.segmentfault.com/?enc=77wCPdm9T5Xrhp%2B6vmyZVA%3D%3D.MCcJfFaIBxCSLcpBO32mchMl28kSgKg1s04jOX6J16KLbiRU1P7RUmyxuaQ1f2yJdOC%2B8CgIH2RxA6FnQbQz4A%3D%3D">https://blog.csdn.net/sinat_39620217/article/details/129119611</a></p>]]></content>
    
    
    <categories>
      
      <category>推荐系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统：Swing-基于ItemCF的改进</title>
    <link href="/2024/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9ASwing-%E5%9F%BA%E4%BA%8EItemCF%E7%9A%84%E6%94%B9%E8%BF%9B/"/>
    <url>/2024/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9ASwing-%E5%9F%BA%E4%BA%8EItemCF%E7%9A%84%E6%94%B9%E8%BF%9B/</url>
    
    <content type="html"><![CDATA[<p>相关链接：</p><p><a href="https://blog.csdn.net/weixin_46838716/article/details/126138597">一文看懂推荐系统：召回02：Swing 模型，和itemCF很相似，区别在于计算相似度的方法不一样_swing模型-CSDN博客</a></p><p>前一篇文章介绍了ItemCF，核心思想是如果两个物品相似，那么就可以推荐给相似的用户。如何定义两个物品相似？就是两个物品的打分分布是相似的，也就是说两个物品重合的用户比例高。</p><h2 id="ItemCF的不足"><a href="#ItemCF的不足" class="headerlink" title="ItemCF的不足"></a>ItemCF的不足</h2><p>ItemCF的不足也提到了，其中之一是对尾部产品的推荐精度不高，而倾向于热门产品。这会出现一种情况，当两个不太相似的物品被发送到同一个微信群中时，这两个物品同时被群友点击，这样就会导致这两个物品的相似度很高，但是这两个物品实际上并不相似。</p><hr><p>为了解决这个问题，阿里巴巴开发了Swing模型，这个召回模型在阿里巴巴早期被多个业务部门验证过有效性。核心逻辑也比较易懂：如果两个物品的重合用户比例较高，<strong>且重合用户不来自于一个小圈子</strong>，那么这两个物品是相似的。</p><p>Swing是一个i2i的召回算法，即通过计算Item-Item相似度来进行推荐。</p><h2 id="什么是Swing？"><a href="#什么是Swing？" class="headerlink" title="什么是Swing？"></a>什么是Swing？</h2><p>Swing意为秋千，在图结构中，如果用户1和用户2同时购买了物品$i$，那么三者就构成了一个秋千。这是一个三阶的交互关系。之前的ItemCF只关注了用户-物品之间的二阶关系，即物品的受众类似，则物品类似。而Swing关注了三阶关系，如果两个用户之间组成的秋千过多（即两个用户属于一个圈子），那么这两个用户的权重越低。</p><p>Swing想要实现的理想场景是，两个用户的喜好完全不同，但是他们同时购买了同样的两个物品，这说明这两个物品非常相似。因此，Swing的结构被称为User-Item-User图结构。</p><h2 id="Swing的公式"><a href="#Swing的公式" class="headerlink" title="Swing的公式"></a>Swing的公式</h2><p>从算法公式上来看，对原先的ItemCF对物品相似度的计算进行了修改，改为计算两个物品中，每个用户对的相似度总和。其中每个用户对的相似度拥有一个惩罚项：两个用户的重合度。记同时喜欢两个物品的用户为集合$\nu$。对于$\nu$中的用户$u_1$和$u_2$，它们的重合度记作$\text{overlap}(u_1,u_2)$。</p><p>下面是Swing对物品相似度的计算公式：</p><p>$\text{sim}(i_1, i_2) &#x3D; \sum_{u_1 \in V} \sum_{u_2 \in V} \frac{1}{\alpha + \text{overlap}(u_1, u_2)}$</p><p>其中$\alpha$为平滑项，用来避免分母为零，可以取一个较小的正数。</p><h2 id="Swing的官方配置参数"><a href="#Swing的官方配置参数" class="headerlink" title="Swing的官方配置参数"></a>Swing的官方配置参数</h2><p>阿里官方的Swing官方配置参数包含了多个参数，其中输入是Pyspark Dataframe。格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">user,item<br>A,t<br>A,r<br>A,p<br>B,t<br>B,r<br>B,p<br>C,p<br>C,q<br>A,h<br>B,h<br>C,h<br></code></pre></td></tr></table></figure><p>需要调整的入参是：</p><ul><li><code>min_user_items</code>：User互动的Item的最小数量，默认10</li><li><code>max_user_items</code>：User互动的Item的最大数量，默认1000</li><li><code>max_item_number</code>：Item参与计算的人数最大值，默认1000</li><li><code>user_alpha</code>：用户权重的平滑项，默认0.0</li><li><code>user_beta</code>：用户权重的beta参数，默认0.5</li></ul><p>其中最后两项是工业场景增加的用户权重，这来源于阿里对Swing的改进：</p><p>$\text{user weight} &#x3D; \frac{1.0}{(\text{userAlpha} + \text{userClickCount})^{\text{userBeta}}}$</p><p>用户权重用于在赋予每个用户对的相似度得分时，对高热度用户进行惩罚。</p><p>这里摘抄了阿里对此的解释：</p><blockquote><p>原版的Swing算法对于物品的同时被触达的用户数量过少的情况，并不适用。从统计学的角度来看，数据量过少，往往会导致结果的误差过大。也就是说当同时触达两个物品的用户数量过少时，这时候swing计算得出的结果误差会比较大。</p><p>举个极端的例子：</p><p>如下图所示，有A、B、C三个视频，$X_1$到$X_{10}$共10个皇马死忠球迷，只关注音乐的音乐爱好者$Y$。皇马死忠球迷会看与皇马相关的内容，不管是热门视频C，还是中低频视频A，他们都会观看，可以假定他们都看了200个关于皇马的视频。其中有一个球迷$X_1$，被其他朋友推荐了一首冷门音乐B，听完发现不喜欢这种暗黑系古典音乐，还是喜欢比较激昂的皇马队歌A。音乐爱好者Y会听各种音乐，不管是A，还是B，都会播放。那么在这种情况下，由于视频A、B的共现用户量过少（只有2个），从而导致swing算法得出的分数<code>s(A,B)=0.33 &gt; s(A,C)=0.22</code>。但是很明显，用户在观看视频A的时候，推荐视频C比推荐视频B要好。</p><p><img src="/images/swing1.png"><br>问题是由两个视频的同时被看的用户数量过少导致的，所以我们需要根据同时观看过两个视频的用户数量来对结果进行处理。我们在swing的基础上，往其公式中增加了指示函数 Id（.） 来达到去噪的目的。同时，引入行为权重来打压过热的用户或物品。改进后的公式如下：</p><p><img src="/images/swing2.png"></p></blockquote><p>可以看到，如果两个物体的共现用户较少，相似度会直接赋予0，因为这个样本不具备普遍性。</p><p>2024&#x2F;7&#x2F;31 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>推荐系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>推荐系统：从协同过滤的起源</title>
    <link href="/2024/07/27/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%BB%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E8%B5%B7%E6%BA%90/"/>
    <url>/2024/07/27/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%BB%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E8%B5%B7%E6%BA%90/</url>
    
    <content type="html"><![CDATA[<p>相关链接：</p><p><a href="https://blog.csdn.net/CRW__DREAM/article/details/124797295">推荐系统常用的评价指标_推荐系统评价指标-CSDN博客</a></p><p><a href="https://www.cnblogs.com/vivotech/p/16516494.html">推荐系统-协同过滤在Spark中的实现 - vivo互联网技术 - 博客园 (cnblogs.com)</a></p><p>从上篇博文到现在又隔了一个月，由于工作内容的转变，转向了推荐&#x2F;风控算法，尤其是CTR模型相关，因此准备系统的学习并实现一下一些常用的推荐和分控算法。</p><p>记得曾经看过一句话，推荐算法是没有Query的搜索系统，这句话非常粗略的介绍了推荐算法。正如搜索系统需要想法设法对用户的输入进行信息抽取，推荐算法的Query则是用户自身的历史行为信息和物品的信息。</p><p><img src="/images/rms1.png" alt="推荐系统分类"></p><p>推荐系统最早出现在90年代，1992年出现了第一个最早的协同过滤系统，由Xerox公司帕罗奥多研究中心研发。当时需要解决的问题是员工需要对大量的邮件进行筛选分类，因此衍生出了这个系统。随着不断的发展，这个协同过滤系统逐渐发展完善，并于1998年被亚马逊公司使用于自己的网站，为用户进行商品的个性化推荐。</p><p>大体上，协同过滤被分为三个子类：User based，Item based和Model based。从核心思想上来介绍协同过滤，可以用一言概括：通过分析用户或者事物之间的相似性来找到目标对象。</p><h1 id="推荐系统的评估指标"><a href="#推荐系统的评估指标" class="headerlink" title="推荐系统的评估指标"></a>推荐系统的评估指标</h1><p>推荐系统和CTR模型简单可以看作是一个多目标&#x2F;单目标分类任务。推荐系统更多考虑到候选物品的排序，CTR则作为一个二分类任务，判断用户是否会点击目标物品。</p><p>作为分类任务时，就可以用一些常规的评估指标对模型进行评估。</p><ul><li>AUC-ROC</li><li>Log Loss</li><li>Precsion&#x2F;Recall&#x2F;F1 Score</li><li>Accuracy</li></ul><p>作为排序任务时，则常用以下指标：</p><ul><li>NDCG：对推荐结果的相关性进行排名，考虑位置的重要性。</li><li>MRR（Mean Reciprocal Rank）：推荐结果中第一个相关物品的倒数平均值。</li><li>MAP（Mean Average Precision）：平均精度，对推荐结果的相关性进行综合评估。</li><li>Hit Rate：推荐系统的推荐物品命中率。</li></ul><h2 id="NDCG：评估推荐系统排序质量的指标"><a href="#NDCG：评估推荐系统排序质量的指标" class="headerlink" title="NDCG：评估推荐系统排序质量的指标"></a>NDCG：评估推荐系统排序质量的指标</h2><p>我们从NDCG的前身开始介绍。</p><p>首先需要了解的相关性得分：</p><p>$\text{Gain}&#x3D; \text{rel}_i$</p><p>这个得分通常是人工标注或者通过用户行为得到。例如当用户点击某个推荐商品时，给商品赋予1分，未点击则为0分。如果购买则赋予2分，以此类推。也可以根据用户自己的打分来进行判断。最终会得到以下一个列表：</p><table><thead><tr><th>Item</th><th>Rel(i)</th></tr></thead><tbody><tr><td>Item A</td><td>1</td></tr><tr><td>Item B</td><td>3</td></tr><tr><td>Item C</td><td>2</td></tr></tbody></table><h3 id="CG"><a href="#CG" class="headerlink" title="CG"></a>CG</h3><p>CG（Cumulative Gain）用于衡量推荐列表中的相关性之和。计算公式如下：</p><p>$CG@k &#x3D; \sum_{i&#x3D;1}^{k} \text{rel}_i$</p><p>其中：</p><ul><li><p>$k \text{ 是推荐列表的长度。}$</p></li><li><p>$\text{rel}_i \text{ 是第 } i \text{ 个推荐物品的相关性得分（通常由实际数据或人工标注给出）。}$</p></li></ul><p>CG只是单纯的累加相关性，不考虑他们之间的排序。我们以上面的列表举例：</p><p>如果我们有两个推荐列表：</p><ul><li>List 1 &#x3D; [A, B, C]</li><li>List 2 &#x3D; [C, A, B]</li></ul><p>他们的CG得分都是A, B, C的相关性得分相加。最终得分为$1+3+2&#x3D;6$。由于不考虑排序的影响，他们的得分是一样的。</p><h3 id="DCG"><a href="#DCG" class="headerlink" title="DCG"></a>DCG</h3><p>如果我们想要考虑排序的因素，使得高排名的物品权重更高，对排名靠后的物品扣分，这时候可以使用DCG作为指标。它的计算方式是在每个CG的结果上除以一个折损值，这样能让排名靠前的结果更加能影响到最终的结果。假设排序越靠后，价值越低，那么到第$i$个位置时，价值为$\frac{1}{log_{2}(i+1)}$，那么第$i$个结果的效益值是$rek_{i}*{\frac{1}{log_{2}(i+1)}}$。</p><p>$DCG_p &#x3D; \sum_{i&#x3D;1}^{p} \frac{2^{\text{rel}_i} - 1}{\log_2(i + 1)}$</p><p>在同样上面的例子中：</p><table><thead><tr><th>Item</th><th>Rel(i)</th><th>Position (i)</th><th>Contribution to DCG</th></tr></thead><tbody><tr><td>Item A</td><td>1</td><td>1</td><td>1</td></tr><tr><td>Item B</td><td>3</td><td>2</td><td>$\frac{3}{\log_2(3)} \approx 1.893$</td></tr><tr><td>Item C</td><td>2</td><td>3</td><td>$\frac{2}{\log_2(4)}&#x3D;1$</td></tr></tbody></table><h3 id="NDCG"><a href="#NDCG" class="headerlink" title="NDCG"></a>NDCG</h3><p>最后就到了NDCG，他是DCG进行了归一化。不过因为两边的检索结果的列表长度可能不一样，所有没法针对两个不同的检索结果进行归一化，这里是除以IDCG。</p><p>IDCG是理想情况下的DCG最大的值，即推荐的最佳排序顺序，根据相关性从高到低排列。</p><p>最终的公式是：$NDCG_{p}&#x3D;\frac{DCG}{IDCG_{p}}$</p><p>这样计算后，NDCG作为一个相对值，不同长度的检索就可以进行比较了。</p><h1 id="基于用户的协同过滤"><a href="#基于用户的协同过滤" class="headerlink" title="基于用户的协同过滤"></a>基于用户的协同过滤</h1><p><img src="/images/usercf1.png"></p><p>基于用户的协同过滤简称UserCF，核心是推荐与用户相似的用户喜欢的物品。简单来说，$n$个用户对$m$个物体的打分会成为一个$n*m$的User-Item矩阵。每个用户都是一个$m$维向量，这样就可以通过计算相似度来计算不同用户之间的相似度。最终能够得到一个下三角矩阵，其中包含了每个用户两两之间的相似度。使用较多的是余弦相似度。</p><p>在实际环境中，用户&#x2F;物品评分矩阵是一个稀疏矩阵。</p><p>UserCF的核心是计算用户相似度，完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> cosine_similarity<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">UserBasedCF</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, ratings, k=<span class="hljs-number">2</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">初始化UserCF模型</span><br><span class="hljs-string"></span><br><span class="hljs-string">入参：</span><br><span class="hljs-string">ratings：二维评分矩阵</span><br><span class="hljs-string">k：最近邻用户数</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.ratings = ratings<br>        self.k = k<br>        self.user_similarity = self.calculate_user_similarity()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_user_similarity</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        计算用户相似度</span><br><span class="hljs-string">        </span><br><span class="hljs-string">        返回：</span><br><span class="hljs-string">        用户相似度的二维数组</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> cosine_similarity(self.ratings)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_rating</span>(<span class="hljs-params">self, user_index, item_index</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        为特定用户计算特定物体的打分</span><br><span class="hljs-string"></span><br><span class="hljs-string">入参：</span><br><span class="hljs-string">user_index：用户的索引</span><br><span class="hljs-string">item_index：物品的索引</span><br><span class="hljs-string">        </span><br><span class="hljs-string">返回：</span><br><span class="hljs-string">预测得分</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 首先根据用户相似度得到最相似的k个用户，并去除自身</span><br>        similar_users = np.argsort(self.user_similarity[user_index])[-self.k:]<br>        similar_users = similar_users[similar_users != user_index]<br>        <br>        numerator = <span class="hljs-number">0</span><br>        denominator = <span class="hljs-number">0</span><br>        <br>        <span class="hljs-comment"># 找到相似用户</span><br>        <span class="hljs-keyword">for</span> neighbor <span class="hljs-keyword">in</span> similar_users:<br>            <span class="hljs-keyword">if</span> self.ratings[neighbor, item_index] &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-comment"># 分子是相似用户对物品的评分*相似度</span><br>                numerator += self.user_similarity[user_index, neighbor] * self.ratings[neighbor, item_index]<br>                <span class="hljs-comment"># 分母是用户相似度之和</span><br>                denominator += <span class="hljs-built_in">abs</span>(self.user_similarity[user_index, neighbor])<br>        <br>        <span class="hljs-keyword">if</span> denominator == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 返回分子/分母</span><br>            <span class="hljs-keyword">return</span> numerator / denominator<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">recommend</span>(<span class="hljs-params">self, user_index, num_recommendations=<span class="hljs-number">5</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        为用户推荐具体物品</span><br><span class="hljs-string">        </span><br><span class="hljs-string">        入参：</span><br><span class="hljs-string">        user_index：用户索引</span><br><span class="hljs-string">        num_recommendations：推荐物品个数</span><br><span class="hljs-string"></span><br><span class="hljs-string">    返回：</span><br><span class="hljs-string">        推荐物品的索引列表</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        user_ratings = self.ratings[user_index]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;用户<span class="hljs-subst">&#123;user_index&#125;</span>的评分：<span class="hljs-subst">&#123;user_ratings&#125;</span>&#x27;</span>)<br>        item_indices = np.where(user_ratings == <span class="hljs-number">0</span>)[<span class="hljs-number">0</span>]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;用户<span class="hljs-subst">&#123;user_index&#125;</span>未评分的物品：<span class="hljs-subst">&#123;item_indices&#125;</span>&#x27;</span>)<br>        <br>        predictions = np.array([self.predict_rating(user_index, item) <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> item_indices])<br>        recommended_items = item_indices[np.argsort(predictions)[-num_recommendations:]]<br>        <br>        <span class="hljs-keyword">return</span> recommended_items<br>        <br>        predictions = np.array([self.predict_rating(user_index, item) <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> item_indices])<br>        recommended_items = item_indices[np.argsort(predictions)[-num_recommendations:]]<br>        <br>        <span class="hljs-keyword">return</span> recommended_items<br></code></pre></td></tr></table></figure><p>现在，我们有一个用户-物品评分矩阵，每行都是一个用户对所有物品的打分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 示例数据：用户-物品评分矩阵</span><br>ratings_matrix = np.array([<br>    [<span class="hljs-number">4</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>],<br>    [<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0</span>],<br>    [<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>]<br>])<br></code></pre></td></tr></table></figure><p>我们想要得到用户0的推荐产品：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 初始化并使用User-based CF模型</span><br>user_cf = UserBasedCF(ratings_matrix, k=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 为用户0推荐物品</span><br>recommendations = user_cf.recommend(<span class="hljs-number">0</span>, num_recommendations=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Recommendations for user 0: <span class="hljs-subst">&#123;recommendations&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 预测用户0对物品1的评分</span><br>predicted_rating = user_cf.predict_rating(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Predicted rating for user 0 on item 1: <span class="hljs-subst">&#123;predicted_rating:<span class="hljs-number">.2</span>f&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>首先实例化模型，需要计算用户相似度。这个相似度被保存在<code>user_cf.user_similarity</code>变量中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">user_cf.user_similarity <br><br>array([[<span class="hljs-number">1.</span>        , <span class="hljs-number">0.37986859</span>, <span class="hljs-number">0.48196269</span>, <span class="hljs-number">0.40875956</span>, <span class="hljs-number">0.6988459</span> ],<br>       [<span class="hljs-number">0.37986859</span>, <span class="hljs-number">1.</span>        , <span class="hljs-number">0.38447322</span>, <span class="hljs-number">0.99453584</span>, <span class="hljs-number">0.</span>        ],<br>       [<span class="hljs-number">0.48196269</span>, <span class="hljs-number">0.38447322</span>, <span class="hljs-number">1.</span>        , <span class="hljs-number">0.4137144</span> , <span class="hljs-number">0.48780488</span>],<br>       [<span class="hljs-number">0.40875956</span>, <span class="hljs-number">0.99453584</span>, <span class="hljs-number">0.4137144</span> , <span class="hljs-number">1.</span>        , <span class="hljs-number">0.</span>        ],<br>       [<span class="hljs-number">0.6988459</span> , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.48780488</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">1.</span>        ]])<br></code></pre></td></tr></table></figure><p>输出是一个共轭矩阵，可以看到用户0和用户2&#x2F;用户4的相似度最高。</p><p>现在我们想找到对用户0的2个推荐物品。首先需要找到用户评分的物品和未评分的物品：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">user_ratings = self.ratings[user_index]<br><span class="hljs-comment"># 用户0的评分：[4 0 0 5 1]</span><br>item_indices = np.where(user_ratings == <span class="hljs-number">0</span>)[<span class="hljs-number">0</span>]<br><span class="hljs-comment"># 用户0未评分的物品：[1 2]</span><br></code></pre></td></tr></table></figure><p>现在就需要对用户0未评分的物品进行预测打分，来判断用户是否会喜欢。</p><p>要进行打分，就需要找到用户最相似的k个用户。这里k设置为2。根据前面计算得到相似用户是2和4。随后根据用户2，4对物品1，2的打分预测目标用户的打分。</p><p>我们需要遍历每个邻居，找到当前邻居对需要计算的物品的打分。如果分数不为0，则将分子设为用户相似度*用户对物品评分的加和，而分母设置为用户相似度的绝对值之和（用于归一化分子的加权和），最后得到的预测得分是相似用户的评分的加权得分。</p><blockquote><p>分母设置为相似度的绝对值之和是为了防止出现负数之后使得分母为0。</p></blockquote><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>假设用户$u$的相似邻居 $Nu$有以下相似度和评分：</p><table><thead><tr><th>用户 $v$</th><th>相似度 $s(u,v)$</th><th>评分 $r_{vi}$</th></tr></thead><tbody><tr><td>用户 1</td><td>0.9</td><td>4</td></tr><tr><td>用户 2</td><td>-0.8</td><td>3</td></tr><tr><td>用户 3</td><td>0.7</td><td>5</td></tr></tbody></table><p>计算预测评分：</p><ol><li><strong>分子</strong>：$(0.9×4)+(−0.8×3)+(0.7×5)&#x3D;3.6−2.4+3.5&#x3D;4.7$</li><li><strong>分母</strong>：$∣0.9∣+∣−0.8∣+∣0.7∣&#x3D;0.9+0.8+0.7&#x3D;2.4$</li><li><strong>预测得分</strong>：$\frac{2.4}{4.7}≈1.96$</li></ol><h2 id="UserCF的不足"><a href="#UserCF的不足" class="headerlink" title="UserCF的不足"></a>UserCF的不足</h2><p>UserCF存在一些不足：</p><ol><li>物体过多导致的稀疏矩阵问题，很多用户可能接触不到百分之一的物品。</li><li>用户增长比物品增长快的时候需要频繁维护相似度矩阵，对存储要求非常大，尤其是高用户的场景。</li></ol><h1 id="基于物品的协同过滤"><a href="#基于物品的协同过滤" class="headerlink" title="基于物品的协同过滤"></a>基于物品的协同过滤</h1><p>相比UserCF，ItemCF被工业界应用的更多，例如此前亚马逊，Netflix和Youtube都使用过它。例如在电商平台某个商品下，会推荐<code>类似商品</code>，或者<code>购买此商品的用户还看过</code>这样的标签。背后用的就是ItemCF。</p><p>流程与UserCF类似。基本思想是根据用户的历史偏好数据计算物品之间的相似性，然后把与用户喜欢的物品相类似的物品推荐给用户。比如物品A和C非常相似，因为喜欢A的用户同时也喜欢C，而用户甲喜欢A，所以把C推荐给用户甲。</p><p>一言概况：喜欢某个物品的用户，也可能喜欢和该物品类似的物品。举一个例子：</p><table><thead><tr><th></th><th>Item 1</th><th>Item 2</th><th>Item 3</th><th>Item 4</th><th>Item 5</th></tr></thead><tbody><tr><td>User 1</td><td>5</td><td>3</td><td>4</td><td>4</td><td></td></tr><tr><td>User 2</td><td>3</td><td>1</td><td>2</td><td>3</td><td>3</td></tr><tr><td>User 3</td><td>4</td><td>3</td><td>4</td><td>3</td><td>5</td></tr><tr><td>User 4</td><td>3</td><td>3</td><td>1</td><td>5</td><td>4</td></tr></tbody></table><p>现在我们想预测User 1对Item 5的打分，就需要：</p><ol><li>计算Item 5和其他Item的相似度</li><li>找到和Item 5最相近的k个物品</li><li>根据User 1和最相近的k个物品的打分计算Item 5的得分</li></ol><p>示例代码和之前类似：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> cosine_similarity<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ItemBasedCF</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, ratings, k=<span class="hljs-number">5</span></span>):<br>        self.ratings = ratings<br>        self.k = k<br>        self.item_similarity = self.calculate_item_similarity()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_item_similarity</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> cosine_similarity(self.ratings.T)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_rating</span>(<span class="hljs-params">self, user_index, item_index</span>):<br>        similar_items = np.argsort(self.item_similarity[item_index])[-(self.k+<span class="hljs-number">1</span>):]<br>        similar_items = similar_items[similar_items != item_index]<br>        <br>        numerator = <span class="hljs-number">0</span><br>        denominator = <span class="hljs-number">0</span><br>        <br>        <span class="hljs-keyword">for</span> neighbor <span class="hljs-keyword">in</span> similar_items:<br>            <span class="hljs-keyword">if</span> self.ratings[user_index, neighbor] &gt; <span class="hljs-number">0</span>:<br>                numerator += self.item_similarity[item_index, neighbor] * self.ratings[user_index, neighbor]<br>                denominator += <span class="hljs-built_in">abs</span>(self.item_similarity[item_index, neighbor])<br>        <br>        <span class="hljs-keyword">if</span> denominator == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> numerator / denominator<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">recommend</span>(<span class="hljs-params">self, user_index, num_recommendations=<span class="hljs-number">5</span></span>):<br>        user_ratings = self.ratings[user_index]<br>        item_indices = np.where(user_ratings == <span class="hljs-number">0</span>)[<span class="hljs-number">0</span>]<br>        <br>        predictions = np.array([self.predict_rating(user_index, item) <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> item_indices])<br>        recommended_items = item_indices[np.argsort(predictions)[-num_recommendations:]]<br>        <br>        <span class="hljs-keyword">return</span> recommended_items<br></code></pre></td></tr></table></figure><p>同样的，先计算物品相似度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">item_cf.item_similarity<br><br>array([[<span class="hljs-number">1.</span>        , <span class="hljs-number">0.86506475</span>, <span class="hljs-number">0.65215465</span>, <span class="hljs-number">0.3030303</span> , <span class="hljs-number">0.11941629</span>],<br>       [<span class="hljs-number">0.86506475</span>, <span class="hljs-number">1.</span>        , <span class="hljs-number">0.74468592</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        ],<br>       [<span class="hljs-number">0.65215465</span>, <span class="hljs-number">0.74468592</span>, <span class="hljs-number">1.</span>        , <span class="hljs-number">0.32607733</span>, <span class="hljs-number">0.</span>        ],<br>       [<span class="hljs-number">0.3030303</span> , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.32607733</span>, <span class="hljs-number">1.</span>        , <span class="hljs-number">0.74635179</span>],<br>       [<span class="hljs-number">0.11941629</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.74635179</span>, <span class="hljs-number">1.</span>        ]])<br></code></pre></td></tr></table></figure><p>可以看到Item 5和Item 4最相似。随后计算得分的时候，分母是最相似的物品的用户打分*相似度，分母同样是相似度的绝对值加和。</p><h1 id="工业离线计算的技巧"><a href="#工业离线计算的技巧" class="headerlink" title="工业离线计算的技巧"></a>工业离线计算的技巧</h1><p>在实际工业中，如果要计算完整的物品相似度，计算量过大，因此需要用一些trick。通过将余弦相似度公式展开后发现，只有当用户A对需要对比的两个物品都打分时，相似度才不为0。因此在计算时需要对这些稀疏数据进行过滤。</p><h1 id="协同过滤的问题"><a href="#协同过滤的问题" class="headerlink" title="协同过滤的问题"></a>协同过滤的问题</h1><p>协同过滤的经典问题就是稀疏性问题，由于超过百分之80的数据都可能是Nan，数据质量并不好。</p><p>另一个问题是无法捕捉到物品本身的信息，仅仅使用了用户与物品的交互信息，而放弃了用户特征，物品特征，为了解决这个问题，工业界逐渐转向了使用逻辑回归之流的算法。</p><p>此外，热门的物品会和大量其他的物品出现相似性，这不是因为它们本身相似，只是因为它经常被购买。为了解决这个问题，出现了MF算法，使用隐向量表示物品。</p><p>第三个问题就是冷启动问题，对于没有历史信息的用户，找不到相似的用户进行推荐。</p><p>为了解决这几个问题，需要对一些热门物品进行惩罚，例如对热门商品或者活跃用户进行惩罚。</p><h1 id="什么时候用UserCF-ItemCF？"><a href="#什么时候用UserCF-ItemCF？" class="headerlink" title="什么时候用UserCF&#x2F;ItemCF？"></a>什么时候用UserCF&#x2F;ItemCF？</h1><p>摘抄一下：</p><ul><li><p>UserCF 由于是基于用户相似度进行推荐， 所以具备更强的社交特性， 这样的特点非常适于用户少， 物品多， 时效性较强的场合， 比如<strong>新闻推荐场景</strong>， 因为新闻本身兴趣点分散， 相比用户对不同新闻的兴趣偏好， 新闻的及时性，热点性往往更加重要， 所以正好适用于发现热点，跟踪热点的趋势。 另外还具有推荐新信息的能力， 更有可能发现惊喜, 因为看的是人与人的相似性, 推出来的结果可能更有惊喜，可以发现用户潜在但自己尚未察觉的兴趣爱好。</p><p>对于用户较少， 要求时效性较强的场合， 就可以考虑UserCF。</p></li><li><p>ItemCF 这个更适用于兴趣变化较为稳定的应用， 更接近于个性化的推荐， 适合物品少，用户多，用户兴趣固定持久， 物品更新速度不是太快的场合， 比如推荐艺术品， 音乐， 电影。</p></li></ul><p>2024&#x2F;7&#x2F;28 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>推荐系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SyncTV+AList+阿里云盘搭建服务器同步观影影院</title>
    <link href="/2024/06/30/SyncTV-Alist-%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%8C%E6%AD%A5%E8%A7%82%E5%BD%B1%E5%BD%B1%E9%99%A2/"/>
    <url>/2024/06/30/SyncTV-Alist-%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%8C%E6%AD%A5%E8%A7%82%E5%BD%B1%E5%BD%B1%E9%99%A2/</url>
    
    <content type="html"><![CDATA[<p>入职前的一周在家里好好休息了一阵，乘着这个功夫，我在阿里云服务器上部署了一些个人感觉比较有意思的服务，例如一个部署于服务器的一个视频播放直播间。</p><p>这个方案主要解决的是多人共同观影的问题。例如以前想要和对象一起看视频，都需要一起打开同一个网站，然后随时同步两个人的观看进度，这中间会出现两边网速不一致导致的卡顿，资源难获取的问题。而通过SyncTV这个项目能够构建一个平台，并在这个平台上实现的资源的共享和同步。</p><h1 id="部署SyncTV"><a href="#部署SyncTV" class="headerlink" title="部署SyncTV"></a>部署SyncTV</h1><p>部署SyncTV相当简单，只需要使用docker就可以快速部署：<code>docker run -d --name synctv -p 8080:8080 synctvorg/synctv</code>。</p><p>这会在服务器的8080端口启动服务，如果需要公网访问，那么需要在服务器的安全组策略设置端口的开放。默认进入这个地址，会出现一个登录界面。管理员账户名&#x2F;密码均为<code>root</code>。</p><p>登录之后，首页会显示为空。这时候就可以随意创建房间了。创建房间后，能够设置房间名，密码等等。</p><p><img src="/images/sync1.png"></p><p>创建完毕之后，就能够进入房间，并且在房间的界面里，能够添加各自形式的影片链接，包括Bilbil，通过添加Bv号，能够添加到影片列表。由于无法登录，播放的B站视频都是720p。</p><p><img src="/images/sync2.png"></p><p>至此，SyncTV顺利部署完成。</p><h1 id="部署AList"><a href="#部署AList" class="headerlink" title="部署AList"></a>部署AList</h1><p>AList是一个多存储的文件列表系统，它能够支持网盘的统一管理。通过这种方式就能够将网盘资源统一在一个服务里。通过将这个服务和SyncTV连接，能够实现直连网盘资源。</p><p>同样通过Docker进行部署：<code>docker run -d --restart=unless-stopped -v /etc/alist:/opt/alist/data -p 5244:5244 -e PUID=0 -e PGID=0 -e UMASK=022 --name=&quot;alist&quot; xhofe/alist:latest</code>。</p><p>随后需要进容器设置一下账户和密码：<code>docker exec -it alist ./alist admin random</code>，<code>docker exec -it alist ./alist admin set YourNewPassword</code></p><p>在后者需要将<code>YourNewPassword</code>设置为你想要的密码。</p><h2 id="在AList部署阿里云盘"><a href="#在AList部署阿里云盘" class="headerlink" title="在AList部署阿里云盘"></a>在AList部署阿里云盘</h2><p>通过访问<code>localhost:5244</code>，能够进入Alist的管理界面。注意同样需要设置端口的开放。</p><p><img src="/images/alist1.png"></p><p>进入存储，我们需要在这里配置阿里云盘的挂载。AList接入了阿里云盘的开发者API，因此能够获取到云盘中的资源。</p><p>我们需要配置的参数选项是以下几个：</p><ul><li>驱动</li><li>挂载路径</li><li>根文件夹ID</li><li>刷新令牌</li><li>Oauth令牌链接</li><li>移除方式</li></ul><p>其中驱动需要配置为<code>阿里云盘Open</code>。挂载路径可以配置为<code>/</code>，意为根目录。</p><p>根文件夹ID为阿里云盘的文件夹ID，打开阿里云盘官网，点击进入要设置的文件夹时点击 URL 后面的字符串，例如<code>https://www.alipan.com/drive/folder/5fe01e1830601baf774e4827a9fb8fb2b5bf7940</code>，这个文件夹的 file_id 即为 5fe01e1830601baf774e4827a9fb8fb2b5bf7940。</p><p>刷新令牌需要在<code>https://alist.nn.ci/tool/aliyundrive/request</code>获取，进入以后需要在里面扫描阿里云盘的二维码，扫描后会获得一长串Token。</p><p>接下来需要修改<code>Oauth令牌链接</code>为：<code>https://api.xhofe.top/alist/ali_open/token</code>。</p><p>保存后，通过访问服务器的5244端口，就能访问到云盘里的内容了。</p><p><img src="/images/alist2.png"></p><p>至此AList也部署完成了。</p><h1 id="SyncTV配置AList"><a href="#SyncTV配置AList" class="headerlink" title="SyncTV配置AList"></a>SyncTV配置AList</h1><p>最后一步是在SyncTV配置AList的账户，我们需要按照以下步骤进行执行：</p><ul><li>管理后台 –&gt; 点击用户名(root) –&gt; 平台绑定</li><li>AList –&gt; 添加账号</li><li>地址：<a href="http://127.0.0.1:5244/">http://127.0.0.1:5244</a> （127.0.0.1需要替换成你的服务器ip）</li><li>输入AList账号密码后点击登录</li></ul><p>此时进入SyncTV的房间，就能在添加影片中选择AList了。</p><p>2024&#x2F;6&#x2F;30 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>瞎折腾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>瞎折腾</tag>
      
      <tag>SyncTV</tag>
      
      <tag>Alist</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pyspark上手使用</title>
    <link href="/2024/06/25/Pyspark%E4%B8%8A%E6%89%8B%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/06/25/Pyspark%E4%B8%8A%E6%89%8B%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>前面复习了一下Spark一些的架构内容，这次复习一下上手Pyspark做一些数据处理。</p><p>上手之前看了一下文档，发现在Spark2.0之后，RDD的概念被Dataset取代了，Dataset也是一个分布式数据集，只不过做了一些底层的优化。</p><h1>简单Demo</h1><p>首先上手一个简单的Pyspark的Demo，对数据进行一些处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> SparkSession<br><span class="hljs-keyword">from</span> pyspark.sql.functions <span class="hljs-keyword">import</span> *<br><br>spark = SparkSession.builder.appName(<span class="hljs-string">&quot;CSV Loader&quot;</span>).getOrCreate()<br>df = spark.read.csv(<span class="hljs-string">&quot;train.csv&quot;</span>, header=<span class="hljs-literal">True</span>, inferSchema=<span class="hljs-literal">True</span>)<br><br>line_id_0 = df.<span class="hljs-built_in">filter</span>(df.<span class="hljs-built_in">id</span>==<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 需要show才能看到</span><br>line_id_0.show()<br><br><span class="hljs-comment"># 计算AveRooms字段的单词数，并显示</span><br><span class="hljs-comment"># select用于选择，size用于计算长度，split用于分割</span><br>df.select(size(split(df.AveRooms, <span class="hljs-string">&quot; &quot;</span>)).alias(<span class="hljs-string">&quot;num_words&quot;</span>)).show()<br><br><span class="hljs-comment"># 缓存</span><br>log_data = df.cache()<br>log_data.count()<br><br>log_data.select(<span class="hljs-string">&quot;id&quot;</span>,<span class="hljs-string">&quot;AveRooms&quot;</span>).show(<span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># 选择AveRooms列，并将其转换为一个列表</span><br>nums = log_data.select(<span class="hljs-string">&quot;AveRooms&quot;</span>).rdd.flatMap(<span class="hljs-keyword">lambda</span> x: x).collect()<br><span class="hljs-built_in">print</span>(nums)<br></code></pre></td></tr></table></figure><h1>流程解析</h1><p>分析一下上面的流程：</p><ul><li>首先需要实例化一个SparkSession对象，这是Spark所有功能的入口。例如：<ul><li><code>spark = SparkSession.builder.appName(&quot;CSV Loader&quot;).getOrCreate()</code>。</li></ul></li><li>随后，需要从一个数据源创建Spark中的DataFrame。例如：<ul><li><code>df = spark.read.csv(&quot;train.csv&quot;, header=True, inferSchema=True)</code>。</li><li><code>df = spark.read.json(&quot;examples/src/main/resources/people.json&quot;)</code>。</li></ul></li><li>在获取到DataFrame之后，能够进行一些基础的操作，例如查看Schema，展示数据，groupBy等操作。例如：<ul><li><code>df.printSchema()</code></li><li><code>df.select(&quot;name&quot;).show()</code></li><li><code>df.select(df['name'], df['age'] + 1).show()</code></li><li><code>df.filter(df['age'] &gt; 21).show()</code></li><li><code>df.groupBy(&quot;age&quot;).count().show()</code></li></ul></li><li>此外，能够直接执行一些SQL语句。例如：<ul><li><code>sqlDF = spark.sql(&quot;SELECT * FROM people&quot;)</code></li></ul></li><li>为了加速读取数据，能够对一些需要长期执行的数据进行缓存，这种方式能够将内存更合理的利用，例如：<ul><li><code>log_data = df.cache()</code></li></ul></li></ul><blockquote><p>Pyspark涵盖了多个接口，建议直接查看源码。路径是<code>examples/src/main/python</code></p></blockquote><p>2024/6/26 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Big Data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Spark</tag>
      
      <tag>Big Data</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Spark架构及基础概念</title>
    <link href="/2024/06/23/Spark%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    <url>/2024/06/23/Spark%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<p>毕业之后就再也没接触过Spark，印象里它的使用方法比较繁琐，所以基本忘光了。刚好工作中可能会接触到相关内容，因此借着休息这几天的空闲时间，复习一下相关内容。</p><h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><p>Spark 是一个通用数据处理引擎，用来进行数据处理任务，例如批处理、流处理、机器学习和图计算。</p><p>Spark和Hive的区别在于，Hive用于在离线数据的处理上，Spark 用于需要实时计算和处理的任务上。</p><blockquote><p>Hadoop和Spark的一个关键区别： Hadoop基于大数据的批处理。 这意味着数据会在一段时间内存储，然后使用Hadoop进行处理。 在Spark中，处理可以实时进行。</p></blockquote><p>Spark主要包含的组件是：</p><ul><li>Spark Core：基础通用执行引擎，其所有其他功能都是基于该平台执行的。</li><li>Spark SQL：Spark Core之上的一个组件，它引入了一种名为SchemaRDD的新数据抽象，提供对结构化和半结构化数据的支持。</li><li>Spark Streaming：利用Spark Core的快速调度功能来执行流式分析。它以小批量采集数据，并对这些小批量数据执行RDD（弹性分布式数据集）转换。</li><li>MLlib：Spark上的分布式机器学习框架。</li><li>GraphX：Spark上的分布式图形处理框架。</li></ul><h1 id="Spark架构"><a href="#Spark架构" class="headerlink" title="Spark架构"></a>Spark架构</h1><p>以下是Spark的架构图：</p><p><img src="https://static001.geekbang.org/infoq/6a/6a017f614dd45c2434cdeb2ef203e07d.png"></p><p>Spark的主要组件包括：</p><ul><li>Spark Driver：即运行Application的main函数并创建SparkContext，创建SparkContext的目的是为了准备Spark应用程序的运行环境。在Spark中由SparkContext负责与Cluster Manager通信，进行资源申请、任务的分配和监控等，当Executor部分运行完毕后，Driver同时负责将SparkContext关闭。</li><li>Cluster Manager：控制整个集群，负责监控Worker。</li><li>Worker：集群中任何一个物理节点，可以在上面启动Executor进程。</li><li>Spark Executors：在每个Worker上为某应用启动的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个任务都有各自独立的Executor。</li><li>Task：被发送到Executor上的工作单元。每个Task负责计算一个分区的数据。</li></ul><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>RDD是Spark中最重要的概念，被称为弹性分布式数据集。这是一个分布式的数据集合，弹性且分布式。它允许在执行多个查询时将工作集缓存在内存中，后续的查询能够重用工作集，这样就能极大的提升查询速度。之所以需要RDD，是因为这个结构能够加速MapReduce这一过程。</p><p>RDD是一个抽象的概念，能够通过几种方式创建：</p><ol><li>从数据源读取</li><li>将已有的集合并行化为RDD</li><li>将已有的RDD通过转换（Transformations）生成新的RDD。</li></ol><p>RDD支持两个操作：</p><ol><li>转换（Transformations）：从现有的RDD创建新的RDD，例如map, filter, join等。</li><li>行动（Actions）：用于触发计算，并返回结果到Driver或存储到外部存储系统，例如collect，count，reduce等。</li></ol><blockquote><p>我的理解是，RDD是Spark中最底层的数据结构，也就是任何操作，都应该是对RDD进行处理，因此在任何操作之前都应包含RDD的初始化。</p></blockquote><p>以下是一段简单的示例代码，用pyspark实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pyspark <span class="hljs-keyword">import</span> SparkContext<br><br><span class="hljs-comment"># 创建 SparkContext，local指Spark运行在本地模式，后者指定应用程序的名称</span><br>sc = SparkContext(<span class="hljs-string">&quot;local&quot;</span>, <span class="hljs-string">&quot;RDD Example&quot;</span>)<br><br><span class="hljs-comment"># 从本地集合创建 RDD</span><br>data = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>rdd = sc.parallelize(data)<br><br><span class="hljs-comment"># 转换操作：将每个元素乘以 2</span><br>rdd2 = rdd.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: x * <span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 行动操作：收集结果</span><br>result = rdd2.collect()<br><br><span class="hljs-comment"># 输出结果</span><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>上面这段代码，首先创建了Context，用来启动Spark应用程序。</p><p>随后创建了一个RDD，并使用map方法对这个RDD进行了转换操作。</p><p>最后使用一个行动操作，用collect获取最后的结果。</p><h1 id="Spark运行流程"><a href="#Spark运行流程" class="headerlink" title="Spark运行流程"></a>Spark运行流程</h1><ol><li>为应用构建起基本的运行环境，由Driver创建一个SparkContext进行资源的申请、任务的分配和监控。</li><li>资源管理器为Executor分配资源，并启动Executor进程。</li><li>SparkContext根据RDD的依赖关系构建DAG图，DAG图提交给DAGScheduler解析成Stage，然后把一个个TaskSet提交给底层调度器TaskScheduler处理。</li><li>Executor向SparkContext申请Task，TaskScheduler将Task发放给Executor运行并提供应用程序代码。</li><li>Task在Executor上运行把执行结果反馈给TaskScheduler，然后反馈给DAGScheduler，运行完毕后写入数据并释放所有资源。</li></ol><p>2024&#x2F;6&#x2F;25 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Big Data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Spark</tag>
      
      <tag>Big Data</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>为什么文本相似度使用余弦相似度？</title>
    <link href="/2024/06/22/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%BD%BF%E7%94%A8%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%9F/"/>
    <url>/2024/06/22/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%BD%BF%E7%94%A8%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<p>最近离职了，刚好有时间研究一些之间没有钻研过的内容。某天洗澡的时候忽然想到余弦相似度的问题，为什么它在NLP中广泛被使用，这次研究一下。</p><p>余弦相似度主要体现的是两个向量在方向上的差异，而对它们的模大小不做要求。计算公式是：$ \text{cosine_similarity}(\mathbf{A}, \mathbf{B}) &#x3D; \frac{\mathbf{A} \cdot \mathbf{B}}{|\mathbf{A}| |\mathbf{B}|} $。</p><p>不用向量的大小来计算相似度有一个好处，如果我们有两个文档，其中一个文档中的Token多，另一个Token少，那么内容多的文档，向量的大小会比内容少的文档的向量更大，如果使用向量大小作为相似度的计算参数之一，可能会导致计算出来的相似度差距过大，而这并不代表两个文档并不相似。</p><p>与之对比的是欧式距离，也就是两个向量的距离上的绝对差异。它体现的是两者之间距离相近的程度。</p><blockquote><p>假如有两个向量，两个人对APP的使用次数与使用时长分别表示为(1,10)和(10,100)。它们的余弦相似度较小，代表这两个人的行为是相同的，然而事实是不同的，两个人的活跃度有着极大的差异，第二个人的活跃度更高，这时就需要使用欧氏距离进行对比。</p><p>不过欧式距离也会收到度量的影响。例如当用户1给Item1和Item2分别打分2和4分，用户2给Item1和Item2分别打分4和8分。两者的打分尺度并不一致，这时使用欧式距离计算两个用户的相似度会无法得到有效的结果，就需要进行标准化。</p></blockquote><blockquote><p>另外，当向量进行归一化后，欧式距离与余弦相似度存在转换关系$ \text{euc}(a, b) &#x3D; 2 \left( 1 - \cos(a, b) \right) $。这其实能说明一定它们之间的关系。</p></blockquote><p><strong>点积</strong></p><p>上面说的余弦相似度完全不考虑向量的长度，事实上能够使用点积来将向量长度的信息一起涵盖入相似度的计算。点积的计算公式是向量夹角的余弦值乘以两个向量的长度得到。当两个向量完全相同时，点积达到最大值。当两者垂直时，点积为0。</p><blockquote><p>点积如何影响相似度度量？</p><p>例如正在计算一组研究论文的相似度。研究论文嵌入向量的长度与被引用次数成正比。</p><p>高被引次数(较长的向量)的论文与其他高被引论文的点积相似度得分更高，因为它们的量级对结果的贡献更大。低被引次数(较短的向量)的论文与高被引次数的论文的点积相似度得分较低，因为它们的量级较小。</p></blockquote><p><strong>高维空间与维度灾难</strong></p><p>随着维度的增长，向量之间的差距会逐渐减小，这时候相似度会趋向于零，导致计算相似度的意义不大。这种情况被称为维度灾难。</p><p>根据定义，维度灾难指<code>对于已知样本数目，存在一个特征数目的最大值，当实际使用的特征数目超过这个最大值时，分类器的性能不是得到改善，而是退化，这一现象被命名为Hughes影响或Hughes现象。</code>这也是为什么高维下，相似度计算的作用会被无限降低。发现这一现象后，出现了一系列降维算法，这就是后话了。</p><p>不过，在高维下，余弦相似度的计算比欧式距离的效果要更好，这就是为什么在嵌入向量的计算中更多的使用余弦相似度。</p><blockquote><p>还有另外一种解释，是从模型训练的角度出发解释维度灾难：在训练样本的时候，在样本数目不变的情况下，随着维度的增高，我们的模型效果会随着维度的增高而降低。也就是说，如果想要达到相同的模型效果，在使用高维度时所需要的样本数量要比低维度的样本数量大的多。</p></blockquote><p><strong>从深度学习思考余弦相似度</strong></p><p>知乎上有一个答主提到了一点，假如我们有一个分类模型，并且用于一个线性层作为最终输出的分类头，我们可以看到，实际上这个线性层在做的事就是将权重和输入的嵌入做点积计算，这和余弦相似度是一致的。</p><blockquote><p>你可以理解训练一个分类模型的过程（已有特征提取的话）就是为每一个类都学出来一个这个类的embedding（线性层的w）。</p></blockquote><p>2024&#x2F;6&#x2F;22 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Data Mining： Kaggle Playground S4 Ep5</title>
    <link href="/2024/06/15/Data-Mining%EF%BC%9A-Kaggle-Playground-S4-Ep5/"/>
    <url>/2024/06/15/Data-Mining%EF%BC%9A-Kaggle-Playground-S4-Ep5/</url>
    
    <content type="html"><![CDATA[<p>工作之后大概有十个月没碰Kaggle，最近打算重新捡起，因此先从最近的Playground开始慢慢热手。</p><p>S4 Ep5的主题是洪水回归预测（Regression with a Flood Prediction Dataset），要求基于一系列特征预测未来是否会发生洪水。</p><h1>数据集展示</h1><p>训练数据集中包含21个特征，目标变量是<code>FloodProbability</code>，一个概率值。评估指标是R2。</p><p>打印一下看看：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>df_train = pd.read_csv(<span class="hljs-string">&#x27;/kaggle/input/playground-series-s4e5/train.csv&#x27;</span>)<br>df_train.head()<br></code></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">id</th><th style="text-align:left">MonsoonIntensity</th><th style="text-align:left">TopographyDrainage</th><th style="text-align:left">RiverManagement</th><th style="text-align:left">Deforestation</th><th style="text-align:left">Urbanization</th><th style="text-align:left">ClimateChange</th><th style="text-align:left">DamsQuality</th><th style="text-align:left">Siltation</th><th style="text-align:left">AgriculturalPractices</th><th style="text-align:left">…</th><th style="text-align:left">DrainageSystems</th><th style="text-align:left">CoastalVulnerability</th><th style="text-align:left">Landslides</th><th style="text-align:left">Watersheds</th><th style="text-align:left">DeterioratingInfrastructure</th><th style="text-align:left">PopulationScore</th><th style="text-align:left">WetlandLoss</th><th style="text-align:left">InadequatePlanning</th><th style="text-align:left">PoliticalFactors</th><th style="text-align:left">FloodProbability</th><th></th></tr></thead><tbody><tr><td style="text-align:left">0</td><td style="text-align:left">0</td><td style="text-align:left">5</td><td style="text-align:left">8</td><td style="text-align:left">5</td><td style="text-align:left">8</td><td style="text-align:left">6</td><td style="text-align:left">4</td><td style="text-align:left">4</td><td style="text-align:left">3</td><td style="text-align:left">3</td><td style="text-align:left">…</td><td style="text-align:left">5</td><td style="text-align:left">3</td><td style="text-align:left">3</td><td style="text-align:left">5</td><td style="text-align:left">4</td><td style="text-align:left">7</td><td style="text-align:left">5</td><td style="text-align:left">7</td><td style="text-align:left">3</td><td>0.445</td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">1</td><td style="text-align:left">6</td><td style="text-align:left">7</td><td style="text-align:left">4</td><td style="text-align:left">4</td><td style="text-align:left">8</td><td style="text-align:left">8</td><td style="text-align:left">3</td><td style="text-align:left">5</td><td style="text-align:left">4</td><td style="text-align:left">…</td><td style="text-align:left">7</td><td style="text-align:left">2</td><td style="text-align:left">0</td><td style="text-align:left">3</td><td style="text-align:left">5</td><td style="text-align:left">3</td><td style="text-align:left">3</td><td style="text-align:left">4</td><td style="text-align:left">3</td><td>0.450</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">6</td><td style="text-align:left">5</td><td style="text-align:left">6</td><td style="text-align:left">7</td><td style="text-align:left">3</td><td style="text-align:left">7</td><td style="text-align:left">1</td><td style="text-align:left">5</td><td style="text-align:left">4</td><td style="text-align:left">…</td><td style="text-align:left">7</td><td style="text-align:left">3</td><td style="text-align:left">7</td><td style="text-align:left">5</td><td style="text-align:left">6</td><td style="text-align:left">8</td><td style="text-align:left">2</td><td style="text-align:left">3</td><td style="text-align:left">3</td><td>0.530</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left">3</td><td style="text-align:left">3</td><td style="text-align:left">4</td><td style="text-align:left">6</td><td style="text-align:left">5</td><td style="text-align:left">4</td><td style="text-align:left">8</td><td style="text-align:left">4</td><td style="text-align:left">7</td><td style="text-align:left">6</td><td style="text-align:left">…</td><td style="text-align:left">2</td><td style="text-align:left">4</td><td style="text-align:left">7</td><td style="text-align:left">4</td><td style="text-align:left">4</td><td style="text-align:left">6</td><td style="text-align:left">5</td><td style="text-align:left">7</td><td style="text-align:left">5</td><td>0.535</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left">4</td><td style="text-align:left">5</td><td style="text-align:left">3</td><td style="text-align:left">2</td><td style="text-align:left">6</td><td style="text-align:left">4</td><td style="text-align:left">4</td><td style="text-align:left">3</td><td style="text-align:left">3</td><td style="text-align:left">3</td><td style="text-align:left">…</td><td style="text-align:left">2</td><td style="text-align:left">2</td><td style="text-align:left">6</td><td style="text-align:left">6</td><td style="text-align:left">4</td><td style="text-align:left">1</td><td style="text-align:left">2</td><td style="text-align:left">3</td><td style="text-align:left">5</td><td>0.415</td></tr></tbody></table><h2 id="目标分布">目标分布</h2><p>初始的特征主要是一些环境/城市化相关的特征，我们观察一下目标变量的分布。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">2</span>))<br>plt.hist(train.FloodProbability, bins=np.linspace(<span class="hljs-number">0.2825</span>, <span class="hljs-number">0.7275</span>, <span class="hljs-number">90</span>), density=<span class="hljs-literal">True</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;density&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;FloodProbability&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/images/pgs4e5_1.png" alt=""></p><p>目标变量是一个离散值，然而只有83个Unique values，范围在0.285至0.725。且所有数值都是0.005的倍数。</p><p><strong>目标变量属于泊松分布</strong></p><p>使用单样本 K-S 检验能够检验样本是否来自某一分布。我们使用 <code>scipy.stats</code> 包中的 <code>ks_2samp</code> 函数来执行 Kolmogorov-Smirnov 检验，并使用 <code>numpy</code> 来生成泊松分布随机样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">target_data = df_train[<span class="hljs-string">&#x27;FloodProbability&#x27;</span>]<br><br><span class="hljs-comment"># 计算目标变量的均值作为泊松分布的 lambda</span><br>lambda_val = target_data.mean()<br><br><span class="hljs-comment"># 生成与目标变量相同大小的泊松分布样本</span><br>poisson_sample = np.random.poisson(lam=lambda_val, size=<span class="hljs-built_in">len</span>(target_data))<br><br><span class="hljs-comment"># 进行 K-S 检验</span><br>d_statistic, p_value = ks_2samp(target_data, poisson_sample)<br><br><span class="hljs-comment"># 打印结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;K-S test: D-statistic = <span class="hljs-subst">&#123;d_statistic&#125;</span>, p-value = <span class="hljs-subst">&#123;p_value&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 判断是否符合泊松分布</span><br><span class="hljs-keyword">if</span> p_value &gt; <span class="hljs-number">0.05</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;无法拒绝零假设，目标变量可能符合泊松分布。&quot;</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;拒绝零假设，目标变量不符合泊松分布。&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="特征分布">特征分布</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">features = df_train.drop(<span class="hljs-string">&#x27;FloodProbability&#x27;</span>,axis=<span class="hljs-number">1</span>).columns<br>_, axs = plt.subplots(<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">12</span>))<br><span class="hljs-keyword">for</span> col, ax <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(features, axs.ravel()):<br>    vc = train[col].value_counts() / <span class="hljs-built_in">len</span>(train)<br>    ax.bar(vc.index, vc)<br>    vc = test[col].value_counts() / <span class="hljs-built_in">len</span>(test)<br>    ax.bar(vc.index, vc, alpha=<span class="hljs-number">0.6</span>)<br>    ax.set_title(col)<br>    ax.xaxis.set_major_locator(MaxNLocator(integer=<span class="hljs-literal">True</span>)) <span class="hljs-comment"># only integer labels</span><br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/images/pgs4e5_2.png" alt=""></p><p>大部分特征都呈现右偏分布，即长尾出现在右边。此外，所有特征都是离散值。</p><h2 id="相关性">相关性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">cc = np.corrcoef(train[corr_features], rowvar=<span class="hljs-literal">False</span>)<br>plt.figure(figsize=(<span class="hljs-number">11</span>, <span class="hljs-number">11</span>))<br>sns.heatmap(cc, center=<span class="hljs-number">0</span>, annot=<span class="hljs-literal">True</span>, fmt=<span class="hljs-string">&#x27;.1f&#x27;</span>,<br>            xticklabels=corr_features, yticklabels=corr_features)<br>plt.title(<span class="hljs-string">&#x27;Correlation matrix&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/images/pgs4e5_3.png" alt=""></p><p>从相关系数上来看，特征之间没有相关性，但所有特征都与目标相关。</p><h2 id="共线性">共线性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> statsmodels.stats.outliers_influence <span class="hljs-keyword">import</span> variance_inflation_factor<br><span class="hljs-keyword">from</span> statsmodels.tools.tools <span class="hljs-keyword">import</span> add_constant<br><br>df_train_with_const = add_constant(df_train) <br><br>vif_data = pd.DataFrame()<br>vif_data[<span class="hljs-string">&quot;feature&quot;</span>] = df_train_with_const.columns<br>vif_data[<span class="hljs-string">&quot;VIF&quot;</span>] = [variance_inflation_factor(df_train_with_const.values, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(df_train_with_const.shape[<span class="hljs-number">1</span>])]<br><br><span class="hljs-built_in">print</span>(vif_data)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">                            feature         VIF<br><span class="hljs-number">0</span>                             const  <span class="hljs-number">152.517829</span><br><span class="hljs-number">1</span>                                <span class="hljs-built_in">id</span>    <span class="hljs-number">1.000011</span><br><span class="hljs-number">2</span>                  MonsoonIntensity    <span class="hljs-number">1.331574</span><br><span class="hljs-number">3</span>                TopographyDrainage    <span class="hljs-number">1.348860</span><br><span class="hljs-number">4</span>                   RiverManagement    <span class="hljs-number">1.343868</span><br><span class="hljs-number">5</span>                     Deforestation    <span class="hljs-number">1.338782</span><br><span class="hljs-number">6</span>                      Urbanization    <span class="hljs-number">1.347294</span><br><span class="hljs-number">7</span>                     ClimateChange    <span class="hljs-number">1.338716</span><br><span class="hljs-number">8</span>                       DamsQuality    <span class="hljs-number">1.346030</span><br><span class="hljs-number">9</span>                         Siltation    <span class="hljs-number">1.338225</span><br><span class="hljs-number">10</span>            AgriculturalPractices    <span class="hljs-number">1.339117</span><br><span class="hljs-number">11</span>                    Encroachments    <span class="hljs-number">1.346542</span><br><span class="hljs-number">12</span>  IneffectiveDisasterPreparedness    <span class="hljs-number">1.343053</span><br><span class="hljs-number">13</span>                  DrainageSystems    <span class="hljs-number">1.340917</span><br><span class="hljs-number">14</span>             CoastalVulnerability    <span class="hljs-number">1.351291</span><br><span class="hljs-number">15</span>                       Landslides    <span class="hljs-number">1.343013</span><br><span class="hljs-number">16</span>                       Watersheds    <span class="hljs-number">1.345418</span><br><span class="hljs-number">17</span>      DeterioratingInfrastructure    <span class="hljs-number">1.334803</span><br><span class="hljs-number">18</span>                  PopulationScore    <span class="hljs-number">1.346067</span><br><span class="hljs-number">19</span>                      WetlandLoss    <span class="hljs-number">1.339142</span><br><span class="hljs-number">20</span>               InadequatePlanning    <span class="hljs-number">1.340360</span><br><span class="hljs-number">21</span>                 PoliticalFactors    <span class="hljs-number">1.348455</span><br><span class="hljs-number">22</span>                 FloodProbability    <span class="hljs-number">6.449539</span><br></code></pre></td></tr></table></figure><p>检查一下共线性。通常来说，VIF小于5，都可以认为共线性没有那么大的影响。VIF超过10时就需要处理一下特征。这里大部分特征之间都没有共线性，因此无需处理。</p><p>这一点也可以通过PCA分析来进行确认：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">pca = PCA()<br>pca.fit(train[features])<br>plt.figure(figsize=(<span class="hljs-number">3</span>, <span class="hljs-number">2.5</span>))<br>plt.plot(pca.explained_variance_ratio_.cumsum())<br>plt.gca().xaxis.set_major_locator(MaxNLocator(integer=<span class="hljs-literal">True</span>)) <span class="hljs-comment"># only integer labels</span><br>plt.title(<span class="hljs-string">&#x27;Principal Components Analysis&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;component#&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;explained variance ratio&#x27;</span>)<br>plt.yticks([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>])<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/images/pgs4e5_4.png" alt=""></p><p>基本上是一条直线，没有显著的特征能够解释大部分方差。</p><h1>特征工程</h1><p>一些社区内的特征工程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">transform</span>(<span class="hljs-params">dataframe: pd.DataFrame</span>) -&gt; pd.DataFrame:<br>    df_copy = dataframe.copy()<br>    features = df_copy.columns.tolist()<br><br>    <span class="hljs-comment"># 计算所有特征的平均值，并乘以 0.1</span><br>    df_copy[<span class="hljs-string">&#x27;mean_features&#x27;</span>] = <span class="hljs-number">0.1</span> * df_copy[features].mean(axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算所有特征的标准差</span><br>    df_copy[<span class="hljs-string">&#x27;std_features&#x27;</span>] = df_copy[features].std(axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算所有特征的最大值</span><br>    df_copy[<span class="hljs-string">&#x27;max_features&#x27;</span>] = df_copy[features].<span class="hljs-built_in">max</span>(axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算所有特征的最小值</span><br>    df_copy[<span class="hljs-string">&#x27;min_features&#x27;</span>] = df_copy[features].<span class="hljs-built_in">min</span>(axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算所有特征的中位数，并乘以 0.1</span><br>    df_copy[<span class="hljs-string">&#x27;median_features&#x27;</span>] = <span class="hljs-number">0.1</span> * df_copy[features].median(axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 假设 NUMERIC_COLS 是一个包含数值列名的列表</span><br>    <span class="hljs-comment"># 计算数值列的总和</span><br>    NUMERIC_COLS = features  <span class="hljs-comment"># 如果所有列都是数值列</span><br>    df_copy[<span class="hljs-string">&#x27;sum_features&#x27;</span>] = df_copy[NUMERIC_COLS].<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 排序数值列并创建新列</span><br>    sorted_features = [<span class="hljs-string">f&#x27;sort_<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> np.arange(<span class="hljs-built_in">len</span>(NUMERIC_COLS))]<br>    df_copy[sorted_features] = np.sort(df_copy[NUMERIC_COLS], axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算四分位数</span><br>    df_copy[<span class="hljs-string">&#x27;q1&#x27;</span>] = df_copy[features].quantile(<span class="hljs-number">0.25</span>, axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;q2&#x27;</span>] = df_copy[features].quantile(<span class="hljs-number">0.50</span>, axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;q3&#x27;</span>] = df_copy[features].quantile(<span class="hljs-number">0.75</span>, axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 删除原始特征列</span><br>    df_copy = df_copy.drop(features, axis=<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-comment"># 一些特征交叉</span><br>    df_copy[<span class="hljs-string">&#x27;ClimateAnthropogenicInteraction&#x27;</span>] = (df[<span class="hljs-string">&#x27;MonsoonIntensity&#x27;</span>] + df[<span class="hljs-string">&#x27;ClimateChange&#x27;</span>]) * (df[<span class="hljs-string">&#x27;Deforestation&#x27;</span>] + df[<span class="hljs-string">&#x27;Urbanization&#x27;</span>] + df[<span class="hljs-string">&#x27;AgriculturalPractices&#x27;</span>] + df[<span class="hljs-string">&#x27;Encroachments&#x27;</span>])<br>    df_copy[<span class="hljs-string">&#x27;InfrastructurePreventionInteraction&#x27;</span>] = (df[<span class="hljs-string">&#x27;DamsQuality&#x27;</span>] + df[<span class="hljs-string">&#x27;DrainageSystems&#x27;</span>] + df[<span class="hljs-string">&#x27;DeterioratingInfrastructure&#x27;</span>]) * (df[<span class="hljs-string">&#x27;RiverManagement&#x27;</span>] + df[<span class="hljs-string">&#x27;IneffectiveDisasterPreparedness&#x27;</span>] + df[<span class="hljs-string">&#x27;InadequatePlanning&#x27;</span>])<br><br>    <span class="hljs-comment"># 计算统计特征</span><br>    df_copy[<span class="hljs-string">&#x27;sum&#x27;</span>] = df[features].<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;std&#x27;</span>] = df[features].std(axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;mean&#x27;</span>] = df[features].mean(axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;max&#x27;</span>] = df[features].<span class="hljs-built_in">max</span>(axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;min&#x27;</span>] = df[features].<span class="hljs-built_in">min</span>(axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;mode&#x27;</span>] = df[features].mode(axis=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 注意：mode 返回的是 DataFrame，需要取第一个值</span><br>    df_copy[<span class="hljs-string">&#x27;median&#x27;</span>] = df[features].median(axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;skew&#x27;</span>] = df[features].skew(axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;kurt&#x27;</span>] = df[features].kurt(axis=<span class="hljs-number">1</span>)<br>    df_copy[<span class="hljs-string">&#x27;entropy&#x27;</span>] = df[num_cols].apply(<span class="hljs-keyword">lambda</span> x: -<span class="hljs-number">1</span>*(x*np.log(x)).<span class="hljs-built_in">sum</span>(), axis=<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-keyword">return</span> df_copy<br><br></code></pre></td></tr></table></figure><p>2024/6/15 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>数据挖掘</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kaggle</tag>
      
      <tag>数据挖掘</tag>
      
      <tag>特征工程</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Why Decoder-Only Instead of Encoder-Only?</title>
    <link href="/2024/06/12/Why-Decoder-Only-Instead-of-Encoder-Only/"/>
    <url>/2024/06/12/Why-Decoder-Only-Instead-of-Encoder-Only/</url>
    
    <content type="html"><![CDATA[<p>为什么现在的语言模型都采用Decoder Only的架构？这是一道经典面试题，这次整理一下做一个记录。</p><p>首先话不多说，先上Transformer架构图：</p><p><img src="/images/transformer.png"></p><p>我们把处理模型输入的模型叫做Encoder，生成输出的模型叫做Decoder。Transformer的具体架构细节无需赘言，左侧是编码器Encoder，右侧是解码器Decoder。我们可以看到，去除掉网络尾部的前馈层，Decoder只比Encoder多了一个Masked后的多头注意力，也就是通过上三角矩阵遮掩掉一部分未来的信息。这时候问题就转变为，为什么语言模型都需要Masked的多头注意力？</p><p><strong>文本生成</strong></p><p>首先，需要明确的是，Encoder在整个网络的架构中，负责将输入的信息转化为高维的内部表示，而Decoder负责根据这个内部表示，生成下一个概率最大的Token。从两者任务上来看，生成式语言模型更加关注于后者的生成特性，对于前者的编码特性并不是那么关注。</p><p>与之相对的是经典的Bert，被用来做文本分类，情感分析等任务。它的架构是Encoder Only，由于它的任务更专注于输出的信息，因此它并不用来生成文本。</p><p>而从语言学的角度来看，我们在每次说话的时候，每说出一个字，都需要考虑到前面已经说出的内容，而非完整内容，这也是为什么需要Mask的原因。</p><p><strong>训练与推理效率</strong></p><p>由于每次只生成下一个Token的特性，语言模型每次生成，都需要完整单独执行一遍模型推理，去除Encoder也是为了计算效率的考究。如果只需要输入的高维表示，则Encoder自身的Embedding层已经足矣。减少了一半的参数，这样在训练和推理时都大大减少了计算复杂度和空间复杂度。</p><p><strong>低秩</strong></p><p>这个想法来自于苏剑林老师，Attention矩阵由一个𝑛×𝑑的矩阵与𝑑×𝑛的矩阵相乘后再加上softmax来得到，由于其中的𝑛远大于𝑑，因此可以认为这个矩阵中有很多无意义的部分。而Decoder中的Attention矩阵经过Mask，变成了下三角矩阵，三角阵的行列式等于对角线元素之积，由于softmax的存在，对角线必然都是正数，所以它的行列式必然是正数，即Decoder-only架构的Attention矩阵一定是满秩的。</p><blockquote><p>其中𝑛是序列长度，𝑑是head_size，在多头注意力中，head_size &#x3D; hidden_size &#x2F; heads，比如BERT base中head_size &#x3D; 768 &#x2F; 12 &#x3D; 64，而预训练长度𝑛一般为512，所以𝑛≫𝑑大致上都是成立的。</p></blockquote><p>满秩说明信息更被充分利用，因此理论上表达能力更强。</p><div class="note note-success">            <p>总结一下，使用Decoder的原因主要如下：</p><ul><li>Encoder的Attention存在低秩问题</li><li>工程上Decoder Only的参数量和推理成本更佳</li></ul>          </div><p>最后，把早先我发在脉脉上的帖子再复制一遍放在这里：</p><hr><p>解码器能用在大语言模型上吗？查阅了资料总结了一下：</p><ol><li>只有编码器的模型通常预训练任务都是学习输入语言的表示，比如通过上下文，判断缺失的单词部分，做完形填空和预测句子对，因此不太适合用于生成语言任务（因为生成语言任务中没有下文，只有上文）</li><li>GLM是在解码器的基础上加上了Prefix掩码，这个Prefix的思想来源于Encoder模型</li><li>也有用同时使用编码器-解码器的语言模型（T5），但是从运行效率上，参数量多了一倍，推理和训练速度都会增加</li><li>从训练角度分析，纯解码器模型在训练后，zeroshot的生成任务效果更好，也更符合对话模型causal model的任务逻辑。而编码-解码器需要在子任务上微调才可以表现更好（因为本身预训练的时候就需要在有上下文，所以一般只用它的思想，也就是在解码器模型上加掩码）</li></ol><p>2024&#x2F;6&#x2F;12 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>时间是最漫长的毒药</title>
    <link href="/2024/06/10/%E6%97%B6%E9%97%B4%E6%98%AF%E6%9C%80%E6%BC%AB%E9%95%BF%E7%9A%84%E6%AF%92%E8%8D%AF/"/>
    <url>/2024/06/10/%E6%97%B6%E9%97%B4%E6%98%AF%E6%9C%80%E6%BC%AB%E9%95%BF%E7%9A%84%E6%AF%92%E8%8D%AF/</url>
    
    <content type="html"><![CDATA[<p>去年年底刚回国的时候，我的发小田恬约我吃了一顿饭。距离上一次碰面又过去了六年，本来是有点事需要改日再约，后来想想还是要去。田恬说再过半年要办婚礼了，邀请我去参加，我说好。</p><p>我跟田恬，老谭从小一起长大，我们都在同一个幼儿园，又在同一个市实验小学，之后又都在立达中学。由于家住的很近，我们从小就会呆在一起玩，家长之间的关系也很近。</p><p>我的奶奶当时是语文老师，周末经常带我们写作文。我们写完作文，就会跑到老谭家里打电脑。当时我们经常玩一款教过山车大亨的游戏，老谭的爸爸妈妈会给我们炸串吃。印象里我特别喜欢吃他们做的里脊肉。田恬的父母记忆里似乎是医生，她的爸爸也特别有趣，偶尔和我们开玩笑也会让我们哈哈大笑。</p><p>小学那段时间是记忆里我很快乐的一段时间，当时爷爷的身体还很好，家里的条件也都很不错。我们每天上学，周末一起玩，感觉可以一直这么走下去。</p><p>我们一起度过了小学，到了初中分了班，我们的接触就慢慢少了。再到了高中就更少了。老谭和田恬的成绩很好，去了当时苏州最好的苏高中，而我当时成绩并不理想，兜兜转转下去了苏州十中。</p><p>匆匆度过高中，我们跟老谭离开了苏州，田恬留在了苏州大学。从那以后，我们就很少见了，就连微信都很少联系。从前我觉得分别很可怕，但是实际上真正的离别在不知不觉间就发生了。</p><p>有人说：选择了一座城市，就选择了一种生活方式。我们沿着各自的生活往前走，而这条路上并没有太多与老友的交汇点。</p><p>19年的时候，我回了一次国，跟老谭和田恬碰了一次头。我们不咸不淡的交流着近况，当时我应该还在读大三，而他们俩正在准备赴美留学的事。在那之后就是疫情，不知不觉间，又过去了五年。老谭留在了美国大厂做后端，田恬在上海做募投，而我辗转多年又回到苏州。</p><p>田恬跟我碰杯说，也只有这个机会才能让大家聚在一起。老谭这次在美国上班没有办法过来，但是他留下了祝福的视频。</p><p>惊喜的是又遇到了老谭的爸妈，也见到了田恬的爸妈。他们和我记忆中的样子一样，几乎没有改变。谭叔叔热情的招呼我，和我合影加微信。他说差点没认出我来，我说叔叔倒是没有什么变化。我们絮絮叨叨聊了很久，聊到小时候小朋友之间的事，又聊到疫情和现在。他说现在国内大环境不好，建议我多考虑考虑外面的机会。我说我很想念当时炸的里脊肉，叔叔哈哈说，当时就喜欢给我们这群小孩子炸东西吃。</p><p>婚礼上，司仪祝福下，田恬和她的新郎肩并肩站在一起，大家纷纷站起来鼓掌，我也一样。此时距离我们刚认识已经过去了二十多年。我的爷爷在十年前就生病卧床不起，原先的房子也早已闲置多年，积满了灰尘和杂物。随着家里逐渐衰败，我越来越少的向外倾诉，也很少表达自己的情绪。而在熙熙攘攘的婚礼现场，我却真真切切的感受到鼻子的酸意。</p><p>那来自透过铺满灰尘的漫长二十年岁月，稚嫩儿童传来的悠悠目光。</p><p>我举起酒杯，敬田恬，敬老谭，敬自己，也敬岁月。</p><p>2024&#x2F;6&#x2F;10 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据库应用：WSL-HIVE的部署</title>
    <link href="/2024/06/09/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BA%94%E7%94%A8%EF%BC%9AWSL-HIVE%E7%9A%84%E9%83%A8%E7%BD%B2/"/>
    <url>/2024/06/09/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BA%94%E7%94%A8%EF%BC%9AWSL-HIVE%E7%9A%84%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>最近开始重新捡起一些数据库相关的知识，以前学习的内容差不多忘完了，这次刚好算作温习一下。这篇博文记录如何在WSL中部署Apache Hive。</p><h1 id="Map-Reduce"><a href="#Map-Reduce" class="headerlink" title="Map-Reduce"></a>Map-Reduce</h1><p>要了解Hive，首先要了解Hadoop。要了解Hadoop，就需要先了解Map-Reduce。</p><p>Map-Reduce来源于谷歌公司发表于2004的一篇论文。它要解决的是传统数据库中无法解决的大数据量的场景。在过去，传统的关系型数据库中，数据都保存在单机上，随着数据量的增大，只能通过扩展单机配置来扩容。为了解决这个问题，就需要一个分布式框架，让多个主机能分开处理任务，这就是Map-Reduce产生的契机。</p><p>Map-Reduce是一个框架，它的工作流程包含两步：Map，Reduce。用户通过编写并行处理的程序，在每台节点上执行，来处理大量的数据。大体上来说，Map过程将数据分割为键值对，随后进行排序及分组，最后由Reduce进行合并，并输出最后的结果。</p><div class="note note-warning">            <p>MapReduce 优点<br>简化编程模型：开发者只需关注 Map 和 Reduce 函数的实现，并行化和分布式处理由框架处理。<br>扩展性：可以轻松扩展到数千台计算机，处理 PB 级别的数据。<br>容错性：框架自动处理任务失败和节点故障，确保任务顺利完成。</p>          </div><div class="note note-sucess">            <p>MapReduce 缺点<br>实时性差：需要进行多次磁盘 I&#x2F;O 操作，MapReduce 适合批处理，不适合实时数据处理。<br>效率较低：对于某些计算密集型任务的性能不行。</p>          </div><pre><code class="mermaid" >graph TD  A[输入分割] --> B[Map任务 1]  A[输入分割] --> C[Map任务 2]  A[输入分割] --> D[Map任务 n]  B[Map任务 1] --> E[中间键值对]  C[Map任务 2] --> E[中间键值对]  D[Map任务 n] --> E[中间键值对]  E[中间键值对] --> F[Shuffle 和 Sort]  F[Shuffle 和 Sort] --> G[Reduce任务 1]  F[Shuffle 和 Sort] --> H[Reduce任务 2]  F[Shuffle 和 Sort] --> I[Reduce任务 n]  G[Reduce任务 1] --> J[最终输出]  H[Reduce任务 2] --> J[最终输出]  I[Reduce任务 n] --> J[最终输出]</code></pre><p>以下是一个更具体的流程图：</p><p><img src="/images/map_2.png"></p><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><p>Hadoop是一个用Java编写的开源框架，旨在实现分布式数据处理。它的组件包括了以下：</p><ul><li>Hadoop HDFS：Hadoop 分布式存储系统。</li><li>Yarn：Hadoop 2.x版本开始才有的资源管理系统。</li><li>MapReduce：并行处理框架。</li></ul><h2 id="Hadoop的部署"><a href="#Hadoop的部署" class="headerlink" title="Hadoop的部署"></a>Hadoop的部署</h2><p>我在Windows的Linux子系统Ubuntu部署Hadoop，由于Hadoop基于Java实现，因此第一步是安装Java。</p><h3 id="Java安装"><a href="#Java安装" class="headerlink" title="Java安装"></a>Java安装</h3><p>在Ubuntu中安装Java相对简单，这里采用了Java8进行实现：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt update<br>sudo apt install openjdk-8-jdk -y<br></code></pre></td></tr></table></figure><p>下载完成后，设置Java 8 为默认的版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo update-alternatives --config java<br></code></pre></td></tr></table></figure><p>上述指令能获取到Java的安装路径。获取路径是为了修改环境变量，我们使用<code>vim ~/.bashrc</code>来修改一下配置，加入以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$PATH</span><br></code></pre></td></tr></table></figure><p>完成后需要使更改生效：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> ~/.bashrc<br></code></pre></td></tr></table></figure><p>使用<code>java -version</code>来检查是否正确安装。</p><h3 id="Hadoop安装"><a href="#Hadoop安装" class="headerlink" title="Hadoop安装"></a>Hadoop安装</h3><p>我部署的版本是hadoop 3.3.4，首先需要从Apache Hadoop官方网站下载Hadoop的二进制文件。从以下url获取到<code>tar</code>包：<a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz">Apache Download Mirrors</a>。也可以通过：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz<br></code></pre></td></tr></table></figure><p>使用<code>tar -xzvf hadoop-3.3.4.tar.gz</code>解压，并移动到一个指定的路径，这里我们放在<code>usr/local/hadoop</code>路径。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -xzvf hadoop-3.3.4.tar.gz<br>sudo <span class="hljs-built_in">mv</span> hadoop-3.3.4 /usr/local/hadoop <br></code></pre></td></tr></table></figure><p>同样的需要配置一下环境变量，使用<code>vim ~/.bashrc</code>进行修改并增加以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Hadoop Environment Variables</span><br><span class="hljs-built_in">export</span> HADOOP_HOME=/usr/local/hadoop<br><span class="hljs-built_in">export</span> HADOOP_INSTALL=<span class="hljs-variable">$HADOOP_HOME</span><br><span class="hljs-built_in">export</span> HADOOP_MAPRED_HOME=<span class="hljs-variable">$HADOOP_HOME</span><br><span class="hljs-built_in">export</span> HADOOP_COMMON_HOME=<span class="hljs-variable">$HADOOP_HOME</span><br><span class="hljs-built_in">export</span> HADOOP_HDFS_HOME=<span class="hljs-variable">$HADOOP_HOME</span><br><span class="hljs-built_in">export</span> YARN_HOME=<span class="hljs-variable">$HADOOP_HOME</span><br><span class="hljs-built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/lib/native<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/sbin:<span class="hljs-variable">$HADOOP_HOME</span>/bin<br><span class="hljs-built_in">export</span> HADOOP_OPTS=<span class="hljs-string">&quot;-Djava.library.path=<span class="hljs-variable">$HADOOP_HOME</span>/lib/native&quot;</span><br></code></pre></td></tr></table></figure><p>使用<code>source ~/.bashrc</code>来应用更改。</p><h3 id="Hadoop配置"><a href="#Hadoop配置" class="headerlink" title="Hadoop配置"></a>Hadoop配置</h3><p>安装完hadoop后还需要配置一下，需要到<code>$HADOOP_HOME/etc/hadoop</code>目录进行修改：</p><p><strong>hadoop-env.sh</strong></p><p>需要替换Java环境变量，这里我的路径是<code>/usr/lib/jvm/java-8-openjdk-amd64</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64<br></code></pre></td></tr></table></figure><p><strong>core-site.xml</strong></p><p>默认是空的，需要加上以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;configuration&gt;<br>   &lt;property&gt;<br>      &lt;name&gt;fs.defaultFS&lt;/name&gt;<br>      &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;<br>   &lt;/property&gt;<br>&lt;/configuration&gt;<br></code></pre></td></tr></table></figure><p><strong>hdfs-site.xml</strong></p><p>用来配置HDFS，因此需要加上配置信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;configuration&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;dfs.replication&lt;/name&gt;<br>        &lt;value&gt;1&lt;/value&gt;<br>    &lt;/property&gt;<br><br>    &lt;property&gt;<br>        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br>        &lt;value&gt;file:///home/zerolovesea/hadoopinfra/hdfs/namenode&lt;/value&gt;<br>    &lt;/property&gt;<br><br>    &lt;property&gt;<br>        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br>        &lt;value&gt;file:///home/zerolovesea/hadoopinfra/hdfs/datanode&lt;/value&gt;<br>    &lt;/property&gt;<br>&lt;/configuration&gt;<br></code></pre></td></tr></table></figure><blockquote><p>具体的配置项解释如下：</p><ul><li>dfs.replication：定义了HDFS中每个文件块的复制因子。值为<code>1</code>意味着每个文件块只有一个副本。</li><li>dfs.namenode.name.dir：指定了NameNode存储其元数据的本地文件系统路径。元数据包括文件系统的目录结构和文件块的信息。</li><li>dfs.datanode.data.dir：指定了DataNode存储实际数据块的本地文件系统路径。</li></ul></blockquote><p><strong>yarn-site.xml</strong></p><p>YARN的配置文件，加入以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;configuration&gt;<br>   &lt;property&gt; <br>      &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; <br>      &lt;value&gt;mapreduce_shuffle&lt;/value&gt; <br>   &lt;/property&gt;<br>&lt;/configuration&gt;<br></code></pre></td></tr></table></figure><p><strong>mapred-site.xml</strong></p><p>用于指定使用的MapReduce框架，加入以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;configuration&gt;<br>   &lt;property&gt; <br>      &lt;name&gt;mapreduce.framework.name&lt;/name&gt; <br>      &lt;value&gt;yarn&lt;/value&gt; <br>   &lt;/property&gt;<br>&lt;/configuration&gt;<br></code></pre></td></tr></table></figure><h3 id="验证安装"><a href="#验证安装" class="headerlink" title="验证安装"></a>验证安装</h3><p>上述配置完成后就可以直接执行了。执行以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs namenode -format <br><br>start-dfs.sh<br>start-yarn.sh<br></code></pre></td></tr></table></figure><p>这样就能够依次启动Hadoop文件系统和Yarn脚本。<code>hdfs namenode -format </code>用来初始化<code>namenode</code>，只需要第一次执行就可以了。</p><p>至此Hadoop安装完毕，我们可以通过访问转发后的端口<code>http://localhost:转发端口/</code>来直接访问到Hadoop的服务。</p><p><img src="/images/hadoop.png"></p><h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><p>Hive和Hadoop的关系可能让有些人不太理解，前者实际上是基于后者的一个衍生工具。由于Hadoop由Java编写，当用户需要实现具体功能的时候，需要使用Java来编写MapReduce任务。也就是需要分开写多个Java代码来实现Map和Reduce的功能，这让一些只懂SQL的用户增加了学习成本。</p><p>为了解决这个问题，才出现了Hive，它用来将SQL转换为MapReduce任务，以帮助用户更快的实现需求。</p><p>Hive的主要组件包括：</p><ul><li>MetaStore: 存储Hive表的元数据。</li><li>HiveQL: 类似于SQL的查询语言。</li><li>执行引擎: 将HiveQL转换为MapReduce任务，执行数据处理。</li></ul><h2 id="Hive的部署"><a href="#Hive的部署" class="headerlink" title="Hive的部署"></a>Hive的部署</h2><h3 id="Hive安装"><a href="#Hive安装" class="headerlink" title="Hive安装"></a>Hive安装</h3><p>我们选择Hive 3.1.3来安装，在选取版本时，需要注意一定要和安装的Hadoop版本相匹配，不然会出现很多问题。首先下载<code>tar</code>包，通过<a href="https://dlcdn.apache.org/hive/">Index of &#x2F;hive (apache.org)</a>或：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz<br></code></pre></td></tr></table></figure><p>随后解压并移动到需要的路径，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -xzvf apache-hive-3.1.3-bin.tar.gz<br>sudo <span class="hljs-built_in">mv</span> apache-hive-3.1.3-bin /usr/local/hive<br></code></pre></td></tr></table></figure><p>同时在<code>bashrc</code>中修改环境变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Hive Environment Variables</span><br><span class="hljs-built_in">export</span> HIVE_HOME=/usr/local/hive<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HIVE_HOME</span>/bin<br></code></pre></td></tr></table></figure><p>使用<code>source ~/.bashrc</code>使更改生效。</p><h3 id="Hive配置"><a href="#Hive配置" class="headerlink" title="Hive配置"></a>Hive配置</h3><p>Hive的配置文件位于<code>$HIVE_HOME/conf</code>目录下。</p><p>我们需要先执行<code>cp hive-env.sh.template hive-env.sh</code>，并在其中添加Hadoop的路径：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> HADOOP_HOME=/usr/local/hadoop<br></code></pre></td></tr></table></figure><p>随后，需要创建并修改路径下的<code>hive-site.xml</code>，这是Hive的主要配置文件：</p><p><strong>hive-site.xml</strong></p><p>默认是没有这个文件的，因此需要创建并添加以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;configuration&gt;<br>   &lt;property&gt;<br>      &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;<br>      &lt;value&gt;jdbc:mysql://localhost:3306/metastore_db?createDatabaseIfNotExist=<span class="hljs-literal">true</span>&lt;/value&gt;<br>      &lt;description&gt;JDBC connect string <span class="hljs-keyword">for</span> a JDBC metastore&lt;/description&gt;<br>   &lt;/property&gt;<br>   &lt;property&gt;<br>      &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;<br>      &lt;value&gt;com.mysql.cj.jdbc.Driver&lt;/value&gt;<br>      &lt;description&gt;Driver class name <span class="hljs-keyword">for</span> a JDBC metastore&lt;/description&gt;<br>   &lt;/property&gt;<br>   &lt;property&gt;<br>      &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;<br>      &lt;value&gt;zerolovesea&lt;/value&gt;<br>      &lt;description&gt;username to use against metastore database&lt;/description&gt;<br>   &lt;/property&gt;<br>   &lt;property&gt;<br>      &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;<br>      &lt;value&gt;zy26yang&lt;/value&gt;<br>      &lt;description&gt;password to use against metastore database&lt;/description&gt;<br>   &lt;/property&gt;<br>   &lt;property&gt;<br>      &lt;name&gt;datanucleus.autoCreateSchema&lt;/name&gt;<br>      &lt;value&gt;<span class="hljs-literal">true</span>&lt;/value&gt;<br>      &lt;description&gt;Auto create the JDO tables needed by the metastore&lt;/description&gt;<br>   &lt;/property&gt;<br>      &lt;property&gt;<br>      &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;<br>      &lt;value&gt;<span class="hljs-literal">true</span>&lt;/value&gt;<br>   &lt;/property&gt;<br>   &lt;property&gt;<br>      &lt;name&gt;hive.server2.authentication&lt;/name&gt;<br>      &lt;value&gt;NONE&lt;/value&gt;<br>   &lt;/property&gt;<br></code></pre></td></tr></table></figure><p>其中有一些是需要自定义的内容，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;property&gt;<br>  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;<br>  &lt;value&gt;zerolovesea&lt;/value&gt;<br>  &lt;description&gt;username to use against metastore database&lt;/description&gt;<br>&lt;/property&gt;<br><br>&lt;property&gt;<br>  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;<br>  &lt;value&gt;zy26yang&lt;/value&gt;<br>  &lt;description&gt;password to use against metastore database&lt;/description&gt;<br>&lt;/property&gt;<br></code></pre></td></tr></table></figure><p>这两段分别用来配置连接数据库时的用户名和密码。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;property&gt;<br>  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;<br>  &lt;value&gt;jdbc:mysql://localhost:3306/metastore_db?createDatabaseIfNotExist=<span class="hljs-literal">true</span>&lt;/value&gt;<br>  &lt;description&gt;JDBC connect string <span class="hljs-keyword">for</span> a JDBC metastore&lt;/description&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;<br>  &lt;value&gt;com.mysql.cj.jdbc.Driver&lt;/value&gt;<br>  &lt;description&gt;Driver class name <span class="hljs-keyword">for</span> a JDBC metastore&lt;/description&gt;<br>&lt;/property&gt;<br></code></pre></td></tr></table></figure><p>这段用于配置MySQL的连接，会在后面解释。</p><h3 id="Hive元数据存储设置"><a href="#Hive元数据存储设置" class="headerlink" title="Hive元数据存储设置"></a>Hive元数据存储设置</h3><p>Hive需要一个元数据存储来保存表和数据库信息。这里我们使用MySQL作为元数据存储。</p><p>首先需要安装MySQL:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt update<br>sudo apt install mysql-server -y<br></code></pre></td></tr></table></figure><p>随后登录MySQL并创建数据库以及用户：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo mysql -u root -p<br></code></pre></td></tr></table></figure><p>进入MySQL后，执行以下命令以创建用户名和密码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">CREATE DATABASE metastore_db;<br>CREATE USER <span class="hljs-string">&#x27;zerolovesea&#x27;</span>@<span class="hljs-string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="hljs-string">&#x27;zy26yang&#x27;</span>;<br>GRANT ALL PRIVILEGES ON metastore_db.* TO <span class="hljs-string">&#x27;zerolovesea&#x27;</span>@<span class="hljs-string">&#x27;localhost&#x27;</span>;<br>FLUSH PRIVILEGES;<br>EXIT;<br></code></pre></td></tr></table></figure><p>这里的用户名和密码就对应前面Hive配置的内容。</p><h3 id="初始化Hive元数据"><a href="#初始化Hive元数据" class="headerlink" title="初始化Hive元数据"></a>初始化Hive元数据</h3><p>Hive提供了一个脚本来初始化元数据表。需要下载MySQL JDBC驱动并将其复制到Hive库目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.29.tar.gz<br>tar -xzvf mysql-connector-java-8.0.29.tar.gz<br>sudo <span class="hljs-built_in">cp</span> mysql-connector-java-8.0.29/mysql-connector-java-8.0.29.jar /usr/local/hive/lib/<br></code></pre></td></tr></table></figure><p>随后执行以下命令来初始化元数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">schematool -initSchema -dbType mysql<br></code></pre></td></tr></table></figure><p>最后启动Hive：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hive<br></code></pre></td></tr></table></figure><p><img src="/images/hive_1.png"></p><p>至此大功告成，我们可以创建一个表，插入数据来验证安装是否成功：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> test (id <span class="hljs-type">INT</span>, name STRING);<br>LOAD DATA <span class="hljs-keyword">LOCAL</span> INPATH <span class="hljs-string">&#x27;/usr/local/hive/examples/files/kv1.txt&#x27;</span> <span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> test;<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> test;<br></code></pre></td></tr></table></figure><p>我们可以通过<code>SHOW TABLES;</code>来查看当前数据库中的所有表：</p><p><img src="/images/hive_2.png"></p><p>也可以查看其中的内容：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql">USE database_name;<br><span class="hljs-keyword">SHOW</span> TABLES;<br></code></pre></td></tr></table></figure><p><img src="/images/hive_3.png"></p><h1 id="使用DBeaver连接Hive"><a href="#使用DBeaver连接Hive" class="headerlink" title="使用DBeaver连接Hive"></a>使用DBeaver连接Hive</h1><p>使用命令行连数据库还是比较麻烦，因此考虑使用DBeaver来连接Hive。要实现它，首先需要让WSL和Windows进行通信。我们在WSL中输出<code>hostname -I</code>来获取WSL的IP地址。</p><p>随后在WSL启动HiveServer2：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hiveserver2<br></code></pre></td></tr></table></figure><p>这时就可以在DBeaver中配置新连接了。在创建新连接中选择Apache Hive，随后连接参数里填上主机，端口，数据库，用户名和密码，就可以连接到WSL的Hive了。</p><p><img src="/images/hive_4.png"></p><h1 id="停止服务"><a href="#停止服务" class="headerlink" title="停止服务"></a>停止服务</h1><p>如果需要停止服务，需要执行以下内容：</p><h4 id="停止Hadoop服务"><a href="#停止Hadoop服务" class="headerlink" title="停止Hadoop服务"></a>停止Hadoop服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 停止YARN</span><br>stop-yarn.sh<br><br><span class="hljs-comment"># 停止HDFS</span><br>stop-dfs.sh<br></code></pre></td></tr></table></figure><h4 id="停止Hive服务"><a href="#停止Hive服务" class="headerlink" title="停止Hive服务"></a>停止Hive服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 停止Hive Metastore</span><br><span class="hljs-comment"># 如果是以后台方式启动的，需要找到其进程并杀掉</span><br><span class="hljs-comment"># 举例：</span><br><span class="hljs-comment"># ps -ef | grep HiveMetaStore</span><br><span class="hljs-comment"># kill &lt;process_id&gt;</span><br><br><span class="hljs-comment"># 停止HiveServer2</span><br><span class="hljs-comment"># 如果是以后台方式启动的，需要找到其进程并杀掉</span><br><span class="hljs-comment"># 举例：</span><br><span class="hljs-comment"># ps -ef | grep HiveServer2</span><br><span class="hljs-comment"># kill &lt;process_id&gt;</span><br></code></pre></td></tr></table></figure><h4 id="关闭WSL"><a href="#关闭WSL" class="headerlink" title="关闭WSL"></a>关闭WSL</h4><p>在停止所有服务之后，就可以安全地关闭WSL：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wsl --shutdown<br></code></pre></td></tr></table></figure><p>这样可以确保Hadoop和Hive服务被优雅地停止，避免数据损坏或任务中断。</p><h3 id="重新启动Hadoop和Hive服务"><a href="#重新启动Hadoop和Hive服务" class="headerlink" title="重新启动Hadoop和Hive服务"></a>重新启动Hadoop和Hive服务</h3><p>下次启动WSL时，需要重新启动Hadoop和Hive服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 启动HDFS</span><br>start-dfs.sh<br><br><span class="hljs-comment"># 启动YARN</span><br>start-yarn.sh<br><br><span class="hljs-comment"># 启动Hive</span><br><span class="hljs-comment"># 如果需要HiveServer2或Metastore，也需要分别启动</span><br></code></pre></td></tr></table></figure><p>2024&#x2F;6&#x2F;9 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HIVE</tag>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Web开发：SQLAlchemy</title>
    <link href="/2024/06/02/Python-Web%E5%BC%80%E5%8F%91%EF%BC%9ASQLAlchemy/"/>
    <url>/2024/06/02/Python-Web%E5%BC%80%E5%8F%91%EF%BC%9ASQLAlchemy/</url>
    
    <content type="html"><![CDATA[<p>上一篇博文简单介绍了Flask的使用，这次深入一下，研究如何将一个Web应用和数据库相结合。这就需要用到今天要提及的SQLAlchemy。</p><p>要了解SQLAlchemy，首先需要认识ORM。ORM在数据库中是指对象关系映射，通过某种映射，开发者可以通过面向对象的方式操作数据库。数据库的表被映射成类，行实例代表数据库中的记录，属性则对应于记录中的字段。具体而言，开发者不需要直接使用SQL语句就能编写DDL等数据库操作指令。</p><h1 id="简单上手"><a href="#简单上手" class="headerlink" title="简单上手"></a>简单上手</h1><p>首先我们简单用Flask蓝图，PostgresSQL来实现一个连接本地数据库，并插入数据的操作。</p><p>要做到这一点，我们需要实现几个内容：</p><ul><li>本地构建一个PG数据库，我使用了docker来构建。</li><li>编写一个<code>db</code>文件，用来定义数据库模型，并且实现数据库写入的操作。</li><li>编写一个Flask应用的配置文件，以达到灵活配置的作用。</li><li>使用蓝图，并在蓝图中定义一个插入数据库的操作路由。</li><li>编写一个Flask主程序，用来实例化Flask程序，并注册蓝图和初始化。</li></ul><h2 id="Postgres数据库的构建"><a href="#Postgres数据库的构建" class="headerlink" title="Postgres数据库的构建"></a>Postgres数据库的构建</h2><p>Docker如何使用就不赘述了，执行以下命令行构建一个数据库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --name flask_db -e POSTGRES_PASSWORD=12345 -p 5432:5432 -d postgres<br></code></pre></td></tr></table></figure><p>上述指令会构建一个名为<code>flask_db</code>的镜像，里面是一个PG数据库，默认名为<code>postgres</code>。</p><h2 id="配置文件的编写"><a href="#配置文件的编写" class="headerlink" title="配置文件的编写"></a>配置文件的编写</h2><p>配置文件用来保存一些隐私数据，例如数据库密码等。我们新建一个<code>config.py</code>文件，里面定义<code>Config</code>类，来保存配置文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> dotenv<br><br>dotenv.load_dotenv()<br><br>DEFAULTS = &#123;<br>    <span class="hljs-string">&#x27;DB_USERNAME&#x27;</span>: <span class="hljs-string">&#x27;postgres&#x27;</span>,<br>    <span class="hljs-string">&#x27;DB_PASSWORD&#x27;</span>: <span class="hljs-string">&#x27;12345&#x27;</span>,<br>    <span class="hljs-string">&#x27;DB_HOST&#x27;</span>: <span class="hljs-string">&#x27;localhost&#x27;</span>,<br>    <span class="hljs-string">&#x27;DB_PORT&#x27;</span>: <span class="hljs-string">&#x27;5432&#x27;</span>,<br>    <span class="hljs-string">&#x27;DB_DATABASE&#x27;</span>: <span class="hljs-string">&#x27;postgres&#x27;</span>,<br>    <span class="hljs-string">&#x27;DB_CHARSET&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,<br>&#125;<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_env</span>(<span class="hljs-params">key</span>):<br>    <span class="hljs-keyword">return</span> os.environ.get(key, DEFAULTS.get(key))<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Config</span>:<br>    SQLALCHEMY_DATABASE_URI = <span class="hljs-string">f&quot;postgresql://<span class="hljs-subst">&#123;get_env(<span class="hljs-string">&#x27;DB_USERNAME&#x27;</span>)&#125;</span>:<span class="hljs-subst">&#123;get_env(<span class="hljs-string">&#x27;DB_PASSWORD&#x27;</span>)&#125;</span>@<span class="hljs-subst">&#123;get_env(<span class="hljs-string">&#x27;DB_HOST&#x27;</span>)&#125;</span>:<span class="hljs-subst">&#123;get_env(<span class="hljs-string">&#x27;DB_PORT&#x27;</span>)&#125;</span>/<span class="hljs-subst">&#123;get_env(<span class="hljs-string">&#x27;DB_DATABASE&#x27;</span>)&#125;</span>&quot;</span><br>    SQLALCHEMY_TRACK_MODIFICATIONS = <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p>配置文件写完，先暂时不用，我们去写数据库相关的操作。</p><h2 id="数据库相关定义"><a href="#数据库相关定义" class="headerlink" title="数据库相关定义"></a>数据库相关定义</h2><p>我们需要用到<code>SQLAlchemy</code>来定义数据库模型。按照顺序，我们需要先对数据库实例化，随后定义模型，以及一个初始化方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask_sqlalchemy <span class="hljs-keyword">import</span> SQLAlchemy<br><br>db = SQLAlchemy()<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>(db.Model):<br>    <span class="hljs-built_in">id</span> = db.Column(db.Integer, primary_key=<span class="hljs-literal">True</span>)<br>    username = db.Column(db.String(<span class="hljs-number">80</span>), unique=<span class="hljs-literal">True</span>, nullable=<span class="hljs-literal">False</span>)<br>    email = db.Column(db.String(<span class="hljs-number">120</span>), unique=<span class="hljs-literal">True</span>, nullable=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&lt;User %r&gt;&#x27;</span> % self.username<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_db</span>():<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> User.query.filter_by(username=<span class="hljs-string">&#x27;admin&#x27;</span>).first():<br>        admin = User(username=<span class="hljs-string">&#x27;admin&#x27;</span>, email=<span class="hljs-string">&#x27;admin@example.com&#x27;</span>)<br>        db.session.add(admin)<br>    <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> User.query.filter_by(username=<span class="hljs-string">&#x27;guest&#x27;</span>).first():<br>        guest = User(username=<span class="hljs-string">&#x27;guest&#x27;</span>, email=<span class="hljs-string">&#x27;guest@example.com&#x27;</span>)<br>        db.session.add(guest)<br>    <br>    db.session.commit()<br></code></pre></td></tr></table></figure><p><code>User</code>类继承自<code>db.Model</code>，实际上就是定义的数据库模型。而<code>init_db</code>用到了事务，来向数据库写入两个sample数据。</p><h2 id="定义蓝图"><a href="#定义蓝图" class="headerlink" title="定义蓝图"></a>定义蓝图</h2><p>随后，我们创建一个<code>blueprint.py</code>，在里面定义一个蓝图，这个蓝图专门负责用户相关的操作。这里我只定义了一个添加用户的操作，并且内容是写死的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Blueprint, request, jsonify<br><span class="hljs-keyword">from</span> db <span class="hljs-keyword">import</span> db, User<br><br>user_bp = Blueprint(<span class="hljs-string">&#x27;user_bp&#x27;</span>, __name__)<br><br><span class="hljs-meta">@user_bp.route(<span class="hljs-params"><span class="hljs-string">&#x27;/add_user&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_user</span>():<br>    username = <span class="hljs-string">&#x27;user1&#x27;</span> <br>    email = <span class="hljs-string">&#x27;zy1@gmail.com&#x27;</span> <br>    new_user = User(username=username, email=email)<br>    db.session.add(new_user)<br>    db.session.commit()<br>    <span class="hljs-keyword">return</span> jsonify(message=<span class="hljs-string">&#x27;User added successfully&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="定义主程序"><a href="#定义主程序" class="headerlink" title="定义主程序"></a>定义主程序</h2><p>目前为止我们构建的三个文件都只是独立且割裂的，我们需要在主程序应用中将它们串联起来。我们构建一个<code>app.py</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><span class="hljs-keyword">from</span> config <span class="hljs-keyword">import</span> Config<br><span class="hljs-keyword">from</span> db <span class="hljs-keyword">import</span> db, User, init_db<br><span class="hljs-keyword">from</span> blueprint <span class="hljs-keyword">import</span> user_bp<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_app</span>():<br>    app = Flask(__name__, instance_relative_config=<span class="hljs-literal">True</span>)<br>    <span class="hljs-comment"># 读取配置文件</span><br>    app.config.from_object(Config)<br><br>    <span class="hljs-comment"># SQLAlchemy的Flask应用初始化方法</span><br>    db.init_app(app)<br><br>    <span class="hljs-comment"># 数据库的初始化，后续用flask db migrate代替</span><br>    <span class="hljs-keyword">with</span> app.app_context():<br>        db.create_all()<br>        init_db()<br>    <br>    <span class="hljs-comment"># 注册蓝图</span><br>    app.register_blueprint(user_bp)<br>    <span class="hljs-keyword">return</span> app<br><br>app = create_app()<br></code></pre></td></tr></table></figure><p>这样，一个简单的应用就完成了。我们使用<code>flask run --debug</code>来执行。这时，直接向<code>http://localhost:5000/add_user</code>发送POST请求后，可以看到数据库里就创建并写入了一张新表。</p><blockquote><p>上面包含了一段内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> app.app_context():<br>    db.create_all()<br>    init_db()<br></code></pre></td></tr></table></figure><p>这段代码的作用是将定义好的模型同步到数据库。不过每次用上下文终归是太麻烦，因此可以使用<code>Flask-Migrate</code>代替。</p></blockquote><h3 id="Flask-Migrate"><a href="#Flask-Migrate" class="headerlink" title="Flask Migrate"></a>Flask Migrate</h3><p>Flask-Migrate是一个 Flask 扩展，用来处理 SQLAlchemy 数据库迁移。例如我们在前面定义的<code>User</code>类中新增一个字段，这时候数据库里并不会直接增加字段，我们就需要使用Flask-Migrate来进行数据库的同步。</p><p>执行<code>pip install flask-migrate</code>进行安装。</p><p>在主应用中导入<code>Migrate</code>模块并初始化，以下是示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask_migrate <span class="hljs-keyword">import</span> Migrate<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_app</span>():<br>    app = Flask(__name__, instance_relative_config=<span class="hljs-literal">True</span>)<br>    app.config.from_object(Config)<br><br>    db.init_app(app)<br>    <span class="hljs-comment"># 初始化 Flask-Migrate</span><br>    migrate = Migrate(app, db)<br><br>    <span class="hljs-keyword">return</span> app<br></code></pre></td></tr></table></figure><p>随后，执行<code>flask db init</code>来初始化迁移脚本的存储库。这个指令类似于Git仓库的初始化，只要执行一次就行了。</p><p>随后需要创建一个迁移的脚本，代码为<code>flask db migrate -m &quot;Initial migration.&quot;</code>。这段代码的作用是检测数据库模型与当前数据库状态之间的差异，并自动生成一个迁移脚本。</p><p>最后执行<code>flask db upgrade</code>，作用是将应用迁移脚本到数据库，并修改数据库结构。</p><p>2024&#x2F;6&#x2F;2 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>Web开发</tag>
      
      <tag>Flask</tag>
      
      <tag>SQLAlchemy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Web开发：Flask框架</title>
    <link href="/2024/06/01/Python-Web%E5%BC%80%E5%8F%91%EF%BC%9AFlask%E6%A1%86%E6%9E%B6/"/>
    <url>/2024/06/01/Python-Web%E5%BC%80%E5%8F%91%EF%BC%9AFlask%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<p>Flask和FastAPI在目前的工作中是老生常谈的话题了，不过一直都是上手就用，遇到不会的就看文档，知识比较散落，并且容易忘记。因此这次做个整理，将Flask中一些常用的概念记录一下。</p><h1 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h1><p>基本用法不再赘述，流程就是先实例化<code>app</code>，使用Flask定义的装饰器来定义路由，最后设置<code>app</code>的监听端口等配置项：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hello_world</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Hello, World!&#x27;</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run(host=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span>, port=<span class="hljs-number">8080</span>, debug=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><blockquote><p>上面的代码有两种执行方法：</p><ol><li>直接python 文件名.py：此时会在本机IP的8080端口起服务。</li><li>命令行设置环境变量，用<code>flask run</code>执行。例如以下：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">export FLASK_APP=myapplication.py <span class="hljs-comment"># 如果文件名为app.py，无需设置环境变量，直接运行flask run</span><br>flask run --host=<span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> --port=<span class="hljs-number">8080</span><br></code></pre></td></tr></table></figure></blockquote><h2 id="基本的HTTP方法"><a href="#基本的HTTP方法" class="headerlink" title="基本的HTTP方法"></a>基本的HTTP方法</h2><p>几种常用的方式能够定义，例如路由方法直接使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> request<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/login&#x27;</span>, methods=[<span class="hljs-string">&#x27;GET&#x27;</span>, <span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">login</span>():<br>    <span class="hljs-keyword">if</span> request.method == <span class="hljs-string">&#x27;POST&#x27;</span>:<br>        <span class="hljs-keyword">return</span> do_the_login()<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> show_the_login_form()<br></code></pre></td></tr></table></figure><p>或者<code>app</code>实例内置的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request<br><br>app = Flask(__name__)<br><br><span class="hljs-meta">@app.get(<span class="hljs-params"><span class="hljs-string">&#x27;/hello&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hello_world</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Hello, World!&#x27;</span><br><br><span class="hljs-meta">@app.post(<span class="hljs-params"><span class="hljs-string">&#x27;/upload&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">upload_file</span>():<br>    file = request.files[<span class="hljs-string">&#x27;file&#x27;</span>]<br>    file.save(<span class="hljs-string">&#x27;/tmp/&#x27;</span> + file.filename)<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;File uploaded&#x27;</span><br></code></pre></td></tr></table></figure><h1 id="读取配置项构建应用"><a href="#读取配置项构建应用" class="headerlink" title="读取配置项构建应用"></a>读取配置项构建应用</h1><p>实际较大的项目中，需要配置诸多选项，这时如果只是用上面的方法构建实例<code>app</code>，那就会比较不灵活，这时能够通过定义应用工厂来实现。所谓应用工厂对应的是设计模式里的工厂函数。以下是官方示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_app</span>(<span class="hljs-params">test_config=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-comment"># 首先构建实例，instance_relative_config用来定义应用配置文件是处于一个相对路径</span><br>    app = Flask(__name__, instance_relative_config=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment"># 加载默认的一些核心配置</span><br>    app.config.from_mapping(<br>        SECRET_KEY=<span class="hljs-string">&#x27;dev&#x27;</span>,<br>        DATABASE=os.path.join(app.instance_path, <span class="hljs-string">&#x27;flaskr.sqlite&#x27;</span>),<br>    )<br><br>    <span class="hljs-keyword">if</span> test_config <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># 读取python文件格式的配置文件，用来设置额外参数</span><br>        app.config.from_pyfile(<span class="hljs-string">&#x27;config.py&#x27;</span>, silent=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 读取字典格式的配置入参，用来设置额外参数</span><br>        app.config.from_mapping(test_config)<br><br>   <span class="hljs-comment"># 确定实例路径存在</span><br>    <span class="hljs-keyword">try</span>:<br>        os.makedirs(app.instance_path)<br>    <span class="hljs-keyword">except</span> OSError:<br>        <span class="hljs-keyword">pass</span><br><br><span class="hljs-meta">    @app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/hello&#x27;</span></span>)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Hello, World!&#x27;</span><br><br>    <span class="hljs-keyword">return</span> app<br></code></pre></td></tr></table></figure><p>执行<code>flask --app flaskr run --debug</code>来运行应用。这时能够在默认<code>5000</code>访问到<code>hello</code>函数。</p><h2 id="实际场景"><a href="#实际场景" class="headerlink" title="实际场景"></a>实际场景</h2><p>以下是一个较为实际的项目场景：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request<br><span class="hljs-keyword">from</span> config <span class="hljs-keyword">import</span> Config<br><br><span class="hljs-comment"># 自定义类，继承自Flask</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ServiceApp</span>(<span class="hljs-title class_ inherited__">Flask</span>):<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_app</span>():<br>    app = ServiceApp(__name__) <span class="hljs-comment"># app = Flask(__name__)</span><br><br>    app.config.from_object(Config())<br>    logging.basicConfig(level=app.config.get(<span class="hljs-string">&#x27;LOG_LEVEL&#x27;</span>, <span class="hljs-string">&#x27;INFO&#x27;</span>))<br><span class="hljs-comment"># 初始化及注册</span><br>    initialize_extensions(app)<br>    register_blueprints(app)<br>    register_commands(app)<br>    <span class="hljs-keyword">return</span> app<br><br>app = create_app()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run(host=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span>, port=<span class="hljs-number">5000</span>) <span class="hljs-comment"># flask run --host 0.0.0.0 --port=5000 --debug</span><br></code></pre></td></tr></table></figure><p>上面的<code>initialize_extensions</code>和注册函数暂且不看，我们在<code>app.config.from_object</code>的入参是一个<code>Config()</code>对象，内容大致如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Config</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.CURRENT_VERSION = <span class="hljs-string">&quot;0.0.1&quot;</span><br>        self.COMMIT_SHA = get_env(<span class="hljs-string">&#x27;COMMIT_SHA&#x27;</span>)<br>        self.EDITION = <span class="hljs-string">&quot;SELF_HOSTED&quot;</span><br>        self.DEPLOY_ENV = get_env(<span class="hljs-string">&#x27;DEPLOY_ENV&#x27;</span>)<br>        self.TESTING = <span class="hljs-literal">False</span><br>        self.LOG_LEVEL = get_env(<span class="hljs-string">&#x27;LOG_LEVEL&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="数据库定义"><a href="#数据库定义" class="headerlink" title="数据库定义"></a>数据库定义</h1><p>和Web应用最紧密相关的无疑是数据库的连接，这里我们假设拥有一个Flask项目，我们在这个项目下构建一个文件夹<code>/db</code>，并在文件夹下新建<code>db.py</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sqlite3<br><br><span class="hljs-comment"># click用来执行命令行脚本相关命令</span><br><span class="hljs-keyword">import</span> click<br><span class="hljs-comment"># g是一个特殊对象，用来存储请求期间的数据</span><br><span class="hljs-comment"># current_app 指向处理请求的flask应用</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> current_app, g <br><br><span class="hljs-comment"># 获得数据库连接</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_db</span>():<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;db&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> g:<br>        g.db = sqlite3.connect(<br>            current_app.config[<span class="hljs-string">&#x27;DATABASE&#x27;</span>],<br>            detect_types=sqlite3.PARSE_DECLTYPES<br>        )<br>        <span class="hljs-comment"># 返回行</span><br>        g.db.row_factory = sqlite3.Row<br>    <span class="hljs-keyword">return</span> g.db<br><br><span class="hljs-comment"># 关闭数据库连接</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">close_db</span>(<span class="hljs-params">e=<span class="hljs-literal">None</span></span>):<br>    db = g.pop(<span class="hljs-string">&#x27;db&#x27;</span>, <span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">if</span> db <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        db.close()<br></code></pre></td></tr></table></figure><p>这里的<code>get_db</code>方法用来获取数据库连接，不过目前数据库里还没有数据。我们需要创建数据。</p><p>首先在<code>/db</code>路径下创建一个<code>schema.sql</code>，里面存储一些创建表的SQL命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">DROP TABLE IF EXISTS user;<br>DROP TABLE IF EXISTS post;<br><br>CREATE TABLE user (<br>  <span class="hljs-built_in">id</span> INTEGER PRIMARY KEY AUTOINCREMENT,<br>  username TEXT UNIQUE NOT NULL,<br>  password TEXT NOT NULL<br>);<br><br>CREATE TABLE post (<br>  <span class="hljs-built_in">id</span> INTEGER PRIMARY KEY AUTOINCREMENT,<br>  author_id INTEGER NOT NULL,<br>  created TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,<br>  title TEXT NOT NULL,<br>  body TEXT NOT NULL,<br>  FOREIGN KEY (author_id) REFERENCES user (<span class="hljs-built_in">id</span>)<br>);<br></code></pre></td></tr></table></figure><p>随后在<code>/db/db.py</code>中加入执行这段命令的Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_db</span>():<br>    db = get_db()<br><br>    <span class="hljs-keyword">with</span> current_app.open_resource(<span class="hljs-string">&#x27;schema.sql&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        db.executescript(f.read().decode(<span class="hljs-string">&#x27;utf8&#x27;</span>))<br><br><br><span class="hljs-meta">@click.command(<span class="hljs-params"><span class="hljs-string">&#x27;init-db&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_db_command</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;Clear the existing data and create new tables.&quot;&quot;&quot;</span><br>    init_db()<br>    click.echo(<span class="hljs-string">&#x27;Initialized the database.&#x27;</span>)<br></code></pre></td></tr></table></figure><p>这段代码的核心是<code>init_db</code>，它首先使用<code>get_db</code>方法连接了数据，随后使用<code>executescript</code>执行了创建数据表的SQL命令。</p><p>随后，通过<code>click</code>库中的<code>command</code>方法，定义了一个<code>init-db</code>的方法。当执行<code>flask init-db</code>时，就会执行<code>init_db_command</code>函数，也就是数据表的初始化。</p><h1 id="注册应用"><a href="#注册应用" class="headerlink" title="注册应用"></a>注册应用</h1><p>上面两个函数现在我们只是写好了，但是并没有和我们的Flask应用相关联，因此我们需要进行注册。</p><p>目前为止，我们对数据库的操作方法都在<code>db.py</code>中，同样的，数据库初始化我们也放在这里。我们加入一个新的方法<code>init_app</code>，它用来执行数据库初始化以及正常关闭。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># init_app方法接收一个Flask实例，并执行绑定的命令</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_app</span>(<span class="hljs-params">app</span>):<br>    app.teardown_appcontext(close_db)<br>    app.cli.add_command(init_db_command)<br></code></pre></td></tr></table></figure><p>随后，我们在Flask应用初始化的位置（例如<code>__init__.py</code>）引入这个方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_app</span>():<br>    app = Flask(__name__, instance_relative_config=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment"># 加载默认的一些核心配置</span><br>    app.config.from_mapping(<br>        SECRET_KEY=<span class="hljs-string">&#x27;dev&#x27;</span>,<br>        DATABASE=os.path.join(app.instance_path, <span class="hljs-string">&#x27;flaskr.sqlite&#x27;</span>),<br>    )<br>    app.config.from_pyfile(<span class="hljs-string">&#x27;config.py&#x27;</span>, silent=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">from</span> . <span class="hljs-keyword">import</span> db<br>    db.init_app(app)<br><br>    <span class="hljs-keyword">return</span> app<br></code></pre></td></tr></table></figure><p>这样，初始化数据库函数就在应用中进行了注册，我们使用<code>flask --app flaskr init-db</code>既可初始化。</p><p><img src="/images/flask1.png"></p><h2 id="实际场景-1"><a href="#实际场景-1" class="headerlink" title="实际场景"></a>实际场景</h2><p>实际场景中，我们项目中会使用<code>SQLAlchemy</code>来实例化数据库。这是一个 Python ORM 框架，用于将数据库操作映射为 Python 对象的操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask_sqlalchemy <span class="hljs-keyword">import</span> SQLAlchemy<br><br>db = SQLAlchemy()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_app</span>(<span class="hljs-params">app</span>):<br>    db.init_app(app)<br></code></pre></td></tr></table></figure><p>同时，我们需要在Flask应用中加上它的配置参数，我们有两种方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><span class="hljs-keyword">from</span> db_module <span class="hljs-keyword">import</span> init_app  <br><br>app = Flask(__name__)<br>app.config[<span class="hljs-string">&#x27;SQLALCHEMY_DATABASE_URI&#x27;</span>] = <span class="hljs-string">&#x27;sqlite:///example.db&#x27;</span><br>init_app(app)  <span class="hljs-comment"># 这会初始化 SQLAlchemy，并使用配置好的数据库 URI</span><br></code></pre></td></tr></table></figure><blockquote><p>通常<code>SQLALCHEMY_DATABASE_URI</code>的格式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">dialect+driver://username:password@host:port/database<br></code></pre></td></tr></table></figure><p><strong>dialect</strong>：SQLAlchemy 使用的数据库类型，如 <code>postgresql</code>, <code>mysql</code>, <code>sqlite</code> 等。<br><strong>driver</strong>：连接数据库时使用的 DBAPI，这通常可以省略。<br><strong>username</strong>：连接数据库的用户名。<br><strong>password</strong>：对应的密码。<br><strong>host</strong>：数据库服务器的地址。<br><strong>port</strong>：数据库服务器的端口。<br><strong>database</strong>：要连接的数据库名称。</p></blockquote><p>面对如此多的参数，我们可以在<code>Config</code>类中定义：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Config</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        db_credentials = &#123;<br>            key: get_env(key) <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span><br>            [<span class="hljs-string">&#x27;DB_USERNAME&#x27;</span>, <span class="hljs-string">&#x27;DB_PASSWORD&#x27;</span>, <span class="hljs-string">&#x27;DB_HOST&#x27;</span>, <span class="hljs-string">&#x27;DB_PORT&#x27;</span>, <span class="hljs-string">&#x27;DB_DATABASE&#x27;</span>, <span class="hljs-string">&#x27;DB_CHARSET&#x27;</span>]<br>        &#125;<br>        self.SQLALCHEMY_DATABASE_URI = <span class="hljs-string">f&quot;postgresql://<span class="hljs-subst">&#123;db_credentials[<span class="hljs-string">&#x27;DB_USERNAME&#x27;</span>]&#125;</span>:<span class="hljs-subst">&#123;db_credentials[<span class="hljs-string">&#x27;DB_PASSWORD&#x27;</span>]&#125;</span>@<span class="hljs-subst">&#123;db_credentials[<span class="hljs-string">&#x27;DB_HOST&#x27;</span>]&#125;</span>:<span class="hljs-subst">&#123;db_credentials[<span class="hljs-string">&#x27;DB_PORT&#x27;</span>]&#125;</span>/<span class="hljs-subst">&#123;db_credentials[<span class="hljs-string">&#x27;DB_DATABASE&#x27;</span>]&#125;</span><span class="hljs-subst">&#123;db_extras&#125;</span>&quot;</span><br></code></pre></td></tr></table></figure><p>随后在Flask应用的设置中引入参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request<br><span class="hljs-keyword">from</span> config <span class="hljs-keyword">import</span> Config<br><br><span class="hljs-comment"># 自定义类，继承自Flask</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ServiceApp</span>(<span class="hljs-title class_ inherited__">Flask</span>):<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_app</span>():<br>    app = ServiceApp(__name__) <span class="hljs-comment"># app = Flask(__name__)</span><br><br>    app.config.from_object(Config())<br>    logging.basicConfig(level=app.config.get(<span class="hljs-string">&#x27;LOG_LEVEL&#x27;</span>, <span class="hljs-string">&#x27;INFO&#x27;</span>))<br><span class="hljs-comment"># 数据库初始化</span><br>    db.init_app(app)<br>    <span class="hljs-keyword">return</span> app<br><br>app = create_app()<br></code></pre></td></tr></table></figure><h1 id="蓝图"><a href="#蓝图" class="headerlink" title="蓝图"></a>蓝图</h1><p>什么是蓝图？在Flask中，我们可以把它看作是一个Flask应用的子集。</p><p>在我们之前的代码中，我们都在为主Flask应用注册路由。例如<code>hello_world</code>方法通过主路由调用。如果项目中包含了多个应用，这时只通过主路由调用就不那么优雅了。Flask提供的蓝图方法支持将应用分解成不同的组件，每个组件都用来处理单独的操作，最后在主路由上统一注册。</p><p>以下是一个简单示例，例如如果想创建一个处理用户相关的蓝图，我们需要实现以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Blueprint<br><br><span class="hljs-comment"># 和主应用一样实例化蓝图，区别只在于对象是Blueprint</span><br>users = Blueprint(<span class="hljs-string">&#x27;users&#x27;</span>, __name__)<br><br><span class="hljs-comment"># 定义路由</span><br><span class="hljs-meta">@users.route(<span class="hljs-params"><span class="hljs-string">&#x27;/login&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">login</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Login Page&#x27;</span><br><br><span class="hljs-meta">@users.route(<span class="hljs-params"><span class="hljs-string">&#x27;/logout&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">logout</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Logout Page&#x27;</span><br></code></pre></td></tr></table></figure><p>随后，我们需要在主Flask应用中对蓝图进行注册：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><span class="hljs-keyword">from</span> module <span class="hljs-keyword">import</span> users<br><br>app = Flask(__name__)<br><span class="hljs-comment"># 注册蓝图，并设置前缀</span><br>app.register_blueprint(users, url_prefix=<span class="hljs-string">&#x27;/users&#x27;</span>)<br></code></pre></td></tr></table></figure><p>当我们注册蓝图后，就可以在<code>/users/login</code>端口进行访问。这就是<code>url_prefix</code>的作用。它的好处就是让应用后加模块化。</p><h2 id="实际场景-2"><a href="#实际场景-2" class="headerlink" title="实际场景"></a>实际场景</h2><p>以下是一个场景：</p><p>首先我们实例化蓝图对象，并设置对应的路由：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Blueprint<br><span class="hljs-keyword">from</span> libs.external_api <span class="hljs-keyword">import</span> ExternalApi<br><br>bp = Blueprint(<span class="hljs-string">&#x27;web&#x27;</span>, __name__, url_prefix=<span class="hljs-string">&#x27;/api&#x27;</span>)<br>api = ExternalApi(bp)<br></code></pre></td></tr></table></figure><p>这里的<code>ExternalApi</code>是我们定义的对象，它继承自<code>flask_restful</code>的<code>Api</code>对象，并覆写了<code>handle_error</code>方法以处理报错信息。</p><p>我们会在这个<code>api</code>中不断添加资源，代码类似于<code>api.add_resource(CompletionApi, &#39;/chat/completions&#39;)</code>。</p><p>随后我们在主应用中注册蓝图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">register_blueprints</span>(<span class="hljs-params">app</span>):<br>    <span class="hljs-keyword">from</span> controllers.web <span class="hljs-keyword">import</span> bp <span class="hljs-keyword">as</span> web_bp<br>    app.register_blueprint(web_bp)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_app</span>():<br>    app = Flask(__name__)<br><br>    app.config.from_object(Config())<br>    logging.basicConfig(level=app.config.get(<span class="hljs-string">&#x27;LOG_LEVEL&#x27;</span>, <span class="hljs-string">&#x27;INFO&#x27;</span>))<br><br>    register_blueprints(app)<br>    <span class="hljs-keyword">return</span> app<br></code></pre></td></tr></table></figure><p>整体的顺序如下：</p><ul><li>初始化API示例，也就是<code>api = Api(bp)</code></li><li>注册蓝图至Flask应用，即<code>app.register_blueprint(bp)</code></li><li>创建API实例后，向实例添加资源。</li></ul><p>2024&#x2F;6&#x2F;1 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>Web开发</tag>
      
      <tag>Flask</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python消息队列：Celery上手</title>
    <link href="/2024/05/25/Python%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%9ACelery%E5%85%A5%E9%97%A8/"/>
    <url>/2024/05/25/Python%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%9ACelery%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<p>上一篇博文里，实现了一个异步任务的场景：调用web服务之后立刻返回结果，后台则继续执行这个任务。这是我工作中的一个真实需求，当我费劲巴拉把这个功能写完之后，我才了解到有一个现成的工具能够实现这个功能，这就是今天要学习的Celery。</p><blockquote><p>Celery是一个简单，灵活、可靠的分布式任务执行框架，可以支持大量任务的并发执行。Celery采用典型生产者和消费者模型。生产者提交任务到任务队列，众多消费者从任务队列中取任务执行。</p></blockquote><p>生产者和消费者模型是一种设计模式，在这种设计模式中，生产者和消费者分别是任务的发布者和任务的获取者，他们没有直接的关联，之间的交流通过中间人(Broker，也称为消息队列)完成。</p><p>在这个过程中，生产者像悬赏榜上的贴告示人一样，将任务发布在消息队列中，任务在任务队列中依次执行后，将结果发送给消费者。在生产环境中，任务队列通常用Redis或RabbitMQ实现。</p><p><img src="/images/celery.png"></p><h1 id="实际场景"><a href="#实际场景" class="headerlink" title="实际场景"></a>实际场景</h1><p>Celery的实际场景在日常生活中经常出现：</p><p>例如Web应用中，当用户触发了一个需要长时间执行的操作时（高计算&#x2F;高IO等会造成阻塞的任务），可以把它作为任务交给Celery去异步执行，执行完再返回给用户。这段时间用户不需要等待。</p><p>对于用户来说，他点击了执行按钮后，得到了一个任务ID，而程序在后台执行，用户只需要等一段时间，通过任务ID拿到任务的执行结果。</p><p>还有一个场景是定时任务：例如需要定时向一些地址发布邮件。</p><blockquote><p>上手代码之前，我发现了大坑，在我的Windows机器上运行Celery程序时，始终报错<code>[ValueError: not enough values to unpack]</code>，起初我以为是代码逻辑的问题，最终发现是Celery的最新版暂时不支持Windows，可以使用WSL或者<code>celery -A my_project_name worker --pool=solo -l info</code>执行。后者的话就意味着单线程执行代码。</p></blockquote><h1 id="最简单的案例"><a href="#最简单的案例" class="headerlink" title="最简单的案例"></a>最简单的案例</h1><p>首先是一个最简单的案例：我们有个计算的程序，负责将输入的两个数字相加，得到结果。为了模拟高计算量的程序，我们在计算时加上sleep2秒。</p><p>现在，我们想让用户在执行该程序时，程序不会因为sleep的两秒而阻塞，而是会在后台执行。这个过程我们放在队列里。要完成这一点，我们要实现以下几个内容：</p><ol><li>我们需要实现本地的一个消息代理Broker，例如Redis</li><li>我们需要实现一个生产者程序，负责生成任务并发送到消息代理。</li><li>需要实现一个消费者程序，负责从消息队列中接收任务并执行它们。</li></ol><p>在这个过程中，生产者不负责执行程序，只负责发布任务。</p><p>以下是代码的实现：</p><hr><p>首先我们用Docker在本地的6379端口启动redis服务，此处不赘述。</p><p>消费者程序，我们命名为<code>tasks.py</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> celery <span class="hljs-keyword">import</span> Celery<br> <br>broker = <span class="hljs-string">&#x27;redis://127.0.0.1:6379&#x27;</span><br>backend = <span class="hljs-string">&#x27;redis://127.0.0.1:6379/0&#x27;</span><br> <br>app = Celery(<span class="hljs-string">&#x27;my_task&#x27;</span>, broker=broker, backend=backend)<br> <br><span class="hljs-meta">@app.task</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">x, y</span>):<br>    time.sleep(<span class="hljs-number">2</span>)     <span class="hljs-comment"># 模拟耗时操作</span><br>    <span class="hljs-keyword">return</span> x + y<br></code></pre></td></tr></table></figure><p>消费者程序里定义了消息代理和结果后端，两个都是用<code>redis</code>实现的。顾名思义，一个用来连接消息队列，一个用来存储结果。</p><p>首先创建了一个Celery实例，名为<code>my_task</code>。<code>@app.task</code>是一个装饰器，将被装饰的函数注册为Celery任务。这样这个函数就能被异步调用了。</p><p>生产者程序，命名为<code>client.py</code>，负责发布任务。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tasks <span class="hljs-keyword">import</span> add<br> <br><span class="hljs-comment"># 异步任务</span><br>add.delay(<span class="hljs-number">2</span>, <span class="hljs-number">8</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;hello world&#x27;</span>)<br></code></pre></td></tr></table></figure><p>生产者中，首先导入了来源于消费者的<code>add</code>函数。<code>add</code>函数经过了<code>@app.task</code>的包装，变成了一个<code>Celery</code>任务。这时候我们就可以通过<code>delay</code>方法来异步执行它，并传入两个参数2，8。</p><p>当执行异步任务的时候，程序不会干等两秒返回结果，而是马上执行下面的<code>print(&#39;hello world&#39;)</code>。而<code>add</code>的结果会在后台计算并返回。</p><p>如何执行他们呢？首先需要在命令行执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">celery -A tasks worker --pool=solo -l info<br></code></pre></td></tr></table></figure><p>这是启动了一个Celery工作进程来监听队列，并执行任务。<code>-A</code>代表应用的模块名来自于<code>tasks.py</code>，<code>worker</code>表示要启动工作进程，<code>loglevel</code>则表示日志级别。</p><p>启动后能看到成功连接的日志：</p><p><img src="/images/celery1.png"></p><p>这时我们在另一个命令行执行<code>python client.py</code>。命令行会马上返回<code>hello world</code>。此时程序会在后台执行，可以在Celery进程的后台看到接收和执行的结果。</p><p><img src="/images/celery2.png"></p><p>这样就实现了一个最简单的用例。</p><h2 id="app-task装饰器"><a href="#app-task装饰器" class="headerlink" title="app.task装饰器"></a>app.task装饰器</h2><p><code>@app.task</code>是一个装饰器，用于将程序包装成Celery的实例，其中有几个需要注意的点。</p><ul><li>如果程序本身有多个装饰器，那么<code>app.task</code>必须在最后一个，也就是最上面的那个装饰器。</li><li><code>app.task</code>包含了一个参数<code>bind</code>，意为绑定方法。如果需要访问当前任务请求的信息，或者添加到自定义的任务基类，就需要设置为True。例如：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.task(<span class="hljs-params">bind=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, x, y</span>):<br>    <span class="hljs-built_in">print</span>(self.request.<span class="hljs-built_in">id</span>)<br></code></pre></td></tr></table></figure><p>此时程序的第一个参数必须是任务实例，不然拿不到任务id。</p><ul><li><code>app.task</code>装饰器支持为每个任务都设置一个名称，再未设置的情况下，默认为<code>任务模块.任务名称</code>。例如：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.task(<span class="hljs-params">name=<span class="hljs-string">&#x27;tasks.add&#x27;</span></span>) </span><span class="hljs-comment"># 不显式设置的话也为task.add</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">x, y</span>): <br>    <span class="hljs-keyword">return</span> x + y<br></code></pre></td></tr></table></figure><ul><li><code>app.task</code>装饰器支持<code>retry</code>，这意味着当报错的时候，可以使用实例的<code>retry</code>方法，例如：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.task(<span class="hljs-params">bind=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">send_twitter_status</span>(<span class="hljs-params">self, oauth, tweet</span>):<br>    <span class="hljs-keyword">try</span>:<br>        twitter = Twitter(oauth)<br>        twitter.update_status(tweet)<br>    <span class="hljs-keyword">except</span> (Twitter.FailWhaleError, Twitter.LoginError) <span class="hljs-keyword">as</span> exc:<br>        <span class="hljs-keyword">raise</span> self.retry(exc=exc)<br></code></pre></td></tr></table></figure><p>或者一种更方便的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.task(<span class="hljs-params">autoretry_for=(<span class="hljs-params">FailWhaleError,</span>),</span></span><br><span class="hljs-params"><span class="hljs-meta">          retry_kwargs=&#123;<span class="hljs-string">&#x27;max_retries&#x27;</span>: <span class="hljs-number">5</span>&#125;</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">refresh_timeline</span>(<span class="hljs-params">user</span>):<br>    <span class="hljs-keyword">return</span> twitter.refresh_timeline(user)<br></code></pre></td></tr></table></figure><h2 id="Delay方法"><a href="#Delay方法" class="headerlink" title="Delay方法"></a>Delay方法</h2><p>Cellery提供的<code>delay</code>方法是异步执行的一个接口，它是另外一个接口<code>apply_async</code>的封装。执行后它们会返回一个<code>AsyncResult</code>的实例，这个实例用来跟踪任务的状态，backend就是用来存储这个的。</p><h2 id="结果的获取"><a href="#结果的获取" class="headerlink" title="结果的获取"></a>结果的获取</h2><p>我们可以在上面的代码里直接获取结果以及任务相关的信息。如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tasks <span class="hljs-keyword">import</span> add<br> <br><span class="hljs-comment"># 异步任务</span><br>res = add.delay(<span class="hljs-number">2</span>, <span class="hljs-number">8</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;hello world&#x27;</span>)<br><br>res.get(timeout=<span class="hljs-number">1</span>) <span class="hljs-comment"># 10，如果出现报错会将调用栈返回</span><br>res.<span class="hljs-built_in">id</span> <span class="hljs-comment"># 获取任务id</span><br>res.get(propagate=<span class="hljs-literal">False</span>) <span class="hljs-comment"># 10，但是不返回报错信息</span><br>res.state <span class="hljs-comment"># 任务状态，包含PENDING/STARTED/SUCCESS/FAILURE等</span><br></code></pre></td></tr></table></figure><p>我们在这里直接获取结果，实际上有点像顺序执行。如果我们拿到了任务id，需要有另外一个服务去查看任务状态要怎么做呢？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tasks <span class="hljs-keyword">import</span> app <span class="hljs-comment"># 先导入Celery实例</span><br><br>res = app.AsyncResult(<span class="hljs-string">&#x27;given-task-id&#x27;</span>) <span class="hljs-comment"># 这时候就可以和上面一样获取任务结果了</span><br></code></pre></td></tr></table></figure><h1 id="构建链"><a href="#构建链" class="headerlink" title="构建链"></a>构建链</h1><p>和Langchain一样，Celery也支持链式调用。例如如果需要在一个任务返回后调用另外一个任务。这时就涉及到签名。所谓签名，就是将一个任务的执行选项和参数进行打包，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">add.signature((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), countdown=<span class="hljs-number">10</span>) <span class="hljs-comment"># 为add任务增加了2，2的参数，和倒计时10秒的执行选项</span><br><br>add.s(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># 简写</span><br></code></pre></td></tr></table></figure><p>对于上面这个签名，也可以直接执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">s1 = add.s(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>res = s1.delay()<br>res.get()<br></code></pre></td></tr></table></figure><p>如果使用链的话是这样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> celery <span class="hljs-keyword">import</span> chain<br><span class="hljs-keyword">from</span> tasks <span class="hljs-keyword">import</span> add, multiply<br><br><span class="hljs-comment"># (4 + 4) * 8</span><br>chain(add.s(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>) | multiply.s(<span class="hljs-number">8</span>))().get()<br></code></pre></td></tr></table></figure><h1 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h1><p>Celery支持路由，也就是根据名称将结果发到不同队列：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">app.conf.update(<br>    task_routes = &#123;<br>        <span class="hljs-string">&#x27;tasks.add&#x27;</span>: &#123;<span class="hljs-string">&#x27;queue&#x27;</span>: <span class="hljs-string">&#x27;add_queue&#x27;</span>&#125;,<br>    &#125;,<br>)<br></code></pre></td></tr></table></figure><p>在执行时，在<code>apply_async</code>方法中加入<code>queue</code>参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tasks <span class="hljs-keyword">import</span> add<br>add.apply_async((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), queue=<span class="hljs-string">&#x27;add_queue&#x27;</span>)<br></code></pre></td></tr></table></figure><p>并在执行时使用<code>-Q</code>来选择队列：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">celery -A tasks worker -Q add_queue<br></code></pre></td></tr></table></figure><h2 id="读取配置文件"><a href="#读取配置文件" class="headerlink" title="读取配置文件"></a>读取配置文件</h2><p>在上面的程序中，Broker和Backend的配置写在程序中，但是也可以写成配置文件，用<code>app</code>的<code>config_from_object</code>方法来加载配置。注意配置文件需要和启动文件放在同一路径下。例如：</p><p>在项目路径下创建<code>celery_config.py</code>，内容为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> timedelta<br><span class="hljs-keyword">from</span> celery.schedules <span class="hljs-keyword">import</span> crontab<br><br>broker_url = <span class="hljs-string">&#x27;redis://127.0.0.1:6379&#x27;</span>               <span class="hljs-comment"># 指定 Broker</span><br>result_backend = <span class="hljs-string">&#x27;redis://127.0.0.1:6379/0&#x27;</span>  <span class="hljs-comment"># 指定 Backend</span><br>broker_connection_retry_on_startup = <span class="hljs-literal">True</span><br><br>imports = (                                  <span class="hljs-comment"># 指定导入的任务模块</span><br>    <span class="hljs-string">&#x27;tasks&#x27;</span>,<br>)<br></code></pre></td></tr></table></figure><p>相应的，<code>tasks.py</code>也要修改一下，修改后内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> celery <span class="hljs-keyword">import</span> Celery<br> <br>app = Celery(<span class="hljs-string">&#x27;demo&#x27;</span>) <span class="hljs-comment"># Celery实例的名称</span><br>app.config_from_object(<span class="hljs-string">&#x27;celery_config&#x27;</span>)<br> <br><span class="hljs-meta">@app.task</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">x, y</span>):<br>    time.sleep(<span class="hljs-number">2</span>)     <span class="hljs-comment"># 模拟耗时操作</span><br>    <span class="hljs-keyword">return</span> x + y<br></code></pre></td></tr></table></figure><p>原先定义地址和app都写在<code>task.py</code>中，现在只要在<code>task.py</code>中直接加载配置文件就可以了。</p><p>2024&#x2F;5&#x2F;26 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>Celery</tag>
      
      <tag>消息队列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>工程实践：高计算量的Python程序状态监测</title>
    <link href="/2024/05/19/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E9%AB%98%E8%AE%A1%E7%AE%97%E9%87%8F%E7%9A%84Python%E7%A8%8B%E5%BA%8F%E7%8A%B6%E6%80%81%E7%9B%91%E6%B5%8B/"/>
    <url>/2024/05/19/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E9%AB%98%E8%AE%A1%E7%AE%97%E9%87%8F%E7%9A%84Python%E7%A8%8B%E5%BA%8F%E7%8A%B6%E6%80%81%E7%9B%91%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<p>最近在项目中遇到一个需求，在一个分多阶段的高计算量程序中，当前端接入服务后，同时能得到程序当前的运行状态。这种场景也比较实际，例如在训练模型时的数据准备，数据预处理，模型训练，打包等。这篇博文考虑一下怎么解决这个问题。</p><h1 id="多线程的实现"><a href="#多线程的实现" class="headerlink" title="多线程的实现"></a>多线程的实现</h1><p>我们先定义一个类。这个类里需要主要要实现两个方法：一个是执行高计算任务的<code>execute_task</code>函数，另一个是获取状态的方法<code>get_status</code>。</p><p>在初始化的时候定义了内部变量<code>current_stage</code>，一个线程锁，和一个判断任务是否结束的Flag。在<code>execute_task</code>中分阶段执行高计算量函数中的每个阶段的函数。当执行完成时，Finish Flag被设定为True。</p><p>真正的计算过程在<code>heavy_computation</code>这个方法里实现，它需要接收<code>stage</code>参数，并且根据不同的阶段进行计算。这里我假定每个阶段都会消耗四秒的时间。</p><p>我们使用<code>get_status</code>方法来获取运行中的状态，它的作用是获取当前的任务状态。<code>get_status</code>被<code>task_monitor</code>调用，每隔0.5秒会监控一下执行状态。</p><p>在主程序中，执行顺序如下：</p><ol><li>实例化Task类。</li><li>创建两个线程，一个是执行任务的线程，另一个是监控状态的线程。</li><li>启动线程。</li><li>使用<code>join</code>等待两个线程的完成。</li></ol><blockquote><p>创建线程的代码中出现了如下内容：<code>monitor_thread = threading.Thread(target=lambda: task_monitor(task))</code>。它和<code>monitor_thread = threading.Thread(target=task_monitor(task))</code>的区别在于后者会在创建线程时直接执行方法，而前者则是在线程实际启动后才会执行。如果使用后者，将会马上执行监控任务，并持续输出处于<code>stage</code>为0的状态，而不会继续走下去。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">HighComputationalTask</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.current_stage = <span class="hljs-number">0</span><br>        self.lock = threading.Lock()<br>        self.finished = <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">execute_task</span>(<span class="hljs-params">self</span>):<br>        stages = <span class="hljs-number">4</span><br>        <span class="hljs-keyword">for</span> stage <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, stages + <span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">with</span> self.lock:<br>                self.current_stage = stage<br>            self.heavy_computation(stage)  <span class="hljs-comment"># 执行某个计算密集的任务阶段</span><br>            time.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 模拟延迟</span><br><br>        <span class="hljs-keyword">with</span> self.lock:<br>            self.finished = <span class="hljs-literal">True</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">heavy_computation</span>(<span class="hljs-params">self, stage</span>):<br>        <span class="hljs-comment"># 在这里添加实际的计算任务</span><br>        time.sleep(<span class="hljs-number">5</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Executing stage <span class="hljs-subst">&#123;stage&#125;</span> of the computation.&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_status</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">with</span> self.lock:<br>            <span class="hljs-keyword">if</span> self.finished:<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Task Completed&quot;</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Currently executing stage <span class="hljs-subst">&#123;self.current_stage&#125;</span>.&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task_monitor</span>(<span class="hljs-params">task</span>):<br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> task.finished:<br>        <span class="hljs-built_in">print</span>(task.get_status())<br>        time.sleep(<span class="hljs-number">0.5</span>)  <span class="hljs-comment"># 每0.5秒检查一次状态</span><br><br><span class="hljs-comment"># 创建任务对象</span><br>task = HighComputationalTask()<br><br><span class="hljs-comment"># 创建线程：一个用于执行任务，一个用于监控任务状态</span><br>task_thread = threading.Thread(target=task.execute_task)<br>monitor_thread = threading.Thread(target=<span class="hljs-keyword">lambda</span>: task_monitor(task))<br><br><span class="hljs-comment"># 启动线程</span><br>task_thread.start()<br>monitor_thread.start()<br><br><span class="hljs-comment"># 等待线程结束</span><br>task_thread.join()<br>monitor_thread.join()<br></code></pre></td></tr></table></figure><h1 id="异步方法的实现"><a href="#异步方法的实现" class="headerlink" title="异步方法的实现"></a>异步方法的实现</h1><p>现在假设我们将高计算任务改成从网络接口的请求调用，这时候的运行瓶颈就出现在网络接口调用。我们可以用异步方法实现一下。代码逻辑基本上一样，区别在于不需要开多线程，只需要异步执行就可以了。</p><blockquote><p>异步和多线程的区别：异步通常在单线程内执行，通过状态切换来防止阻塞，由特定的库来实现，而多线程由操作系统来分配上下文切换。</p><p>多线程适合高计算任务，异步适合高IO任务。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> asyncio<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">HighComputationalTask</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.current_stage = <span class="hljs-number">0</span><br>        self.finished = <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">execute_task</span>(<span class="hljs-params">self</span>):<br>        stages = <span class="hljs-number">4</span><br>        <span class="hljs-keyword">for</span> stage <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, stages + <span class="hljs-number">1</span>):<br>            self.current_stage = stage<br>            <span class="hljs-keyword">await</span> self.heavy_computation(stage)<br>            <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 模拟延迟</span><br><br>        self.finished = <span class="hljs-literal">True</span><br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">heavy_computation</span>(<span class="hljs-params">self, stage</span>):<br>        <span class="hljs-comment"># 模拟异步执行的计算任务</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Executing stage <span class="hljs-subst">&#123;stage&#125;</span> of the computation.&quot;</span>)<br>        <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 模拟计算延迟</span><br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_status</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">if</span> self.finished:<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Task Completed&quot;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Currently executing stage <span class="hljs-subst">&#123;self.current_stage&#125;</span>.&quot;</span><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">task_monitor</span>(<span class="hljs-params">task</span>):<br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> task.finished:<br>        status = <span class="hljs-keyword">await</span> task.get_status()<br>        <span class="hljs-built_in">print</span>(status)<br>        <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">0.5</span>)<br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    task = HighComputationalTask()<br>    task_future = asyncio.create_task(task.execute_task())<br>    monitor_future = asyncio.create_task(task_monitor(task))<br>    <span class="hljs-keyword">await</span> asyncio.gather(task_future, monitor_future)<br><br>asyncio.run(main())<br></code></pre></td></tr></table></figure><h1 id="使用Flask实现接口请求状态"><a href="#使用Flask实现接口请求状态" class="headerlink" title="使用Flask实现接口请求状态"></a>使用Flask实现接口请求状态</h1><p>假设我们的服务是一个网络服务，其他人不光能通过调用接口来启动服务，也能调用另一个接口来接收状态。这时候就需要对相应的任务包装成接口对外开放。我们用Flask来模拟一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, jsonify, request<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">import</span> threading<br><br>app = Flask(__name__)<br>tasks = &#123;&#125;  <span class="hljs-comment"># 存储任务的字典</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ComputationalTask</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.stages = <span class="hljs-number">4</span><br>        self.current_stage = <span class="hljs-number">0</span><br>        self.finished = <span class="hljs-literal">False</span><br>        self.result = <span class="hljs-literal">None</span>  <span class="hljs-comment"># 初始化结果存储变量</span><br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">execute_task</span>(<span class="hljs-params">self</span>):<br>        data = <span class="hljs-literal">None</span>  <span class="hljs-comment"># 初始化Data</span><br>        <span class="hljs-keyword">for</span> stage <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, self.stages + <span class="hljs-number">1</span>):<br>            self.current_stage = stage<br>            data = <span class="hljs-keyword">await</span> self.heavy_computation(stage, data)  <span class="hljs-comment"># 使用正确的变量data</span><br>            self.result = data  <span class="hljs-comment"># 更新结果</span><br>        self.finished = <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">return</span> data<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">heavy_computation</span>(<span class="hljs-params">self, stage, input_data</span>):<br>        <span class="hljs-comment"># 模拟计算密集型任务</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Executing stage <span class="hljs-subst">&#123;stage&#125;</span> with input data: <span class="hljs-subst">&#123;input_data&#125;</span>.&quot;</span>)<br>        <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 模拟计算延迟</span><br>        <span class="hljs-keyword">return</span> input_data <br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_status</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 获取当前状态</span><br>        <span class="hljs-keyword">if</span> self.finished:<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Task Completed&quot;</span>, self.result<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Currently executing stage <span class="hljs-subst">&#123;self.current_stage&#125;</span>.&quot;</span>, self.result<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">start_async_task</span>(<span class="hljs-params">task_id</span>):<br>    loop = asyncio.new_event_loop()<br>    task = ComputationalTask()<br>    tasks[task_id] = task<br>    final_result = loop.run_until_complete(task.execute_task())<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Task <span class="hljs-subst">&#123;task_id&#125;</span> completed with result: <span class="hljs-subst">&#123;final_result&#125;</span>&quot;</span>)<br>    loop.close()<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/start_task/&lt;task_id&gt;&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)  </span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">start_task</span>(<span class="hljs-params">task_id</span>):<br>    <span class="hljs-comment"># 如果已有任务，直接返回</span><br>    <span class="hljs-keyword">if</span> task_id <span class="hljs-keyword">in</span> tasks:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Task is already running or completed.&#x27;</span>&#125;), <span class="hljs-number">400</span><br>    thread = threading.Thread(target=start_async_task, args=(task_id,))<br>    thread.start()<br>    <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">f&#x27;Task <span class="hljs-subst">&#123;task_id&#125;</span> started.&#x27;</span>&#125;), <span class="hljs-number">200</span><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/task_status/&lt;task_id&gt;&#x27;</span>, methods=[<span class="hljs-string">&#x27;GET&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task_status</span>(<span class="hljs-params">task_id</span>):<br>    <span class="hljs-keyword">if</span> task_id <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> tasks:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Task not found.&#x27;</span>&#125;), <span class="hljs-number">404</span><br>    status, result = tasks[task_id].get_status()<br>    <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;task_id&#x27;</span>: task_id, <span class="hljs-string">&#x27;status&#x27;</span>: status, <span class="hljs-string">&#x27;result&#x27;</span>: result&#125;), <span class="hljs-number">200</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run(debug=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>启动服务后，我们向默认端口5000端口发送请求来启动任务，也可以发送请求获取当前执行的状态。启动任务的地址是<code>http://localhost:5000/start_task/task123</code>。</p><p><img src="/images/async_0.png"></p><p><img src="/images/async_1.png"></p><h1 id="获取参数并直接返回结果"><a href="#获取参数并直接返回结果" class="headerlink" title="获取参数并直接返回结果"></a>获取参数并直接返回结果</h1><p>我们细化一下，用户通过Post命令向启动任务的接口进行传参，我们获取到参数后，执行任务，并直接返回结果，在执行过程时能通过GET方法查看到执行的阶段。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request, jsonify<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">import</span> threading<br><br>app = Flask(__name__)<br>tasks = &#123;&#125;  <span class="hljs-comment"># 存储任务的字典</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ComputationalTask</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, initial_data</span>):<br>        self.data = initial_data  <span class="hljs-comment"># 初始化入参</span><br>        self.stages = <span class="hljs-number">4</span><br>        self.current_stage = <span class="hljs-number">0</span><br>        self.finished = <span class="hljs-literal">False</span><br>        self.result = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">execute_task</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> stage <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, self.stages + <span class="hljs-number">1</span>):<br>            self.current_stage = stage<br>            self.data = <span class="hljs-keyword">await</span> self.process_stage(self.data, stage)  <span class="hljs-comment"># 更新每阶段处理的结果</span><br>            <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 模拟处理时间</span><br>        self.finished = <span class="hljs-literal">True</span><br>        self.result = self.data<br>        <span class="hljs-keyword">return</span> self.result<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">process_stage</span>(<span class="hljs-params">self, input_data, stage</span>):<br>        <span class="hljs-comment"># 模拟每阶段处理逻辑，输出为输入的修改版</span><br>        result = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;input_data&#125;</span> processed at stage <span class="hljs-subst">&#123;stage&#125;</span>&quot;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Processing stage <span class="hljs-subst">&#123;stage&#125;</span> with data: <span class="hljs-subst">&#123;result&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">return</span> result<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">start_async_task</span>(<span class="hljs-params">task_id, initial_data</span>):<br>    <span class="hljs-comment"># 开启event loop</span><br>    loop = asyncio.new_event_loop()<br>    task = ComputationalTask(initial_data)<br>    tasks[task_id] = &#123;<span class="hljs-string">&#x27;task&#x27;</span>: task, <span class="hljs-string">&#x27;thread&#x27;</span>: <span class="hljs-literal">None</span>&#125;<br>    <span class="hljs-comment"># 获取结果并保存</span><br>    final_result = loop.run_until_complete(task.execute_task())<br>    <br>    tasks[task_id][<span class="hljs-string">&#x27;result&#x27;</span>] = final_result<br>    loop.close()<br>    <span class="hljs-keyword">return</span> final_result<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/start_task&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">start_task</span>():<br>    <span class="hljs-comment"># 解析入参</span><br>    req_data = request.get_json()<br>    task_id = req_data.get(<span class="hljs-string">&#x27;task_id&#x27;</span>)<br>    initial_data = req_data.get(<span class="hljs-string">&#x27;data&#x27;</span>)<br>    <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> task_id <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> initial_data:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Missing task_id or data in request.&#x27;</span>&#125;), <span class="hljs-number">400</span><br>    <span class="hljs-keyword">if</span> task_id <span class="hljs-keyword">in</span> tasks:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Task is already running or completed.&#x27;</span>&#125;), <span class="hljs-number">400</span><br>    <br>    <span class="hljs-comment"># 开始执行</span><br>    thread = threading.Thread(target=start_async_task, args=(task_id, initial_data))<br>    thread.start()<br>    tasks[task_id][<span class="hljs-string">&#x27;thread&#x27;</span>] = thread<br>    thread.join()  <span class="hljs-comment"># 等待任务完成</span><br>    final_result = tasks[task_id][<span class="hljs-string">&#x27;result&#x27;</span>]<br>    <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">f&#x27;Task <span class="hljs-subst">&#123;task_id&#125;</span> completed.&#x27;</span>, <span class="hljs-string">&#x27;result&#x27;</span>: final_result&#125;), <span class="hljs-number">200</span><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/task_status/&lt;task_id&gt;&#x27;</span>, methods=[<span class="hljs-string">&#x27;GET&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task_status</span>(<span class="hljs-params">task_id</span>):<br>    <span class="hljs-keyword">if</span> task_id <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> tasks:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Task not found.&#x27;</span>&#125;), <span class="hljs-number">404</span><br>    task = tasks[task_id][<span class="hljs-string">&#x27;task&#x27;</span>]<br>    <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;task_id&#x27;</span>: task_id, <span class="hljs-string">&#x27;status&#x27;</span>: <span class="hljs-string">&#x27;Completed&#x27;</span> <span class="hljs-keyword">if</span> task.finished <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;In progress&#x27;</span>&#125;), <span class="hljs-number">200</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run(debug=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h1 id="添加Uuid-通过接口获取结果-定时清理任务"><a href="#添加Uuid-通过接口获取结果-定时清理任务" class="headerlink" title="添加Uuid&#x2F;通过接口获取结果&#x2F;定时清理任务"></a>添加Uuid&#x2F;通过接口获取结果&#x2F;定时清理任务</h1><p>在前面的基础上，可以在每次调用的时候返回一个uuid，通过这个uuid来查询任务执行状态。此外，也可以用获取状态的接口获取最终的返回值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request, jsonify<br><span class="hljs-keyword">import</span> uuid<br><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">import</span> time<br><br>app = Flask(__name__)<br>tasks = &#123;&#125;  <span class="hljs-comment"># 记录任务</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ComputationalTask</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, initial_data</span>):<br>        self.data = initial_data <span class="hljs-comment"># 初始数据</span><br>        self.stages = <span class="hljs-number">4</span> <span class="hljs-comment"># 总阶段数</span><br>        self.current_stage = <span class="hljs-number">0</span><br>        self.finished = <span class="hljs-literal">False</span><br>        self.result = <span class="hljs-literal">None</span> <span class="hljs-comment"># 当前输出</span><br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">execute_task</span>(<span class="hljs-params">self</span>):<br>        data = self.data<br>        <span class="hljs-comment"># 执行任务</span><br>        <span class="hljs-keyword">for</span> stage <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, self.stages + <span class="hljs-number">1</span>):<br>            self.current_stage = stage<br>            data = <span class="hljs-keyword">await</span> self.process_stage(stage, data)<br>            <span class="hljs-comment"># 获取当前阶段的输出</span><br>            self.result = data<br>        self.finished = <span class="hljs-literal">True</span><br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">process_stage</span>(<span class="hljs-params">self, stage, input_data</span>):<br>        <span class="hljs-comment"># 根据当前阶段进行计算</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Executing stage <span class="hljs-subst">&#123;stage&#125;</span> with input: <span class="hljs-subst">&#123;input_data&#125;</span>&quot;</span>)<br>        result = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;input_data&#125;</span> -&gt; processed by stage <span class="hljs-subst">&#123;stage&#125;</span>&quot;</span><br>        <span class="hljs-keyword">await</span> asyncio.sleep(<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> result<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_status</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 如果已结束，返回结果</span><br>        <span class="hljs-keyword">if</span> self.finished:<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Task Completed&quot;</span>, self.result<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Currently executing stage <span class="hljs-subst">&#123;self.current_stage&#125;</span>.&quot;</span>, self.result<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">start_async_task</span>(<span class="hljs-params">task_id, initial_data</span>):<br>    <span class="hljs-comment"># 启动异步服务</span><br>    loop = asyncio.new_event_loop()<br>    asyncio.set_event_loop(loop)<br>    task = ComputationalTask(initial_data)<br>    tasks[task_id] = task<br>    loop.run_until_complete(task.execute_task())<br>    loop.close()<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/start_task&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">start_task</span>():<br>    <span class="hljs-comment"># 解析数据</span><br>    req_data = request.get_json()<br>    task_id = <span class="hljs-built_in">str</span>(uuid.uuid4())<br>    initial_data = req_data.get(<span class="hljs-string">&#x27;data&#x27;</span>)<br>    <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> initial_data:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Missing data in request.&#x27;</span>&#125;), <span class="hljs-number">400</span><br>    <span class="hljs-keyword">if</span> task_id <span class="hljs-keyword">in</span> tasks:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Task is already running or completed.&#x27;</span>&#125;), <span class="hljs-number">400</span><br>    <br>    thread = threading.Thread(target=start_async_task, args=(task_id, initial_data))<br>    thread.start()<br>    <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Task started.&#x27;</span>, <span class="hljs-string">&#x27;task_id&#x27;</span>: task_id&#125;), <span class="hljs-number">200</span><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/task_status/&lt;task_id&gt;&#x27;</span>, methods=[<span class="hljs-string">&#x27;GET&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task_status</span>(<span class="hljs-params">task_id</span>):<br>    <span class="hljs-keyword">if</span> task_id <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> tasks:<br>        <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;message&#x27;</span>: <span class="hljs-string">&#x27;Task not found.&#x27;</span>&#125;), <span class="hljs-number">404</span><br>    status, result = tasks[task_id].get_status()<br>    <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;task_id&#x27;</span>: task_id, <span class="hljs-string">&#x27;status&#x27;</span>: status&#125;), <span class="hljs-number">200</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cleanup_tasks</span>():<br>    <span class="hljs-comment"># 清理队列</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        time.sleep(<span class="hljs-number">60</span>)<br>        <span class="hljs-keyword">with</span> app.app_context():<br>            <span class="hljs-comment"># 删除已经结束的任务</span><br>            keys_to_remove = [k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> tasks.items() <span class="hljs-keyword">if</span> v[<span class="hljs-string">&#x27;task&#x27;</span>].finished]<br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> keys_to_remove:<br>                <span class="hljs-keyword">del</span> tasks[key]<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Removed finished task <span class="hljs-subst">&#123;key&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    cleaner_thread = threading.Thread(target=cleanup_tasks, daemon=<span class="hljs-literal">True</span>)<br>    cleaner_thread.start()<br>    app.run(debug=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p><img src="/images/async_3.png"></p><p><img src="/images/async_4.png"></p><p>这样，每次调用接口就可以从返回一个任务ID，通过这个ID发送请求来查询任务状态。并且每个60s会清理任务ID的字典，防止字典过大。实际使用中，可以用redis来代替这个部分。</p><p>2024&#x2F;5&#x2F;19 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>异步方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征工程：类别变量除了独热编码还有什么编码？</title>
    <link href="/2024/05/16/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%EF%BC%9A%E7%B1%BB%E5%88%AB%E5%8F%98%E9%87%8F%E9%99%A4%E4%BA%86%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81%E8%BF%98%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%96%E7%A0%81%EF%BC%9F/"/>
    <url>/2024/05/16/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%EF%BC%9A%E7%B1%BB%E5%88%AB%E5%8F%98%E9%87%8F%E9%99%A4%E4%BA%86%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81%E8%BF%98%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%96%E7%A0%81%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<p>在学习机器学习的过程中，在学习各式各样的模型前，数据预处理往往是我们最先开始学习的部分。这部分内容看起来没有各式各样的模型那样抓人眼球，但是在整个机器学习流程中扮演着非常重要的角色。有一句经典的话：“数据质量决定上限，而模型只是逼近这个上限。”</p><p>在刚开始打Kaggle的那段时间，我只用过Label Encoding和OneHot Encoding。这两个编码方式各有优劣，我的理解是，Label Encoding适合有序分类。OneHot Encoding适合无序分类，但会让维度线性增长。一个场景就是地点特征，如果一个分类中有五十个城市，独热编码会带来五十个维度，而标签编码会为不同城市带来错误的位置信息。</p><p>显然这两种编码方式不足以应付所有的场景，因此有必要接触和学习一下新的编码方式。Python中的Category Encoders库封装了22种编码方式，今天来解读一下。</p><p><img src="/images/category.png" alt=""></p><h1>Ordinal Encoding</h1><p>首先是Ordinal Encoding，序列编码。这种编码针对的是有序的标签，例如学历，等级等等。对于一个具有 𝑚 个类别的特征 ，我们将其对应地映射到 [0,𝑚−1] 的整数。</p><p>这样做的好处是，比Label Encoder处理的标签增加了类别之间的等级/数值关系。缺点是不能处理无序标签，而且类别之前的距离关系也不够精确。</p><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> category_encoders <span class="hljs-keyword">as</span> ce<br><br>data = &#123;<br>    <span class="hljs-string">&#x27;CustomerID&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>],<br>    <span class="hljs-string">&#x27;Satisfaction&#x27;</span>: [<span class="hljs-string">&#x27;Satisfied&#x27;</span>, <span class="hljs-string">&#x27;Dissatisfied&#x27;</span>, <span class="hljs-string">&#x27;Neutral&#x27;</span>, <span class="hljs-string">&#x27;Satisfied&#x27;</span>, <span class="hljs-string">&#x27;Dissatisfied&#x27;</span>],<br>    <span class="hljs-string">&#x27;ProductType&#x27;</span>: [<span class="hljs-string">&#x27;Electronics&#x27;</span>, <span class="hljs-string">&#x27;Furniture&#x27;</span>, <span class="hljs-string">&#x27;Electronics&#x27;</span>, <span class="hljs-string">&#x27;Clothing&#x27;</span>, <span class="hljs-string">&#x27;Furniture&#x27;</span>]<br>&#125;<br><br>X = pd.DataFrame(data)<br><br>encoder = ce.OrdinalEncoder(cols=[<span class="hljs-string">&#x27;Satisfaction&#x27;</span>, <span class="hljs-string">&#x27;ProductType&#x27;</span>], return_df=<span class="hljs-literal">True</span>)<br>numeric_dataset  = encoder.fit_transform(X)<br></code></pre></td></tr></table></figure><p>除了这种方式，也可以直接用map方法来映射：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">ord_map = &#123;<span class="hljs-string">&#x27;Gen 1&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;Gen 2&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;Gen 3&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;Gen 4&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;Gen 5&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;Gen 6&#x27;</span>: <span class="hljs-number">6</span>&#125;<br>df[<span class="hljs-string">&#x27;Category_Label&#x27;</span>] = df[<span class="hljs-string">&#x27;Category_Label&#x27;</span>].<span class="hljs-built_in">map</span>(ord_map)<br></code></pre></td></tr></table></figure><h1>Count Encoding/Frequency Encoding</h1><p>下一个编码方式是频数编码，即将类别特征替换为在数据集中出现的次数。假如某个特征出现了100次，那么就记作100。</p><p>这种编码方式适合高基数的数据集，也就是类别数特别多。在前面提到的多城市场景，它可以作为一种编码方式，来体现城市的热门程度。不过它只考虑类别自身出现的次数，不考虑类别之间的关系，会丢失一定的信息。此外，不同类别的出现次数可能一致，这也会带来一定的混淆。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>data = &#123;<span class="hljs-string">&#x27;Category&#x27;</span>: [<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>]&#125;<br>df = pd.DataFrame(data)<br><br>frequency_map = df[<span class="hljs-string">&#x27;Category&#x27;</span>].value_counts(normalize=<span class="hljs-literal">True</span>).to_dict()<br><span class="hljs-comment">#frequency_map = df.groupby(&#x27;Category&#x27;).size()/len(df)</span><br>df[<span class="hljs-string">&#x27;Category_Frequency&#x27;</span>] = df[<span class="hljs-string">&#x27;Category&#x27;</span>].<span class="hljs-built_in">map</span>(frequency_map)<br><br><span class="hljs-built_in">print</span>(df[[<span class="hljs-string">&#x27;Category&#x27;</span>, <span class="hljs-string">&#x27;Category_Frequency&#x27;</span>]])<br></code></pre></td></tr></table></figure><p><img src="/images/prepro_3.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> category_encoders <span class="hljs-keyword">as</span> ce<br><br>data = &#123;<br>    <span class="hljs-string">&#x27;CustomerID&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>],<br>    <span class="hljs-string">&#x27;Satisfaction&#x27;</span>: [<span class="hljs-string">&#x27;Satisfied&#x27;</span>, <span class="hljs-string">&#x27;Dissatisfied&#x27;</span>, <span class="hljs-string">&#x27;Neutral&#x27;</span>, <span class="hljs-string">&#x27;Satisfied&#x27;</span>, <span class="hljs-string">&#x27;Dissatisfied&#x27;</span>],<br>    <span class="hljs-string">&#x27;ProductType&#x27;</span>: [<span class="hljs-string">&#x27;Electronics&#x27;</span>, <span class="hljs-string">&#x27;Furniture&#x27;</span>, <span class="hljs-string">&#x27;Electronics&#x27;</span>, <span class="hljs-string">&#x27;Clothing&#x27;</span>, <span class="hljs-string">&#x27;Furniture&#x27;</span>]<br>&#125;<br><br>X = pd.DataFrame(data)<br><br>encoder = ce.CountEncoder(cols=[<span class="hljs-string">&#x27;Satisfaction&#x27;</span>, <span class="hljs-string">&#x27;ProductType&#x27;</span>], return_df=<span class="hljs-literal">True</span>)<br>numeric_dataset  = encoder.fit_transform(X)<br></code></pre></td></tr></table></figure><h1>Binary Encoding/Hash Encoding/Base N Encoding</h1><p>我把二进制编码，哈希编码和BaseN编码放在了一起，因为它们都是只是将类别进行映射。</p><p>二进制编码分为两步：先为每个类别分配ID，再根据ID生成对应的二进制编码。本质上是用二进制对ID进行哈希映射。</p><p>哈希编码也是类似，字符串将被转换为一个惟一的哈希值。对于稀疏的高维特征，可以使用哈希编码。</p><p>BaseN编码则是将类别编码为Base-N代表的数组，N越高代表输出的维度越高。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> category_encoders <span class="hljs-keyword">as</span> ce<br><br>data = &#123;<br>    <span class="hljs-string">&#x27;Color&#x27;</span>: [<span class="hljs-string">&#x27;Red&#x27;</span>, <span class="hljs-string">&#x27;Blue&#x27;</span>, <span class="hljs-string">&#x27;Green&#x27;</span>, <span class="hljs-string">&#x27;Blue&#x27;</span>, <span class="hljs-string">&#x27;Red&#x27;</span>]<br>&#125;<br><br>X = pd.DataFrame(data)<br><br>encoder = ce.HashingEncoder(n_components=<span class="hljs-number">3</span>)<br>numeric_dataset = encoder.fit_transform(X[<span class="hljs-string">&#x27;Color&#x27;</span>])<br><br><span class="hljs-built_in">print</span>(numeric_dataset)<br></code></pre></td></tr></table></figure><p><img src="/images/prepro_8.png" alt=""></p><h1>Target Encoding</h1><p>目标编码，对于每个类别，计算该类别下目标变量的均值，或者其他统计量（中位数等等）。这是一种有监督的编码方式。如果直接使用均值，可能会过拟合，在更普适的情况下，利用样本的先验概率和后验概率结合权重函数来得到均值，其中还会进行一些贝叶斯平滑。</p><p><img src="/images/prepro_4.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">data = &#123;<br>    <span class="hljs-string">&#x27;CustomerID&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>],<br>    <span class="hljs-string">&#x27;Satisfaction&#x27;</span>: [<span class="hljs-string">&#x27;Satisfied&#x27;</span>, <span class="hljs-string">&#x27;Dissatisfied&#x27;</span>, <span class="hljs-string">&#x27;Neutral&#x27;</span>, <span class="hljs-string">&#x27;Satisfied&#x27;</span>, <span class="hljs-string">&#x27;Dissatisfied&#x27;</span>],<br>    <span class="hljs-string">&#x27;ProductType&#x27;</span>: [<span class="hljs-string">&#x27;Electronics&#x27;</span>, <span class="hljs-string">&#x27;Furniture&#x27;</span>, <span class="hljs-string">&#x27;Electronics&#x27;</span>, <span class="hljs-string">&#x27;Clothing&#x27;</span>, <span class="hljs-string">&#x27;Furniture&#x27;</span>],<br>    <span class="hljs-string">&#x27;Target&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>] <br>&#125;<br><br>df = pd.DataFrame(data)<br><br>X = df[[<span class="hljs-string">&#x27;CustomerID&#x27;</span>, <span class="hljs-string">&#x27;Satisfaction&#x27;</span>, <span class="hljs-string">&#x27;ProductType&#x27;</span>]]<br>Y = df[<span class="hljs-string">&#x27;Target&#x27;</span>]<br><br>encoder = ce.TargetEncoder(cols=[<span class="hljs-string">&#x27;Satisfaction&#x27;</span>, <span class="hljs-string">&#x27;ProductType&#x27;</span>], min_samples_leaf=<span class="hljs-number">10</span>, smoothing=<span class="hljs-number">1.0</span>)<br>numeric_dataset = encoder.fit_transform(X, Y)<br><br>numeric_dataset<br></code></pre></td></tr></table></figure><p><img src="/images/prepro_6.png" alt=""></p><p>基于Target Encoding的思想，衍生出了不同的编码方式。</p><h2 id="CatBoost-Encoding">CatBoost Encoding</h2><p>和Target Encoding思想类似，CatBoost Encoding使用目标变量的统计数据（如平均值）来替换每个类别，区别在于CatBoost 编码采取了特殊的策略来降低目标泄露（target leakage）和过拟合的风险。公式如下：$\text{Encoded value} =\frac{\text{TargetSum} + \text{prior}}{\text{FeatureCount} + 1} \tag{1}$。</p><ul><li><strong>Target Sum</strong>：指定类别在Target Value中的总和。找到所有类别为目标类别的行，计算它们对应的Target的和。</li><li><strong>Prior</strong>：对于整个数据集而言，Target值的总和/所有的观测变量数目。这个值是固定的，即数据的行数/Target的总和。</li><li><strong>FeatureCount</strong>：到目前为止已经看到的、具有与此相同值的分类特征的总数。+1防止分母为0。</li></ul><p>例如，对于 <code>color=[&quot;red&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;red&quot;, &quot;black&quot;, &quot;black&quot;, &quot;blue&quot;, &quot;green&quot;] and target column with values, target=[1, 2, 3, 2, 3, 1, 4, 4, 2, 3]</code>。</p><p>这里，先验$\text{prior}=25/10=2.5$。</p><p>对于分类<code>red</code>，$\text{TargetSum}=1+3+1=5$，而<code>red</code>在特征中出现了3次。因此$\text{FeatureCount}=3$ 。所以最后编码为：$(5+2.5)/(3+1)=1.875$。</p><h2 id="M-Estimator-Encoding">M Estimator Encoding</h2><p>M Estimator Encoding是Target Encoding的简化版本。用于在保留类别之间差异的同时，通过引入全局均值来减少每个类别中的方差。它在处理具有少量样本的类别时比较有效。公式如下：</p><p>$\text{Encoded value} = \frac{n \times \text{mean}(y_{\text{category}}) + m \times \text{mean}(y_{\text{global}})}{n + m}$。</p><ul><li><p>$n$ 是当前类别中的样本数量。</p></li><li><p>$\text{mean}(y_{\text{category}}) $是当前类别的目标均值。</p></li><li><p>$\text{mean}(y_{\text{global}})$ 是全数据集的目标均值。</p></li><li><p>$m$ 是一个平滑参数，它决定了全局均值在编码中的权重，值越大，编码值越倾向于全局均值。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> category_encoders <span class="hljs-keyword">as</span> ce<br><br>data = &#123;<br>    <span class="hljs-string">&#x27;Color&#x27;</span>: [<span class="hljs-string">&#x27;Red&#x27;</span>, <span class="hljs-string">&#x27;Blue&#x27;</span>, <span class="hljs-string">&#x27;Green&#x27;</span>, <span class="hljs-string">&#x27;Blue&#x27;</span>, <span class="hljs-string">&#x27;Red&#x27;</span>],<br>    <span class="hljs-string">&#x27;Outcome&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>] <br>&#125;<br><br>df = pd.DataFrame(data)<br>encoder = ce.MEstimateEncoder(cols=[<span class="hljs-string">&#x27;Color&#x27;</span>], m=<span class="hljs-number">5.0</span>)  <br><br>df_encoded = encoder.fit_transform(df[<span class="hljs-string">&#x27;Color&#x27;</span>], df[<span class="hljs-string">&#x27;Outcome&#x27;</span>])<br><span class="hljs-built_in">print</span>(df_encoded)<br></code></pre></td></tr></table></figure><h1>Leave One Out</h1><p>Leave One Out也是基于目标编码，不过在传统的目标编码中，类别的编码值通过计算该类别中所有样本的目标变量均值获得。因为当前样本的目标值也参与了编码值的计算，可能会导致过拟合。留一编码通过对每个样本进行编码时排除该样本的目标值，来减少这种过拟合的风险。</p><p>公式如下：$\mu_{x_i}^{(-i)} = \frac{\sum_{j \neq i} y_j \cdot \mathbb{I}(x_j = x_i)}{\sum_{j \neq i} \mathbb{I}(x_j = x_i)}$</p><p>公式表示为为类别$x_i$的样本中，排除第$i$个样本后的目标变量均值。</p><p><strong>分子部分</strong>：计算类别为$x_i$的样本中，排除第$i$个样本后的目标变量之和。</p><p><strong>分母部分</strong>：计算类别为$x_i$的样本中，排除第$i$个样本后的样本数量。</p><p>$\mathbb{I}(x_j = x_i)$是指示函数，$x_j = x_i$时取值为1，否则为0。</p><p>这种情况下，当类别中目标值不同时，留一编码值会有所变化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> category_encoders <span class="hljs-keyword">as</span> ce<br><br>X = pd.DataFrame(np.array([[<span class="hljs-string">&#x27;male&#x27;</span>,<span class="hljs-number">10</span>],[<span class="hljs-string">&#x27;female&#x27;</span>, <span class="hljs-number">20</span>], [<span class="hljs-string">&#x27;male&#x27;</span>,<span class="hljs-number">10</span>], <br>                       [<span class="hljs-string">&#x27;female&#x27;</span>,<span class="hljs-number">20</span>],[<span class="hljs-string">&#x27;female&#x27;</span>,<span class="hljs-number">10</span>],[<span class="hljs-string">&#x27;female&#x27;</span>,<span class="hljs-number">30</span>],[<span class="hljs-string">&#x27;male&#x27;</span>,<span class="hljs-number">10</span>]]),<br>             columns = [<span class="hljs-string">&#x27;Sex&#x27;</span>,<span class="hljs-string">&#x27;Type&#x27;</span>])<br>y = np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>])<br><span class="hljs-built_in">print</span>(X)<br><br>encoder = ce.LeaveOneOutEncoder(cols = [<span class="hljs-string">&#x27;Sex&#x27;</span>, <span class="hljs-string">&#x27;Type&#x27;</span>]).fit(X,y)<br><span class="hljs-built_in">print</span>(encoder.transform(X))<br></code></pre></td></tr></table></figure><p><img src="/images/prepro_5.png" alt=""></p><h1>WoE</h1><p>证据权重（Weight of Evidence）是关于分类自变量和因变量之间关系的编码方式。源自信用评分领域，曾用于区分用户是违约拖欠还是已经偿还贷款。证据权重的数学定义是优势比的自然对数，即：$\text{WoE} = \log\left(\frac{\text{Non-Events or Goods}}{\text{Events or Bads}}\right)$。</p><ul><li><strong>Non-Events or Goods</strong> ：在某个特定组或桶中好客户的比例。</li><li><strong>Events or Bads</strong> ：在同一个组或桶中坏客户的比例。</li></ul><p>如果一个分类变量的某个类别中有 20% 是坏客户（events），80% 是好客户（non-events），那么该类别的 WoE 计算为：</p><p>$\text{WoE} = \ln\left(\frac{\text{Proportion of Non-Events}}{\text{Proportion of Events}}\right) = \ln\left(\frac{80%}{20%}\right) = \ln(4)$</p><p>这个值表明该类别相对于其他类别在区分好坏客户上的强度。WoE 值越高，表明在该组中的好客户（non-events）的比例远高于坏客户（events）。这意味着该组的风险较低，或者说该组对于预测目标变量（比如违约）是有利的。WoE值越低（特别是负值），表示该组中坏客户的比例高于好客户。这意味着该组的风险较高，或者说该组对于预测目标变量是不利的。WoE为0，则这个组中的分布是完全随机的，预测能力完全不够。</p><p>WoE的问题在于没有考虑到变量之间的相关性，也只是从自身特征出发。此外，它只适用于二分类问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">data = &#123;<br>    <span class="hljs-string">&#x27;CustomerID&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>],<br>    <span class="hljs-string">&#x27;Satisfaction&#x27;</span>: [<span class="hljs-string">&#x27;Satisfied&#x27;</span>, <span class="hljs-string">&#x27;Dissatisfied&#x27;</span>, <span class="hljs-string">&#x27;Neutral&#x27;</span>, <span class="hljs-string">&#x27;Satisfied&#x27;</span>, <span class="hljs-string">&#x27;Dissatisfied&#x27;</span>],<br>    <span class="hljs-string">&#x27;ProductType&#x27;</span>: [<span class="hljs-string">&#x27;Electronics&#x27;</span>, <span class="hljs-string">&#x27;Furniture&#x27;</span>, <span class="hljs-string">&#x27;Electronics&#x27;</span>, <span class="hljs-string">&#x27;Clothing&#x27;</span>, <span class="hljs-string">&#x27;Furniture&#x27;</span>],<br>    <span class="hljs-string">&#x27;Target&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]  <br>&#125;<br><br>df = pd.DataFrame(data)<br>target = df[<span class="hljs-string">&#x27;Target&#x27;</span>]<br><br>woe_encoder = ce.WOEEncoder()<br><br>df_encoded = woe_encoder.fit_transform(df[[<span class="hljs-string">&#x27;Satisfaction&#x27;</span>, <span class="hljs-string">&#x27;ProductType&#x27;</span>]], target)<br><span class="hljs-built_in">print</span>(df_encoded)<br></code></pre></td></tr></table></figure><p><img src="/images/prepro_7.png" alt=""></p><h1>总结</h1><ul><li>离散特征的类别数过多的情况不宜使用OneHot Encoder，容易维度爆炸。</li><li>Target Encoder容易过拟合，因此需要加入CV，正则项。可以考虑使用Leave One Out。</li><li>对于有序离散特征，可以尝试使用OrdinalEncoder，BinaryEncoder，OneHotEncoder，LeaveOneOutEncoder，TargetEncoder。</li><li>对于回归问题，TargetEncoder和LeaveOneOutEncoder效果可能一般。</li><li>如果离散特征高基数，可以用LeaveOneOutEncoder，WOEEncoder，MEstimateEncoder。</li></ul><p>2024/5/19 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>数据挖掘</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据挖掘</tag>
      
      <tag>特征工程</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式训练：了解Deepspeed中的ZeRO1/2/3</title>
    <link href="/2024/05/12/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%EF%BC%9A%E4%BA%86%E8%A7%A3Deepspeed%E4%B8%AD%E7%9A%84ZeRO1-2-3/"/>
    <url>/2024/05/12/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%EF%BC%9A%E4%BA%86%E8%A7%A3Deepspeed%E4%B8%AD%E7%9A%84ZeRO1-2-3/</url>
    
    <content type="html"><![CDATA[<p>DeepSpeed是微软推出的大规模模型分布式训练的工具，主要实现了ZeRO并行训练算法。这篇博文主要是了解一下ZeRO。</p><p>分布式训练场景目前主要分成三个策略：</p><ul><li>数据并行</li><li>模型并行</li><li>流水线并行</li></ul><p>在数据并行的策略下，每个模型都需要跑一个完整的模型，这时就需要考虑训练模型占用的参数量。今天要学习的ZeRO就是为了这个场景而诞生的。</p><p>ZeRO的全称是Zero Redundancy Optimizer，意为去除冗余的优化器。在之前的分布式训练中，我们了解到训练模型时，主要占用的参数主要分为了三个部分：模型参数（<strong>Parameters</strong>），优化器状态（<strong>Optimizer States</strong>），梯度(<strong>Gradients</strong>)，他们三个简称为OPG。其中优化器状态会占据大约2倍参数量的显存空间，这取决于选择的优化器，也是整个训练中占据最大空间的部分。</p><p>通常要解决训练占用的显存空间，之前的方法是用混合精度的方法，让参数部分用低精度来前向传播，高精度进行优化器更新。</p><p>除此之外有没有其他的解决方案？ZeRO提供了另一种思路：使用切片来达到时间换空间的效果。</p><h1 id="ZeRO的三个级别"><a href="#ZeRO的三个级别" class="headerlink" title="ZeRO的三个级别"></a>ZeRO的三个级别</h1><p>ZeRO被分为了三个级别：</p><ol><li>ZeRO1：对优化器状态进行拆分。<strong>显存消耗减少 4 倍，通信量与数据并行相同。</strong></li><li>ZeRO2：在ZeRO1的基础上，对梯度进行拆分。<strong>显存消耗减少 8 倍，通信量与数据并行相同。</strong></li><li>ZeRO3：在ZeRO2的基础上，对模型参数进行拆分。<strong>模型占用的显存被平均分配到每个 GPU 中，显存消耗量与数据并行的并行度成线性反比关系，但通信量会有些许增加。</strong></li></ol><p>论文中给出了三个阶段的显存消耗分布情况：</p><p><img src="/images/zerodp.jpg"></p><h2 id="ZeRO1"><a href="#ZeRO1" class="headerlink" title="ZeRO1"></a>ZeRO1</h2><p>模型训练中，正向传播和反向传播并不会用到优化器状态，只有在梯度更新的时候才会使用梯度和优化器状态计算新参数。因此每个进程单独使用一段优化器状态，对各自进程的参数更新完之后，再把各个进程的模型参数合并形成完整的模型。</p><p>假设我们有 𝑁𝑑 个并行的进程，<strong>ZeRO-1</strong> 会将完整优化器的状态等分成 𝑁𝑑 份并储存在各个进程中。当反向传播完成之后，每个进程的优化器会对自己储存的优化器状态（包括Momentum、Variance 与 FP32 Master Parameters）进行计算与更新。更新过后的<code>Partitioned FP32 Master Parameters</code>会通过<code>All-gather</code>传回到各个进程中。完成一次完整的参数更新。</p><p>通过 ZeRO-1 对优化器状态的分段化储存，7.5B 参数量的模型内存占用将由原始数据并行下的 <strong>120GB 缩减到 31.4GB</strong>。</p><h2 id="ZeRO2"><a href="#ZeRO2" class="headerlink" title="ZeRO2"></a>ZeRO2</h2><p>第二阶段中对梯度进行了拆分，在一个Layer的梯度都被计算出来后： 梯度通过<code>All-reduce</code>进行聚合， 聚合后的梯度只会被某一个进程用来更新参数，因此其它进程上的这段梯度不再被需要，可以立马释放掉。</p><p>通过 ZeRO-2 对梯度和优化器状态的分段化储存，7.5B 参数量的模型内存占用将由 ZeRO-1 中 <strong>31.4GB 进一步下降到 16.6GB</strong>。</p><h2 id="ZeRO3"><a href="#ZeRO3" class="headerlink" title="ZeRO3"></a>ZeRO3</h2><p>第三阶段就是对模型参数进行分割。在ZeRO3中，模型的每一层都被切片，每个进程存储权重张量的一部分。在前向和后向传播过程中（每个进程仍然看到不同的微批次数据），不同的进程交换它们所拥有的部分（按需进行参数通信），并计算激活函数和梯度。</p><p>初始化的时候。ZeRO3将一个模型中每个子层中的参数分片放到不同进程中，训练过程中，每个进程进行正常的正向&#x2F;反向传播，然后通过<code>All-gather</code>进行汇总，构建成完整的模型。</p><h1 id="图解"><a href="#图解" class="headerlink" title="图解"></a>图解</h1><p>官方给出了一个五分钟的解释视频，我们一张张截取看一下：</p><ol><li>首先我们有一个16个Transformer块构成的模型，每一个块都是一个Transformer块。</li></ol><p><img src="/images/deep1.png"></p><ol start="2"><li>有一个很大的数据集和四个GPU。</li></ol><p><img src="/images/deep2.png"></p><ol start="3"><li>我们使用三阶段策略，将OPG和数据都进行拆分放在四张卡上。</li></ol><p><img src="/images/deep3.png"></p><ol start="4"><li>每个模块下的格子代表模块占用的显存。第一行是FP16版本的模型权重参数，第二行是FP16的梯度，用来反向传播时更新权重，剩下的大部分绿色部分是优化器使用的显存部分，包含（FP32梯度，FP32方差，FP32动量，FP32参数）它只有在FP16梯度计算后才会被使用。ZeRO3使用了混合精度，因此前向传播中使用了半精度的参数。</li></ol><p><img src="/images/deep4.png"></p><p><img src="/images/deep5.png"></p><ol start="5"><li>每个模块还需要一部分空间用于存放激活值，也就是上面蓝色的部分。</li></ol><p><img src="/images/deep6.png"></p><ol start="6"><li>每个GPU都会负责模型的一部分，也就是图中的$M_0 - M_3$。</li></ol><p><img src="/images/deep7.png"></p><ol start="7"><li>现在进入ZeRO3的一个分布式训练流程：</li></ol><ul><li>首先，GPU_0将自身已经有的模型部分权重$M_0$通过<code>broadcast</code>发送到其他GPU。</li></ul><p><img src="/images/deep8.gif"></p><ul><li>当所有GPU都有了权重$M_0$后，除了GPU_0以外的GPU会将他们存储在一个临时缓存中。</li><li>进行前向传播，每个GPU都会使用$M_0$的参数在自己的进程的数据上进行前向传播，只有每个层的激活值会被保留。</li><li>$M_0$计算完成后，其他GPU删除这部分的模型参数。</li></ul><p><img src="/images/deep9.gif"></p><ul><li>接下来，GPU_1将自己的模型权重参数$M_1$广播发送到其他GPU。所有GPU上使用$M_1$进行前向传播。</li><li>$M_1$计算完成后，其他GPU删除这部分的模型参数。</li><li>依次类推，将每个GPU上的各自的模型权重都训练完。</li><li>前向传播结束后，每个GPU都根据自己数据集计算一个损失。</li></ul><p><img src="/images/deep10.png"></p><ul><li>开始反向传播。首先所有GPU都会拿到最后一个模型分块（也就是$M_3$）的损失。反向传播会在这块模型上进行，$M_3$的激活值会从保存好的激活值上进行计算。</li></ul><p><img src="/images/deep11.png"></p><p><img src="/images/deep12.png"></p><ul><li>其他GPU将自己计算的$M_3$的梯度发送给GPU_3进行梯度累积，最后在GPU_3上更新并保存最终的$M_3$权重参数。</li></ul><blockquote><p>备注：梯度累积之前讲过，将几个小批次的数据的梯度累积，累加够一个大批次后更新模型权重。</p></blockquote><p><img src="/images/deep13.gif"></p><ul><li>其他GPU删除临时存储的$M_3$权重参数和梯度，所有GPU都删除$M_3$的激活值。</li><li>GPU_2发送$M_2$参数到其他GPU，以便它们进行反向传播并计算梯度。</li><li>依次类推，直到每个GPU上自己部分的模型参数都更新完。</li><li>现在每个GPU都有自己的梯度了，开始计算参数更新。</li><li>优化器部分在每个GPU上开始并行。</li></ul><p><img src="/images/deep14.png"></p><ul><li>优化器会生成FP32精度的模型权重，然后转换至FP16精度。</li></ul><p><img src="/images/deep15.png"></p><ul><li>FP16精度的权重成为了下一个迭代开始时的模型参数，至此一个训练迭代完成。</li></ul><p>总结一下，基本上就是把模型拆的更细了，原先的模型并行只是拆模型，现在不光拆模型，还把内部的优化器给拆了，并且只有在使用到的时候才会占据显存。</p><p>2024&#x2F;5&#x2F;12 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式训练</tag>
      
      <tag>Deepspeed</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解读KANs：网络架构中对激活函数的学习</title>
    <link href="/2024/05/07/%E8%A7%A3%E8%AF%BBKANs%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E4%B8%AD%E5%AF%B9%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E5%AD%A6%E4%B9%A0/"/>
    <url>/2024/05/07/%E8%A7%A3%E8%AF%BBKANs%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E4%B8%AD%E5%AF%B9%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>整个五一假期都没有碰代码（除了第一天捣鼓了一点小玩意）。到了假期末的时候刷了一下Github的热榜，看到一个国人的开源仓库冲上了日榜，也就是今天要学习的内容，KANs。</p><p>作者是斯坦福大学的博士生刘子鸣，他将自己开发的网络命名为Kolmogorov-Arnold Networks。在他的博客上介绍了自己，毕业于北大物理系，并曾在微软亚院实习。目前他主要研究的方向是传统物理和AI的交叉学科，看起来很笼统。看了一下Google Scholar，引用最高的几篇文章偏向机器学习方面。</p><hr><p>该文的命名来源于Kolmogorov-Arnold表示定理，此前我完全没有了解过。看了很多网上的解释，我理解为任何<strong>多变量连续</strong>函数都可以表示为多个单变量、加法连续函数的有限组合。</p><p>公式如下：$ f(\mathbf{x}) &#x3D; f(x_1, \dots, x_n) &#x3D; \sum_{q&#x3D;0}^{2n} \Phi_q \left( \sum_{p&#x3D;1}^n \phi_{qp}(x_p) \right) $</p><p>这里等号后面的括号里和括号外就是从$[0,1]$的$R$的连续函数。括号里是内部函数，外则是外部函数。连续函数可以是线性变换函数或者二次函数等等。</p><p>这个理论在机器学习领域可以简化为：学习高维函数的过程可以简化成学习多项式数量的一维函数。KANs的想法则是替代前馈网络：$ \mathbf{y} &#x3D; \sigma(\mathbf{Wx} + \mathbf{b}) $</p><blockquote><p>为什么之前在机器学习中没有被人们所使用？论文中给出了自己的解释：</p><p>有人可能天真地认为这对机器学习来说是个好消息：学习高维函数归结为学习多项式数量的一维函数。然而，这些一维函数可能是非光滑的，甚至是分形的，因此在实践中可能无法学习。由于这种病态行为，科尔莫戈洛夫-阿诺德表示定理在机器学习中基本上被判了死刑，被认为在理论上是正确的，但在实践中是无用的。</p></blockquote><p>拿Github上的原图来展示一下：</p><p><img src="/images/kans.png"></p><p>在前馈网络中，最终需要拟合的函数由多个线性函数（$W$权重）以及非线性函数（激活函数）组合而成。而在KANs则变为了$KAN(x)&#x3D;(\Phi_3\circ \Phi_2 \circ \Phi_1)(x)$。</p><p>上图同时还展示了另外一点，那就是KANs网络的可学习参数要比MLP要少了很多。其中$\Phi_2$用来实现非线性函数。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>作者的工程能力很强，提供了基于Pytorch写的框架，不过据他所说，目前代码还有一些不足。而目前Github社区也有人迅速跟进。目前这个名为<code>efficent-kan</code>的项目已经获得了超过两千颗星，链接：<a href="https://github.com/Blealtan/efficient-kan/tree/master">Blealtan&#x2F;efficient-kan: An efficient pure-PyTorch implementation of Kolmogorov-Arnold Network (KAN)</a>。</p><p>看了一眼源码，代码量不多，但是需要比较深的数学背景，所以暂时跳过这个部分。</p><h1 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h1><p>项目用MNIST数据集进行了测试训练，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> efficient_kan <span class="hljs-keyword">import</span> KAN<br><br><span class="hljs-comment"># Train on MNIST</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># Load MNIST</span><br>transform = transforms.Compose(<br>    [transforms.ToTensor(), transforms.Normalize((<span class="hljs-number">0.5</span>,), (<span class="hljs-number">0.5</span>,))]<br>)<br>trainset = torchvision.datasets.MNIST(<br>    root=<span class="hljs-string">&quot;./data&quot;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform<br>)<br>valset = torchvision.datasets.MNIST(<br>    root=<span class="hljs-string">&quot;./data&quot;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transform<br>)<br>trainloader = DataLoader(trainset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>)<br>valloader = DataLoader(valset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 定义模型，输入Size是28*28像素，输出Size是10个分类</span><br>model = KAN([<span class="hljs-number">28</span> * <span class="hljs-number">28</span>, <span class="hljs-number">64</span>, <span class="hljs-number">10</span>])<br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>model.to(device)<br><span class="hljs-comment"># AdamW优化器</span><br>optimizer = optim.AdamW(model.parameters(), lr=<span class="hljs-number">1e-3</span>, weight_decay=<span class="hljs-number">1e-4</span>)<br><span class="hljs-comment"># LR学习率</span><br>scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=<span class="hljs-number">0.8</span>)<br><br><span class="hljs-comment"># 定义损失</span><br>criterion = nn.CrossEntropyLoss()<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    <span class="hljs-comment"># Train</span><br>    model.train()<br>    <span class="hljs-keyword">with</span> tqdm(trainloader) <span class="hljs-keyword">as</span> pbar:<br>        <span class="hljs-keyword">for</span> i, (images, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pbar):<br>            images = images.view(-<span class="hljs-number">1</span>, <span class="hljs-number">28</span> * <span class="hljs-number">28</span>).to(device)<br>            optimizer.zero_grad()<br>            output = model(images)<br>            loss = criterion(output, labels.to(device))<br>            loss.backward()<br>            optimizer.step()<br>            accuracy = (output.argmax(dim=<span class="hljs-number">1</span>) == labels.to(device)).<span class="hljs-built_in">float</span>().mean()<br>            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer.param_groups[<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;lr&#x27;</span>])<br><br>    <span class="hljs-comment"># Validation</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    val_loss = <span class="hljs-number">0</span><br>    val_accuracy = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> valloader:<br>            images = images.view(-<span class="hljs-number">1</span>, <span class="hljs-number">28</span> * <span class="hljs-number">28</span>).to(device)<br>            output = model(images)<br>            val_loss += criterion(output, labels.to(device)).item()<br>            val_accuracy += (<br>                (output.argmax(dim=<span class="hljs-number">1</span>) == labels.to(device)).<span class="hljs-built_in">float</span>().mean().item()<br>            )<br>    val_loss /= <span class="hljs-built_in">len</span>(valloader)<br>    val_accuracy /= <span class="hljs-built_in">len</span>(valloader)<br><br>    <span class="hljs-comment"># 更新学习率</span><br>    scheduler.step()<br><br>    <span class="hljs-built_in">print</span>(<br>        <span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, Val Loss: <span class="hljs-subst">&#123;val_loss&#125;</span>, Val Accuracy: <span class="hljs-subst">&#123;val_accuracy&#125;</span>&quot;</span><br>    )<br></code></pre></td></tr></table></figure><p>从结果上来看，KANs在收敛速度上比传统的MLP要快，精度相差不大。不过MLP存在过拟合的问题。数据集过小。还需要在更多的场景验证。</p><p>总的来说，KANs架构带来最大的两个优势：</p><ol><li>计算复杂度降低带来的收敛速度提高。</li><li>动态图结构（区别于MLP的静态图结构中固定的激活函数）更加灵活，大家普遍认为这能解决灾难性遗忘的问题，因为训练时，较远的权重参数之间不会有太大的影响。</li></ol><p>2024&#x2F;5&#x2F;11 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>网络架构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式训练：使用Accelerate进行分布式训练</title>
    <link href="/2024/05/02/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%EF%BC%9A%E4%BD%BF%E7%94%A8Accelerate%E8%BF%9B%E8%A1%8C%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"/>
    <url>/2024/05/02/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%EF%BC%9A%E4%BD%BF%E7%94%A8Accelerate%E8%BF%9B%E8%A1%8C%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/</url>
    
    <content type="html"><![CDATA[<p>Accelerate是HuggingFace发布的Pytorch高级库，主要是封装了Pytorch当中训练部分的模块。在之前的了解中，我们了解了Pytorch中包含了大量的分布式训练API，如何灵活的调用他们需要费时费力去记忆，为此Accelerate提供了统一的接口，来配置分布式训练参数。</p><p>先看看官方的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br><br><span class="hljs-comment"># 实例化加速器</span><br>accelerator = Accelerator()<br><br><span class="hljs-comment"># 准备一下模型/优化器/dataloader等</span><br>model, optimizer, training_dataloader, scheduler = accelerator.prepare(<br>     model, optimizer, training_dataloader, scheduler)<br><br><span class="hljs-comment"># 开始训练</span><br><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> training_dataloader:<br>      optimizer.zero_grad()<br>      inputs, targets = batch<br>      inputs = inputs.to(device)<br>      targets = targets.to(device)<br>      outputs = model(inputs)<br>      loss = loss_function(outputs, targets)<br>      accelerator.backward(loss)<br>      optimizer.step()<br>      scheduler.step()<br></code></pre></td></tr></table></figure><p>可以看到是比较简单易懂的。</p><h1 id="使用Accelerate进行DDP训练"><a href="#使用Accelerate进行DDP训练" class="headerlink" title="使用Accelerate进行DDP训练"></a>使用Accelerate进行DDP训练</h1><p>下面我们用一个实际例子来对比一下使用Accelerate和不使用的区别。我们使用一个文本分类任务来进行训练。首先是不使用加速库的情况：</p><p>我们的数据集示例如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">label,review<br>1,<span class="hljs-string">&quot;距离川沙公路较近,但是公交指示不对,如果是&quot;</span><span class="hljs-string">&quot;蔡陆线&quot;</span><span class="hljs-string">&quot;的话,会非常麻烦.建议用别的路线.房间较为简单.&quot;</span><br>1,商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!<br></code></pre></td></tr></table></figure><p>先是准备一下Dataset和DataLoader：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> Adam<br><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> random_split<br><span class="hljs-keyword">from</span> torch.utils.data.distributed <span class="hljs-keyword">import</span> DistributedSampler<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertForSequenceClassification<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.data = pd.read_csv(<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>)<br>        self.data = self.data.dropna()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">return</span> self.data.iloc[index][<span class="hljs-string">&quot;review&quot;</span>], self.data.iloc[index][<span class="hljs-string">&quot;label&quot;</span>]<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataloader</span>():<br><br>    dataset = MyDataset()<br><br>    trainset, validset = random_split(dataset, lengths=[<span class="hljs-number">0.9</span>, <span class="hljs-number">0.1</span>], generator=torch.Generator().manual_seed(<span class="hljs-number">42</span>))<br><br>    tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;/gemini/code/model&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_func</span>(<span class="hljs-params">batch</span>):<br>        texts, labels = [], []<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> batch:<br>            texts.append(item[<span class="hljs-number">0</span>])<br>            labels.append(item[<span class="hljs-number">1</span>])<br>        inputs = tokenizer(texts, max_length=<span class="hljs-number">128</span>, padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>        inputs[<span class="hljs-string">&quot;labels&quot;</span>] = torch.tensor(labels)<br>        <span class="hljs-keyword">return</span> inputs<br><br>    trainloader = DataLoader(trainset, batch_size=<span class="hljs-number">32</span>, collate_fn=collate_func, sampler=DistributedSampler(trainset))<br>    validloader = DataLoader(validset, batch_size=<span class="hljs-number">64</span>, collate_fn=collate_func, sampler=DistributedSampler(validset))<br><br>    <span class="hljs-keyword">return</span> trainloader, validloader<br></code></pre></td></tr></table></figure><p>随后准备模型和优化器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_model_and_optimizer</span>():<br><span class="hljs-comment"># 准备模型</span><br>    model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;/gemini/code/model&quot;</span>)<br><br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>        model = model.to(<span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>]))<br><span class="hljs-comment"># 使用DDP设置</span><br>    model = DDP(model)<br>    optimizer = Adam(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br><br>    <span class="hljs-keyword">return</span> model, optimizer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_rank_0</span>(<span class="hljs-params">info</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;RANK&quot;</span>]) == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(info)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model, validloader</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    acc_num = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.inference_mode():<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> validloader:<br>            <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>                batch = &#123;k: v.to(<span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()&#125;<br>            output = model(**batch)<br>            pred = torch.argmax(output.logits, dim=-<span class="hljs-number">1</span>)<br>            acc_num += (pred.long() == batch[<span class="hljs-string">&quot;labels&quot;</span>].long()).<span class="hljs-built_in">float</span>().<span class="hljs-built_in">sum</span>()<br>    dist.all_reduce(acc_num)<br>    <span class="hljs-keyword">return</span> acc_num / <span class="hljs-built_in">len</span>(validloader.dataset)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model, optimizer, trainloader, validloader, epoch=<span class="hljs-number">3</span>, log_step=<span class="hljs-number">100</span></span>):<br>    global_step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> ep <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        model.train()<br>        trainloader.sampler.set_epoch(ep)<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainloader:<br>            <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>                batch = &#123;k: v.to(<span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()&#125;<br>            optimizer.zero_grad()<br>            output = model(**batch)<br>            loss = output.loss<br>            loss.backward()<br>            optimizer.step()<br>            <span class="hljs-keyword">if</span> global_step % log_step == <span class="hljs-number">0</span>:<br>                dist.all_reduce(loss, op=dist.ReduceOp.AVG)<br>                print_rank_0(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, global_step: <span class="hljs-subst">&#123;global_step&#125;</span>, loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&quot;</span>)<br>            global_step += <span class="hljs-number">1</span><br>        acc = evaluate(model, validloader)<br>        print_rank_0(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, acc: <span class="hljs-subst">&#123;acc&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    dist.init_process_group(backend=<span class="hljs-string">&quot;nccl&quot;</span>)<br>    trainloader, validloader = prepare_dataloader()<br>    model, optimizer = prepare_model_and_optimizer()<br>    train(model, optimizer, trainloader, validloader)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure><p>我们使用<code>touchrun --nproc_per_node=2 ddp.py</code>来执行这个训练任务。</p><hr><p>下面使用Accelerate来进行同样的训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.data = pd.read_csv(<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>)<br>        self.data = self.data.dropna()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">return</span> self.data.iloc[index][<span class="hljs-string">&quot;review&quot;</span>], self.data.iloc[index][<span class="hljs-string">&quot;label&quot;</span>]<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataloader</span>():<br><br>    dataset = MyDataset()<br><br>    trainset, validset = random_split(dataset, lengths=[<span class="hljs-number">0.9</span>, <span class="hljs-number">0.1</span>], generator=torch.Generator().manual_seed(<span class="hljs-number">42</span>))<br><br>    tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;/gemini/code/model&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_func</span>(<span class="hljs-params">batch</span>):<br>        texts, labels = [], []<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> batch:<br>            texts.append(item[<span class="hljs-number">0</span>])<br>            labels.append(item[<span class="hljs-number">1</span>])<br>        inputs = tokenizer(texts, max_length=<span class="hljs-number">128</span>, padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>        inputs[<span class="hljs-string">&quot;labels&quot;</span>] = torch.tensor(labels)<br>        <span class="hljs-keyword">return</span> inputs<br><br>    <span class="hljs-comment"># 数据部分把Sample参数替换成shuffle</span><br>    trainloader = DataLoader(trainset, batch_size=<span class="hljs-number">32</span>, collate_fn=collate_func, shuffle=<span class="hljs-literal">True</span>)<br>    validloader = DataLoader(validset, batch_size=<span class="hljs-number">64</span>, collate_fn=collate_func, shuffle=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">return</span> trainloader, validloader<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_model_and_optimizer</span>():<br>    model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;/gemini/code/model&quot;</span>)<br>    optimizer = Adam(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br>    <span class="hljs-keyword">return</span> model, optimizer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model, validloader, accelerator: Accelerator</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    acc_num = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.inference_mode():<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> validloader:<br>            output = model(**batch)<br>            pred = torch.argmax(output.logits, dim=-<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># 将所有机器的预测结果进行汇总</span><br>            <span class="hljs-comment"># gather_for_metrics是accelerator的内置方法，用于汇总通信组的信息</span><br>            pred, refs = accelerator.gather_for_metrics((pred, batch[<span class="hljs-string">&quot;labels&quot;</span>]))<br>            acc_num += (pred.long() == refs.long()).<span class="hljs-built_in">float</span>().<span class="hljs-built_in">sum</span>()<br>    <span class="hljs-keyword">return</span> acc_num / <span class="hljs-built_in">len</span>(validloader.dataset)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model, optimizer, trainloader, validloader, accelerator: Accelerator, epoch=<span class="hljs-number">3</span>, log_step=<span class="hljs-number">10</span></span>):<br>    global_step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> ep <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        model.train()<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainloader:<br>            optimizer.zero_grad()<br>            output = model(**batch)<br>            loss = output.loss<br>            accelerator.backward(loss)<br>            optimizer.step()<br>            <span class="hljs-keyword">if</span> global_step % log_step == <span class="hljs-number">0</span>:<br>                <span class="hljs-comment"># dist.all_reduce(loss, op=dist.ReduceOP.AVG)</span><br>                <span class="hljs-comment"># 将Loss在所有机器上合并取均值，不然不同机器的Loss是不一样的</span><br>                <span class="hljs-comment"># accelerator提供了同样的包装</span><br>                loss = accelerator.reduce(loss, <span class="hljs-string">&quot;mean&quot;</span>)<br>                <span class="hljs-comment"># 直接可以print日志，而不需要指定Rank来print</span><br>                accelerator.<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, global_step: <span class="hljs-subst">&#123;global_step&#125;</span>, loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&quot;</span>)<br>            global_step += <span class="hljs-number">1</span><br>        acc = evaluate(model, validloader, accelerator)<br>        accelerator.<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, acc: <span class="hljs-subst">&#123;acc&#125;</span>&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br><span class="hljs-comment"># 实例化</span><br>    accelerator = Accelerator()<br><br>    trainloader, validloader = prepare_dataloader()<br>    model, optimizer = prepare_model_and_optimizer()<br><br>    model, optimizer, trainloader, validloader = accelerator.prepare(model, optimizer, trainloader, validloader)<br><br>    train(model, optimizer, trainloader, validloader, accelerator)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure><p>我们使用<code>touchrun --nproc_per_node=2 accelerate.py</code>来开始训练，或者还能使用<code>accelerate launch accelerate.py</code>。如果使用后者，还能在终端输入<code>accelerate config</code>来设置训练的参数。在设置完之后，使用<code>accelerate launch accelerate.py</code>，就可以直接调用前面设置的参数来进行训练。</p><h1 id="两者的差别"><a href="#两者的差别" class="headerlink" title="两者的差别"></a>两者的差别</h1><p>我们来对比一下这两种方式分别有什么区别：</p><ol><li>原生<code>DDP</code>中需要在<code>DataLoader</code>中设置<code>sampler</code>，使用<code>Accelerate</code>则不需要。</li><li>原生<code>DDP</code>中需要将模型进行包装<code>model = DDP(model)</code>，另一个则不需要。</li><li>原生需要在训练时初始化进程组<code>dist.init_process_group</code>，<code>Accelerate</code>则不需要，只需要实例化<code>Accelerate</code>。</li><li>数据，模型，优化器都使用了<code>accelerate.prepare</code>来进行分布式的准备。</li><li>训练中，<code>trainloder.sampler.set_epoch()</code>以及后续的<code>batch</code>发送到不同机器这一步也省略了。</li><li>打印日志可以使用<code>accelerate.print()</code>实现。</li></ol><h1 id="使用混合精度进行训练"><a href="#使用混合精度进行训练" class="headerlink" title="使用混合精度进行训练"></a>使用混合精度进行训练</h1><p>混合精度训练结合了32位的单精度浮点数和16位半精度来进行训练。首先加载完整的32位的完整精度模型，随后将它复制一份成16位的半精度模型。16bit的低精度模型会被用来前向传播，得到的16bit精度的梯度会被转为32bit，传入优化器。最后在32位的模型上进行参数更新。</p><p>通过这种方式，能够加速训练，但是不会减少对显存的需求。</p><p>假设模型参数量为M：</p><table><thead><tr><th></th><th>混合精度</th><th>单精度</th></tr></thead><tbody><tr><td>模型</td><td>(4+2) Bytes * M</td><td>4 Bytes * M</td></tr><tr><td>优化器</td><td>8 Bytes * M</td><td>8 Bytes * M</td></tr><tr><td>梯度</td><td>(2 + ) Bytes * M</td><td>4 Bytes * M</td></tr><tr><td>激活值</td><td>2 Bytes * A</td><td>4 Bytes * A</td></tr><tr><td>汇总</td><td>(16 + ) Bytes * M + 2 Bytes * A</td><td>16 Bytes * M + 4 Bytes * A</td></tr></tbody></table><p>当使用混合精度训练时，不光需要一个完整模型，还需要一个半精度模型，因此模型这占用了4 + 2倍的参数量。优化器占用的参数量不变，梯度这在前向传播时变成了半精度，只在更新时会拿出一组参数提高为单精度，因此可以视作2 + 的参数量。此外，激活值也会变为半精度。</p><p>使用Accelerate时，只需要使用以下几种方法就可以进行混合精度训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 方法一</span><br>accelerator = Accelerator(mixed_percision = <span class="hljs-string">&#x27;bf16&#x27;</span>)<br><br><span class="hljs-comment"># 方法二</span><br>acclerator config &amp;&amp; choice bf <span class="hljs-number">16</span><br><br><span class="hljs-comment"># 方法三</span><br>accelerator launch --mixed_precision bf <span class="hljs-number">16</span> &#123;script.py&#125;<br></code></pre></td></tr></table></figure><h1 id="使用梯度累积进行训练"><a href="#使用梯度累积进行训练" class="headerlink" title="使用梯度累积进行训练"></a>使用梯度累积进行训练</h1><p>在显卡显存过小的时候，能够使用梯度累积的功能来模拟大Batch Size的训练效果。</p><p>梯度累积的流程如下：</p><ol><li>分割Batch：将大Batch分割为多个Mini Batch</li><li>计算梯度：每个Mini Batch独立计算梯度</li><li>累积梯度：将Mini Batch的梯度进行累积，而不是马上更新参数</li><li>更新参数：当积累到一定数量，统一使用累积的梯度更新参数</li></ol><p>示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">accumulation_steps = <span class="hljs-number">4</span> <span class="hljs-comment"># 累积步数</span><br>model.zero_grad() <span class="hljs-comment"># 清空梯度</span><br><span class="hljs-keyword">for</span> step, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>    outputs = model(inputs)<br>    loss = criterion(outputs, targets) <br>    loss = loss/accumulation_steps <span class="hljs-comment"># 对损失进行缩放</span><br>    loss.backward()<br>    <span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % accumulation_step == <span class="hljs-number">0</span>: <span class="hljs-comment"># 只有达到累积的步数才会更新</span><br>        optimizer.step()<br>        model.zero_grad()<br></code></pre></td></tr></table></figure><p>在Accelerate的实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 在实例化时设置累积步数</span><br>accelerator = Accelerator(gradient_accumulation_steps=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>然后再训练时计算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model, optimizer, trainloader, validloader, accelerator: Accelerator, epoch=<span class="hljs-number">3</span>, log_step=<span class="hljs-number">10</span></span>):<br>    global_step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> ep <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        model.train()<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainloader:<br>            <span class="hljs-comment"># 加入上下文</span><br>            <span class="hljs-keyword">with</span> accelerator.accumulate(model):<br>                optimizer.zero_grad()<br>                output = model(**batch)<br>                loss = output.loss<br>                accelerator.backward(loss)<br>                optimizer.step()<br>                <br>                <span class="hljs-keyword">if</span> accelerator.sync_gradients:<br>                    global_step += <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">if</span> global_step % log_step == <span class="hljs-number">0</span>:<br>                        loss = accelerator.reduce(loss, <span class="hljs-string">&quot;mean&quot;</span>)<br>                        accelerator.<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, global_step: <span class="hljs-subst">&#123;global_step&#125;</span>, loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&quot;</span>)<br>                <br>        acc = evaluate(model, validloader, accelerator)<br>        accelerator.<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, acc: <span class="hljs-subst">&#123;acc&#125;</span>&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>2024&#x2F;5&#x2F;2 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式训练</tag>
      
      <tag>Accelerate</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>工程实践：Nginx了解与入门</title>
    <link href="/2024/04/27/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9ANginx%E4%BA%86%E8%A7%A3%E4%B8%8E%E5%85%A5%E9%97%A8/"/>
    <url>/2024/04/27/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9ANginx%E4%BA%86%E8%A7%A3%E4%B8%8E%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<p>Nginx是一个Http服务器，常常被用在高并发，反向代理和负载均衡的场景下。这块内容一直没时间研究，刚好周末刷一下，恶补一下知识。</p><p>我用Docker启动了Nginx容器，以下内容均在容器内实现。</p><p>在启动了容器后，首先使用<code>nginx -v</code>查看版本。并用<code>service nginx status</code>来检查运行状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># nginx -v</span><br>nginx version: nginx/1.26.0<br><span class="hljs-comment"># service nginx status</span><br>nginx is running.<br></code></pre></td></tr></table></figure><p>如果已经正确运行，这时候访问<code>localhost</code>，就能看到<code>Welcome to nginx</code>的页面。这意味着人们已经可以通过网址来访问我们的Web服务器了。</p><h1 id="Nginx配置文件"><a href="#Nginx配置文件" class="headerlink" title="Nginx配置文件"></a>Nginx配置文件</h1><p>Nginx的配置文件在Linux系统下位于<code>/etc/nginx</code>，名为<code>nginx.conf</code>。我们进去看一下，这是默认的配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br><span class="hljs-comment">#user  nobody;</span><br>worker_processes  1;<br><br><span class="hljs-comment">#error_log  logs/error.log;</span><br><span class="hljs-comment">#error_log  logs/error.log  notice;</span><br><span class="hljs-comment">#error_log  logs/error.log  info;</span><br><br><span class="hljs-comment">#pid        logs/nginx.pid;</span><br><br><br>events &#123;<br>    worker_connections  1024;<br>&#125;<br><br><br>http &#123;<br>    include       mime.types;<br>    default_type  application/octet-stream;<br><br>    <span class="hljs-comment">#log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span><br>    <span class="hljs-comment">#                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span><br>    <span class="hljs-comment">#                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;</span><br><br>    <span class="hljs-comment">#access_log  logs/access.log  main;</span><br><br>    sendfile        on;<br>    <span class="hljs-comment">#tcp_nopush     on;</span><br><br>    <span class="hljs-comment">#keepalive_timeout  0;</span><br>    keepalive_timeout  65;<br><br>    <span class="hljs-comment">#gzip  on;</span><br><br>    server &#123;<br>        listen       80;<br>        server_name  localhost;<br><br>        <span class="hljs-comment">#charset koi8-r;</span><br><br>        <span class="hljs-comment">#access_log  logs/host.access.log  main;</span><br><br>        location / &#123;<br>            root   html;<br>            index  index.html index.htm;<br>        &#125;<br><br>        <span class="hljs-comment">#error_page  404              /404.html;</span><br><br>        <span class="hljs-comment"># redirect server error pages to the static page /50x.html</span><br>        <span class="hljs-comment">#</span><br>        error_page   500 502 503 504  /50x.html;<br>        location = /50x.html &#123;<br>            root   html;<br>        &#125;<br><br></code></pre></td></tr></table></figure><p>看着云里雾里，为了学习配置文件，我们备份一下，再写个新的配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mv</span> nginx.conf nginx.conf.bak<br><span class="hljs-built_in">touch</span> nginx.conf<br></code></pre></td></tr></table></figure><p>通常修改配置文件后，需要使用<code>nginx -t</code>来进行检查，查看是否能正确执行。不过现在是空的配置文件，会报错。</p><p>报错信息提示：<code>no &quot;events&quot; section in configuration</code>。<code>events</code>字段代表<code>nginx</code>如何处理连接。</p><p>我们可以修改一下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">events &#123;&#125;<br></code></pre></td></tr></table></figure><p>这时候<code>nginx -t</code>不报错了。</p><p>检查完文件后，就需要重新加载，指令是<code>nginx -s reload</code>。启动完之后，发现之前的<code>localhost</code>无法访问了，意料之中。</p><blockquote><p>好吧，并不是意料之中。我在Windows上依然访问到了<code>localhost</code>。很神奇，哪怕我把<code>nginx</code>容器关闭，依然能访问。这说明Windows上有其他进程调用了<code>nginx</code>，最后发现是<code>Docker Desktop</code>。应该是WSL里有配置<code>nginx</code>。</p></blockquote><p>解决了这个小插曲，后面我就不用Docker启动了。我在官网下了<code>nginx</code>的压缩包，解压后在路径下执行命令行：<code>start nginx</code>，即可启动服务。</p><h1 id="Web服务器"><a href="#Web服务器" class="headerlink" title="Web服务器"></a>Web服务器</h1><p>同样备份清空，现在无法访问了。这就是<code>http</code>字段需要配置的内容：我们需要在这个字段内配置<code>server</code>，也就是http服务。例如如果服务器需要监听80端口，就这么写：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">events &#123;<br>   <br>&#125;<br><br>http &#123;<br>server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>完成这一步，reload一下发现又可以访问<code>localhost</code>了，因为这次我们准确提供了IP和端口，用户可以直接访问了。Perfecto！</p><blockquote><p>这里其实还有一点问题。配置文件里是需要配置资源的，正常来说未配置资源时，会报错403 Forbidden。这就是<code>nginx</code>未找到资源。而它在未设置字段时默认读取<code>html</code>路径下的<code>index.html</code>。因此，当我修改了它的名字时，页面成功报错。</p></blockquote><p>在<code>server</code>字段，我们不一定需要设置资源地址，还可以返回状态码和对应字段。例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">events &#123;<br>   <br>&#125;<br><br>http &#123;<br>server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br><span class="hljs-built_in">return</span> 200 <span class="hljs-string">&#x27;egg old wet.\n&#x27;</span>;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这时候访问<code>localhost</code>，就会返回这句话。也可以通过<code>curl localhost</code>从命令行访问到这句话。</p><p>配置文件中还可以设置资源根目录，我们进行如下修改，此时<code>nginx</code>就会从指定路径访问默认的<code>index.html</code>，而如果路径下没有这个文件，则会报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">events &#123;<br>   <br>&#125;<br><br>http &#123;<br>server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>root C:/nginx-1.26.0/html;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果要指定文件，则需要给<code>index</code>字段进行赋值。这里我新建了一个自己页面，路径为<code>C:\nginx-1.26.0\html</code>，页面名为<code>test.html</code>。那么，配置文件这边需要改为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">events &#123;<br>   <br>&#125;<br><br>http &#123;<br>server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>root C:/nginx-1.26.0/html;<br>index test.html;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这时访问<code>localhost</code>，就可以正确显示了。</p><p><img src="/images/091715.png"></p><p>有的时候，需要在页面文件内引入各种其他文件。在配置文件的相同路径下，有一个<code>mime.types</code>的文件，这是对于各种文件类型的解析。我们需要对它进行引入，才能让web服务器正确解析文件。因此，我们需要在配置文件中加上<code>include</code>字段：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">events &#123;<br>   <br>&#125;<br><br>http &#123;<br>include mime.types; <span class="hljs-comment"># 由于是同路径，按照相对路径导入</span><br>server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>root C:/nginx-1.26.0/html;<br>index test.html;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里的配置是全局配置，所以被放在了单个的<code>server</code>块外部。</p><p>除了这个配置，<code>nginx</code>自身的配置在<code>conf.d</code>中的<code>default.conf</code>中定义，如果需要修改就要在那里进行改动，例如一开始默认的<code>index.html</code>就在那里设置。</p><p>同样的，我们也可以把上面写的这些配置也通过一个文件进行导入。我们在<code>conf.d</code>路径下新建<code>default.conf</code>，并把内容复制其中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>root C:/nginx-1.26.0/html;<br>index test.html;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后我们回到<code>nginx.conf</code>文件，导入这个配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">events &#123;<br>   <br>&#125;<br><br>http &#123;<br>include mime.types; <span class="hljs-comment"># 由于是同路径，按照相对路径导入</span><br>include C:/nginx-1.26.0/conf.d/*.conf <span class="hljs-comment"># 导入路径下所有conf文件</span><br>&#125;<br></code></pre></td></tr></table></figure><p>reload一下，就实现了将配置文件分开执行的效果，有点像编程语言的导入库。这让<code>config</code>文件更加简洁。</p><p>现在，我想在<code>default.conf</code>中设定在访问<code>localhost</code>的时候，能够直接访问根目录。那么我需要在<code>default.conf</code>如下设置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>location / &#123;<br>root C:/nginx-1.26.0/html;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>用这种方式可以更方便的定义路径。</p><p>现在，我想在访问<code>localhost/app</code>的时候能够访问到这个路径下的index文件，因此我们需要在<code>location</code>字段加上<code>app</code>路径，即：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>location /app &#123;<br>root C:/nginx-1.26.0/html/app; <span class="hljs-comment"># 对应的还需要新建一个app的文件夹来存放资源</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里需要注意，<code>location</code>后面的字段需要在<code>root</code>里找到一样的字段，否则<code>nginx</code>会找不到。现在，通过访问<code>localhost/app/</code>或<code>localhost/app/index.html</code>都可以访问到index页面。</p><blockquote><p>当我们输入<code>location /app</code>时，它就会在root路径寻找<code>app</code>为前缀的文件或URI（例如文件夹：localhost&#x2F;apple&#x2F;）。如果找不到就会报错。</p></blockquote><p>为了安全隐患，防止用户可以访问到路径下其他文件，我们可以指定<code>location</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>location = /app/index.html &#123;<br>root C:/nginx-1.26.0/html/app; <span class="hljs-comment"># 对应的还需要新建一个app的文件夹来存放资源</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这时，URI和文件路径必须完全匹配才能访问，即只有访问<code>localhost/app/index.html</code>才能访问资源。</p><p>此外，还可以使用正则来进行模糊匹配，例如我们的路径下有视频文件0-9.avi共九个文件，我们只想开放6-9这三个文件，就需要在<code>location</code>中设置正则表达式，只有访问指定名字的文件，才能访问到路径下的视频文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>location ~ /app/video[6-9].avi &#123;<br>root C:/nginx-1.26.0/html/app; <span class="hljs-comment"># 对应的还需要新建一个app的文件夹来存放资源</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>有时候，我们想要隐藏真实地址，来避免用户直接访问资源，这时可以用<code>rewrite</code>的字段来进行重定向。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>root C:/nginx-1.26.0/html/app; <br><br>rewrite /temp /app/index.html; <span class="hljs-comment"># temp是临时设定的路径</span><br>&#125;<br></code></pre></td></tr></table></figure><p>此时访问<code>localhost/temp</code>即可访问到资源，而且用户也不会察觉到文件在服务器的真实路径。</p><h1 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h1><p>反向代理区别于正向代理，是为服务器上的资源和服务代理出去，访客通过访问服务器代理的多台子服务器，就能访问到网站，这样做能够进行负载均衡，减少主服务器的负担。</p><p>什么是正向代理，简单来说就是VPN，我们通过访问一个代理服务器，这个服务器代表我们去访问我们无法直连的服务器。正反代理代表的角色正好相反。</p><p>下面就用<code>nginx</code>来实现一下反向代理。假如我们创建了两个服务app&#x2F;app1，分别监听3000和3001端口。此时我们需要修改配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>root C:/nginx-1.26.0/html/app; <br>error_page 404 /404.html;<br>index index.html;<br><br>location /app1 &#123;<br>proxy_pass http://localhost:3000; <span class="hljs-comment"># 对3000端口的服务进行反向代理</span><br>&#125;<br><br>location /app2 &#123;<br>proxy_pass http://localhost:3001;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这样，访问指定的路径，就可以访问到对应端口运行的项目的资源。例如，访问<code>localhost/app1</code>就能访问到3000端口。实战中，可以通过修改<code>server_name</code>来设置不同后端。例如改为<code>zerolovesea.com</code></p><h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><p>使用<code>nginx</code>来设置负载均衡，需要在<code>http</code>块内设置<code>upstream</code>块，即上游服务器。我们修改配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash">upstream backend-servers &#123;<br>server localhost:3000; <span class="hljs-comment"># 负载均衡的两个服务器</span><br>server localhost:3001; <span class="hljs-comment"># 负载均衡的两个服务器</span><br>&#125;<br><br>server &#123;<br>listen 80;<br>server_name localhost; <span class="hljs-comment"># IP地址或域名</span><br><br>root C:/nginx-1.26.0/html/app; <br>error_page 404 /404.html;<br>index index.html;<br><br>location / &#123;<br>proxy_pass http://backend-servers; <span class="hljs-comment"># 将流量引导指定服务器</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这样访问<code>localhost</code>时，通过不断刷新，可以看到我们在3000和3001的服务中来回变化，这时因为服务器默认使用轮询的方式来进行负载均衡。我们可以使用<code>weight</code>字段来分配不同服务的权重占比，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">upstream backend-servers &#123;<br>server localhost:3000 weight=2;<span class="hljs-comment"># 负载均衡的两个服务器</span><br>server localhost:3001 weight=6; <span class="hljs-comment"># 负载均衡的两个服务器</span><br>&#125;<br></code></pre></td></tr></table></figure><p>2024&#x2F;4&#x2F;27 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>后端</tag>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>工程实践：对已有的Docker镜像进行增量更新</title>
    <link href="/2024/04/20/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%AF%B9%E5%B7%B2%E6%9C%89%E7%9A%84Docker%E9%95%9C%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%A2%9E%E9%87%8F%E6%9B%B4%E6%96%B0/"/>
    <url>/2024/04/20/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%AF%B9%E5%B7%B2%E6%9C%89%E7%9A%84Docker%E9%95%9C%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%A2%9E%E9%87%8F%E6%9B%B4%E6%96%B0/</url>
    
    <content type="html"><![CDATA[<p>近期的工作中有这么一个场景：项目代码需要进行频繁的更新，并打包成镜像在客户现场进行部署。由于需要使用CUDA的镜像，因此每次打包完的tar包都有13G之多。为了解决每次更新都会出现的传输过慢问题，我们采用了大镜像包+小更新镜像包的方式。</p><p>思路很简单，就是先构建一个大的基础包，每次将需要更新的内容传进容器，再build一个新版本。</p><h1 id="基础镜像"><a href="#基础镜像" class="headerlink" title="基础镜像"></a>基础镜像</h1><p>首先，我们有一个基础镜像的服务：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3.1&#x27;</span><br><br><span class="hljs-attr">services:</span><br>  <span class="hljs-comment"># cuda_base:</span><br>  <span class="hljs-comment">#   platform: linux/amd64</span><br>  <span class="hljs-comment">#   build: </span><br>  <span class="hljs-comment">#     context: ../infers</span><br>  <span class="hljs-comment">#     dockerfile: Dockerfile.base</span><br>  <span class="hljs-comment">#   image: behavior-detector-cuda-base:$&#123;TAG&#125;</span><br>    <br>  <span class="hljs-attr">frontend:</span><br>    <span class="hljs-attr">platform:</span> <span class="hljs-string">linux/amd64</span><br>    <span class="hljs-attr">build:</span> <br>      <span class="hljs-attr">context:</span> <span class="hljs-string">../frontend</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">behavior-detector-frontend:$&#123;TAG&#125;</span><br><br>  <span class="hljs-attr">infers:</span><br>    <span class="hljs-attr">platform:</span> <span class="hljs-string">linux/amd64</span><br>    <span class="hljs-attr">build:</span> <br>      <span class="hljs-attr">context:</span> <span class="hljs-string">../infers</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile</span><br>      <span class="hljs-attr">args:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">TAG=$&#123;TAG&#125;</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">behavior-detector-infers:$&#123;TAG&#125;</span><br>    <span class="hljs-comment"># depends_on:</span><br>    <span class="hljs-comment">#   - cuda_base</span><br><br>  <span class="hljs-attr">backend:</span><br>    <span class="hljs-attr">platform:</span> <span class="hljs-string">linux/amd64</span><br>    <span class="hljs-attr">build:</span> <br>      <span class="hljs-attr">context:</span> <span class="hljs-string">../backend</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile</span><br>      <span class="hljs-attr">args:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">TAG=$&#123;TAG&#125;</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">behavior-detector-backend:$&#123;TAG&#125;</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">frontend</span><br></code></pre></td></tr></table></figure><p>通过构建以上的<code>compose</code>文件，就能得到前后端和推理端的基础镜像。</p><h1 id="更新包脚本"><a href="#更新包脚本" class="headerlink" title="更新包脚本"></a>更新包脚本</h1><p>我们通常在项目的各个路径下进行开发。当我们把<code>infers</code>或者<code>backend</code>开发完毕后，就需要对这两个项目的文件夹进行打包。为此，我们定义一个<code>save_patch.sh</code>来将内容进行打包。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-meta">#! /usr/bin/env bash</span><br>PROJECT_DIR=$(<span class="hljs-built_in">cd</span> `<span class="hljs-built_in">dirname</span> <span class="hljs-variable">$0</span>`/..; <span class="hljs-built_in">pwd</span>)<br><br>. .<span class="hljs-built_in">env</span><br><span class="hljs-comment"># 加载.env文件 设置临时环境变量</span><br><br><span class="hljs-comment"># 获取上一层目录的绝对路径</span><br><br>tar -cvf infers_patch_<span class="hljs-variable">$&#123;TAG&#125;</span>.<span class="hljs-variable">$&#123;PATCH_VERSION&#125;</span>.tar -C <span class="hljs-variable">$&#123;PROJECT_DIR&#125;</span>/infers/ .<br><br>tar -cvf backend_patch_<span class="hljs-variable">$&#123;TAG&#125;</span>.<span class="hljs-variable">$&#123;PATCH_VERSION&#125;</span>.tar -C <span class="hljs-variable">$&#123;PROJECT_DIR&#125;</span>/backend/ .<br></code></pre></td></tr></table></figure><p>上面的脚本做了两件事，读取配置文件；将推理和后端的文件夹<code>infers</code>和<code>backend</code>打成tar包。</p><h1 id="加载包脚本"><a href="#加载包脚本" class="headerlink" title="加载包脚本"></a>加载包脚本</h1><p>当我们拿到了更新包以后，就需要将包导入到已有的镜像，并发布一版新镜像。这里给出一个<code>load_patch.sh</code>。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-meta">#! /usr/bin/env bash</span><br><br><span class="hljs-comment"># 加载.env文件 设置临时环境变量</span><br>. .<span class="hljs-built_in">env</span><br><br><span class="hljs-comment"># 当前目录</span><br>CURRENT_DIR=$(<span class="hljs-built_in">cd</span> `<span class="hljs-built_in">dirname</span> <span class="hljs-variable">$0</span>`; <span class="hljs-built_in">pwd</span>)<br><br>\<span class="hljs-built_in">cp</span> -rf <span class="hljs-variable">$&#123;CURRENT_DIR&#125;</span>/infers_patch_<span class="hljs-variable">$&#123;TAG&#125;</span>.<span class="hljs-variable">$&#123;PATCH_VERSION&#125;</span>.tar infers_patch.tar<br>\<span class="hljs-built_in">cp</span> -rf <span class="hljs-variable">$&#123;CURRENT_DIR&#125;</span>/backend_patch_<span class="hljs-variable">$&#123;TAG&#125;</span>.<span class="hljs-variable">$&#123;PATCH_VERSION&#125;</span>.tar backend_patch.tar<br>docker compose  -f docker-compose.patch.yaml build<br></code></pre></td></tr></table></figure><p>这里做的几件事：将更新包复制成<code>infers_path.tar</code>和<code>backend_patch.tar</code>。这两个包会被之后的<code>compose</code>文件使用来构建镜像。</p><h1 id="Docker-Compose-Patch"><a href="#Docker-Compose-Patch" class="headerlink" title="Docker Compose Patch"></a>Docker Compose Patch</h1><p>构建更新后的镜像需要用到<code>docker compose.patch.yaml</code>文件：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3.1&#x27;</span><br><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">infers:</span><br>    <span class="hljs-attr">platform:</span> <span class="hljs-string">linux/amd64</span><br>    <span class="hljs-comment"># 定义构建的上下文</span><br>    <span class="hljs-attr">build:</span> <br>      <span class="hljs-attr">context:</span> <span class="hljs-string">.</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile.infers.patch</span><br>      <span class="hljs-attr">args:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">TAG=$&#123;TAG&#125;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">PATCH_VERSION=$&#123;PATCH_VERSION&#125;</span><br>    <span class="hljs-comment"># 定义构建的镜像标签</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">behavior-detector-infers:$&#123;TAG&#125;.$&#123;PATCH_VERSION&#125;</span><br><br>  <span class="hljs-attr">backend:</span><br>    <span class="hljs-attr">platform:</span> <span class="hljs-string">linux/amd64</span><br>    <span class="hljs-attr">build:</span> <br>      <span class="hljs-attr">context:</span> <span class="hljs-string">.</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile.backend.patch</span><br>      <span class="hljs-attr">args:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">TAG=$&#123;TAG&#125;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">PATCH_VERSION=$&#123;PATCH_VERSION&#125;</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">behavior-detector-backend:$&#123;TAG&#125;.$&#123;PATCH_VERSION&#125;</span><br></code></pre></td></tr></table></figure><p>当我们build的时候，就会生成两个镜像：<code>behavior-detector-infers</code>和<code>behavior-detector-backend</code>。</p><h1 id="更新包Dockfile"><a href="#更新包Dockfile" class="headerlink" title="更新包Dockfile"></a>更新包Dockfile</h1><p>项目中频繁更新的部分是<code>infers</code>和<code>backend</code>容器，因此为这两个部分的更新包单独写Dockerfile。</p><p>后端更新包：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">ARG</span> TAG=<span class="hljs-number">1.0</span>.<span class="hljs-number">0</span><br><span class="hljs-keyword">ARG</span> PATCH_VERSION=<span class="hljs-number">1</span><br><span class="hljs-keyword">FROM</span> behavior-detector-backend:$&#123;TAG&#125;<br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /backend_app</span><br><br><span class="hljs-comment"># 删除目录下的文件</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">rm</span> -rf /backend_app/*</span><br><br><span class="hljs-comment"># 复制项目文件</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> backend_patch.tar /backend_app/</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> tar xvf /backend_app/backend_patch.tar -C /backend_app</span><br><br><span class="hljs-comment"># 暴露端口号</span><br><span class="hljs-comment"># 80 前端服务</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">80</span><br><span class="hljs-comment"># python 服务</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">7091</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">7092</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">7093</span><br><br><span class="hljs-comment"># 启动 FastAPI 应用</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;bash&quot;</span>, <span class="hljs-string">&quot;start.sh&quot;</span>]</span><br></code></pre></td></tr></table></figure><p>推理更新包：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">ARG</span> TAG=<span class="hljs-number">1.0</span>.<span class="hljs-number">0</span><br><span class="hljs-keyword">ARG</span> PATCH_VERSION=<span class="hljs-number">1</span><br><span class="hljs-keyword">FROM</span> behavior-detector-infers:$&#123;TAG&#125;<br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /infer_app</span><br><br><span class="hljs-comment"># 复制项目文件</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">rm</span> -rf /infer_app/*</span><br><br><span class="hljs-keyword">COPY</span><span class="language-bash"> infers_patch.tar /infer_app/</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> tar xvf /infer_app/infers_patch.tar -C /infer_app</span><br><br><span class="hljs-comment"># 暴露端口</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">58090</span><br><br><span class="hljs-comment"># 默认命令</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;bash&quot;</span>, <span class="hljs-string">&quot;start.sh&quot;</span>, <span class="hljs-string">&quot;prod&quot;</span>]</span><br></code></pre></td></tr></table></figure><h1 id="Docker-Compose-Prod"><a href="#Docker-Compose-Prod" class="headerlink" title="Docker Compose Prod"></a>Docker Compose Prod</h1><p>最后还需要有一个实际部署的<code>docker compose</code>文件，这个文件是实际真正部署的容器镜像：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3.1&#x27;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">redis-service:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">redis:latest</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;6379:6379&quot;</span><br><br>  <span class="hljs-attr">detector-service-api:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">behavior-detector-backend:$&#123;TAG&#125;.$&#123;PATCH_VERSION&#125;</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">RUNTIME_ENV=prod</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">RUNTIME_SERVICE_TYPE=api</span><br><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_HOST=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_PORT=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_DBNAME=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_USER=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_PASSWD=xxxx</span><br><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">REDIS_HOST=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">REDIS_PORT=6379</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">REDIS_PASSWD=</span><br><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/logs:/app/logs</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/captures:/app/captures</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/targets:/app/targets</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/html:/app/html</span><br>      <br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;7901:80&quot;</span><br>      <br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">redis-service</span><br><br>  <span class="hljs-attr">detector-service-stream:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">behavior-detector-backend:$&#123;TAG&#125;.$&#123;PATCH_VERSION&#125;</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">environment:</span><br><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">RUNTIME_ENV=prod</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">RUNTIME_SERVICE_TYPE=stream</span><br><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_HOST=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_PORT=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_DBNAME=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_USER=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">POSTGRESQL_PASSWD=xxxx</span><br><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">REDIS_HOST=xxxx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">REDIS_PORT=6379</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">REDIS_PASSWD=</span><br><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/logs:/app/logs</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/captures:/app/captures</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/targets:/app/targets</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/html:/app/html</span><br><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">redis-service</span><br>      <br>  <span class="hljs-attr">staytime:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">behavior-detector-infers:$&#123;TAG&#125;.$&#123;PATCH_VERSION&#125;</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;58093:58090&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app:/app</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ENV_MODEL_NAME=staytime</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ENV_GUNICORN_WORKERS=1</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ENV_CUDA_DEVICE=0</span><br>    <span class="hljs-attr">deploy:</span><br>      <span class="hljs-attr">resources:</span><br>        <span class="hljs-attr">reservations:</span><br>          <span class="hljs-attr">devices:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">driver:</span> <span class="hljs-string">nvidia</span><br>              <span class="hljs-attr">count:</span> <span class="hljs-string">all</span><br>              <span class="hljs-attr">capabilities:</span> [ <span class="hljs-string">gpu</span> ]<br></code></pre></td></tr></table></figure><p>实际使用中，使用<code>docker compose -f docker-compose.prod.yaml up -d</code>即可进行部署。</p><p>2024&#x2F;4&#x2F;22 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>源码分析：LlaMA3的工程代码实现</title>
    <link href="/2024/04/20/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9ALlaMA3%E6%94%B9%E8%BF%9B%E4%B8%8E%E6%9E%B6%E6%9E%84/"/>
    <url>/2024/04/20/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9ALlaMA3%E6%94%B9%E8%BF%9B%E4%B8%8E%E6%9E%B6%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h1 id="源码部分"><a href="#源码部分" class="headerlink" title="源码部分"></a>源码部分</h1><p>LlaMA3的仓库和代码相当精简，核心的模型部分由四个文件组成，分别是<code>model.py</code>，<code>generation.py</code>，<code>test_tokenizer</code>，<code>tokenizer</code>。除此之外还有两个测试脚本：<code>example_chat_completion.py</code>，<code>example_text_completion.py</code>。</p><h2 id="Tokenizer-py"><a href="#Tokenizer-py" class="headerlink" title="Tokenizer.py"></a>Tokenizer.py</h2><p>Tokenizer类用于文本分词和编码&#x2F;解码。</p><p>代码中的Tokenizer类有以下功能：</p><ul><li>初始化：通过传入Tiktoken模型文件的路径来初始化Tokenizer对象。</li><li>分词和编码：使用Tiktoken模型对文本进行分词和编码。</li><li>解码：将编码后的文本解码为原始文本。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> logging <span class="hljs-keyword">import</span> getLogger<br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> (<br>    AbstractSet,<br>    cast,<br>    Collection,<br>    <span class="hljs-type">Dict</span>,<br>    Iterator,<br>    <span class="hljs-type">List</span>,<br>    <span class="hljs-type">Literal</span>,<br>    <span class="hljs-type">Sequence</span>,<br>    TypedDict,<br>    <span class="hljs-type">Union</span>,<br>)<br><br><span class="hljs-keyword">import</span> tiktoken<br><span class="hljs-keyword">from</span> tiktoken.load <span class="hljs-keyword">import</span> load_tiktoken_bpe<br><br><br>logger = getLogger(__name__)<br><br><span class="hljs-comment"># Role是一个字符串，只能是&quot;system&quot;, &quot;user&quot;, &quot;assistant&quot;中的一个</span><br>Role = <span class="hljs-type">Literal</span>[<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;assistant&quot;</span>]<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Message</span>(<span class="hljs-title class_ inherited__">TypedDict</span>):<br>    role: Role<br>    content: <span class="hljs-built_in">str</span><br><br><span class="hljs-comment"># Dialog是一个Message的列表</span><br>Dialog = <span class="hljs-type">Sequence</span>[Message]<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tokenizer</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    使用Tiktoken分词器对文本进行分词和编码/解码。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    special_tokens: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>]<br>    <span class="hljs-comment"># 保留的特殊token数量</span><br>    num_reserved_special_tokens = <span class="hljs-number">256</span><br><br>    pat_str = <span class="hljs-string">r&quot;(?i:&#x27;s|&#x27;t|&#x27;re|&#x27;ve|&#x27;m|&#x27;ll|&#x27;d)|[^\r\n\p&#123;L&#125;\p&#123;N&#125;]?\p&#123;L&#125;+|\p&#123;N&#125;&#123;1,3&#125;| ?[^\s\p&#123;L&#125;\p&#123;N&#125;]+[\r\n]*|\s*[\r\n]+|\s+(?!\S)|\s+&quot;</span>  <span class="hljs-comment"># noqa: E501</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_path: <span class="hljs-built_in">str</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        使用Tiktoken模型文件初始化分词器。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            model_path (str): Tiktoken模型路径。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> os.path.isfile(model_path), model_path<br><br>        mergeable_ranks = load_tiktoken_bpe(model_path)<br>        num_base_tokens = <span class="hljs-built_in">len</span>(mergeable_ranks)<br>        <span class="hljs-comment"># 定义特殊token</span><br>        special_tokens = [<br>            <span class="hljs-string">&quot;&lt;|begin_of_text|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|end_of_text|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|reserved_special_token_0|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|reserved_special_token_1|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|reserved_special_token_2|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|reserved_special_token_3|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|start_header_id|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|end_header_id|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|reserved_special_token_4|&gt;&quot;</span>,<br>            <span class="hljs-string">&quot;&lt;|eot_id|&gt;&quot;</span>,  <span class="hljs-comment"># end of turn</span><br>        ] + [<br>            <span class="hljs-string">f&quot;&lt;|reserved_special_token_<span class="hljs-subst">&#123;i&#125;</span>|&gt;&quot;</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>, self.num_reserved_special_tokens - <span class="hljs-number">5</span>)<br>        ]<br>        <span class="hljs-comment"># 为每个特殊token分配一个ID</span><br>        self.special_tokens = &#123;<br>            token: num_base_tokens + i <span class="hljs-keyword">for</span> i, token <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(special_tokens)<br>        &#125;<br>        self.model = tiktoken.Encoding(<br>            name=Path(model_path).name,<br>            pat_str=self.pat_str,<br>            mergeable_ranks=mergeable_ranks,<br>            special_tokens=self.special_tokens,<br>        )<br>        logger.info(<span class="hljs-string">f&quot;Reloaded tiktoken model from <span class="hljs-subst">&#123;model_path&#125;</span>&quot;</span>)<br><br>        self.n_words: <span class="hljs-built_in">int</span> = self.model.n_vocab<br>        <span class="hljs-comment"># 开始和结束的token ID</span><br>        self.bos_id: <span class="hljs-built_in">int</span> = self.special_tokens[<span class="hljs-string">&quot;&lt;|begin_of_text|&gt;&quot;</span>]<br>        self.eos_id: <span class="hljs-built_in">int</span> = self.special_tokens[<span class="hljs-string">&quot;&lt;|end_of_text|&gt;&quot;</span>]<br>        self.pad_id: <span class="hljs-built_in">int</span> = -<span class="hljs-number">1</span><br>        self.stop_tokens = &#123;<br>            self.special_tokens[<span class="hljs-string">&quot;&lt;|end_of_text|&gt;&quot;</span>],<br>            self.special_tokens[<span class="hljs-string">&quot;&lt;|eot_id|&gt;&quot;</span>],<br>        &#125;<br>        logger.info(<br>            <span class="hljs-string">f&quot;#words: <span class="hljs-subst">&#123;self.n_words&#125;</span> - BOS ID: <span class="hljs-subst">&#123;self.bos_id&#125;</span> - EOS ID: <span class="hljs-subst">&#123;self.eos_id&#125;</span>&quot;</span><br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        s: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">        *,</span><br><span class="hljs-params">        bos: <span class="hljs-built_in">bool</span>,</span><br><span class="hljs-params">        eos: <span class="hljs-built_in">bool</span>,</span><br><span class="hljs-params">        allowed_special: <span class="hljs-type">Union</span>[<span class="hljs-type">Literal</span>[<span class="hljs-string">&quot;all&quot;</span>], AbstractSet[<span class="hljs-built_in">str</span>]] = <span class="hljs-built_in">set</span>(<span class="hljs-params"></span>),</span><br><span class="hljs-params">        disallowed_special: <span class="hljs-type">Union</span>[<span class="hljs-type">Literal</span>[<span class="hljs-string">&quot;all&quot;</span>], Collection[<span class="hljs-built_in">str</span>]] = (<span class="hljs-params"></span>),</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        将字符串编码为Token ID列表。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        参数：</span><br><span class="hljs-string">        - s（str）：要编码的输入字符串。</span><br><span class="hljs-string">        - bos（bool）：是否在开头添加序列开始标记。</span><br><span class="hljs-string">        - eos（bool）：是否在末尾添加序列结束标记。</span><br><span class="hljs-string">        - allowed_tokens（&quot;all&quot; | set [str]）：允许在字符串中出现的特殊标记。</span><br><span class="hljs-string">        - disallowed_tokens（&quot;all&quot; | set [str]）：在字符串中出现时会引发错误的特殊标记。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        返回：</span><br><span class="hljs-string">        - list [int]：标记ID的列表。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        默认情况下，将disallowed_tokens设置为()会忽略特殊标记进行编码。具体来说：</span><br><span class="hljs-string">        - 将disallowed_tokens设置为()将导致所有对应于特殊标记的文本被编码为自然文本（而不是引发错误）。</span><br><span class="hljs-string">        - 将allowed_tokens设置为&quot;all&quot;将将所有对应于特殊标记的文本视为特殊标记进行编码。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">type</span>(s) <span class="hljs-keyword">is</span> <span class="hljs-built_in">str</span><br><br>        <span class="hljs-comment"># 分词器可以处理&lt;=400k个字符，否则会抛出异常</span><br>        TIKTOKEN_MAX_ENCODE_CHARS = <span class="hljs-number">400_000</span><br><br>        <span class="hljs-comment"># 这里我们迭代子序列，如果超过了最大连续非空格或空格字符的限制，就会分割</span><br>        MAX_NO_WHITESPACES_CHARS = <span class="hljs-number">25_000</span><br><br>        <span class="hljs-comment"># substrs是一个生成器，每次生成一个子串</span><br>        substrs = (<br>            substr<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(s), TIKTOKEN_MAX_ENCODE_CHARS)<br>            <span class="hljs-keyword">for</span> substr <span class="hljs-keyword">in</span> self._split_whitespaces_or_nonwhitespaces(<br>                s[i : i + TIKTOKEN_MAX_ENCODE_CHARS], MAX_NO_WHITESPACES_CHARS<br>            )<br>        )<br>        t: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>] = []<br>        <br>        <span class="hljs-comment"># 将token ID添加到t中</span><br>        <span class="hljs-keyword">for</span> substr <span class="hljs-keyword">in</span> substrs:<br>            t.extend(<br>                self.model.encode(<br>                    substr,<br>                    allowed_special=allowed_special,<br>                    disallowed_special=disallowed_special,<br>                )<br>            )<br>        <span class="hljs-keyword">if</span> bos:<br>            t.insert(<span class="hljs-number">0</span>, self.bos_id)<br>        <span class="hljs-keyword">if</span> eos:<br>            t.append(self.eos_id)<br>        <span class="hljs-keyword">return</span> t<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, t: <span class="hljs-type">Sequence</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        将token ID列表解码为字符串。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        参数：</span><br><span class="hljs-string">        - t（List[int]）：要解码的标记ID列表。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        返回：</span><br><span class="hljs-string">        - str：解码后的字符串。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 这里的类型转换是安全的。Tiktoken不会对序列进行任何与列表相关的操作。</span><br>        <span class="hljs-keyword">return</span> self.model.decode(cast(<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], t))<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_split_whitespaces_or_nonwhitespaces</span>(<span class="hljs-params"></span><br><span class="hljs-params">        s: <span class="hljs-built_in">str</span>, max_consecutive_slice_len: <span class="hljs-built_in">int</span></span><br><span class="hljs-params">    </span>) -&gt; Iterator[<span class="hljs-built_in">str</span>]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        分割字符串`s`，使得每个子字符串中不包含超过`max_consecutive_slice_len`个连续的空格或连续的非空格。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        current_slice_len = <span class="hljs-number">0</span><br>        current_slice_is_space = s[<span class="hljs-number">0</span>].isspace() <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(s) &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>        slice_start = <span class="hljs-number">0</span><br><br>        <br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s)):<br>            is_now_space = s[i].isspace()<br>            <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">            如果当前子串的空格性质与当前字符的空格性质不同</span><br><span class="hljs-string">            则将当前子串的长度设为1，当前子串的空格性质设为当前字符的空格性质</span><br><span class="hljs-string">            否则，当前子串的长度加1</span><br><span class="hljs-string">            如果当前子串的长度大于最大连续子串长度，则生成当前子串</span><br><span class="hljs-string">            &quot;&quot;&quot;</span><br>            <span class="hljs-keyword">if</span> current_slice_is_space ^ is_now_space:<br>                current_slice_len = <span class="hljs-number">1</span><br>                current_slice_is_space = is_now_space<br>            <span class="hljs-keyword">else</span>:<br>                current_slice_len += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> current_slice_len &gt; max_consecutive_slice_len:<br>                    <span class="hljs-keyword">yield</span> s[slice_start:i]<br>                    slice_start = i<br>                    current_slice_len = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">yield</span> s[slice_start:]<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ChatFormat</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    将对话编码为适合聊天完成的格式。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, tokenizer: Tokenizer</span>):<br>        self.tokenizer = tokenizer<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_header</span>(<span class="hljs-params">self, message: Message</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        tokens = []<br>        tokens.append(self.tokenizer.special_tokens[<span class="hljs-string">&quot;&lt;|start_header_id|&gt;&quot;</span>])<br>        tokens.extend(self.tokenizer.encode(message[<span class="hljs-string">&quot;role&quot;</span>], bos=<span class="hljs-literal">False</span>, eos=<span class="hljs-literal">False</span>))<br>        tokens.append(self.tokenizer.special_tokens[<span class="hljs-string">&quot;&lt;|end_header_id|&gt;&quot;</span>])<br>        tokens.extend(self.tokenizer.encode(<span class="hljs-string">&quot;\n\n&quot;</span>, bos=<span class="hljs-literal">False</span>, eos=<span class="hljs-literal">False</span>))<br>        <span class="hljs-keyword">return</span> tokens<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_message</span>(<span class="hljs-params">self, message: Message</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        tokens = self.encode_header(message)<br>        tokens.extend(<br>            self.tokenizer.encode(message[<span class="hljs-string">&quot;content&quot;</span>].strip(), bos=<span class="hljs-literal">False</span>, eos=<span class="hljs-literal">False</span>)<br>        )<br>        tokens.append(self.tokenizer.special_tokens[<span class="hljs-string">&quot;&lt;|eot_id|&gt;&quot;</span>])<br>        <span class="hljs-keyword">return</span> tokens<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_dialog_prompt</span>(<span class="hljs-params">self, dialog: Dialog</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        tokens = []<br>        tokens.append(self.tokenizer.special_tokens[<span class="hljs-string">&quot;&lt;|begin_of_text|&gt;&quot;</span>])<br>        <span class="hljs-keyword">for</span> message <span class="hljs-keyword">in</span> dialog:<br>            tokens.extend(self.encode_message(message))<br>        <span class="hljs-comment"># Add the start of an assistant message for the model to complete.</span><br>        tokens.extend(self.encode_header(&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;&quot;</span>&#125;))<br>        <span class="hljs-keyword">return</span> tokens<br></code></pre></td></tr></table></figure><h2 id="test-tokenizer"><a href="#test-tokenizer" class="headerlink" title="test_tokenizer"></a>test_tokenizer</h2><p>meta提供了一个测试分词器的脚本。这里会对分词器的各个功能进行断言。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> unittest <span class="hljs-keyword">import</span> TestCase<br><span class="hljs-keyword">from</span> llama.tokenizer <span class="hljs-keyword">import</span> ChatFormat, Tokenizer<br><br><span class="hljs-comment"># TOKENIZER_PATH=&lt;path&gt; python -m unittest llama/test_tokenizer.py</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TokenizerTests</span>(<span class="hljs-title class_ inherited__">TestCase</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setUp</span>(<span class="hljs-params">self</span>):<br>        self.tokenizer = Tokenizer(os.environ[<span class="hljs-string">&quot;TOKENIZER_PATH&quot;</span>])<br>        self.<span class="hljs-built_in">format</span> = ChatFormat(self.tokenizer)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_special_tokens</span>(<span class="hljs-params">self</span>):<br>        self.assertEqual(<br>            self.tokenizer.special_tokens[<span class="hljs-string">&quot;&lt;|begin_of_text|&gt;&quot;</span>],<br>            <span class="hljs-number">128000</span>,<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_encode</span>(<span class="hljs-params">self</span>):<br>        self.assertEqual(<br>            self.tokenizer.encode(<br>                <span class="hljs-string">&quot;This is a test sentence.&quot;</span>,<br>                bos=<span class="hljs-literal">True</span>,<br>                eos=<span class="hljs-literal">True</span><br>            ),<br>            [<span class="hljs-number">128000</span>, <span class="hljs-number">2028</span>, <span class="hljs-number">374</span>, <span class="hljs-number">264</span>, <span class="hljs-number">1296</span>, <span class="hljs-number">11914</span>, <span class="hljs-number">13</span>, <span class="hljs-number">128001</span>],<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_decode</span>(<span class="hljs-params">self</span>):<br>        self.assertEqual(<br>            self.tokenizer.decode(<br>                [<span class="hljs-number">128000</span>, <span class="hljs-number">2028</span>, <span class="hljs-number">374</span>, <span class="hljs-number">264</span>, <span class="hljs-number">1296</span>, <span class="hljs-number">11914</span>, <span class="hljs-number">13</span>, <span class="hljs-number">128001</span>],<br>            ),<br>            <span class="hljs-string">&quot;&lt;|begin_of_text|&gt;This is a test sentence.&lt;|end_of_text|&gt;&quot;</span>,<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_encode_message</span>(<span class="hljs-params">self</span>):<br>        message = &#123;<br>            <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>            <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;This is a test sentence.&quot;</span>,<br>        &#125;<br>        self.assertEqual(<br>            self.<span class="hljs-built_in">format</span>.encode_message(message),<br>            [<br>                <span class="hljs-number">128006</span>,  <span class="hljs-comment"># &lt;|start_header_id|&gt;</span><br>                <span class="hljs-number">882</span>,  <span class="hljs-comment"># &quot;user&quot;</span><br>                <span class="hljs-number">128007</span>,  <span class="hljs-comment"># &lt;|end_of_header|&gt;</span><br>                <span class="hljs-number">271</span>,  <span class="hljs-comment"># &quot;\n\n&quot;</span><br>                <span class="hljs-number">2028</span>, <span class="hljs-number">374</span>, <span class="hljs-number">264</span>, <span class="hljs-number">1296</span>, <span class="hljs-number">11914</span>, <span class="hljs-number">13</span>,  <span class="hljs-comment"># This is a test sentence.</span><br>                <span class="hljs-number">128009</span>,  <span class="hljs-comment"># &lt;|eot_id|&gt;</span><br>            ]<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_encode_dialog</span>(<span class="hljs-params">self</span>):<br>        dialog = [<br>            &#123;<br>                <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>                <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;This is a test sentence.&quot;</span>,<br>            &#125;,<br>            &#123;<br>                <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>                <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;This is a response.&quot;</span>,<br>            &#125;<br>        ]<br>        self.assertEqual(<br>            self.<span class="hljs-built_in">format</span>.encode_dialog_prompt(dialog),<br>            [<br>                <span class="hljs-number">128000</span>,  <span class="hljs-comment"># &lt;|begin_of_text|&gt;</span><br>                <span class="hljs-number">128006</span>,  <span class="hljs-comment"># &lt;|start_header_id|&gt;</span><br>                <span class="hljs-number">9125</span>,     <span class="hljs-comment"># &quot;system&quot;</span><br>                <span class="hljs-number">128007</span>,  <span class="hljs-comment"># &lt;|end_of_header|&gt;</span><br>                <span class="hljs-number">271</span>,     <span class="hljs-comment"># &quot;\n\n&quot;</span><br>                <span class="hljs-number">2028</span>, <span class="hljs-number">374</span>, <span class="hljs-number">264</span>, <span class="hljs-number">1296</span>, <span class="hljs-number">11914</span>, <span class="hljs-number">13</span>,  <span class="hljs-comment"># &quot;This is a test sentence.&quot;</span><br>                <span class="hljs-number">128009</span>,  <span class="hljs-comment"># &lt;|eot_id|&gt;</span><br>                <span class="hljs-number">128006</span>,  <span class="hljs-comment"># &lt;|start_header_id|&gt;</span><br>                <span class="hljs-number">882</span>,     <span class="hljs-comment"># &quot;user&quot;</span><br>                <span class="hljs-number">128007</span>,  <span class="hljs-comment"># &lt;|end_of_header|&gt;</span><br>                <span class="hljs-number">271</span>,     <span class="hljs-comment"># &quot;\n\n&quot;</span><br>                <span class="hljs-number">2028</span>, <span class="hljs-number">374</span>, <span class="hljs-number">264</span>, <span class="hljs-number">2077</span>, <span class="hljs-number">13</span>,  <span class="hljs-comment"># &quot;This is a response.&quot;,</span><br>                <span class="hljs-number">128009</span>,  <span class="hljs-comment"># &lt;|eot_id|&gt;</span><br>                <span class="hljs-number">128006</span>,  <span class="hljs-comment"># &lt;|start_header_id|&gt;</span><br>                <span class="hljs-number">78191</span>,   <span class="hljs-comment"># &quot;assistant&quot;</span><br>                <span class="hljs-number">128007</span>,  <span class="hljs-comment"># &lt;|end_of_header|&gt;</span><br>                <span class="hljs-number">271</span>,     <span class="hljs-comment"># &quot;\n\n&quot;</span><br>            ]<br>        )<br></code></pre></td></tr></table></figure><h2 id="generation-py"><a href="#generation-py" class="headerlink" title="generation.py"></a>generation.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Optional</span>, <span class="hljs-type">Tuple</span>, TypedDict<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> fairscale.nn.model_parallel.initialize <span class="hljs-keyword">import</span> (<br>    get_model_parallel_rank,<br>    initialize_model_parallel,<br>    model_parallel_is_initialized,<br>)<br><br><span class="hljs-keyword">from</span> llama.model <span class="hljs-keyword">import</span> ModelArgs, Transformer<br><span class="hljs-keyword">from</span> llama.tokenizer <span class="hljs-keyword">import</span> ChatFormat, Dialog, Message, Tokenizer<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CompletionPrediction</span>(TypedDict, total=<span class="hljs-literal">False</span>):<br>    generation: <span class="hljs-built_in">str</span><br>    tokens: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]  <span class="hljs-comment"># not required</span><br>    logprobs: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]  <span class="hljs-comment"># not required</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ChatPrediction</span>(TypedDict, total=<span class="hljs-literal">False</span>):<br>    generation: Message<br>    tokens: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]  <span class="hljs-comment"># not required</span><br>    logprobs: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]  <span class="hljs-comment"># not required</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Llama</span>:<br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">build</span>(<span class="hljs-params"></span><br><span class="hljs-params">        ckpt_dir: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">        tokenizer_path: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">        max_seq_len: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        max_batch_size: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        model_parallel_size: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        seed: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-string">&quot;Llama&quot;</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        通过初始化和加载模型检查点来构建一个Llama实例。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        参数：</span><br><span class="hljs-string">        - ckpt_dir（str）：包含检查点文件的目录路径。</span><br><span class="hljs-string">        - tokenizer_path（str）：分词器文件的路径。</span><br><span class="hljs-string">        - max_seq_len（int）：输入文本的最大序列长度。</span><br><span class="hljs-string">        - max_batch_size（int）：推理的最大批处理大小。</span><br><span class="hljs-string">        - model_parallel_size（Optional[int]，可选）：模型并行进程的数量。</span><br><span class="hljs-string">            如果未提供，则从环境中确定。默认为None。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        返回：</span><br><span class="hljs-string">        - Llama：具有加载的模型和分词器的Llama类的实例。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        抛出：</span><br><span class="hljs-string">        - AssertionError：如果指定目录中没有检查点文件，或者模型并行大小与检查点文件的数量不匹配。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        注意：</span><br><span class="hljs-string">        - 此方法初始化分布式进程组，将设备设置为CUDA，并加载预训练模型和分词器。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> torch.distributed.is_initialized():<br>            torch.distributed.init_process_group(<span class="hljs-string">&quot;nccl&quot;</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> model_parallel_is_initialized():<br>            <span class="hljs-keyword">if</span> model_parallel_size <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                model_parallel_size = <span class="hljs-built_in">int</span>(os.environ.get(<span class="hljs-string">&quot;WORLD_SIZE&quot;</span>, <span class="hljs-number">1</span>))<br>            initialize_model_parallel(model_parallel_size)<br><br>        local_rank = <span class="hljs-built_in">int</span>(os.environ.get(<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>, <span class="hljs-number">0</span>))<br>        torch.cuda.set_device(local_rank)<br><br>        <span class="hljs-comment"># seed must be the same in all processes</span><br>        torch.manual_seed(seed)<br><br>        <span class="hljs-keyword">if</span> local_rank &gt; <span class="hljs-number">0</span>:<br>            sys.stdout = <span class="hljs-built_in">open</span>(os.devnull, <span class="hljs-string">&quot;w&quot;</span>)<br><br>        start_time = time.time()<br>        checkpoints = <span class="hljs-built_in">sorted</span>(Path(ckpt_dir).glob(<span class="hljs-string">&quot;*.pth&quot;</span>))<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(checkpoints) &gt; <span class="hljs-number">0</span>, <span class="hljs-string">f&quot;no checkpoint files found in <span class="hljs-subst">&#123;ckpt_dir&#125;</span>&quot;</span><br>        <span class="hljs-keyword">assert</span> model_parallel_size == <span class="hljs-built_in">len</span>(<br>            checkpoints<br>        ), <span class="hljs-string">f&quot;Loading a checkpoint for MP=<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(checkpoints)&#125;</span> but world size is <span class="hljs-subst">&#123;model_parallel_size&#125;</span>&quot;</span><br>        ckpt_path = checkpoints[get_model_parallel_rank()]<br>        checkpoint = torch.load(ckpt_path, map_location=<span class="hljs-string">&quot;cpu&quot;</span>)<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(Path(ckpt_dir) / <span class="hljs-string">&quot;params.json&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            params = json.loads(f.read())<br><br>        model_args: ModelArgs = ModelArgs(<br>            max_seq_len=max_seq_len,<br>            max_batch_size=max_batch_size,<br>            **params,<br>        )<br>        tokenizer = Tokenizer(model_path=tokenizer_path)<br>        <span class="hljs-keyword">assert</span> model_args.vocab_size == tokenizer.n_words<br>        <span class="hljs-keyword">if</span> torch.cuda.is_bf16_supported():<br>            torch.set_default_tensor_type(torch.cuda.BFloat16Tensor)<br>        <span class="hljs-keyword">else</span>:<br>            torch.set_default_tensor_type(torch.cuda.HalfTensor)<br>        model = Transformer(model_args)<br>        model.load_state_dict(checkpoint, strict=<span class="hljs-literal">False</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Loaded in <span class="hljs-subst">&#123;time.time() - start_time:<span class="hljs-number">.2</span>f&#125;</span> seconds&quot;</span>)<br><br>        <span class="hljs-keyword">return</span> Llama(model, tokenizer)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model: Transformer, tokenizer: Tokenizer</span>):<br>        self.model = model<br>        self.tokenizer = tokenizer<br>        self.formatter = ChatFormat(tokenizer)<br><br><span class="hljs-meta">    @torch.inference_mode()</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generate</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        prompt_tokens: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]],</span><br><span class="hljs-params">        max_gen_len: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.6</span>,</span><br><span class="hljs-params">        top_p: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.9</span>,</span><br><span class="hljs-params">        logprobs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        echo: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]], <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]]]]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        使用语言生成模型根据提供的提示生成文本序列。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        参数：</span><br><span class="hljs-string">        - prompt_tokens（List[List[int]]）：标记化提示的列表，其中每个提示表示为整数列表。</span><br><span class="hljs-string">        - max_gen_len（int）：生成的文本序列的最大长度。</span><br><span class="hljs-string">        - temperature（float，可选）：用于控制采样中的随机性的温度值。默认为0.6。</span><br><span class="hljs-string">        - top_p（float，可选）：用于nucleus采样的top-p概率阈值。默认为0.9。</span><br><span class="hljs-string">        - logprobs（bool，可选）：指示是否计算标记对数概率的标志。默认为False。</span><br><span class="hljs-string">        - echo（bool，可选）：指示是否在生成的输出中包含提示标记的标志。默认为False。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        返回：</span><br><span class="hljs-string">        - Tuple[List[List[int]]，Optional[List[List[float]]]]：包含生成的标记序列的元组，如果logprobs为True，则还包含相应的标记对数概率。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        注意：</span><br><span class="hljs-string">        - 此方法使用提供的提示作为生成文本的基础。它使用nucleus采样来产生具有受控随机性的文本。</span><br><span class="hljs-string">        - 如果logprobs为True，则为每个生成的标记计算标记对数概率。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        params = self.model.params<br>        bsz = <span class="hljs-built_in">len</span>(prompt_tokens)<br>        <span class="hljs-keyword">assert</span> bsz &lt;= params.max_batch_size, (bsz, params.max_batch_size)<br><br>        min_prompt_len = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(t) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> prompt_tokens)<br>        max_prompt_len = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">len</span>(t) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> prompt_tokens)<br>        <span class="hljs-keyword">assert</span> max_prompt_len &lt;= params.max_seq_len<br>        total_len = <span class="hljs-built_in">min</span>(params.max_seq_len, max_gen_len + max_prompt_len)<br><br>        pad_id = self.tokenizer.pad_id<br>        tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=<span class="hljs-string">&quot;cuda&quot;</span>)<br>        <span class="hljs-keyword">for</span> k, t <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(prompt_tokens):<br>            tokens[k, : <span class="hljs-built_in">len</span>(t)] = torch.tensor(t, dtype=torch.long, device=<span class="hljs-string">&quot;cuda&quot;</span>)<br>        <span class="hljs-keyword">if</span> logprobs:<br>            token_logprobs = torch.zeros_like(tokens, dtype=torch.<span class="hljs-built_in">float</span>)<br><br>        prev_pos = <span class="hljs-number">0</span><br>        eos_reached = torch.tensor([<span class="hljs-literal">False</span>] * bsz, device=<span class="hljs-string">&quot;cuda&quot;</span>)<br>        input_text_mask = tokens != pad_id<br>        <span class="hljs-keyword">if</span> min_prompt_len == total_len:<br>            logits = self.model.forward(tokens, prev_pos)<br>            token_logprobs = -F.cross_entropy(<br>                <span class="hljs-built_in">input</span>=logits.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>                target=tokens,<br>                reduction=<span class="hljs-string">&quot;none&quot;</span>,<br>                ignore_index=pad_id,<br>            )<br><br>        stop_tokens = torch.tensor(<span class="hljs-built_in">list</span>(self.tokenizer.stop_tokens))<br><br>        <span class="hljs-keyword">for</span> cur_pos <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(min_prompt_len, total_len):<br>            logits = self.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)<br>            <span class="hljs-keyword">if</span> temperature &gt; <span class="hljs-number">0</span>:<br>                probs = torch.softmax(logits[:, -<span class="hljs-number">1</span>] / temperature, dim=-<span class="hljs-number">1</span>)<br>                next_token = sample_top_p(probs, top_p)<br>            <span class="hljs-keyword">else</span>:<br>                next_token = torch.argmax(logits[:, -<span class="hljs-number">1</span>], dim=-<span class="hljs-number">1</span>)<br><br>            next_token = next_token.reshape(-<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># only replace token if prompt has already been generated</span><br>            next_token = torch.where(<br>                input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token<br>            )<br>            tokens[:, cur_pos] = next_token<br>            <span class="hljs-keyword">if</span> logprobs:<br>                token_logprobs[:, prev_pos + <span class="hljs-number">1</span> : cur_pos + <span class="hljs-number">1</span>] = -F.cross_entropy(<br>                    <span class="hljs-built_in">input</span>=logits.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>                    target=tokens[:, prev_pos + <span class="hljs-number">1</span> : cur_pos + <span class="hljs-number">1</span>],<br>                    reduction=<span class="hljs-string">&quot;none&quot;</span>,<br>                    ignore_index=pad_id,<br>                )<br>            eos_reached |= (~input_text_mask[:, cur_pos]) &amp; (<br>                torch.isin(next_token, stop_tokens)<br>            )<br>            prev_pos = cur_pos<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">all</span>(eos_reached):<br>                <span class="hljs-keyword">break</span><br><br>        <span class="hljs-keyword">if</span> logprobs:<br>            token_logprobs = token_logprobs.tolist()<br>        out_tokens, out_logprobs = [], []<br>        <span class="hljs-keyword">for</span> i, toks <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tokens.tolist()):<br>            <span class="hljs-comment"># cut to max gen len</span><br>            start = <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> echo <span class="hljs-keyword">else</span> <span class="hljs-built_in">len</span>(prompt_tokens[i])<br>            toks = toks[start : <span class="hljs-built_in">len</span>(prompt_tokens[i]) + max_gen_len]<br>            probs = <span class="hljs-literal">None</span><br>            <span class="hljs-keyword">if</span> logprobs:<br>                probs = token_logprobs[i][start : <span class="hljs-built_in">len</span>(prompt_tokens[i]) + max_gen_len]<br>            <span class="hljs-comment"># cut to after eos tok if any</span><br>            <span class="hljs-keyword">for</span> stop_token <span class="hljs-keyword">in</span> self.tokenizer.stop_tokens:<br>                <span class="hljs-keyword">try</span>:<br>                    eos_idx = toks.index(stop_token)<br>                    toks = toks[:eos_idx]<br>                    probs = probs[:eos_idx] <span class="hljs-keyword">if</span> logprobs <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>                <span class="hljs-keyword">except</span> ValueError:<br>                    <span class="hljs-keyword">pass</span><br>            out_tokens.append(toks)<br>            out_logprobs.append(probs)<br>        <span class="hljs-keyword">return</span> (out_tokens, out_logprobs <span class="hljs-keyword">if</span> logprobs <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">text_completion</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        prompts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>],</span><br><span class="hljs-params">        temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.6</span>,</span><br><span class="hljs-params">        top_p: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.9</span>,</span><br><span class="hljs-params">        max_gen_len: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        logprobs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        echo: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[CompletionPrediction]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        使用语言生成模型对一组提示进行文本补全。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        参数：</span><br><span class="hljs-string">        - prompts（List[str]）：要进行补全的文本提示列表。</span><br><span class="hljs-string">        - temperature（float，可选）：用于控制采样中的随机性的温度值。默认为0.6。</span><br><span class="hljs-string">        - top_p（float，可选）：用于nucleus采样的top-p概率阈值。默认为0.9。</span><br><span class="hljs-string">        - max_gen_len（Optional[int]，可选）：生成的补全序列的最大长度。</span><br><span class="hljs-string">            如果未提供，则设置为模型的最大序列长度减1。</span><br><span class="hljs-string">        - logprobs（bool，可选）：指示是否计算标记对数概率的标志。默认为False。</span><br><span class="hljs-string">        - echo（bool，可选）：指示是否在生成的输出中包含提示标记的标志。默认为False。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        返回：</span><br><span class="hljs-string">        - List[CompletionPrediction]：补全预测的列表，每个预测包含生成的文本补全。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        注意：</span><br><span class="hljs-string">        - 此方法使用提供的提示生成文本补全，使用nucleus采样引入受控随机性。</span><br><span class="hljs-string">        - 如果logprobs为True，则为每个生成的标记计算标记对数概率。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> max_gen_len <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            max_gen_len = self.model.params.max_seq_len - <span class="hljs-number">1</span><br>        prompt_tokens = [self.tokenizer.encode(x, bos=<span class="hljs-literal">True</span>, eos=<span class="hljs-literal">False</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> prompts]<br>        generation_tokens, generation_logprobs = self.generate(<br>            prompt_tokens=prompt_tokens,<br>            max_gen_len=max_gen_len,<br>            temperature=temperature,<br>            top_p=top_p,<br>            logprobs=logprobs,<br>            echo=echo,<br>        )<br>        <span class="hljs-keyword">if</span> logprobs:<br>            <span class="hljs-keyword">return</span> [<br>                &#123;<br>                    <span class="hljs-string">&quot;generation&quot;</span>: self.tokenizer.decode(t),<br>                    <span class="hljs-string">&quot;tokens&quot;</span>: [self.tokenizer.decode([x]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> t],<br>                    <span class="hljs-string">&quot;logprobs&quot;</span>: logprobs_i,<br>                &#125;<br>                <span class="hljs-keyword">for</span> t, logprobs_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(generation_tokens, generation_logprobs)<br>            ]<br>        <span class="hljs-keyword">return</span> [&#123;<span class="hljs-string">&quot;generation&quot;</span>: self.tokenizer.decode(t)&#125; <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> generation_tokens]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completion</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        dialogs: <span class="hljs-type">List</span>[Dialog],</span><br><span class="hljs-params">        temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.6</span>,</span><br><span class="hljs-params">        top_p: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.9</span>,</span><br><span class="hljs-params">        max_gen_len: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        logprobs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[ChatPrediction]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        使用语言生成模型对一组对话进行生成助手回复。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        参数：</span><br><span class="hljs-string">        - dialogs（List[Dialog]）：对话列表，其中每个对话是一组消息。</span><br><span class="hljs-string">        - temperature（float，可选）：用于控制采样中的随机性的温度值。默认为0.6。</span><br><span class="hljs-string">        - top_p（float，可选）：用于nucleus采样的top-p概率阈值。默认为0.9。</span><br><span class="hljs-string">        - max_gen_len（Optional[int]，可选）：生成的回复序列的最大长度。</span><br><span class="hljs-string">            如果未提供，则设置为模型的最大序列长度减1。</span><br><span class="hljs-string">        - logprobs（bool，可选）：指示是否计算标记对数概率的标志。默认为False。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        返回：</span><br><span class="hljs-string">        - List[ChatPrediction]：聊天预测的列表，每个预测包含助手生成的回复。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        注意：</span><br><span class="hljs-string">        - 此方法为提供的对话生成助手回复。</span><br><span class="hljs-string">        - 它使用nucleus采样来引入文本生成中的受控随机性。</span><br><span class="hljs-string">        - 如果logprobs为True，则为每个生成的标记计算标记对数概率。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> max_gen_len <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            max_gen_len = self.model.params.max_seq_len - <span class="hljs-number">1</span><br><br>        prompt_tokens = [<br>            self.formatter.encode_dialog_prompt(dialog) <span class="hljs-keyword">for</span> dialog <span class="hljs-keyword">in</span> dialogs<br>        ]<br>        generation_tokens, generation_logprobs = self.generate(<br>            prompt_tokens=prompt_tokens,<br>            max_gen_len=max_gen_len,<br>            temperature=temperature,<br>            top_p=top_p,<br>            logprobs=logprobs,<br>        )<br>        <span class="hljs-keyword">if</span> logprobs:<br>            <span class="hljs-keyword">return</span> [<br>                &#123;<br>                    <span class="hljs-string">&quot;generation&quot;</span>: &#123;<br>                        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>,<br>                        <span class="hljs-string">&quot;content&quot;</span>: self.tokenizer.decode(t),<br>                    &#125;,<br>                    <span class="hljs-string">&quot;tokens&quot;</span>: [self.tokenizer.decode([x]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> t],<br>                    <span class="hljs-string">&quot;logprobs&quot;</span>: logprobs_i,<br>                &#125;<br>                <span class="hljs-keyword">for</span> t, logprobs_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(generation_tokens, generation_logprobs)<br>            ]<br>        <span class="hljs-keyword">return</span> [<br>            &#123;<br>                <span class="hljs-string">&quot;generation&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>,<br>                    <span class="hljs-string">&quot;content&quot;</span>: self.tokenizer.decode(t),<br>                &#125;,<br>            &#125;<br>            <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> generation_tokens<br>        ]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sample_top_p</span>(<span class="hljs-params">probs, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    对概率分布进行top-p（nucleus）采样。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    参数：</span><br><span class="hljs-string">    - probs（torch.Tensor）：概率分布张量。</span><br><span class="hljs-string">    - p（float）：top-p采样的概率阈值。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    返回：</span><br><span class="hljs-string">    - torch.Tensor：采样的标记索引。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    注意：</span><br><span class="hljs-string">    - Top-p采样选择累积概率质量超过阈值p的最小标记集。根据所选的标记重新归一化分布。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    probs_sort, probs_idx = torch.sort(probs, dim=-<span class="hljs-number">1</span>, descending=<span class="hljs-literal">True</span>)<br>    probs_sum = torch.cumsum(probs_sort, dim=-<span class="hljs-number">1</span>)<br>    mask = probs_sum - probs_sort &gt; p<br>    probs_sort[mask] = <span class="hljs-number">0.0</span><br>    probs_sort.div_(probs_sort.<span class="hljs-built_in">sum</span>(dim=-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>))<br>    next_token = torch.multinomial(probs_sort, num_samples=<span class="hljs-number">1</span>)<br>    next_token = torch.gather(probs_idx, -<span class="hljs-number">1</span>, next_token)<br>    <span class="hljs-keyword">return</span> next_token<br></code></pre></td></tr></table></figure><h2 id="model-py"><a href="#model-py" class="headerlink" title="model.py"></a>model.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>, <span class="hljs-type">Tuple</span><br><br><span class="hljs-keyword">import</span> fairscale.nn.model_parallel.initialize <span class="hljs-keyword">as</span> fs_init<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> fairscale.nn.model_parallel.layers <span class="hljs-keyword">import</span> (<br>    ColumnParallelLinear,<br>    RowParallelLinear,<br>    VocabParallelEmbedding,<br>)<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ModelArgs</span>:<br>    dim: <span class="hljs-built_in">int</span> = <span class="hljs-number">4096</span><br>    n_layers: <span class="hljs-built_in">int</span> = <span class="hljs-number">32</span><br>    n_heads: <span class="hljs-built_in">int</span> = <span class="hljs-number">32</span><br>    n_kv_heads: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span><br>    vocab_size: <span class="hljs-built_in">int</span> = -<span class="hljs-number">1</span><br>    multiple_of: <span class="hljs-built_in">int</span> = <span class="hljs-number">256</span>  <span class="hljs-comment"># make SwiGLU hidden layer size multiple of large power of 2</span><br>    ffn_dim_multiplier: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">float</span>] = <span class="hljs-literal">None</span><br>    norm_eps: <span class="hljs-built_in">float</span> = <span class="hljs-number">1e-5</span><br>    rope_theta: <span class="hljs-built_in">float</span> = <span class="hljs-number">500000</span><br><br>    max_batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">32</span><br>    max_seq_len: <span class="hljs-built_in">int</span> = <span class="hljs-number">2048</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RMSNorm</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim: <span class="hljs-built_in">int</span>, eps: <span class="hljs-built_in">float</span> = <span class="hljs-number">1e-6</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.eps = eps<br>        self.weight = nn.Parameter(torch.ones(dim))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_norm</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> x * torch.rsqrt(x.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).mean(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) + self.eps)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        output = self._norm(x.<span class="hljs-built_in">float</span>()).type_as(x)<br>        <span class="hljs-keyword">return</span> output * self.weight<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">precompute_freqs_cis</span>(<span class="hljs-params">dim: <span class="hljs-built_in">int</span>, end: <span class="hljs-built_in">int</span>, theta: <span class="hljs-built_in">float</span> = <span class="hljs-number">10000.0</span></span>):<br>    freqs = <span class="hljs-number">1.0</span> / (theta ** (torch.arange(<span class="hljs-number">0</span>, dim, <span class="hljs-number">2</span>)[: (dim // <span class="hljs-number">2</span>)].<span class="hljs-built_in">float</span>() / dim))<br>    t = torch.arange(end, device=freqs.device, dtype=torch.float32)<br>    freqs = torch.outer(t, freqs)<br>    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  <span class="hljs-comment"># complex64</span><br>    <span class="hljs-keyword">return</span> freqs_cis<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reshape_for_broadcast</span>(<span class="hljs-params">freqs_cis: torch.Tensor, x: torch.Tensor</span>):<br>    ndim = x.ndim<br>    <span class="hljs-keyword">assert</span> <span class="hljs-number">0</span> &lt;= <span class="hljs-number">1</span> &lt; ndim<br>    <span class="hljs-keyword">assert</span> freqs_cis.shape == (x.shape[<span class="hljs-number">1</span>], x.shape[-<span class="hljs-number">1</span>])<br>    shape = [d <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> i == ndim - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i, d <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(x.shape)]<br>    <span class="hljs-keyword">return</span> freqs_cis.view(*shape)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rotary_emb</span>(<span class="hljs-params"></span><br><span class="hljs-params">    xq: torch.Tensor,</span><br><span class="hljs-params">    xk: torch.Tensor,</span><br><span class="hljs-params">    freqs_cis: torch.Tensor,</span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Tuple</span>[torch.Tensor, torch.Tensor]:<br>    xq_ = torch.view_as_complex(xq.<span class="hljs-built_in">float</span>().reshape(*xq.shape[:-<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>    xk_ = torch.view_as_complex(xk.<span class="hljs-built_in">float</span>().reshape(*xk.shape[:-<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)<br>    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(<span class="hljs-number">3</span>)<br>    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(<span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">return</span> xq_out.type_as(xq), xk_out.type_as(xk)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">repeat_kv</span>(<span class="hljs-params">x: torch.Tensor, n_rep: <span class="hljs-built_in">int</span></span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;torch.repeat_interleave(x, dim=2, repeats=n_rep)&quot;&quot;&quot;</span><br>    bs, slen, n_kv_heads, head_dim = x.shape<br>    <span class="hljs-keyword">if</span> n_rep == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> x<br>    <span class="hljs-keyword">return</span> (<br>        x[:, :, :, <span class="hljs-literal">None</span>, :]<br>        .expand(bs, slen, n_kv_heads, n_rep, head_dim)<br>        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)<br>    )<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, args: ModelArgs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.n_kv_heads = args.n_heads <span class="hljs-keyword">if</span> args.n_kv_heads <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> args.n_kv_heads<br>        model_parallel_size = fs_init.get_model_parallel_world_size()<br>        self.n_local_heads = args.n_heads // model_parallel_size<br>        self.n_local_kv_heads = self.n_kv_heads // model_parallel_size<br>        self.n_rep = self.n_local_heads // self.n_local_kv_heads<br>        self.head_dim = args.dim // args.n_heads<br><br>        self.wq = ColumnParallelLinear(<br>            args.dim,<br>            args.n_heads * self.head_dim,<br>            bias=<span class="hljs-literal">False</span>,<br>            gather_output=<span class="hljs-literal">False</span>,<br>            init_method=<span class="hljs-keyword">lambda</span> x: x,<br>        )<br>        self.wk = ColumnParallelLinear(<br>            args.dim,<br>            self.n_kv_heads * self.head_dim,<br>            bias=<span class="hljs-literal">False</span>,<br>            gather_output=<span class="hljs-literal">False</span>,<br>            init_method=<span class="hljs-keyword">lambda</span> x: x,<br>        )<br>        self.wv = ColumnParallelLinear(<br>            args.dim,<br>            self.n_kv_heads * self.head_dim,<br>            bias=<span class="hljs-literal">False</span>,<br>            gather_output=<span class="hljs-literal">False</span>,<br>            init_method=<span class="hljs-keyword">lambda</span> x: x,<br>        )<br>        self.wo = RowParallelLinear(<br>            args.n_heads * self.head_dim,<br>            args.dim,<br>            bias=<span class="hljs-literal">False</span>,<br>            input_is_parallel=<span class="hljs-literal">True</span>,<br>            init_method=<span class="hljs-keyword">lambda</span> x: x,<br>        )<br><br>        self.cache_k = torch.zeros(<br>            (<br>                args.max_batch_size,<br>                args.max_seq_len,<br>                self.n_local_kv_heads,<br>                self.head_dim,<br>            )<br>        ).cuda()<br>        self.cache_v = torch.zeros(<br>            (<br>                args.max_batch_size,<br>                args.max_seq_len,<br>                self.n_local_kv_heads,<br>                self.head_dim,<br>            )<br>        ).cuda()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        x: torch.Tensor,</span><br><span class="hljs-params">        start_pos: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        freqs_cis: torch.Tensor,</span><br><span class="hljs-params">        mask: <span class="hljs-type">Optional</span>[torch.Tensor],</span><br><span class="hljs-params">    </span>):<br>        bsz, seqlen, _ = x.shape<br>        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)<br><br>        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)<br>        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)<br>        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)<br><br>        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)<br><br>        self.cache_k = self.cache_k.to(xq)<br>        self.cache_v = self.cache_v.to(xq)<br><br>        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk<br>        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv<br><br>        keys = self.cache_k[:bsz, : start_pos + seqlen]<br>        values = self.cache_v[:bsz, : start_pos + seqlen]<br><br>        <span class="hljs-comment"># repeat k/v heads if n_kv_heads &lt; n_heads</span><br>        keys = repeat_kv(<br>            keys, self.n_rep<br>        )  <span class="hljs-comment"># (bs, cache_len + seqlen, n_local_heads, head_dim)</span><br>        values = repeat_kv(<br>            values, self.n_rep<br>        )  <span class="hljs-comment"># (bs, cache_len + seqlen, n_local_heads, head_dim)</span><br><br>        xq = xq.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># (bs, n_local_heads, seqlen, head_dim)</span><br>        keys = keys.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># (bs, n_local_heads, cache_len + seqlen, head_dim)</span><br>        values = values.transpose(<br>            <span class="hljs-number">1</span>, <span class="hljs-number">2</span><br>        )  <span class="hljs-comment"># (bs, n_local_heads, cache_len + seqlen, head_dim)</span><br>        scores = torch.matmul(xq, keys.transpose(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)) / math.sqrt(self.head_dim)<br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            scores = scores + mask  <span class="hljs-comment"># (bs, n_local_heads, seqlen, cache_len + seqlen)</span><br>        scores = F.softmax(scores.<span class="hljs-built_in">float</span>(), dim=-<span class="hljs-number">1</span>).type_as(xq)<br>        output = torch.matmul(scores, values)  <span class="hljs-comment"># (bs, n_local_heads, seqlen, head_dim)</span><br>        output = output.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(bsz, seqlen, -<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> self.wo(output)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeedForward</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        dim: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        hidden_dim: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        multiple_of: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        ffn_dim_multiplier: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">float</span>],</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        hidden_dim = <span class="hljs-built_in">int</span>(<span class="hljs-number">2</span> * hidden_dim / <span class="hljs-number">3</span>)<br>        <span class="hljs-comment"># custom dim factor multiplier</span><br>        <span class="hljs-keyword">if</span> ffn_dim_multiplier <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            hidden_dim = <span class="hljs-built_in">int</span>(ffn_dim_multiplier * hidden_dim)<br>        hidden_dim = multiple_of * ((hidden_dim + multiple_of - <span class="hljs-number">1</span>) // multiple_of)<br><br>        self.w1 = ColumnParallelLinear(<br>            dim, hidden_dim, bias=<span class="hljs-literal">False</span>, gather_output=<span class="hljs-literal">False</span>, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )<br>        self.w2 = RowParallelLinear(<br>            hidden_dim, dim, bias=<span class="hljs-literal">False</span>, input_is_parallel=<span class="hljs-literal">True</span>, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )<br>        self.w3 = ColumnParallelLinear(<br>            dim, hidden_dim, bias=<span class="hljs-literal">False</span>, gather_output=<span class="hljs-literal">False</span>, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.w2(F.silu(self.w1(x)) * self.w3(x))<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TransformerBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, layer_id: <span class="hljs-built_in">int</span>, args: ModelArgs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.n_heads = args.n_heads<br>        self.dim = args.dim<br>        self.head_dim = args.dim // args.n_heads<br>        self.attention = Attention(args)<br>        self.feed_forward = FeedForward(<br>            dim=args.dim,<br>            hidden_dim=<span class="hljs-number">4</span> * args.dim,<br>            multiple_of=args.multiple_of,<br>            ffn_dim_multiplier=args.ffn_dim_multiplier,<br>        )<br>        self.layer_id = layer_id<br>        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)<br>        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        x: torch.Tensor,</span><br><span class="hljs-params">        start_pos: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        freqs_cis: torch.Tensor,</span><br><span class="hljs-params">        mask: <span class="hljs-type">Optional</span>[torch.Tensor],</span><br><span class="hljs-params">    </span>):<br>        h = x + self.attention(self.attention_norm(x), start_pos, freqs_cis, mask)<br>        out = h + self.feed_forward(self.ffn_norm(h))<br>        <span class="hljs-keyword">return</span> out<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Transformer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, params: ModelArgs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.params = params<br>        self.vocab_size = params.vocab_size<br>        self.n_layers = params.n_layers<br><br>        self.tok_embeddings = VocabParallelEmbedding(<br>            params.vocab_size, params.dim, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )<br><br>        self.layers = torch.nn.ModuleList()<br>        <span class="hljs-keyword">for</span> layer_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(params.n_layers):<br>            self.layers.append(TransformerBlock(layer_id, params))<br><br>        self.norm = RMSNorm(params.dim, eps=params.norm_eps)<br>        self.output = ColumnParallelLinear(<br>            params.dim, params.vocab_size, bias=<span class="hljs-literal">False</span>, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )<br><br>        self.freqs_cis = precompute_freqs_cis(<br>            params.dim // params.n_heads,<br>            params.max_seq_len * <span class="hljs-number">2</span>,<br>            params.rope_theta,<br>        )<br><br><span class="hljs-meta">    @torch.inference_mode()</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, tokens: torch.Tensor, start_pos: <span class="hljs-built_in">int</span></span>):<br>        _bsz, seqlen = tokens.shape<br>        h = self.tok_embeddings(tokens)<br>        self.freqs_cis = self.freqs_cis.to(h.device)<br>        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]<br><br>        mask = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> seqlen &gt; <span class="hljs-number">1</span>:<br>            mask = torch.full((seqlen, seqlen), <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;-inf&quot;</span>), device=tokens.device)<br><br>            mask = torch.triu(mask, diagonal=<span class="hljs-number">1</span>)<br><br>            <span class="hljs-comment"># When performing key-value caching, we compute the attention scores</span><br>            <span class="hljs-comment"># only for the new sequence. Thus, the matrix of scores is of size</span><br>            <span class="hljs-comment"># (seqlen, cache_len + seqlen), and the only masked entries are (i, j) for</span><br>            <span class="hljs-comment"># j &gt; cache_len + i, since row i corresponds to token cache_len + i.</span><br>            mask = torch.hstack(<br>                [torch.zeros((seqlen, start_pos), device=tokens.device), mask]<br>            ).type_as(h)<br><br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>            h = layer(h, start_pos, freqs_cis, mask)<br>        h = self.norm(h)<br>        output = self.output(h).<span class="hljs-built_in">float</span>()<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h2 id="example-chat-completation-py"><a href="#example-chat-completation-py" class="headerlink" title="example_chat_completation.py"></a>example_chat_completation.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Optional</span><br><br><span class="hljs-keyword">import</span> fire<br><br><span class="hljs-keyword">from</span> llama <span class="hljs-keyword">import</span> Dialog, Llama<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params"></span><br><span class="hljs-params">    ckpt_dir: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">    tokenizer_path: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">    temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.6</span>,</span><br><span class="hljs-params">    top_p: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.9</span>,</span><br><span class="hljs-params">    max_seq_len: <span class="hljs-built_in">int</span> = <span class="hljs-number">512</span>,</span><br><span class="hljs-params">    max_batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">4</span>,</span><br><span class="hljs-params">    max_gen_len: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params"></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Examples to run with the models finetuned for chat. Prompts correspond of chat</span><br><span class="hljs-string">    turns between the user and assistant with the final one always being the user.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    An optional system prompt at the beginning to control how the model should respond</span><br><span class="hljs-string">    is also supported.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    The context window of llama3 models is 8192 tokens, so `max_seq_len` needs to be &lt;= 8192.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    `max_gen_len` is optional because finetuned models are able to stop generations naturally.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    generator = Llama.build(<br>        ckpt_dir=ckpt_dir,<br>        tokenizer_path=tokenizer_path,<br>        max_seq_len=max_seq_len,<br>        max_batch_size=max_batch_size,<br>    )<br><br>    dialogs: <span class="hljs-type">List</span>[Dialog] = [<br>        [&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;what is the recipe of mayonnaise?&quot;</span>&#125;],<br>        [<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;I am going to Paris, what should I see?&quot;</span>&#125;,<br>            &#123;<br>                <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>,<br>                <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;&quot;&quot;\</span><br><span class="hljs-string">Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:</span><br><span class="hljs-string"></span><br><span class="hljs-string">1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.</span><br><span class="hljs-string">2. The Louvre Museum: The Louvre is one of the world&#x27;s largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.</span><br><span class="hljs-string">3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.</span><br><span class="hljs-string"></span><br><span class="hljs-string">These are just a few of the many attractions that Paris has to offer. With so much to see and do, it&#x27;s no wonder that Paris is one of the most popular tourist destinations in the world.&quot;&quot;&quot;</span>,<br>            &#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;What is so great about #1?&quot;</span>&#125;,<br>        ],<br>        [<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Always answer with Haiku&quot;</span>&#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;I am going to Paris, what should I see?&quot;</span>&#125;,<br>        ],<br>        [<br>            &#123;<br>                <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,<br>                <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Always answer with emojis&quot;</span>,<br>            &#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;How to go from Beijing to NY?&quot;</span>&#125;,<br>        ],<br>    ]<br>    results = generator.chat_completion(<br>        dialogs,<br>        max_gen_len=max_gen_len,<br>        temperature=temperature,<br>        top_p=top_p,<br>    )<br><br>    <span class="hljs-keyword">for</span> dialog, result <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(dialogs, results):<br>        <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> dialog:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;msg[<span class="hljs-string">&#x27;role&#x27;</span>].capitalize()&#125;</span>: <span class="hljs-subst">&#123;msg[<span class="hljs-string">&#x27;content&#x27;</span>]&#125;</span>\n&quot;</span>)<br>        <span class="hljs-built_in">print</span>(<br>            <span class="hljs-string">f&quot;&gt; <span class="hljs-subst">&#123;result[<span class="hljs-string">&#x27;generation&#x27;</span>][<span class="hljs-string">&#x27;role&#x27;</span>].capitalize()&#125;</span>: <span class="hljs-subst">&#123;result[<span class="hljs-string">&#x27;generation&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>]&#125;</span>&quot;</span><br>        )<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n==================================\n&quot;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    fire.Fire(main)<br></code></pre></td></tr></table></figure><h2 id="example-text-completion-py"><a href="#example-text-completion-py" class="headerlink" title="example_text_completion.py"></a>example_text_completion.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><br><span class="hljs-keyword">import</span> fire<br><br><span class="hljs-keyword">from</span> llama <span class="hljs-keyword">import</span> Llama<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params"></span><br><span class="hljs-params">    ckpt_dir: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">    tokenizer_path: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">    temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.6</span>,</span><br><span class="hljs-params">    top_p: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.9</span>,</span><br><span class="hljs-params">    max_seq_len: <span class="hljs-built_in">int</span> = <span class="hljs-number">128</span>,</span><br><span class="hljs-params">    max_gen_len: <span class="hljs-built_in">int</span> = <span class="hljs-number">64</span>,</span><br><span class="hljs-params">    max_batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">4</span>,</span><br><span class="hljs-params"></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Examples to run with the pre-trained models (no fine-tuning). Prompts are</span><br><span class="hljs-string">    usually in the form of an incomplete text prefix that the model can then try to complete.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    The context window of llama3 models is 8192 tokens, so `max_seq_len` needs to be &lt;= 8192.</span><br><span class="hljs-string">    `max_gen_len` is needed because pre-trained models usually do not stop completions naturally.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    generator = Llama.build(<br>        ckpt_dir=ckpt_dir,<br>        tokenizer_path=tokenizer_path,<br>        max_seq_len=max_seq_len,<br>        max_batch_size=max_batch_size,<br>    )<br><br>    prompts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>] = [<br>        <span class="hljs-comment"># For these prompts, the expected answer is the natural continuation of the prompt</span><br>        <span class="hljs-string">&quot;I believe the meaning of life is&quot;</span>,<br>        <span class="hljs-string">&quot;Simply put, the theory of relativity states that &quot;</span>,<br>        <span class="hljs-string">&quot;&quot;&quot;A brief message congratulating the team on the launch:</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Hi everyone,</span><br><span class="hljs-string"></span><br><span class="hljs-string">        I just &quot;&quot;&quot;</span>,<br>        <span class="hljs-comment"># Few shot prompt (providing a few examples before asking model to complete more);</span><br>        <span class="hljs-string">&quot;&quot;&quot;Translate English to French:</span><br><span class="hljs-string"></span><br><span class="hljs-string">        sea otter =&gt; loutre de mer</span><br><span class="hljs-string">        peppermint =&gt; menthe poivrée</span><br><span class="hljs-string">        plush girafe =&gt; girafe peluche</span><br><span class="hljs-string">        cheese =&gt;&quot;&quot;&quot;</span>,<br>    ]<br>    results = generator.text_completion(<br>        prompts,<br>        max_gen_len=max_gen_len,<br>        temperature=temperature,<br>        top_p=top_p,<br>    )<br>    <span class="hljs-keyword">for</span> prompt, result <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prompts, results):<br>        <span class="hljs-built_in">print</span>(prompt)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;&gt; <span class="hljs-subst">&#123;result[<span class="hljs-string">&#x27;generation&#x27;</span>]&#125;</span>&quot;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n==================================\n&quot;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    fire.Fire(main)<br></code></pre></td></tr></table></figure><p>2024&#x2F;4&#x2F;23 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>代码实战</tag>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker Compose编写指南</title>
    <link href="/2024/04/20/Docker-Compose%E7%BC%96%E5%86%99%E6%8C%87%E5%8D%97/"/>
    <url>/2024/04/20/Docker-Compose%E7%BC%96%E5%86%99%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p>相关链接：<a href="https://www.runoob.com/docker/docker-compose.html">Docker Compose | 菜鸟教程</a></p><p>前面学习了一些Docker容器的构建和应用，实际项目中通常不止用到一个Docker，往往会有多个Docker组建网络，这个时候就需要用到Docker Compose了。</p><blockquote><p>Docker Compose用于定义和运行多容器。通过<code>docker-compose up</code>能够启动在<code>docker-compose.yml</code>中定义的整个应用程序。</p></blockquote><h1 id="Compose的三个步骤"><a href="#Compose的三个步骤" class="headerlink" title="Compose的三个步骤"></a>Compose的三个步骤</h1><ol><li>使用Dockerfile定义容器环境。</li><li>使用<code>docker-compose.yaml</code>定义构成应用的服务。</li><li>使用<code>docker-compose up</code>来启动服务。</li></ol><h1 id="示例配置"><a href="#示例配置" class="headerlink" title="示例配置"></a>示例配置</h1><p>以下提供了一个<code>docker-compose.yml</code>的示例配置文件：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># 使用Docker Compose文件格式版本3</span><br><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3&quot;</span>  <br><br><span class="hljs-attr">services:</span><br><br>  <span class="hljs-attr">redis:</span><br>    <span class="hljs-comment"># 使用基于Alpine Linux的Redis镜像，体积较小</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">redis:alpine</span>  <br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-comment"># 将容器的6379端口暴露给主机</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;6379&quot;</span>  <br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-comment"># 连接到前端网络</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">frontend</span>  <br>  <span class="hljs-attr">db:</span><br>    <span class="hljs-comment"># 使用PostgreSQL 9.4版本的官方镜像</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">postgres:9.4</span>  <br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-comment"># 持久化PostgreSQL数据</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">db-data:/var/lib/postgresql/data</span>  <br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-comment"># 连接到后端网络</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">backend</span>  <br><br>  <span class="hljs-attr">vote:</span><br>    <span class="hljs-comment"># 添加构建配置</span><br>    <span class="hljs-attr">build:</span>  <br>      <span class="hljs-comment"># 设置Docker构建上下文目录为当前目录下的vote子目录</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./vote</span>  <br>      <span class="hljs-comment"># 指定Dockerfile文件路径</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile</span>  <br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-comment"># 映射容器的80端口到主机的5000端口</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-number">5000</span><span class="hljs-string">:80</span>  <br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-comment"># 连接到前端网络</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">frontend</span>  <br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-comment"># 依赖于redis服务</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">redis</span>  <br><br>  <span class="hljs-attr">result:</span><br>    <span class="hljs-comment"># 添加构建配置</span><br>    <span class="hljs-attr">build:</span>  <br>      <span class="hljs-comment"># 设置Docker构建上下文目录为当前目录下的result子目录</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./result</span>  <br>      <span class="hljs-comment"># 指定Dockerfile文件路径</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile</span>  <br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-comment"># 映射容器的80端口到主机的5001端口</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-number">5001</span><span class="hljs-string">:80</span>  <br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-comment"># 连接到后端网络</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">backend</span>  <br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-comment"># 依赖于数据库服务</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">db</span>  <br><br>  <span class="hljs-attr">worker:</span><br>    <span class="hljs-comment"># 工作服务的镜像，用于处理后台任务</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">dockersamples/examplevotingapp_worker</span>  <br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-comment"># 连接到前端网络</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">frontend</span>  <br>      <span class="hljs-comment"># 也连接到后端网络</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">backend</span>  <br><br>  <span class="hljs-attr">visualizer:</span><br>    <span class="hljs-comment"># 使用稳定版本的可视化工具镜像</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">dockersamples/visualizer:stable</span>  <br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-comment"># 映射端口8080到主机</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;8080:8080&quot;</span>  <br>    <span class="hljs-comment"># 设置容器停止前的宽限期为1分30秒</span><br>    <span class="hljs-attr">stop_grace_period:</span> <span class="hljs-string">1m30s</span>  <br>    <span class="hljs-comment"># 挂载Docker套接字文件</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;/var/run/docker.sock:/var/run/docker.sock&quot;</span>  <br><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-comment"># 声明前端网络</span><br>  <span class="hljs-attr">frontend:</span>  <br>  <span class="hljs-comment"># 声明后端网络</span><br>  <span class="hljs-attr">backend:</span>  <br><br><span class="hljs-attr">volumes:</span><br>  <span class="hljs-comment"># 声明持久化卷，用于存储数据库数据</span><br>  <span class="hljs-attr">db-data:</span>  <br></code></pre></td></tr></table></figure><p>上面这个示例展示了compose的基础使用方法。我们拉取了Docker Hub的官方镜像作为我们服务中的基础镜像，并在<code>images</code>选项中定义镜像的版本。除此之外，<code>enviroment</code>，<code>ports</code>都比较好理解，也就是在这个服务中对应容器对外拿的环境变量，以及端口。</p><h1 id="利用自己构建的镜像定义compose"><a href="#利用自己构建的镜像定义compose" class="headerlink" title="利用自己构建的镜像定义compose"></a>利用自己构建的镜像定义compose</h1><p>上面的例子中，我们的服务使用的是官方镜像，这种情况下我们无需写Dockerfile。而如果我们需要自己定义镜像，应该怎么处理呢？以下是一个示例：</p><h2 id="定义应用"><a href="#定义应用" class="headerlink" title="定义应用"></a>定义应用</h2><p>首先，我们定义一个应用，它基于Flask，使用Redis监听等待时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">import</span> redis<br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br>cache = redis.Redis(host=<span class="hljs-string">&#x27;redis&#x27;</span>, port=<span class="hljs-number">6379</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_hit_count</span>():<br>    retries = <span class="hljs-number">5</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-keyword">return</span> cache.incr(<span class="hljs-string">&#x27;hits&#x27;</span>)<br>        <span class="hljs-keyword">except</span> redis.exceptions.ConnectionError <span class="hljs-keyword">as</span> exc:<br>            <span class="hljs-keyword">if</span> retries == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">raise</span> exc<br>            retries -= <span class="hljs-number">1</span><br>            time.sleep(<span class="hljs-number">0.5</span>)<br><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>    count = get_hit_count()<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Hello World! I have been seen &#123;&#125; times.\n&#x27;</span>.<span class="hljs-built_in">format</span>(count)<br></code></pre></td></tr></table></figure><p>随后我们需要写一个<code>requirements.txt</code>。这里只要两个依赖项：flask和redis。</p><h2 id="编写Dockerfile"><a href="#编写Dockerfile" class="headerlink" title="编写Dockerfile"></a>编写Dockerfile</h2><p>下一步是写Dockerfile，我们以python 3.7作为基础镜像。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 基础镜像</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.7</span>-alpine<br><br><span class="hljs-comment"># 工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /code</span><br><br><span class="hljs-comment"># 环境变量 设置app.py作为Flask启动默认脚本</span><br><span class="hljs-keyword">ENV</span> FLASK_APP app.py<br><br><span class="hljs-keyword">ENV</span> FLASK_RUN_HOST <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span><br><br><span class="hljs-comment"># 复制安装依赖项</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> requirements.txt requirements.txt</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install -r requirements.txt</span><br><br><span class="hljs-comment"># 将当前目录的文件复制到容器的工作目录</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> . .</span><br><br><span class="hljs-comment"># 启动</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;flask&quot;</span>, <span class="hljs-string">&quot;run&quot;</span>]</span><br></code></pre></td></tr></table></figure><h2 id="编写Docker-Compose"><a href="#编写Docker-Compose" class="headerlink" title="编写Docker Compose"></a>编写Docker Compose</h2><p>接下来定义<code>docker-compose.yml</code>。我们在目录路径下新建文件，内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3&#x27;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-comment"># web服务通过当前路径下的Dockerfile自动构建</span><br>  <span class="hljs-attr">web:</span><br>    <span class="hljs-attr">build:</span> <span class="hljs-string">.</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-comment"># 宿主机端口：容器端口</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5000:5000&quot;</span><br>  <span class="hljs-attr">redis:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">&quot;redis:alpine&quot;</span><br></code></pre></td></tr></table></figure><p><img src="/images/docker_compose.png"></p><p>接下来就是<code>docker-compose up</code>。这将会构建web镜像并拉取redis镜像（也可以先<code>docker-compose build</code>再<code>up</code>）。此时访问<code>localhost:5000</code>即可观察到前面写的页面服务。</p><h2 id="设置挂载路径"><a href="#设置挂载路径" class="headerlink" title="设置挂载路径"></a>设置挂载路径</h2><p>对应flask服务，能够实时修改代码并更新，这时可以把宿主机的代码挂载到容器内，这样就可以随时修改应用程序，而无需重新构建镜像。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3&#x27;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">web:</span><br>    <span class="hljs-attr">build:</span> <span class="hljs-string">.</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5000:5000&quot;</span><br>    <span class="hljs-comment"># 添加了挂载路径，将当前目录挂载至容器目录</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">.:/code</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-comment"># Flask环境变量</span><br>      <span class="hljs-attr">FLASK_ENV:</span> <span class="hljs-string">development</span><br>  <span class="hljs-attr">redis:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">&quot;redis:alpine&quot;</span><br></code></pre></td></tr></table></figure><h1 id="Docker-Compose命令行"><a href="#Docker-Compose命令行" class="headerlink" title="Docker Compose命令行"></a>Docker Compose命令行</h1><p>Docker Compose的命令行参数有以下几个常用参数：</p><h2 id="docker-compose"><a href="#docker-compose" class="headerlink" title="docker compose"></a>docker compose</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker-compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...]<br><br>-f --file FILE指定Compose模板文件，默认为docker-compose.yml<br>-p --project-name NAME 指定项目名称，默认使用当前所在目录为项目名<br>--verbose  输出更多调试信息<br>-v，-version 打印版本并退出<br>--log-level LEVEL 定义日志等级(DEBUG, INFO, WARNING, ERROR, CRITICAL)<br></code></pre></td></tr></table></figure><h2 id="docker-compose-up"><a href="#docker-compose-up" class="headerlink" title="docker compose up"></a>docker compose up</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker-compose up [options] [--scale SERVICE=NUM...] [SERVICE...]<br><br>-d 在后台运行服务容器<br>-no-color 不是有颜色来区分不同的服务的控制输出<br>-no-deps 不启动服务所链接的容器<br>--force-recreate 强制重新创建容器，不能与-no-recreate同时使用<br>–no-recreate 如果容器已经存在，则不重新创建，不能与–force-recreate同时使用<br>–no-build 不自动构建缺失的服务镜像<br>–build 在启动容器前构建服务镜像<br>–abort-on-container-exit 停止所有容器，如果任何一个容器被停止，不能与-d同时使用<br>-t, –<span class="hljs-built_in">timeout</span> TIMEOUT 停止容器时候的超时（默认为10秒）<br>–remove-orphans 删除服务中没有在compose文件中定义的容器<br></code></pre></td></tr></table></figure><h2 id="docker-compose-build"><a href="#docker-compose-build" class="headerlink" title="docker compose build"></a>docker compose build</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker-compose build [options] [--build-arg key=val...] [SERVICE...]<br>构建（重新构建）项目中的服务容器。<br><br>–compress 通过gzip压缩构建上下环境<br>–force-rm 删除构建过程中的临时容器<br>–no-cache 构建镜像过程中不使用缓存<br>–pull 始终尝试通过拉取操作来获取更新版本的镜像<br>-m, –memory MEM为构建的容器设置内存大小<br>–build-arg key=val为服务设置build-time变量<br>服务容器一旦构建后，将会带上一个标记名。可以随时在项目目录下运行docker-compose build来重新构建服务<br></code></pre></td></tr></table></figure><p>以上是几个常用的命令行指令，还有<code>down</code>，<code>start</code>等指令比较易懂，就不放这了。</p><h1 id="Service配置项"><a href="#Service配置项" class="headerlink" title="Service配置项"></a>Service配置项</h1><p><code>docker-compose.yml</code>的大部分配置都聚焦在<code>service</code>这一块，有很多参数需要了解：</p><h2 id="build"><a href="#build" class="headerlink" title="build"></a>build</h2><p>指定 <code>Dockerfile</code> 所在文件夹的路径,<code>Compose</code> 将会利用它自动构建镜像。如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3.8&#x27;</span><br><span class="hljs-attr">services:</span><br><br>  <span class="hljs-attr">webapp:</span><br>    <span class="hljs-attr">build:</span> <span class="hljs-string">./dir</span><br></code></pre></td></tr></table></figure><h3 id="context"><a href="#context" class="headerlink" title="context"></a>context</h3><p>可以使用 <code>context</code> 指定文件夹路径（可以是 Dockerfile 的目录路径，也可以是 git 存储库的 url），使用 <code>dockerfile</code> 指定 <code>Dockerfile</code> 文件名，使用 <code>arg</code> 为 <code>Dockerfile</code>中的变量赋值。如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3.8&#x27;</span><br><span class="hljs-attr">services:</span><br><br>  <span class="hljs-attr">webapp:</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./dir</span><br>      <span class="hljs-attr">dockerfile:</span> <span class="hljs-string">Dockerfile-alternate</span><br>      <span class="hljs-attr">args:</span><br>        <span class="hljs-attr">buildno:</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>如果在 <code>build</code> 同时指定了 <code>image</code>，那么 Compose 会使用在 <code>image</code> 中指定的名字和标签来命名最终构建的镜像。如:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">build:</span> <span class="hljs-string">./dir</span><br><span class="hljs-attr">image:</span> <span class="hljs-string">webapp:tag</span><br></code></pre></td></tr></table></figure><p>这将从 <code>./dir</code>构建，生成名为 <code>webapp</code>，标签为：<code>tag</code> 的镜像。</p><p><code>build</code>参数下包括了以下参数：</p><ul><li>context：上下文路径。</li><li>dockerfile：指定构建镜像的 Dockerfile 文件名。</li><li>args：添加构建参数，这是只能在构建过程中访问的环境变量。</li><li>labels：设置构建镜像的标签。</li><li>target：多层构建，可以指定构建哪一层。</li></ul><h2 id="image"><a href="#image" class="headerlink" title="image"></a>image</h2><p>指定要从哪个镜像启动容器，以下是一个示例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">webserver:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;80:80&quot;</span><br></code></pre></td></tr></table></figure><p>假如已经在本地有了一个自定义的镜像，也可以进行类似的操作：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">myservice:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">myusername/myapp:1.0</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;8080:80&quot;</span><br></code></pre></td></tr></table></figure><blockquote><p>当需要使用<code>docker compose build</code>时，<code>docker compose.yml</code>文件中需要包含的是<code>build</code>参数，这需要和<code>images</code>区分开。</p></blockquote><h2 id="volumes"><a href="#volumes" class="headerlink" title="volumes"></a>volumes</h2><p>设置挂载路径，书写格式是<code>宿主机文件路径：容器文件路径</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">db:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">postgres</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">db-data:/var/lib/postgresql/data</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-attr">POSTGRES_PASSWORD:</span> <span class="hljs-string">mysecretpassword</span><br><br><span class="hljs-attr">volumes:</span><br>  <span class="hljs-attr">db-data:</span><br></code></pre></td></tr></table></figure><h2 id="restart"><a href="#restart" class="headerlink" title="restart"></a>restart</h2><p><code>restart</code>是容器的重启策略，包括了：</p><ul><li><code>no</code>：默认值，容器不会在退出时自动重启。</li><li><code>always</code>：无论容器因何种原因停止，都将尝试重启容器。</li><li><code>on-failure</code>：仅当容器非正常退出时（退出状态非零）重启容器。</li><li><code>unless-stopped</code>：除非容器被人为停止（例如通过 Docker 命令），否则在退出时总是重启。</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">web:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;80:80&quot;</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br></code></pre></td></tr></table></figure><h2 id="command"><a href="#command" class="headerlink" title="command"></a>command</h2><p>覆盖容器启动的默认命令：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">command:</span> [<span class="hljs-string">&quot;bundle&quot;</span>, <span class="hljs-string">&quot;exec&quot;</span>, <span class="hljs-string">&quot;thin&quot;</span>, <span class="hljs-string">&quot;-p&quot;</span>, <span class="hljs-string">&quot;3000&quot;</span>]<br></code></pre></td></tr></table></figure><p>这样就不需要重写Dockerfile并构建新镜像。</p><h2 id="container-name"><a href="#container-name" class="headerlink" title="container_name"></a>container_name</h2><p>指定容器名称。默认将会使用 <code>项目名称_服务名称_序号</code> 这样的格式，设置此项后可以自定义容器名：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">webapp:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">node:14</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">webapp_dev</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;3000:3000&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">.:/app</span><br>    <span class="hljs-attr">working_dir:</span> <span class="hljs-string">/app</span><br>    <span class="hljs-attr">command:</span> <span class="hljs-string">npm</span> <span class="hljs-string">start</span><br></code></pre></td></tr></table></figure><p>这样设置以后，就可以通过<code>docker logs webapp_dev</code> 或 <code>docker exec -it webapp_dev /bin/bash</code> 等命令来操作这个容器，而不是<code>项目名_webapp_</code>这样类似的格式。</p><h2 id="depends-on"><a href="#depends-on" class="headerlink" title="depends_on"></a>depends_on</h2><p>指定服务之间的依赖关系，以便按顺序启动服务。以下例子中会先启动 <code>redis</code> <code>db</code> 再启动 <code>web</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3.8&#x27;</span><br><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">web:</span><br>    <span class="hljs-attr">build:</span> <span class="hljs-string">.</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">db</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">redis</span><br><br>  <span class="hljs-attr">redis:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">redis</span><br><br>  <span class="hljs-attr">db:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">postgres</span><br></code></pre></td></tr></table></figure><h2 id="env-file"><a href="#env-file" class="headerlink" title="env_file"></a>env_file</h2><p>从文件中添加环境变量。可以是单个值或列表。</p><p>如果通过 <code>docker-compose -f FILE</code> 方式来指定了 Compose 文件，则 <code>env_file</code> 中变量的路径相对于文件所在目录。</p><p>在 <code>environment</code> 声明的变量，会覆盖这些值。即使这些值为空或未定义。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">env_file:</span> <span class="hljs-string">.env</span><br><br><span class="hljs-attr">env_file:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">./common.env</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">./apps/web.env</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">/opt/secrets.env</span><br></code></pre></td></tr></table></figure><p>假设我们有一个<code>.env</code>文件内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">DB_HOST=localhost</span><br><span class="hljs-string">DB_USER=myuser</span><br><span class="hljs-string">DB_PASS=mypassword</span><br></code></pre></td></tr></table></figure><p>我们在<code>docker compose</code>文件中定义：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">webapp:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">my-webapp-image</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5000:5000&quot;</span><br>    <span class="hljs-attr">env_file:</span> <br>      <span class="hljs-bullet">-</span> <span class="hljs-string">.env</span><br></code></pre></td></tr></table></figure><p>当服务启动时，<code>docker compose</code>会从配置文件中读取环境变量并设置在容器中。</p><h2 id="environment"><a href="#environment" class="headerlink" title="environment"></a>environment</h2><p>管理环境变量的另一种方式是使用<code>environment</code>参数。它可以显式的在yaml文件中配置环境变量：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">webapp:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">my-webapp-image</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5000:5000&quot;</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">DB_HOST=localhost</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">DB_USER=myuser</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">DB_PASS=mypassword</span><br></code></pre></td></tr></table></figure><blockquote><p>使用<code>env_file</code>可以更好地管理大量或敏感的环境变量，而<code>environment</code>提供了直接和灵活的方式来设置少量或不敏感的环境变量。</p></blockquote><h2 id="secrets"><a href="#secrets" class="headerlink" title="secrets"></a>secrets</h2><p>存储敏感数据，例如 <code>mysql</code> 服务密码。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">redis:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">redis:latest</span><br>    <span class="hljs-attr">deploy:</span><br>      <span class="hljs-attr">replicas:</span> <span class="hljs-number">1</span><br>    <span class="hljs-attr">secrets:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">my_secret</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">my_other_secret</span><br><span class="hljs-attr">secrets:</span><br>  <span class="hljs-attr">my_secret:</span><br>    <span class="hljs-attr">file:</span> <span class="hljs-string">./my_secret.txt</span><br>  <span class="hljs-attr">my_other_secret:</span><br>    <span class="hljs-attr">external:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><h2 id="network"><a href="#network" class="headerlink" title="network"></a>network</h2><p>通过<code>network</code>参数设置不同容器之间的通信：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">webapp:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">my-webapp-image</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">frontend</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5000:5000&quot;</span><br><br>  <span class="hljs-attr">db:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">my-db-image</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">backend</span><br><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">frontend:</span><br>  <span class="hljs-attr">backend:</span><br></code></pre></td></tr></table></figure><p>上述例子中：</p><ul><li>webapp 服务只连接到 frontend 网络。</li><li>db 服务只连接到 backend 网络。</li></ul><p>通过这种方式，webapp 不能直接访问 db，除非将 db 也连接到 frontend 网络或者 webapp 连接到 backend 网络。</p><h2 id="expose"><a href="#expose" class="headerlink" title="expose"></a>expose</h2><p>在服务内部的网络里开放端口，这是让一个服务内的不同容器相互通信。它与<code>ports</code>不同，并不对外开放端口。</p><p>假如网络中有前后端服务的容器服务，我们需要前后端的容器相互对接端口，我们需要编写以下内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&quot;3.8&quot;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">frontend:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">frontend-image</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;5000:5000&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">app-network</span><br><br>  <span class="hljs-attr">backend:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">backend-image</span><br>    <span class="hljs-attr">expose:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;4000&quot;</span><br>    <span class="hljs-attr">networks:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">app-network</span><br><br><span class="hljs-attr">networks:</span><br>  <span class="hljs-attr">app-network:</span><br></code></pre></td></tr></table></figure><p>在这个配置中：</p><ul><li><code>frontend</code>服务通过<code>ports</code>指令将容器的 5000 端口映射到宿主机的 5000 端口，允许外部网络访问。</li><li><code>backend</code>服务使用<code>expose</code>指令暴露 4000 端口，但这个端口只在内部<code>app-network</code>网络中可见，外部网络无法直接访问。</li><li><code>frontend</code>和<code>backend</code>都连接到了同一个<code>app-network</code>网络，因此<code>frontend</code>可以通过内部网络访问<code>backend</code>的 4000 端口，进行必要的数据交互。</li></ul><p>如果不设置<code>networks</code>选项的话，会链接到默认的网络中。</p><p>2024&#x2F;4&#x2F;21 于苏州 </p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VSCode必备快捷键一览</title>
    <link href="/2024/04/20/VsCode%E5%BF%85%E5%A4%87%E5%BF%AB%E6%8D%B7%E9%94%AE%E4%B8%80%E8%A7%88/"/>
    <url>/2024/04/20/VsCode%E5%BF%85%E5%A4%87%E5%BF%AB%E6%8D%B7%E9%94%AE%E4%B8%80%E8%A7%88/</url>
    
    <content type="html"><![CDATA[<p>工作中时常有批量处理代码的场景，以前我都是纯鼠标点来点去，实在是太原始人了。痛定思痛，打算花一点时间研究一下VSCode中快捷键的用法。</p><h1 id="查询-替换与批量操作"><a href="#查询-替换与批量操作" class="headerlink" title="查询&#x2F;替换与批量操作"></a>查询&#x2F;替换与批量操作</h1><h2 id="批量选中"><a href="#批量选中" class="headerlink" title="批量选中"></a>批量选中</h2><p>当我们想选择所有出现在当前选中的变量，并对其进行批量修改，只需要执行<code>Ctrl+F2</code>。这会选中所有相同的字段，你可以对他们进行统一的处理。</p><p><img src="/images/100151.gif" alt="Ctrl+F2批量选择"></p><p>或者我们也可以用<code>Alt+Click</code>，这样允许你通过点击的方式批量插入光标。</p><p><img src="/images/101943.gif" alt="Alt+Click批量选择"></p><p>还有更方便的：<code>Ctrl+D</code>，这能够选中当前光标所在位置的变量。当你多次连点，就会选中所有相同变量。</p><p><img src="/images/103536.gif" alt="Ctrl+D批量选择"></p><h2 id="查询-替换"><a href="#查询-替换" class="headerlink" title="查询&#x2F;替换"></a>查询&#x2F;替换</h2><p><code>Ctrl+F</code>是经典的查询快捷键。<code>Ctrl+H</code>则是替换快捷键。当替换后，依次回车来对输入进行更改。</p><p><img src="/images/103021.gif" alt="Ctrl+F/H进行查询替换"></p><h1 id="显示"><a href="#显示" class="headerlink" title="显示"></a>显示</h1><table><thead><tr><th>快捷键</th><th>作用</th></tr></thead><tbody><tr><td><code>F11</code></td><td>切换全屏模式</td></tr><tr><td><code>Ctrl+B</code></td><td>侧边栏隐藏</td></tr><tr><td><code>Ctrl + Shift + V</code></td><td>预览Markdown文件</td></tr></tbody></table><h1 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h1><table><thead><tr><th>快捷键</th><th>作用</th></tr></thead><tbody><tr><td><code>Ctrl + Shift + N</code></td><td>新建窗口</td></tr><tr><td><code>Ctrl + Shift + W</code></td><td>关闭窗口</td></tr><tr><td><code>Ctrl + P</code></td><td>快速打开文件</td></tr></tbody></table><p>2024&#x2F;4&#x2F;20 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>VSCode</tag>
      
      <tag>工作流</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>源码分析：MoE专家架构</title>
    <link href="/2024/04/10/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9AMoE%E4%B8%93%E5%AE%B6%E6%9E%B6%E6%9E%84/"/>
    <url>/2024/04/10/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9AMoE%E4%B8%93%E5%AE%B6%E6%9E%B6%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<p>相关链接：</p><p><a href="https://huggingface.co/blog/zh/moe">混合专家模型（MoE）详解</a></p><p><a href="https://www.jiqizhixin.com/articles/2024-02-15-7">手把手教你，从零开始实现一个稀疏混合专家架构语言模型（MoE） </a></p><p>MoE专家模型因为Mixtral的使用让大家又一次了解了这个架构，事实上这个架构起源于 1991 年的论文 <a href="https://www.cs.toronto.edu/~hinton/absps/jjnh91.pdf">Adaptive Mixture of Local Experts</a>。这种思想旨在使用多个独立的网络组成一个监督模型，该模型中，每个独立的网络（也被称作专家网络）专注于训练样本中的不同数据。这个系统中，一个门控网络被训练来决定哪个专家被选中。</p><p>这和传统的机器学习模型中的Ensemble模型有点类似，都是结合了多个模型来处理任务，区别在于MoE的子模型是根据不同的任务建模，并且多了一个门控单元。</p><blockquote><p>我的理解：MoE是如何体现在语言模型上的？可以理解为生成文本时，会根据上一段文本中的内容进行预测。在上一段文本中，每个Token都有一个专门的专家处理，来给出预测。</p></blockquote><h1 id="Pytorch实现简单的专家网络"><a href="#Pytorch实现简单的专家网络" class="headerlink" title="Pytorch实现简单的专家网络"></a>Pytorch实现简单的专家网络</h1><p>这里用pytorch实现一个简单的专家网络。完成这个任务需要有几个部分：</p><ol><li>需要一个Dataset。</li><li>需要一个DataLoader。</li><li>需要一个TopN函数，用来选择需要的专家网络。</li><li>需要一个单个的Expert网络。</li><li>需要一个完整的MoE网络。</li><li>需要一个损失函数和评估函数。</li><li>需要完整的训练过程。</li></ol><h2 id="Dataset与DataLoader"><a href="#Dataset与DataLoader" class="headerlink" title="Dataset与DataLoader"></a>Dataset与DataLoader</h2> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, Dataset<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 创建一些随机数据（替换为真实数据）</span><br>num_samples = <span class="hljs-number">1000</span><br>num_features = <span class="hljs-number">300</span>  <span class="hljs-comment"># 假设文本已经转换为固定大小的向量</span><br>num_classes = <span class="hljs-number">10</span>    <span class="hljs-comment"># 假设有10个类别</span><br><br><span class="hljs-comment"># 随机生成数据和标签</span><br>X = np.random.randn(num_samples, num_features) <span class="hljs-comment"># (1000, 300)</span><br>y = np.random.randint(<span class="hljs-number">0</span>, num_classes, num_samples) <span class="hljs-comment"># (1000,)</span><br><br><span class="hljs-comment"># 划分训练集和测试集</span><br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># 定义 Dataset</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TextDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-comment"># features: (num_samples, num_features) # 1000个样本，每个样本300个嵌入特征</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, features, labels</span>):<br>        self.features = features<br>        self.labels = labels<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.labels)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> torch.tensor(self.features[idx], dtype=torch.<span class="hljs-built_in">float</span>), torch.tensor(self.labels[idx], dtype=torch.long)<br><br><span class="hljs-comment"># 创建 DataLoader</span><br>train_dataset = TextDataset(X_train, y_train)<br>train_loader = DataLoader(train_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>test_dataset = TextDataset(X_test, y_test)<br>test_loader = DataLoader(test_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><h2 id="TopN函数"><a href="#TopN函数" class="headerlink" title="TopN函数"></a>TopN函数</h2><p>门控网络是一个线性层，它将输入的完整的Tensor转换为所有的专家网络数大小的张量，代表着每个专家的得分。随后取Top N个专家的Index。</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">###模型定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TopKGating</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, num_experts, top_k=<span class="hljs-number">2</span></span>):<br>        <span class="hljs-built_in">super</span>(TopKGating, self).__init__()<br>        <span class="hljs-comment"># 初始化线性层作为门控机制</span><br>        self.gate = nn.Linear(input_dim, num_experts) <span class="hljs-comment"># (300, 4)</span><br>        <span class="hljs-comment"># 设置要选择的顶部专家数量</span><br>        self.top_k = top_k<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 计算每个专家的分数</span><br>        gating_scores = self.gate(x) <span class="hljs-comment"># x: (batch_size, input_dim) (32, 300) gating_scores: (batch_size, num_experts) (32, 4)</span><br>        <span class="hljs-comment"># 选取分数最高的 top_k 个专家，并返回它们的索引和 softmax 权重</span><br>        top_k_values, top_k_indices = torch.topk(F.softmax(gating_scores, dim=<span class="hljs-number">1</span>), self.top_k)<br>        <span class="hljs-keyword">return</span> top_k_indices, top_k_values<br></code></pre></td></tr></table></figure><h2 id="专家网络"><a href="#专家网络" class="headerlink" title="专家网络"></a>专家网络</h2><p>专家网络就是一个简单的神经网络：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Expert</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, output_dim</span>):<br>        <span class="hljs-built_in">super</span>(Expert, self).__init__()<br>        <span class="hljs-comment"># 为每个专家定义一个简单的神经网络</span><br>        self.net = nn.Sequential(<br>            nn.Linear(input_dim, <span class="hljs-number">4</span>*input_dim),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">4</span>*input_dim, output_dim)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 通过专家网络传递输入数据</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;expert input shape&#x27;</span>, x.shape) <span class="hljs-comment"># (batch_size, input_dim) (32, 300) </span><br>        <span class="hljs-keyword">return</span> self.net(x) <span class="hljs-comment"># output = self.net(x) # (batch_size, output_dim) (32, 10)</span><br></code></pre></td></tr></table></figure><h2 id="MoE网络"><a href="#MoE网络" class="headerlink" title="MoE网络"></a>MoE网络</h2><p>我们假设这是一个分类任务，那么构建MoE网络需要如下参数：输出的Tensor，类别数量，专家数量，TopN。假如是文本预测任务，那么类别数量就是词表大小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MoE</span>(nn.Module):<br>     <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, num_classes, num_experts, top_k=<span class="hljs-number">2</span></span>):<br>         <span class="hljs-built_in">super</span>(MoE, self).__init__()<br>         <span class="hljs-comment"># 设置专家数量</span><br>         self.num_experts = num_experts<br>         <span class="hljs-comment"># 设置类别数量</span><br>         self.num_classes = num_classes<br>         <span class="hljs-comment"># 初始化 TopK 门控层</span><br>         self.gating = TopKGating(input_dim, num_experts, top_k)<br>         <span class="hljs-comment"># 创建专家网络的列表，每个专家是一个 Expert 实例</span><br>         self.experts = nn.ModuleList([Expert(input_dim, num_classes) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_experts)])<br> <br>     <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>         <span class="hljs-comment"># 获取批量大小</span><br>         batch_size = x.size(<span class="hljs-number">0</span>) <span class="hljs-comment"># (32, 300)</span><br>     <br>         <span class="hljs-comment"># 通过门控层获得 top_k 专家的索引和门控权重</span><br>         indices, gates = self.gating(x)  <span class="hljs-comment"># indices：[batch_size, top_k], gates：[batch_size, top_k]</span><br>     <br>         <span class="hljs-comment"># 准备收集选定专家的输出</span><br>         expert_outputs = torch.zeros(batch_size, indices.size(<span class="hljs-number">1</span>), self.num_classes).to(x.device)<br>     <br>         <span class="hljs-comment"># 遍历每个样本和其对应的 top_k 专家</span><br>         <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size): <span class="hljs-comment"># 32</span><br>             <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;第i个batch&#x27;</span>, i)<br>             <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(indices.size(<span class="hljs-number">1</span>)): <span class="hljs-comment"># 2，即top_k</span><br>                 expert_idx = indices[i, j].item()  <span class="hljs-comment"># 获取专家的索引，即门控权重最大的专家</span><br>                 <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Top2专家&#x27;</span>, expert_idx) <br>                 <span class="hljs-built_in">print</span>(self.experts[expert_idx]) <span class="hljs-comment"># 打印专家网络 一个完整的神经网络</span><br>                 <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;-----&#x27;</span>)<br>                 <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;x[i] shape&#x27;</span>, x[i].shape) <span class="hljs-comment"># (300,)</span><br>                 <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;x[i].unsqueeze(0) shape&#x27;</span>, x[i].unsqueeze(<span class="hljs-number">0</span>).shape) <span class="hljs-comment"># (1, 300) 在第0维度上增加一个维度</span><br>                 expert_outputs[i, j, :] = self.experts[expert_idx](x[i].unsqueeze(<span class="hljs-number">0</span>)) <span class="hljs-comment"># 通过专家网络传递输入数据，(1, 300)-&gt;(1, 10)</span><br>                 <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;expert_outputs shape&#x27;</span>, expert_outputs.shape) <span class="hljs-comment"># (32, 2, 10)</span><br><br>         <span class="hljs-comment"># 将门控权重扩展到与专家输出相同的维度</span><br>         gates = gates.unsqueeze(-<span class="hljs-number">1</span>).expand(-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, self.num_classes)  <span class="hljs-comment"># 形状：[batch_size, top_k, num_classes]</span><br>     <br>         <span class="hljs-comment"># 计算加权的专家输出的和</span><br>         output = (gates * expert_outputs).<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>)<br>         <span class="hljs-keyword">return</span> output, gates.<span class="hljs-built_in">sum</span>(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 返回模型输出和门控使用率以用于负载平衡损失计算</span><br></code></pre></td></tr></table></figure><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br> <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">moe_loss</span>(<span class="hljs-params">output, target, gating_weights, lambda_balance=<span class="hljs-number">0.1</span></span>):<br>     <span class="hljs-comment"># 标准损失（例如交叉熵损失）</span><br>     <span class="hljs-comment"># output 是模型的输出，target 是真实的标签</span><br>     standard_loss = F.cross_entropy(output, target)<br> <br>     <span class="hljs-comment"># 负载平衡损失</span><br>     <span class="hljs-comment"># gating_weights 是门控权重，表示每个专家的使用率</span><br>     <span class="hljs-comment"># 使用标准差来衡量各专家使用率的平衡程度</span><br>     balance_loss = torch.std(gating_weights)<br> <br>     <span class="hljs-comment"># 总损失</span><br>     <span class="hljs-comment"># 结合标准损失和负载平衡损失，lambda_balance 是一个超参数，用于控制负载平衡损失在总损失中的比重</span><br>     total_loss = standard_loss + lambda_balance * balance_loss<br>     <span class="hljs-keyword">return</span> total_loss<br></code></pre></td></tr></table></figure><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"> <span class="hljs-comment"># 初始化模型</span><br>model = MoE(input_dim=num_features, num_classes=num_classes, num_experts=<span class="hljs-number">4</span>, top_k=<span class="hljs-number">2</span>)<br> optimizer = torch.optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>)<br> <br> <span class="hljs-comment"># 训练循环</span><br>num_epochs = <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    model.train()<br>    total_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> features, labels <span class="hljs-keyword">in</span> train_loader:<br>         optimizer.zero_grad()<br>         outputs, gating_weights = model(features)<br>         loss = moe_loss(outputs, labels, gating_weights)<br>         loss.backward()<br>         optimizer.step()<br>         total_loss += loss.item()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>, Loss: <span class="hljs-subst">&#123;total_loss/<span class="hljs-built_in">len</span>(train_loader)&#125;</span>&#x27;</span>)<br> <br> <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model, data_loader</span>):<br>     model.<span class="hljs-built_in">eval</span>()<br>     predictions, true_labels = [], []<br>     <span class="hljs-keyword">with</span> torch.no_grad():<br>         <span class="hljs-keyword">for</span> features, labels <span class="hljs-keyword">in</span> data_loader:<br>             s = time.time()<br>             outputs, _ = model(features)<br>             e = time.time()<br>             <span class="hljs-built_in">print</span>(e-s)<br>             predicted = torch.argmax(outputs, dim=<span class="hljs-number">1</span>)<br>             predictions.extend(predicted.tolist())<br>             true_labels.extend(labels.tolist())<br>     <span class="hljs-keyword">return</span> accuracy_score(true_labels, predictions)<br></code></pre></td></tr></table></figure><p>以下是一个Epoch的输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs bash">Expert(<br>  (net): Sequential(<br>    (0): Linear(in_features=300, out_features=1200, bias=True)<br>    (1): ReLU()<br>    (2): Linear(in_features=1200, out_features=10, bias=True)<br>  )<br>)<br>-----<br>x[i] shape torch.Size([300])<br>x[i].unsqueeze(0) shape torch.Size([1, 300])<br>expert_outputs shape torch.Size([32, 2, 10])<br>第i个batch 0<br>Top2专家 0<br>Expert(<br>  (net): Sequential(<br>    (0): Linear(in_features=300, out_features=1200, bias=True)<br>    (1): ReLU()<br>    (2): Linear(in_features=1200, out_features=10, bias=True)<br>  )<br>)<br>-----<br>x[i] shape torch.Size([300])<br>x[i].unsqueeze(0) shape torch.Size([1, 300])<br>expert_outputs shape torch.Size([32, 2, 10])<br>Top2专家 1<br>Expert(<br>  (net): Sequential(<br>    (0): Linear(in_features=300, out_features=1200, bias=True)<br>    (1): ReLU()<br>    (2): Linear(in_features=1200, out_features=10, bias=True)<br>  )<br>)<br>-----<br>x[i] shape torch.Size([300])<br>x[i].unsqueeze(0) shape torch.Size([1, 300])<br>expert_outputs shape torch.Size([32, 2, 10])<br>第i个batch_size 26<br>Top2专家 2<br>Expert(<br>  (net): Sequential(<br>    (0): Linear(in_features=300, out_features=1200, bias=True)<br>    (1): ReLU()<br>    (2): Linear(in_features=1200, out_features=10, bias=True)<br>  )<br>)<br>-----<br>x[i] shape torch.Size([300])<br>x[i].unsqueeze(0) shape torch.Size([1, 300])<br>expert_outputs shape torch.Size([32, 2, 10])<br>Top2专家 3<br>Expert(<br>  (net): Sequential(<br>    (0): Linear(in_features=300, out_features=1200, bias=True)<br>    (1): ReLU()<br>    (2): Linear(in_features=1200, out_features=10, bias=True)<br>  )<br>)<br>-----<br></code></pre></td></tr></table></figure><h1 id="Mixtral-MoE源码"><a href="#Mixtral-MoE源码" class="headerlink" title="Mixtral MoE源码"></a>Mixtral MoE源码</h1><p>同时附上了Transformer中Mixtral的MoE源码：</p><p>首先是Mixtral的单个专家模块，它将输入层经过一个被激活过的线性层，再经过两个线性层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MixtralBLockSparseTop2MLP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: MixtralConfig</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># FFNSize，一般是 HidSize x4</span><br>        self.ffn_dim = config.intermediate_size<br>        <span class="hljs-comment"># HidSize，隐藏状态的向量尺寸</span><br>        self.hidden_dim = config.hidden_size<br><br>        <span class="hljs-comment"># 用于隐藏状态扩张的线性层</span><br>        self.w1 = nn.Linear(self.hidden_dim, self.ffn_dim, bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-comment"># 用于隐藏状态收缩的线性层</span><br>        self.w2 = nn.Linear(self.ffn_dim, self.hidden_dim, bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-comment"># 用于计算隐藏状态门控的线性层</span><br>        self.w3 = nn.Linear(self.hidden_dim, self.ffn_dim, bias=<span class="hljs-literal">False</span>)<br><br>        self.act_fn = ACT2FN[config.hidden_act]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, hidden_states</span>):<br>        <span class="hljs-comment"># 输入隐藏状态的形状为 [BatchSize, SeqLen, HidSize]、</span><br>        <span class="hljs-comment"># 输入经过第三个线性层并激活，得到门控</span><br>        <span class="hljs-comment"># 输入经过第一个线性层，乘以门控，经过第二个线性层，得到输出</span><br>        current_hidden_states = self.act_fn(self.w1(hidden_states)) * self.w3(hidden_states)<br>        current_hidden_states = self.w2(current_hidden_states)<br>        <span class="hljs-keyword">return</span> current_hidden_states<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MixtralBLockSparseTop2MLP</span>(<span class="hljs-title class_ inherited__">MixtralBlockSparseTop2MLP</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>):<br>        logger.warning_once(<br>            <span class="hljs-string">&quot;MixtralBLockSparseTop2MLP is deprecated by MixtralBlockSparseTop2MLP and will be removed in v4.40.&quot;</span><br>        )<br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br></code></pre></td></tr></table></figure><p>以下代码是MoE的模型构建：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># MOE 的架构</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MixtralSparseMoeBlock</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    This implementation is</span><br><span class="hljs-string">    strictly equivalent to standard MoE with full capacity (no</span><br><span class="hljs-string">    dropped tokens). It&#x27;s faster since it formulates MoE operations</span><br><span class="hljs-string">    in terms of block-sparse operations to accomodate imbalanced</span><br><span class="hljs-string">    assignments of tokens to experts, whereas standard MoE either</span><br><span class="hljs-string">    (1) drop tokens at the cost of reduced performance or (2) set</span><br><span class="hljs-string">    capacity factor to number of experts and thus waste computation</span><br><span class="hljs-string">    and memory on padding.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># HidSize，隐藏状态的向量尺寸</span><br>        self.hidden_dim = config.hidden_size<br>        self.ffn_dim = config.intermediate_size<br>        <span class="hljs-comment"># NExp，专家数量</span><br>        self.num_experts = config.num_local_experts<br>        <span class="hljs-comment"># TopK，激活的专家数量</span><br>        self.top_k = config.num_experts_per_tok<br><br>        <span class="hljs-comment"># 门控线性层</span><br>        self.gate = nn.Linear(self.hidden_dim, self.num_experts, bias=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-comment"># 专家模块列表，每个都是 FFN</span><br>        self.experts = nn.ModuleList([MixtralBLockSparseTop2MLP(config) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_experts)])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, hidden_states: torch.Tensor</span>) -&gt; torch.Tensor:<br>        <span class="hljs-string">&quot;&quot;&quot; &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 输入尺寸：[BatchSize, SeqLen, HidSize]</span><br>        <span class="hljs-comment"># 获取 BatchSize（批量大小）</span><br>        <span class="hljs-comment">#     SeqLen（序列长度）</span><br>        <span class="hljs-comment">#     HidSize（隐藏状态尺寸）</span><br>        batch_size, sequence_length, hidden_dim = hidden_states.shape<br>        <span class="hljs-comment"># 将输入前两维合并，[BatchSize * SeqLen, HidSize]</span><br>        hidden_states = hidden_states.view(-<span class="hljs-number">1</span>, hidden_dim)<br>        <span class="hljs-comment"># 将隐藏状态传入门控线性层得到专家得分</span><br>        <span class="hljs-comment"># 每个样本的每个单词都有一组得分</span><br>        <span class="hljs-comment"># [BatchSize * SeqLen, NExp]</span><br>        router_logits = self.gate(hidden_states)<br>        <span class="hljs-comment"># 专家得分经过 Softmax 得到专家概率</span><br>        routing_weights = F.softmax(router_logits, dim=<span class="hljs-number">1</span>, dtype=torch.<span class="hljs-built_in">float</span>)<br>        <span class="hljs-comment"># 计算每个得分的 TOPK，得到专家索引</span><br>        <span class="hljs-comment"># routing_weights：TOPK 专家概率，[BatchSize * SeqLen, TopK]</span><br>        <span class="hljs-comment"># selected_experts：TOPK 专家索引，[BatchSize * SeqLen, TopK]</span><br>        routing_weights, selected_experts = torch.topk(routing_weights, self.top_k, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 专家概率归一化，使每组得分和为一</span><br>        routing_weights /= routing_weights.<span class="hljs-built_in">sum</span>(dim=-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>        <span class="hljs-comment"># 转换为输入的数据类型</span><br>        routing_weights = routing_weights.to(hidden_states.dtype)<br>        <span class="hljs-comment"># 将最终的隐藏状态初始化为零，用于累加</span><br>        final_hidden_states = torch.zeros(<br>            (batch_size * sequence_length, hidden_dim), dtype=hidden_states.dtype, device=hidden_states.device<br>        )<br><br>        <span class="hljs-comment"># 将专家索引单热化，交换前后两维，得到专家的掩码</span><br>        <span class="hljs-comment"># [NExp, TopK, BatchSize * SeqLen]</span><br>        <span class="hljs-comment"># mask[i, j, k] 表示第 k 个单词的第 j 个专家是不是专家 i</span><br>        expert_mask = torch.nn.functional.one_hot(selected_experts, num_classes=self.num_experts).permute(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br><br>        <span class="hljs-comment"># 遍历每个专家，expert_idx 为专家索引</span><br>        <span class="hljs-keyword">for</span> expert_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_experts):<br>            <span class="hljs-comment"># 获取当前专家模块</span><br>            expert_layer = self.experts[expert_idx]<br>            <span class="hljs-comment"># 使用索引来索引掩码，得到当前专家的掩码矩阵</span><br>            <span class="hljs-comment"># [TopK, BatchSize * SeqLen]</span><br>            <span class="hljs-comment"># 它的元素 [i, j] 表示第 j 个样本的第 i 个专家是不是当前专家</span><br>            <span class="hljs-comment"># where 计算调用该专家的单词序号（top_x），以及该专家的排名（idx）</span><br>            idx, top_x = torch.where(expert_mask[expert_idx])<br><br>            <span class="hljs-comment"># 如果没有单词调用该专家，转到下一个</span><br>            <span class="hljs-keyword">if</span> top_x.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">continue</span><br><br>            <span class="hljs-comment"># 转 Python 列表</span><br>            top_x_list = top_x.tolist()<br>            idx_list = idx.tolist()<br><br>            <span class="hljs-comment"># 获取调用该专家的单词的隐藏状态，[NHid, HidSize]</span><br>            current_state = hidden_states[<span class="hljs-literal">None</span>, top_x_list].reshape(-<span class="hljs-number">1</span>, hidden_dim)<br>            <span class="hljs-comment"># 将隐藏状态传入当前专家，得到专家输出，[NHid, HidSize]</span><br>            <span class="hljs-comment"># 获取调用该专家的单词的专家概率，[NHid, 1]</span><br>            <span class="hljs-comment"># 二者相乘</span><br>            current_hidden_states = expert_layer(current_state) * routing_weights[top_x_list, idx_list, <span class="hljs-literal">None</span>]<br><br>            <span class="hljs-comment"># 将隐藏状态加到最终隐藏状态</span><br>            <span class="hljs-comment"># 即 final_hidden_states[top_x[i]] += current_hidden_states[i]</span><br>            final_hidden_states.index_add_(<span class="hljs-number">0</span>, top_x, current_hidden_states.to(hidden_states.dtype))<br>        <span class="hljs-comment"># 拆分第一维，[BatchSize, SeqLen, HidSize]</span><br>        final_hidden_states = final_hidden_states.reshape(batch_size, sequence_length, hidden_dim)<br>        <span class="hljs-keyword">return</span> final_hidden_states, router_logits<br></code></pre></td></tr></table></figure><p>2024&#x2F;4&#x2F;14 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>代码实战</tag>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Yolo v5的工程代码实现：超参数与优化策略</title>
    <link href="/2024/04/05/Yolo-v5%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E4%B8%8E%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/"/>
    <url>/2024/04/05/Yolo-v5%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E4%B8%8E%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/</url>
    
    <content type="html"><![CDATA[<p>在Yolo v5的代码中，训练时有几个需要配置的文件。一个是模型的yaml文件，当中包含了多个参数。</p><h1 id="Model-yaml"><a href="#Model-yaml" class="headerlink" title="Model.yaml"></a>Model.yaml</h1><p>我们以最小的yolov5s.yaml为例，它的配置文件如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">nc:</span> <span class="hljs-number">80</span> <span class="hljs-comment"># 需要预测的分类数</span><br><span class="hljs-attr">depth_multiple:</span> <span class="hljs-number">0.33</span> <span class="hljs-comment"># 网络深度的系数</span><br><span class="hljs-attr">width_multiple:</span> <span class="hljs-number">0.50</span> <span class="hljs-comment"># 网络宽度的系数</span><br><br><span class="hljs-comment"># 先验框配置，也可以直接写数字表示聚类数</span><br><span class="hljs-attr">anchors:</span> <span class="hljs-comment"># 9个anchor，其中P表示特征图的层级，P3/8该层特征图缩放为1/8,是第3层特征</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">10</span>, <span class="hljs-number">13</span>, <span class="hljs-number">16</span>, <span class="hljs-number">30</span>, <span class="hljs-number">33</span>, <span class="hljs-number">23</span>] <span class="hljs-comment"># P3/8 FPN接主干网络下采样8倍后的anchor大小,检测小目标,10,13是一组尺寸，总共三组检测小目标</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">30</span>, <span class="hljs-number">61</span>, <span class="hljs-number">62</span>, <span class="hljs-number">45</span>, <span class="hljs-number">59</span>, <span class="hljs-number">119</span>] <span class="hljs-comment"># P4/16 FPN接主干网络下采样4倍后的anchor大小,检测中目标，共三组</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">116</span>, <span class="hljs-number">90</span>, <span class="hljs-number">156</span>, <span class="hljs-number">198</span>, <span class="hljs-number">373</span>, <span class="hljs-number">326</span>] <span class="hljs-comment"># P5/32 FPN接主干网络下采样2倍后的anchor大小,检测大目标，共三组</span><br><br><span class="hljs-attr">backbone:</span><br>  <span class="hljs-comment"># [from, number, module, args]</span><br>  [<br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">64</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]], <span class="hljs-comment"># 0-P1/2</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">128</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]], <span class="hljs-comment"># 1-P2/4</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">128</span>]],<br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]], <span class="hljs-comment"># 3-P3/8</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">6</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">256</span>]],<br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]], <span class="hljs-comment"># 5-P4/16</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">9</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>]],<br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]], <span class="hljs-comment"># 7-P5/32</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">1024</span>]],<br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">SPPF</span>, [<span class="hljs-number">1024</span>, <span class="hljs-number">5</span>]], <span class="hljs-comment"># 9</span><br>  ]<br><br><span class="hljs-attr">head:</span> [<br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]],<br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">nn.Upsample</span>, [<span class="hljs-string">None</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&quot;nearest&quot;</span>]],<br>    [[<span class="hljs-number">-1</span>, <span class="hljs-number">6</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]], <span class="hljs-comment"># cat backbone P4</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>, <span class="hljs-literal">False</span>]], <span class="hljs-comment"># 13</span><br><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]],<br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">nn.Upsample</span>, [<span class="hljs-string">None</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&quot;nearest&quot;</span>]],<br>    [[<span class="hljs-number">-1</span>, <span class="hljs-number">4</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]], <span class="hljs-comment"># cat backbone P3</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">256</span>, <span class="hljs-literal">False</span>]], <span class="hljs-comment"># 17 (P3/8-small)</span><br><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],<br>    [[<span class="hljs-number">-1</span>, <span class="hljs-number">14</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]], <span class="hljs-comment"># cat head P4</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>, <span class="hljs-literal">False</span>]], <span class="hljs-comment"># 20 (P4/16-medium)</span><br><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],<br>    [[<span class="hljs-number">-1</span>, <span class="hljs-number">10</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]], <span class="hljs-comment"># cat head P5</span><br>    [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">1024</span>, <span class="hljs-literal">False</span>]], <span class="hljs-comment"># 23 (P5/32-large)</span><br><br>    [[<span class="hljs-number">17</span>, <span class="hljs-number">20</span>, <span class="hljs-number">23</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Detect</span>, [<span class="hljs-string">nc</span>, <span class="hljs-string">anchors</span>]], <span class="hljs-comment"># Detect(P3, P4, P5)</span><br>  ]<br><br></code></pre></td></tr></table></figure><h2 id="网络深度与宽度"><a href="#网络深度与宽度" class="headerlink" title="网络深度与宽度"></a>网络深度与宽度</h2><p>第一个需要了解的是这里的是<code>depth_multiple</code> 和<code>width_multiple</code> 。</p><p><code>depth_multiple</code>: 有些模块需要重复n次，这时就会将<code>depth_multiple</code>$&#x2F;times$n来控制模块重复的次数。例如在模型架构图中，包含C3模块如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># ...省略其余模块</span><br>[<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">128</span>]<br>[<span class="hljs-number">-1</span>, <span class="hljs-number">6</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">128</span>]<br>[<span class="hljs-number">-1</span>, <span class="hljs-number">9</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">128</span>]<br>[<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">128</span>]<br></code></pre></td></tr></table></figure><p>这里的第二个数字用来控制C3模块中残差模块的个数。这时就将<code>depth_multiple</code>乘以它来控制重复的次数，这时实际的残差模块的重复次数为<code>1,2,3,1</code>，网络的深度就变浅了。当然，本来就为1的不会变。</p><blockquote><p>C3模块是一个含有3个卷积层的bottleneck模块。留着以后学习。</p></blockquote><p><img src="/images/c3.png" alt="C3"></p><p><code>width_multiple</code>: 控制某些模块输出的channel数。例如卷积层的channel数，用于控制网络宽度。例如卷积层：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml">[<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">64</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]]<br></code></pre></td></tr></table></figure><p>其中的<code>[64, 6, 2, 2]</code>代表输出通道数，卷积核，步长，Padding。当<code>width_multiple</code>为0.5时，输出通道数即为32。</p><h2 id="Anchor"><a href="#Anchor" class="headerlink" title="Anchor"></a>Anchor</h2><p>引用链接：</p><p><a href="https://blog.csdn.net/qq_46110834/article/details/111410923">锚框(anchor box)&#x2F;先验框(prior bounding box)概念介绍及其生成-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/63024247">锚框：Anchor box综述 - 知乎 (zhihu.com)</a></p><p>Yolov5中使用K-means的聚类来初始化9个锚框。这九个锚框分别在三个检测层的Feature Map上被使用。</p><p>尺度越大，Feature Map越大，对原图的下采样越小，感受野也越小，设置的Anchor也越小，对原图的小物体预测效果更好。</p><blockquote><p>锚框又称为先验框，在Faster R-CNN中被提出。原先的目标检测方法需要使用固定尺寸的滑动窗口，遍历固定大小的窗口里的像素来判断是否是目标。这样会导致不适合形变较大的物体，并且计算量过大。</p><p>因此Faster R-CNN中加入了RPN（Regional Proposal），区域候选框。它负责找到图像中最可能出现目标分类的候选区域。</p><p>锚框则是人为预先选择好的不同大小的候选框。模型去预测Grounding Truth和锚框的偏移量。</p><p>篇幅有限，之后再学习。</p></blockquote><p>总之，这个参数是对预测图片中的物体大小进行适配。如果检测物体较小，则需要调小。Yolo v5中，如果Anchor只设置为数字，则会调用AutoAnchor，找到最佳的锚框。</p><p>在Yaml文件中，Anchors可以看到包含三个列表，表示给三个尺度分配，这三个尺度在[[17, 20, 23], 1, Detect, [nc, anchors]] 指明，分别是网络的第17、20和23层。注释P3&#x2F;8是指输入下采样了23 &#x3D; 8倍，我们也可以发现网络的第17层特征图为输入的1&#x2F;8。</p><p>[[17, 20, 23], 1, Detect, [nc, anchors]] 表示把第17、20和23三层作为Detect模块的输入， [nc, anchors]是初始化Detect模块的参数。Detect模块在model&#x2F;yolo.py中声明，相当于从模型中提出想要的层作为输入，转换为相应的检测头，其输出用来计算loss。</p><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p>网络架构分为了Backbone和Head，这两个写法是一样。Yolov5按照配置文件实例化各个层，每行的列表中的四个元素分别代表：[from, number, module, args]：</p><ul><li>from：该层的输入，-1代表上一层</li><li>number：该层的数量</li><li>module：类名</li><li>args：类的初始化参数</li></ul><h1 id="hyp-scrach-yaml"><a href="#hyp-scrach-yaml" class="headerlink" title="hyp.scrach.yaml"></a>hyp.scrach.yaml</h1><p><code>data/hyps</code>中存放了默认的初始化超参数。示例如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">lr0:</span> <span class="hljs-number">0.01</span>  <span class="hljs-comment"># 初始学习率 (SGD=1E-2, Adam=1E-3)</span><br><span class="hljs-attr">lrf:</span> <span class="hljs-number">0.2</span>  <span class="hljs-comment"># 循环学习率 (lr0 * lrf)</span><br><span class="hljs-attr">momentum:</span> <span class="hljs-number">0.937</span>  <span class="hljs-comment"># SGD momentum/Adam beta1 学习率动量</span><br><span class="hljs-attr">weight_decay:</span> <span class="hljs-number">0.0005</span>  <span class="hljs-comment"># 权重衰减系数 </span><br><span class="hljs-attr">warmup_epochs:</span> <span class="hljs-number">3.0</span>  <span class="hljs-comment"># 预热学习 (fractions ok)</span><br><span class="hljs-attr">warmup_momentum:</span> <span class="hljs-number">0.8</span>  <span class="hljs-comment"># 预热学习动量</span><br><span class="hljs-attr">warmup_bias_lr:</span> <span class="hljs-number">0.1</span>  <span class="hljs-comment"># 预热初始学习率</span><br><span class="hljs-attr">box:</span> <span class="hljs-number">0.05</span>  <span class="hljs-comment"># iou损失系数</span><br><span class="hljs-attr">cls:</span> <span class="hljs-number">0.5</span>  <span class="hljs-comment"># cls损失系数</span><br><span class="hljs-attr">cls_pw:</span> <span class="hljs-number">1.0</span>  <span class="hljs-comment"># cls BCELoss正样本权重</span><br><span class="hljs-attr">obj:</span> <span class="hljs-number">1.0</span>  <span class="hljs-comment"># 有无物体系数(scale with pixels)</span><br><span class="hljs-attr">obj_pw:</span> <span class="hljs-number">1.0</span>  <span class="hljs-comment"># 有无物体BCELoss正样本权重</span><br><span class="hljs-attr">iou_t:</span> <span class="hljs-number">0.20</span>  <span class="hljs-comment"># IoU训练时的阈值</span><br><span class="hljs-attr">anchor_t:</span> <span class="hljs-number">4.0</span>  <span class="hljs-comment"># anchor的长宽比（长:宽 = 4:1）</span><br><span class="hljs-comment"># anchors: 3  # 每个输出层的anchors数量(0 to ignore)</span><br></code></pre></td></tr></table></figure><p>以下系数是数据增强系数，包括颜色空间和图片空间：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">fl_gamma:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># focal loss gamma (efficientDet default gamma=1.5)</span><br><span class="hljs-attr">hsv_h:</span> <span class="hljs-number">0.015</span>  <span class="hljs-comment"># 色调 (fraction)</span><br><span class="hljs-attr">hsv_s:</span> <span class="hljs-number">0.7</span>  <span class="hljs-comment"># 饱和度 (fraction)</span><br><span class="hljs-attr">hsv_v:</span> <span class="hljs-number">0.4</span>  <span class="hljs-comment"># 亮度 (fraction)</span><br><span class="hljs-attr">degrees:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># 旋转角度 (+/- deg)</span><br><span class="hljs-attr">translate:</span> <span class="hljs-number">0.1</span>  <span class="hljs-comment"># 平移(+/- fraction)</span><br><span class="hljs-attr">scale:</span> <span class="hljs-number">0.5</span>  <span class="hljs-comment"># 图像缩放 (+/- gain)</span><br><span class="hljs-attr">shear:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># 图像剪切 (+/- deg)</span><br><span class="hljs-attr">perspective:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># 透明度 (+/- fraction), range 0-0.001</span><br><span class="hljs-attr">flipud:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># 进行上下翻转概率 (probability)</span><br><span class="hljs-attr">fliplr:</span> <span class="hljs-number">0.5</span>  <span class="hljs-comment"># 进行左右翻转概率 (probability)</span><br><span class="hljs-attr">mosaic:</span> <span class="hljs-number">1.0</span>  <span class="hljs-comment"># 进行Mosaic概率 (probability)</span><br><span class="hljs-attr">mixup:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># 进行图像混叠概率（即，多张图像重叠在一起） (probability)</span><br></code></pre></td></tr></table></figure><p>此外，在训练时，还可以调整训练超参数，包括训练图片的尺寸，Batch，Epoch等等。</p><p>2024&#x2F;4&#x2F;8 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>CV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CV</tag>
      
      <tag>工程实践</tag>
      
      <tag>Yolo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Yolo v5的工程代码实现：train.py</title>
    <link href="/2024/04/03/Yolo-v5%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%9Atrain-py/"/>
    <url>/2024/04/03/Yolo-v5%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%9Atrain-py/</url>
    
    <content type="html"><![CDATA[<p>距离上次解读Yolo v5的工程代码又过了一段时间，这次继续debug一下它的<code>train.py</code>。</p><h1 id="导入依赖库"><a href="#导入依赖库" class="headerlink" title="导入依赖库"></a>导入依赖库</h1><p>首先就是大段的依赖导入各种库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse       <span class="hljs-comment"># 解析命令行参数模块</span><br><span class="hljs-keyword">import</span> math           <span class="hljs-comment"># 数学公式模块</span><br><span class="hljs-keyword">import</span> os             <span class="hljs-comment"># 与操作系统进行交互的模块 包含文件路径操作和解析</span><br><span class="hljs-keyword">import</span> random         <span class="hljs-comment"># 生成随机数的模块</span><br><span class="hljs-keyword">import</span> sys            <span class="hljs-comment"># sys系统模块 包含了与Python解释器和它的环境有关的函数</span><br><span class="hljs-keyword">import</span> time           <span class="hljs-comment"># 时间模块 更底层</span><br><span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy <span class="hljs-comment"># 深拷贝模块</span><br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime <span class="hljs-comment"># 基本日期和时间类型模块</span><br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path <span class="hljs-comment"># Path模块将str转换为Path对象 使字符串路径易于操作</span><br><span class="hljs-keyword">import</span> subprocess     <span class="hljs-comment"># 命令行模块</span><br><br><span class="hljs-keyword">try</span>:<br>    <span class="hljs-keyword">import</span> comet_ml  <span class="hljs-comment"># must be imported before torch (if installed)</span><br><span class="hljs-keyword">except</span> ImportError:<br>    comet_ml = <span class="hljs-literal">None</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> yaml<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> lr_scheduler <span class="hljs-comment"># 学习率模块</span><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><p>这里的<code>deepcopy</code>区别于平时的<code>=</code>进行赋值，不同在于，<code>=</code>只是把对象的内存地址拷贝，最终引用的还是原来的同一个对象。而深拷贝则是完完全全把内容复制成一个新的对象。此时修改这个新对象，不会把老对象的内容改变。</p><p>接下来导入自定义模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 获取当前文件的绝对路径，使用Path库将其转换为Path对象</span><br>FILE = Path(__file__).resolve()<br>ROOT = FILE.parents[<span class="hljs-number">0</span>]  <span class="hljs-comment"># YOLOv5的根目录，例如D://yolov5</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(ROOT) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sys.path:<br>    sys.path.append(<span class="hljs-built_in">str</span>(ROOT))  <span class="hljs-comment"># add ROOT to PATH</span><br>ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  <span class="hljs-comment"># relative</span><br><br><span class="hljs-keyword">import</span> val <span class="hljs-keyword">as</span> validate  <span class="hljs-comment"># for end-of-epoch mAP</span><br><span class="hljs-keyword">from</span> models.experimental <span class="hljs-keyword">import</span> attempt_load <span class="hljs-comment"># 实验性的代码</span><br><span class="hljs-keyword">from</span> models.yolo <span class="hljs-keyword">import</span> Model <span class="hljs-comment"># yolo模型</span><br><span class="hljs-keyword">from</span> utils.autoanchor <span class="hljs-keyword">import</span> check_anchors <span class="hljs-comment"># 定义自动锚框生成的方法</span><br><span class="hljs-keyword">from</span> utils.autobatch <span class="hljs-keyword">import</span> check_train_batch_size <span class="hljs-comment"># 定义自动生成批次大小的方法</span><br><span class="hljs-keyword">from</span> utils.callbacks <span class="hljs-keyword">import</span> Callbacks <span class="hljs-comment"># 为日志服务的回调函数</span><br><span class="hljs-keyword">from</span> utils.dataloaders <span class="hljs-keyword">import</span> create_dataloader <br><span class="hljs-keyword">from</span> utils.downloads <span class="hljs-keyword">import</span> attempt_download, is_url<br><span class="hljs-keyword">from</span> utils.general <span class="hljs-keyword">import</span> (<br>    LOGGER,<br>    TQDM_BAR_FORMAT,<br>    check_amp,<br>    check_dataset,<br>    check_file,<br>    check_git_info,<br>    check_git_status,<br>    check_img_size,<br>    check_requirements,<br>    check_suffix,<br>    check_yaml,<br>    colorstr,<br>    get_latest_run,<br>    increment_path,<br>    init_seeds,<br>    intersect_dicts,<br>    labels_to_class_weights,<br>    labels_to_image_weights,<br>    methods,<br>    one_cycle,<br>    print_args,<br>    print_mutation,<br>    strip_optimizer,<br>    yaml_save,<br>)<br><span class="hljs-keyword">from</span> utils.loggers <span class="hljs-keyword">import</span> LOGGERS, Loggers<br><span class="hljs-keyword">from</span> utils.loggers.comet.comet_utils <span class="hljs-keyword">import</span> check_comet_resume<br><span class="hljs-keyword">from</span> utils.loss <span class="hljs-keyword">import</span> ComputeLoss<br><span class="hljs-keyword">from</span> utils.metrics <span class="hljs-keyword">import</span> fitness<br><span class="hljs-keyword">from</span> utils.plots <span class="hljs-keyword">import</span> plot_evolve <span class="hljs-comment"># 定义了Annotator类，可以在图像上绘制矩形框和标注信息</span><br><span class="hljs-keyword">from</span> utils.torch_utils <span class="hljs-keyword">import</span> (<br>    EarlyStopping,<br>    ModelEMA,<br>    de_parallel,<br>    select_device,<br>    smart_DDP,<br>    smart_optimizer,<br>    smart_resume,<br>    torch_distributed_zero_first,<br>)<br></code></pre></td></tr></table></figure><h1 id="分布式训练初始化"><a href="#分布式训练初始化" class="headerlink" title="分布式训练初始化"></a>分布式训练初始化</h1><p>导包完成后，需要配置一些分布式训练的参数，分别是Local Rank, Rank和World Size。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">LOCAL_RANK = <span class="hljs-built_in">int</span>(os.getenv(<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>, -<span class="hljs-number">1</span>))  <span class="hljs-comment"># 当前Worker 是这台机器上的第几个 Worker：当前进程对应的GPU</span><br>RANK = <span class="hljs-built_in">int</span>(os.getenv(<span class="hljs-string">&quot;RANK&quot;</span>, -<span class="hljs-number">1</span>)) <span class="hljs-comment"># 当前 Worker 是全局第几个 Worker rank = 0 的主机为 master 节点</span><br>WORLD_SIZE = <span class="hljs-built_in">int</span>(os.getenv(<span class="hljs-string">&quot;WORLD_SIZE&quot;</span>, <span class="hljs-number">1</span>)) <span class="hljs-comment"># 总共有几个Worker </span><br>GIT_INFO = check_git_info()<br></code></pre></td></tr></table></figure><h1 id="Train函数"><a href="#Train函数" class="headerlink" title="Train函数"></a>Train函数</h1><p>最重要的部分，<code>train</code>函数包含四个入参：</p><ul><li><code>hyp</code>：超参数</li><li><code>opt</code>： 命令行参数</li><li><code>device</code>：当前设备</li><li><code>callbacks</code> ：用于存储<code>Loggers</code>日志记录器中的函数，方便在每个训练阶段控制日志的记录情况</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">hyp, opt, device, callbacks</span>):  <span class="hljs-comment"># hyp is path/to/hyp.yaml or hyp dictionary</span><br><span class="hljs-comment"># 先从opt获取参数，包含了日志保存路径，轮次、批次、权重、进程序号(主要用于分布式训练)等</span><br>    save_dir, epochs, batch_size, weights, single_cls, evolve, data, cfg, resume, noval, nosave, workers, freeze = (<br>        Path(opt.save_dir),<br>        opt.epochs,<br>        opt.batch_size,<br>        opt.weights,<br>        opt.single_cls,<br>        opt.evolve,<br>        opt.data,<br>        opt.cfg,<br>        opt.resume,<br>        opt.noval,<br>        opt.nosave,<br>        opt.workers,<br>        opt.freeze,<br>    )<br>    callbacks.run(<span class="hljs-string">&quot;on_pretrain_routine_start&quot;</span>)<br><br>    <span class="hljs-comment"># 设置保存权重路径 如runs/train/exp1/weights</span><br>    w = save_dir / <span class="hljs-string">&quot;weights&quot;</span>  <span class="hljs-comment"># weights dir</span><br>    <span class="hljs-comment"># 新建文件夹 weights train evolve</span><br>    (w.parent <span class="hljs-keyword">if</span> evolve <span class="hljs-keyword">else</span> w).mkdir(parents=<span class="hljs-literal">True</span>, exist_ok=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># make dir</span><br>    <span class="hljs-comment"># 保存训练结果的目录，如last.pt和best.pt</span><br>    last, best = w / <span class="hljs-string">&quot;last.pt&quot;</span>, w / <span class="hljs-string">&quot;best.pt&quot;</span><br><br>    <span class="hljs-comment"># 加载超参数</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(hyp, <span class="hljs-built_in">str</span>):<br>        <span class="hljs-comment"># 若hyp是字符串，即认定为路径，则加载超参数为字典</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(hyp, errors=<span class="hljs-string">&quot;ignore&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            hyp = yaml.safe_load(f)  <span class="hljs-comment"># load hyps dict</span><br>    LOGGER.info(colorstr(<span class="hljs-string">&quot;hyperparameters: &quot;</span>) + <span class="hljs-string">&quot;, &quot;</span>.join(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;k&#125;</span>=<span class="hljs-subst">&#123;v&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> hyp.items()))<br>    opt.hyp = hyp.copy()  <span class="hljs-comment"># for saving hyps to checkpoints</span><br><br>    <span class="hljs-comment"># Save run settings</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> evolve:<br>        yaml_save(save_dir / <span class="hljs-string">&quot;hyp.yaml&quot;</span>, hyp)<br>        yaml_save(save_dir / <span class="hljs-string">&quot;opt.yaml&quot;</span>, <span class="hljs-built_in">vars</span>(opt))<br><br>    <span class="hljs-comment"># Loggers</span><br>    data_dict = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> &#123;-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;:<br>        include_loggers = <span class="hljs-built_in">list</span>(LOGGERS)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(opt, <span class="hljs-string">&quot;ndjson_console&quot;</span>, <span class="hljs-literal">False</span>):<br>            include_loggers.append(<span class="hljs-string">&quot;ndjson_console&quot;</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(opt, <span class="hljs-string">&quot;ndjson_file&quot;</span>, <span class="hljs-literal">False</span>):<br>            include_loggers.append(<span class="hljs-string">&quot;ndjson_file&quot;</span>)<br></code></pre></td></tr></table></figure><p>这里的<code>Callback</code>方法有点像之前看过的装饰器，首先注册某个事件，当运行到特定事件时进行调用。</p><blockquote><p>hook函数是程序中预定义好的函数，这个函数处于原有程序流程当中（暴露一个钩子出来）。 我们需要再在有流程中钩子定义的函数块中实现某个具体的细节，需要把我们的实现，挂接或者注册（register）到钩子里，使得hook函数对目标可用。</p></blockquote><p>hook函数最常使用在某种流程处理当中。这个流程往往有很多步骤。hook函数常常挂载在这些步骤中，为增加额外的一些操作，提供灵活性。</p><p>yolov5训练流程中，hook函数在一个训练过程中，会轮询多次训练集，每次称为一个epoch，每个epoch又分为多个batch来训练。 流程先后拆解成:</p><ul><li>开始训练</li><li>训练一个epoch前</li><li>训练一个batch前</li><li>训练一个batch后</li><li>训练一个epoch后。</li><li>评估验证集</li><li>结束训练</li></ul><p>这些步骤是穿插在训练一个batch数据的过程中，这些可以理解成是钩子函数，我们可能需要在这些钩子函数中实现一些定制化的东西，比如在训练一个epoch后我们要保存下训练的损失，这时候我们就需要按照以下流程执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 要向其注册操作的回调钩子名称</span><br>callbacks.register_action(hook = <span class="hljs-string">&quot;on_pretrain_routine_start&quot;</span>,name = <span class="hljs-string">&quot;log_function&quot;</span> , callback=on_pretrain_routine_start)<br><span class="hljs-comment"># 调用hook，test_kwargs是on_pretrain_routine_start事件对应钩子函数的入参</span><br>callbacks.run(<span class="hljs-string">&quot;on_pretrain_routine_start&quot;</span>,<span class="hljs-string">&quot;test_kwargs&quot;</span>)<br><span class="hljs-comment"># 打印hook信息</span><br>callbacks.get_registered_actions(<span class="hljs-string">&quot;on_pretrain_routine_start&quot;</span>)<br></code></pre></td></tr></table></figure><p>以下是源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Callbacks</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;&quot; Handles all registered callbacks for YOLOv5 Hooks.&quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># Define the available callbacks</span><br>        self._callbacks = &#123;<br>            <span class="hljs-string">&quot;on_pretrain_routine_start&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_pretrain_routine_end&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_train_start&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_train_epoch_start&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_train_batch_start&quot;</span>: [],<br>            <span class="hljs-string">&quot;optimizer_step&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_before_zero_grad&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_train_batch_end&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_train_epoch_end&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_val_start&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_val_batch_start&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_val_image_end&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_val_batch_end&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_val_end&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_fit_epoch_end&quot;</span>: [],  <span class="hljs-comment"># fit = train + val</span><br>            <span class="hljs-string">&quot;on_model_save&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_train_end&quot;</span>: [],<br>            <span class="hljs-string">&quot;on_params_update&quot;</span>: [],<br>            <span class="hljs-string">&quot;teardown&quot;</span>: [],<br>        &#125;<br>        self.stop_training = <span class="hljs-literal">False</span>  <span class="hljs-comment"># set True to interrupt training</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">register_action</span>(<span class="hljs-params">self, hook, name=<span class="hljs-string">&quot;&quot;</span>, callback=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Register a new action to a callback hook.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            hook: 要向其注册操作的回调钩子名称</span><br><span class="hljs-string">            name: 动作的名称，供以后参考</span><br><span class="hljs-string">            callback: 对fire的回调</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> hook <span class="hljs-keyword">in</span> self._callbacks, <span class="hljs-string">f&quot;hook &#x27;<span class="hljs-subst">&#123;hook&#125;</span>&#x27; not found in callbacks <span class="hljs-subst">&#123;self._callbacks&#125;</span>&quot;</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">callable</span>(callback), <span class="hljs-string">f&quot;callback &#x27;<span class="hljs-subst">&#123;callback&#125;</span>&#x27; is not callable&quot;</span><br>        self._callbacks[hook].append(&#123;<span class="hljs-string">&quot;name&quot;</span>: name, <span class="hljs-string">&quot;callback&quot;</span>: callback&#125;)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_registered_actions</span>(<span class="hljs-params">self, hook=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        &quot; Returns all the registered actions by callback hook.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            hook: 需要检查的钩子函数名</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> self._callbacks[hook] <span class="hljs-keyword">if</span> hook <span class="hljs-keyword">else</span> self._callbacks<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self, hook, *args, thread=<span class="hljs-literal">False</span>, **kwargs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Loop through the registered actions and fire all callbacks on main thread.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            hook: 需要检查的钩子函数名</span><br><span class="hljs-string">            args: 从YoloV5接收的参数</span><br><span class="hljs-string">            thread: (boolean) 是否在线程中执行</span><br><span class="hljs-string">            kwargs: 从YoloV5接收的Keyword</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br><br>        <span class="hljs-keyword">assert</span> hook <span class="hljs-keyword">in</span> self._callbacks, <span class="hljs-string">f&quot;hook &#x27;<span class="hljs-subst">&#123;hook&#125;</span>&#x27; not found in callbacks <span class="hljs-subst">&#123;self._callbacks&#125;</span>&quot;</span><br>        <span class="hljs-keyword">for</span> logger <span class="hljs-keyword">in</span> self._callbacks[hook]:<br>            <span class="hljs-keyword">if</span> thread:<br>                threading.Thread(target=logger[<span class="hljs-string">&quot;callback&quot;</span>], args=args, kwargs=kwargs, daemon=<span class="hljs-literal">True</span>).start()<br>            <span class="hljs-keyword">else</span>:<br>                logger[<span class="hljs-string">&quot;callback&quot;</span>](*args, **kwargs)<br></code></pre></td></tr></table></figure><p>随后是加载日志信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">loggers = Loggers(<br>    save_dir=save_dir,<br>    weights=weights,<br>    opt=opt,<br>    hyp=hyp,<br>    logger=LOGGER,<br>    include=<span class="hljs-built_in">tuple</span>(include_loggers),<br>)<br><br><span class="hljs-comment"># Register actions</span><br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> methods(loggers):<br><span class="hljs-comment"># 将日志记录器中的方法与字符串进行绑定</span><br>    callbacks.register_action(k, callback=<span class="hljs-built_in">getattr</span>(loggers, k))<br><br><span class="hljs-comment"># Process custom dataset artifact link</span><br>data_dict = loggers.remote_dataset<br><span class="hljs-keyword">if</span> resume:  <span class="hljs-comment"># If resuming runs from remote artifact</span><br>    weights, epochs, hyp, batch_size = opt.weights, opt.epochs, opt.hyp, opt.batch_size<br></code></pre></td></tr></table></figure><p>加载其他参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Config</span><br><span class="hljs-comment"># 是否绘图，使用进化算法则不绘制</span><br>plots = <span class="hljs-keyword">not</span> evolve <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> opt.noplots  <span class="hljs-comment"># create plots</span><br>cuda = device.<span class="hljs-built_in">type</span> != <span class="hljs-string">&quot;cpu&quot;</span><br><span class="hljs-comment"># 随机种子</span><br>init_seeds(opt.seed + <span class="hljs-number">1</span> + RANK, deterministic=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 同步所有进程</span><br><span class="hljs-keyword">with</span> torch_distributed_zero_first(LOCAL_RANK):<br><span class="hljs-comment"># 检查数据集，如果没找到数据集则下载数据集(仅适用于项目中自带的yaml文件数据集)</span><br>    data_dict = data_dict <span class="hljs-keyword">or</span> check_dataset(data)  <span class="hljs-comment"># check if None</span><br><span class="hljs-comment"># 获取训练集、测试集图片路径</span><br>train_path, val_path = data_dict[<span class="hljs-string">&quot;train&quot;</span>], data_dict[<span class="hljs-string">&quot;val&quot;</span>]<br><br><span class="hljs-comment"># nc：数据集有多少种类别</span><br>nc = <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> single_cls <span class="hljs-keyword">else</span> <span class="hljs-built_in">int</span>(data_dict[<span class="hljs-string">&quot;nc&quot;</span>])  <span class="hljs-comment"># number of classes</span><br><span class="hljs-comment"># names: 数据集所有类别的名字，如果设置了single_cls则为一类</span><br>names = &#123;<span class="hljs-number">0</span>: <span class="hljs-string">&quot;item&quot;</span>&#125; <span class="hljs-keyword">if</span> single_cls <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(data_dict[<span class="hljs-string">&quot;names&quot;</span>]) != <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> data_dict[<span class="hljs-string">&quot;names&quot;</span>]  <span class="hljs-comment"># class names</span><br><br><span class="hljs-comment"># 当前数据集是否是coco数据集(80个类别)</span><br>is_coco = <span class="hljs-built_in">isinstance</span>(val_path, <span class="hljs-built_in">str</span>) <span class="hljs-keyword">and</span> val_path.endswith(<span class="hljs-string">&quot;coco/val2017.txt&quot;</span>)  <span class="hljs-comment"># COCO dataset</span><br></code></pre></td></tr></table></figure><p>下一段是预训练模型的加载：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型加载/断点续传</span><br><span class="hljs-comment"># 检查文件后缀是否是.pt</span><br>check_suffix(weights, <span class="hljs-string">&quot;.pt&quot;</span>)  <span class="hljs-comment"># check weights</span><br><span class="hljs-comment"># 加载预训练权重</span><br>pretrained = weights.endswith(<span class="hljs-string">&quot;.pt&quot;</span>)<br><span class="hljs-keyword">if</span> pretrained:<br><span class="hljs-comment"># 用于同步不同进程对数据读取的上下文管理器</span><br>    <span class="hljs-keyword">with</span> torch_distributed_zero_first(LOCAL_RANK):<br>        <span class="hljs-comment"># 如果本地不存在就从google云盘中自动下载模型</span><br>        <span class="hljs-comment"># 建议提前下载下来放进weights目录</span><br>        weights = attempt_download(weights)  <span class="hljs-comment"># download if not found locally</span><br>        <br>    <span class="hljs-comment"># 加载模型及参数，加载到CPU以防止显存泄露</span><br>    ckpt = torch.load(weights, map_location=<span class="hljs-string">&quot;cpu&quot;</span>)  <span class="hljs-comment"># load checkpoint to CPU to avoid CUDA memory leak</span><br>    <br>    <span class="hljs-comment"># 加载模型</span><br>    model = Model(cfg <span class="hljs-keyword">or</span> ckpt[<span class="hljs-string">&quot;model&quot;</span>].yaml, ch=<span class="hljs-number">3</span>, nc=nc, anchors=hyp.get(<span class="hljs-string">&quot;anchors&quot;</span>)).to(device)  <span class="hljs-comment"># create</span><br>    <br>    <span class="hljs-comment"># 若cfg 或 hyp.get(&#x27;anchors&#x27;)不为空且不使用中断训练 exclude=[&#x27;anchor&#x27;] 否则 exclude=[]</span><br>    exclude = [<span class="hljs-string">&quot;anchor&quot;</span>] <span class="hljs-keyword">if</span> (cfg <span class="hljs-keyword">or</span> hyp.get(<span class="hljs-string">&quot;anchors&quot;</span>)) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> resume <span class="hljs-keyword">else</span> []  <span class="hljs-comment"># exclude keys</span><br>    <br>    <span class="hljs-comment"># 将预训练模型中的所有参数保存下来，赋值给csd</span><br>    csd = ckpt[<span class="hljs-string">&quot;model&quot;</span>].<span class="hljs-built_in">float</span>().state_dict()  <span class="hljs-comment"># checkpoint state_dict as FP32</span><br>    <span class="hljs-comment"># 判断预训练参数和新创建的模型参数有多少是相同的</span><br>    <span class="hljs-comment"># 筛选字典中的键值对，把exclude删除</span><br>    csd = intersect_dicts(csd, model.state_dict(), exclude=exclude)  <span class="hljs-comment"># intersect</span><br>    <br>    <span class="hljs-comment"># 模型创建</span><br>    model.load_state_dict(csd, strict=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># load</span><br>    LOGGER.info(<span class="hljs-string">f&quot;Transferred <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(csd)&#125;</span>/<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(model.state_dict())&#125;</span> items from <span class="hljs-subst">&#123;weights&#125;</span>&quot;</span>)  <span class="hljs-comment"># report</span><br><span class="hljs-keyword">else</span>:<br><span class="hljs-comment"># 直接加载模型，ch为输入图片通道</span><br>    model = Model(cfg, ch=<span class="hljs-number">3</span>, nc=nc, anchors=hyp.get(<span class="hljs-string">&quot;anchors&quot;</span>)).to(device)  <span class="hljs-comment"># create</span><br>amp = check_amp(model)  <span class="hljs-comment"># check AMP</span><br></code></pre></td></tr></table></figure><p>这里有几个函数需要看一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@contextmanager</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">torch_distributed_zero_first</span>(<span class="hljs-params">local_rank: <span class="hljs-built_in">int</span></span>):<br>    <span class="hljs-keyword">if</span> local_rank <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]:<br>        dist.barrier(device_ids=[local_rank])<br>    <span class="hljs-keyword">yield</span><br>    <span class="hljs-keyword">if</span> local_rank == <span class="hljs-number">0</span>:<br>        dist.barrier(device_ids=[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><p>这里的核心是<code>dist.barrier()</code>。是 PyTorch 分布式训练中用于同步进程的一种机制，它能够在所有进程到达同一个 barrier 时进行同步，等待所有进程都完成操作之后才能继续执行。</p><p>具体来说，当一个进程调用 <code>dist.barrier()</code> 时，它会阻塞等待其他进程也到达该点。只有当所有进程都到达该 barrier 点时，它们才会被释放，然后可以继续执行后面的代码。</p><p>这个方法用来确保非主进程在等待主进程执行某些操作的时候不会执行其他操作，而主进程在完成操作后会等待其他进程到达同步点。</p><p>另一个重要的点是<code>@contextmanager</code>和<code>yield</code>。它用来简化上下文管理。</p><p>加载模型这边用了<code>Model</code>方法，这个方法来自于<code>DetectionModel</code>类。源码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DetectionModel</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    <span class="hljs-comment"># YOLOv5 检测模型</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, cfg=<span class="hljs-string">&quot;yolov5s.yaml&quot;</span>, ch=<span class="hljs-number">3</span>, nc=<span class="hljs-literal">None</span>, anchors=<span class="hljs-literal">None</span></span>):  <span class="hljs-comment"># model, input channels, number of classes</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(cfg, <span class="hljs-built_in">dict</span>):<br>            self.yaml = cfg  <span class="hljs-comment"># 模型字典</span><br>        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># yaml文件</span><br>            <span class="hljs-keyword">import</span> yaml  <span class="hljs-comment"># for torch hub</span><br><br>            self.yaml_file = Path(cfg).name<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(cfg, encoding=<span class="hljs-string">&quot;ascii&quot;</span>, errors=<span class="hljs-string">&quot;ignore&quot;</span>) <span class="hljs-keyword">as</span> f:<br>                self.yaml = yaml.safe_load(f)  <span class="hljs-comment"># model dict</span><br><br>        <span class="hljs-comment"># 定义模型</span><br>        ch = self.yaml[<span class="hljs-string">&quot;ch&quot;</span>] = self.yaml.get(<span class="hljs-string">&quot;ch&quot;</span>, ch)  <span class="hljs-comment"># 从模型的yaml文件中拿到input channels</span><br>        <span class="hljs-keyword">if</span> nc <span class="hljs-keyword">and</span> nc != self.yaml[<span class="hljs-string">&quot;nc&quot;</span>]:<br>            LOGGER.info(<span class="hljs-string">f&quot;Overriding model.yaml nc=<span class="hljs-subst">&#123;self.yaml[<span class="hljs-string">&#x27;nc&#x27;</span>]&#125;</span> with nc=<span class="hljs-subst">&#123;nc&#125;</span>&quot;</span>)<br>            self.yaml[<span class="hljs-string">&quot;nc&quot;</span>] = nc  <span class="hljs-comment"># 覆写yaml value</span><br>        <span class="hljs-keyword">if</span> anchors:<br>            LOGGER.info(<span class="hljs-string">f&quot;Overriding model.yaml anchors with anchors=<span class="hljs-subst">&#123;anchors&#125;</span>&quot;</span>)<br>            self.yaml[<span class="hljs-string">&quot;anchors&quot;</span>] = <span class="hljs-built_in">round</span>(anchors)  <span class="hljs-comment"># 使用hyp的anchors覆写yaml的anchors</span><br>        self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  <span class="hljs-comment"># model, savelist</span><br>        self.names = [<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.yaml[<span class="hljs-string">&quot;nc&quot;</span>])]  <span class="hljs-comment"># default names</span><br>        self.inplace = self.yaml.get(<span class="hljs-string">&quot;inplace&quot;</span>, <span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment"># Build strides, anchors</span><br>        m = self.model[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># Detect()</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, (Detect, Segment)):<br>            s = <span class="hljs-number">256</span>  <span class="hljs-comment"># 2x min stride</span><br>            m.inplace = self.inplace<br>            forward = <span class="hljs-keyword">lambda</span> x: self.forward(x)[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, Segment) <span class="hljs-keyword">else</span> self.forward(x)<br>            m.stride = torch.tensor([s / x.shape[-<span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> forward(torch.zeros(<span class="hljs-number">1</span>, ch, s, s))])  <span class="hljs-comment"># forward</span><br>            check_anchor_order(m)<br>            m.anchors /= m.stride.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>            self.stride = m.stride<br>            self._initialize_biases()  <span class="hljs-comment"># only run once</span><br><br>        <span class="hljs-comment"># Init weights, biases</span><br>        initialize_weights(self)<br>        self.info()<br>        LOGGER.info(<span class="hljs-string">&quot;&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, augment=<span class="hljs-literal">False</span>, profile=<span class="hljs-literal">False</span>, visualize=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-keyword">if</span> augment:<br>            <span class="hljs-keyword">return</span> self._forward_augment(x)  <span class="hljs-comment"># augmented inference, None</span><br>        <span class="hljs-keyword">return</span> self._forward_once(x, profile, visualize)  <span class="hljs-comment"># single-scale inference, train</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward_augment</span>(<span class="hljs-params">self, x</span>):<br>        img_size = x.shape[-<span class="hljs-number">2</span>:]  <span class="hljs-comment"># height, width</span><br>        s = [<span class="hljs-number">1</span>, <span class="hljs-number">0.83</span>, <span class="hljs-number">0.67</span>]  <span class="hljs-comment"># scales</span><br>        f = [<span class="hljs-literal">None</span>, <span class="hljs-number">3</span>, <span class="hljs-literal">None</span>]  <span class="hljs-comment"># flips (2-ud, 3-lr)</span><br>        y = []  <span class="hljs-comment"># outputs</span><br>        <span class="hljs-keyword">for</span> si, fi <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(s, f):<br>            xi = scale_img(x.flip(fi) <span class="hljs-keyword">if</span> fi <span class="hljs-keyword">else</span> x, si, gs=<span class="hljs-built_in">int</span>(self.stride.<span class="hljs-built_in">max</span>()))<br>            yi = self._forward_once(xi)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># forward</span><br>            yi = self._descale_pred(yi, fi, si, img_size)<br>            y.append(yi)<br>        y = self._clip_augmented(y)  <span class="hljs-comment"># clip augmented tails</span><br>        <span class="hljs-keyword">return</span> torch.cat(y, <span class="hljs-number">1</span>), <span class="hljs-literal">None</span>  <span class="hljs-comment"># augmented inference, train</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_descale_pred</span>(<span class="hljs-params">self, p, flips, scale, img_size</span>):<br>        <span class="hljs-comment"># de-scale predictions following augmented inference (inverse operation)</span><br>        <span class="hljs-keyword">if</span> self.inplace:<br>            p[..., :<span class="hljs-number">4</span>] /= scale  <span class="hljs-comment"># de-scale</span><br>            <span class="hljs-keyword">if</span> flips == <span class="hljs-number">2</span>:<br>                p[..., <span class="hljs-number">1</span>] = img_size[<span class="hljs-number">0</span>] - p[..., <span class="hljs-number">1</span>]  <span class="hljs-comment"># de-flip ud</span><br>            <span class="hljs-keyword">elif</span> flips == <span class="hljs-number">3</span>:<br>                p[..., <span class="hljs-number">0</span>] = img_size[<span class="hljs-number">1</span>] - p[..., <span class="hljs-number">0</span>]  <span class="hljs-comment"># de-flip lr</span><br>        <span class="hljs-keyword">else</span>:<br>            x, y, wh = p[..., <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / scale, p[..., <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / scale, p[..., <span class="hljs-number">2</span>:<span class="hljs-number">4</span>] / scale  <span class="hljs-comment"># de-scale</span><br>            <span class="hljs-keyword">if</span> flips == <span class="hljs-number">2</span>:<br>                y = img_size[<span class="hljs-number">0</span>] - y  <span class="hljs-comment"># de-flip ud</span><br>            <span class="hljs-keyword">elif</span> flips == <span class="hljs-number">3</span>:<br>                x = img_size[<span class="hljs-number">1</span>] - x  <span class="hljs-comment"># de-flip lr</span><br>            p = torch.cat((x, y, wh, p[..., <span class="hljs-number">4</span>:]), -<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> p<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_clip_augmented</span>(<span class="hljs-params">self, y</span>):<br>        <span class="hljs-comment"># Clip YOLOv5 augmented inference tails</span><br>        nl = self.model[-<span class="hljs-number">1</span>].nl  <span class="hljs-comment"># number of detection layers (P3-P5)</span><br>        g = <span class="hljs-built_in">sum</span>(<span class="hljs-number">4</span>**x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(nl))  <span class="hljs-comment"># grid points</span><br>        e = <span class="hljs-number">1</span>  <span class="hljs-comment"># exclude layer count</span><br>        i = (y[<span class="hljs-number">0</span>].shape[<span class="hljs-number">1</span>] // g) * <span class="hljs-built_in">sum</span>(<span class="hljs-number">4</span>**x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(e))  <span class="hljs-comment"># indices</span><br>        y[<span class="hljs-number">0</span>] = y[<span class="hljs-number">0</span>][:, :-i]  <span class="hljs-comment"># large</span><br>        i = (y[-<span class="hljs-number">1</span>].shape[<span class="hljs-number">1</span>] // g) * <span class="hljs-built_in">sum</span>(<span class="hljs-number">4</span> ** (nl - <span class="hljs-number">1</span> - x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(e))  <span class="hljs-comment"># indices</span><br>        y[-<span class="hljs-number">1</span>] = y[-<span class="hljs-number">1</span>][:, i:]  <span class="hljs-comment"># small</span><br>        <span class="hljs-keyword">return</span> y<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_initialize_biases</span>(<span class="hljs-params">self, cf=<span class="hljs-literal">None</span></span>): <br>        m = self.model[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># Detect() module</span><br>        <span class="hljs-keyword">for</span> mi, s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(m.m, m.stride):  <span class="hljs-comment"># from</span><br>            b = mi.bias.view(m.na, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># conv.bias(255) to (3,85)</span><br>            b.data[:, <span class="hljs-number">4</span>] += math.log(<span class="hljs-number">8</span> / (<span class="hljs-number">640</span> / s) ** <span class="hljs-number">2</span>)  <span class="hljs-comment"># obj (8 objects per 640 image)</span><br>            b.data[:, <span class="hljs-number">5</span> : <span class="hljs-number">5</span> + m.nc] += (<br>                math.log(<span class="hljs-number">0.6</span> / (m.nc - <span class="hljs-number">0.99999</span>)) <span class="hljs-keyword">if</span> cf <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> torch.log(cf / cf.<span class="hljs-built_in">sum</span>())<br>            )  <span class="hljs-comment"># cls</span><br>            mi.bias = torch.nn.Parameter(b.view(-<span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p><code>parse_model</code>方法的两个入参分别是<code>d</code>, <code>ch</code>。前者是模型字典，后者是输入通道数。它会遍历读取模型的文件，然后返回一个搭好的nn.Sequential()，也就是搭好的模型。</p><p>在加载模型后，可以对模型进一些调整：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">  <span class="hljs-comment"># 冻结层</span><br>  <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">  冻结模型层,设置冻结层名字即可</span><br><span class="hljs-string">  作用：冰冻一些层，就使得这些层在反向传播的时候不再更新权重,需要冻结的层,可以写在freeze列表中</span><br><span class="hljs-string">  freeze为命令行参数，默认为0，表示不冻结</span><br><span class="hljs-string">  &quot;&quot;&quot;</span>    <br><br>  freeze = [<span class="hljs-string">f&quot;model.<span class="hljs-subst">&#123;x&#125;</span>.&quot;</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> (freeze <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(freeze) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-built_in">range</span>(freeze[<span class="hljs-number">0</span>]))]  <span class="hljs-comment"># layers to freeze</span><br>  <br>  <span class="hljs-comment"># 遍历所有层</span><br>  <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> model.named_parameters():<br>  <span class="hljs-comment"># 为所有层的参数设置梯度</span><br>      v.requires_grad = <span class="hljs-literal">True</span>  <span class="hljs-comment"># train all layers</span><br><span class="hljs-comment"># 冻结训练的层，梯度不更新</span><br>      <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(x <span class="hljs-keyword">in</span> k <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> freeze):<br>          LOGGER.info(<span class="hljs-string">f&quot;freezing <span class="hljs-subst">&#123;k&#125;</span>&quot;</span>)<br>          v.requires_grad = <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p>模型设置完就是设置一些训练参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 图片大小/batch size设置</span><br><span class="hljs-comment"># 获取模型总步长和模型输入图片分辨率</span><br>gs = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">int</span>(model.stride.<span class="hljs-built_in">max</span>()), <span class="hljs-number">32</span>)  <span class="hljs-comment"># grid size (max stride)</span><br><span class="hljs-comment"># 检查输入图片分辨率是否能被32整除</span><br>imgsz = check_img_size(opt.imgsz, gs, floor=gs * <span class="hljs-number">2</span>)  <span class="hljs-comment"># verify imgsz is gs-multiple</span><br><br><span class="hljs-comment"># 设置Batch size</span><br><span class="hljs-keyword">if</span> RANK == -<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> batch_size == -<span class="hljs-number">1</span>:  <span class="hljs-comment"># single-GPU only, estimate best batch size</span><br>    <span class="hljs-comment"># 确保batch size满足要求</span><br>    batch_size = check_train_batch_size(model, imgsz, amp)<br>    loggers.on_params_update(&#123;<span class="hljs-string">&quot;batch_size&quot;</span>: batch_size&#125;)<br><br><span class="hljs-comment"># 优化器设置/分组优化设置</span><br>nbs = <span class="hljs-number">64</span>  <span class="hljs-comment"># nominal batch size</span><br>accumulate = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">round</span>(nbs / batch_size), <span class="hljs-number">1</span>)  <span class="hljs-comment"># accumulate loss before optimizing</span><br><br><span class="hljs-comment"># 根据accumulate设置权重衰减参数，防止过拟合</span><br>hyp[<span class="hljs-string">&quot;weight_decay&quot;</span>] *= batch_size * accumulate / nbs  <span class="hljs-comment"># scale weight_decay</span><br></code></pre></td></tr></table></figure><p>这里有几个参数需要注意：</p><ul><li><p><code>nbs</code>: nominal batch size，名义上的batch_size。这里的nbs跟命令行参数中的batch_size不同，命令行中的batch_size默认为16，nbs设置为64。</p></li><li><p><code>accumulate</code>: 累计次数，在这里 nbs&#x2F;batch_size（64&#x2F;16）计算出 opt.batch_size输入多少批才达到nbs的水平。简单来说，nbs为64，代表想要达到的batch_size，这里的数值是64；batch_size为opt.batch_size，这里的数值是16。64&#x2F;16等于4，也就是opt.batch_size需要输入4批才能达到nbs，accumulate等于4。(round表示四舍五入取整数，而max表示accumulate不能低于1。)</p></li><li><p>当给模型喂了4批图片数据后，将四批图片数据得到的梯度值，做累积。当每累积到4批数据时，才会对参数做更新，这样就实现了与batch_size&#x3D;64时相同的效果。</p></li><li><p>最后还要做权重参数的缩放，因为batch_size发生了变化，所有权重参数也要做相应的缩放。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 设置优化器</span><br>optimizer = smart_optimizer(model, opt.optimizer, hyp[<span class="hljs-string">&quot;lr0&quot;</span>], hyp[<span class="hljs-string">&quot;momentum&quot;</span>], hyp[<span class="hljs-string">&quot;weight_decay&quot;</span>])<br><br><span class="hljs-comment"># 学习率/EMA/归一化</span><br><span class="hljs-comment"># 是否选择余弦退火学习率</span><br><span class="hljs-keyword">if</span> opt.cos_lr:<br>    lf = one_cycle(<span class="hljs-number">1</span>, hyp[<span class="hljs-string">&quot;lrf&quot;</span>], epochs)  <span class="hljs-comment"># cosine 1-&gt;hyp[&#x27;lrf&#x27;]</span><br><span class="hljs-keyword">else</span>:<br><span class="hljs-comment"># 线性学习率，通过线性插值的方式调整学习率</span><br>    lf = <span class="hljs-keyword">lambda</span> x: (<span class="hljs-number">1</span> - x / epochs) * (<span class="hljs-number">1.0</span> - hyp[<span class="hljs-string">&quot;lrf&quot;</span>]) + hyp[<span class="hljs-string">&quot;lrf&quot;</span>]  <span class="hljs-comment"># linear</span><br>scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)  <span class="hljs-comment"># plot_lr_scheduler(optimizer, scheduler, epochs)</span><br></code></pre></td></tr></table></figure><p>训练前最后准备：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python">   <span class="hljs-comment"># EMA （指数移动平均），考虑历史值对参数的影响，目的是为了收敛的曲线更加平滑</span><br>   <span class="hljs-comment"># 为模型创建EMA指数滑动平均,如果GPU进程数大于1,则不创建</span><br>   ema = ModelEMA(model) <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> &#123;-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125; <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br><br>   <span class="hljs-comment"># Resume 断点续训</span><br>   <span class="hljs-comment"># 断点续训其实就是把上次训练结束的模型作为预训练模型，并从中加载参数</span><br>   best_fitness, start_epoch = <span class="hljs-number">0.0</span>, <span class="hljs-number">0</span><br>   <br>   <span class="hljs-comment"># 如果有预训练</span><br>   <span class="hljs-keyword">if</span> pretrained:<br>       <span class="hljs-keyword">if</span> resume:<br>       <span class="hljs-comment"># Epochs 加载训练的迭代次数</span><br>       <span class="hljs-comment"># start_epoch是从上次的epoch接着训练</span><br>           best_fitness, start_epoch, epochs = smart_resume(ckpt, optimizer, ema, weights, epochs, resume)<br>       <span class="hljs-comment"># 将预训练的相关参数从内存中删除</span><br>       <span class="hljs-keyword">del</span> ckpt, csd<br><br>   <span class="hljs-comment"># DP mode 使用单机多卡模式训练，目前一般不使用</span><br>   <span class="hljs-comment"># rank为进程编号。如果rank=-1且gpu数量&gt;1则使用DataParallel单机多卡模式，效果并不好（分布不平均）</span><br>   <span class="hljs-comment"># rank=-1且gpu数量=1时,不会进行分布式</span><br>   <span class="hljs-keyword">if</span> cuda <span class="hljs-keyword">and</span> RANK == -<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> torch.cuda.device_count() &gt; <span class="hljs-number">1</span>:<br>       LOGGER.warning(<br>           <span class="hljs-string">&quot;WARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n&quot;</span><br>           <span class="hljs-string">&quot;See Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.&quot;</span><br>       )<br>       model = torch.nn.DataParallel(model)<br><br><span class="hljs-comment"># SyncBatchNorm  多卡的BN归一化</span><br>   <span class="hljs-keyword">if</span> opt.sync_bn <span class="hljs-keyword">and</span> cuda <span class="hljs-keyword">and</span> RANK != -<span class="hljs-number">1</span>:<br>       model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)<br>       LOGGER.info(<span class="hljs-string">&quot;Using SyncBatchNorm()&quot;</span>)<br></code></pre></td></tr></table></figure><p>总结一下，加载模型这边主要做了四件事：</p><p>（1）载入模型：载入模型(预训练&#x2F;不预训练) + 检查数据集 + 设置数据集路径参数(train_path、test_path) + 设置冻结层</p><p>（2）优化器：参数设置(<code>nbs</code>、<code>accumulate</code>、<code>hyp[&#39;weight_decay&#39;]</code>) + 分组优化(pg0、pg1、pg2) + 选择优化器 + 为三个优化器选择优化方式 + 删除变量</p><p>（3）学习率：线性学习率 + one cycle学习率 + 实例化 scheduler + 画出学习率变化曲线</p><p>（4）训练前最后准备：EMA + 断点续训+ 迭代次数的加载 + DP + SyncBatchNorm）</p><p>加载数据集:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Trainloader 数据加载/Anchor调整</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">返回一个训练数据加载器，一个数据集对象:</span><br><span class="hljs-string">训练数据加载器是一个可迭代的对象，可以通过for循环加载1个batch_size的数据</span><br><span class="hljs-string">数据集对象包括数据集的一些参数，包括所有标签值、所有的训练数据路径、每张图片的尺寸等等</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>train_loader, dataset = create_dataloader(<br>    train_path,<br>    imgsz,<br>    batch_size // WORLD_SIZE,<br>    gs,<br>    single_cls,<br>    hyp=hyp,<br>    augment=<span class="hljs-literal">True</span>,<br>    cache=<span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> opt.cache == <span class="hljs-string">&quot;val&quot;</span> <span class="hljs-keyword">else</span> opt.cache,<br>    rect=opt.rect,<br>    rank=LOCAL_RANK,<br>    workers=workers,<br>    image_weights=opt.image_weights,<br>    quad=opt.quad,<br>    prefix=colorstr(<span class="hljs-string">&quot;train: &quot;</span>),<br>    shuffle=<span class="hljs-literal">True</span>,<br>    seed=opt.seed,<br>)<br>labels = np.concatenate(dataset.labels, <span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 标签编号最大值</span><br>mlc = <span class="hljs-built_in">int</span>(labels[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">max</span>())  <span class="hljs-comment"># max label class</span><br><br><span class="hljs-comment"># 如果小于类别数则表示有问题</span><br><span class="hljs-keyword">assert</span> mlc &lt; nc, <span class="hljs-string">f&quot;Label class <span class="hljs-subst">&#123;mlc&#125;</span> exceeds nc=<span class="hljs-subst">&#123;nc&#125;</span> in <span class="hljs-subst">&#123;data&#125;</span>. Possible class labels are 0-<span class="hljs-subst">&#123;nc - <span class="hljs-number">1</span>&#125;</span>&quot;</span><br><br><span class="hljs-comment"># Process 0 验证集数据集加载</span><br><span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> &#123;-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;:<br>    val_loader = create_dataloader(<br>        val_path,<br>        imgsz,<br>        batch_size // WORLD_SIZE * <span class="hljs-number">2</span>,<br>        gs,<br>        single_cls,<br>        hyp=hyp,<br>        cache=<span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> noval <span class="hljs-keyword">else</span> opt.cache,<br>        rect=<span class="hljs-literal">True</span>,<br>        rank=-<span class="hljs-number">1</span>,<br>        workers=workers * <span class="hljs-number">2</span>,<br>        pad=<span class="hljs-number">0.5</span>,<br>        prefix=colorstr(<span class="hljs-string">&quot;val: &quot;</span>),<br>    )[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><p>Anchor锚框计算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 如果没有断点续传</span><br>      <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> resume:<br>      <span class="hljs-comment"># Anchors 计算默认锚框anchor与数据集标签框的高宽比</span><br>          <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.noautoanchor:<br>          <span class="hljs-comment"># 进行自动锚框设置</span><br>              check_anchors(dataset, model=model, thr=hyp[<span class="hljs-string">&quot;anchor_t&quot;</span>], imgsz=imgsz)  <span class="hljs-comment"># run AutoAnchor</span><br>              <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">              参数dataset代表的是训练集，hyp[&#x27;anchor_t&#x27;]是从配置文件hpy.scratch.yaml读取的超参数，anchor_t:4.0</span><br><span class="hljs-string">              当配置文件中的anchor计算bpr（best possible recall）小于0.98时才会重新计算anchor。</span><br><span class="hljs-string">              best possible recall最大值1，如果bpr小于0.98，程序会根据数据集的label自动学习anchor的尺寸</span><br><span class="hljs-string">              &#x27;&#x27;&#x27;</span><br>          <span class="hljs-comment"># 模型半精度</span><br>          model.half().<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># pre-reduce anchor precision</span><br><span class="hljs-comment"># 在每个训练前例行程序结束时触发所有已注册的回调</span><br>      callbacks.run(<span class="hljs-string">&quot;on_pretrain_routine_end&quot;</span>, labels, names)<br><br>  <span class="hljs-comment"># 训练配置/多尺度训练/热身训练</span><br>  <span class="hljs-keyword">if</span> cuda <span class="hljs-keyword">and</span> RANK != -<span class="hljs-number">1</span>:<br>      model = smart_DDP(model)<br></code></pre></td></tr></table></figure><p>现在进入训练过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型初始化</span><br>   <span class="hljs-comment"># Model attributes 根据自己数据集的类别数和网络FPN层数设置各个损失的系数</span><br>   nl = de_parallel(model).model[-<span class="hljs-number">1</span>].nl  <span class="hljs-comment"># number of detection layers (to scale hyps)</span><br>   <span class="hljs-comment"># box为预测框的损失</span><br>   hyp[<span class="hljs-string">&quot;box&quot;</span>] *= <span class="hljs-number">3</span> / nl  <span class="hljs-comment"># scale to layers</span><br>   <span class="hljs-comment"># cls为分类的损失</span><br>   hyp[<span class="hljs-string">&quot;cls&quot;</span>] *= nc / <span class="hljs-number">80</span> * <span class="hljs-number">3</span> / nl  <span class="hljs-comment"># scale to classes and layers</span><br>   <span class="hljs-comment"># obj为置信度损失</span><br>   hyp[<span class="hljs-string">&quot;obj&quot;</span>] *= (imgsz / <span class="hljs-number">640</span>) ** <span class="hljs-number">2</span> * <span class="hljs-number">3</span> / nl  <span class="hljs-comment"># scale to image size and layers</span><br>   <span class="hljs-comment"># 标签平滑</span><br>   hyp[<span class="hljs-string">&quot;label_smoothing&quot;</span>] = opt.label_smoothing<br>   <span class="hljs-comment"># 设置模型的类别，然后将检测的类别个数保存到模型</span><br>   model.nc = nc  <br>   <span class="hljs-comment"># 设置模型的超参数，然后将超参数保存到模型</span><br>   model.hyp = hyp  <br>   <span class="hljs-comment"># 从训练的样本标签得到类别权重，然后将类别权重保存至模型</span><br>   model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  <span class="hljs-comment"># attach class weights</span><br>   <span class="hljs-comment"># 获取类别的名字，然后将分类标签保存至模型</span><br>   model.names = names<br></code></pre></td></tr></table></figure><p>训练热身部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Start training</span><br>t0 = time.time()<br><span class="hljs-comment"># Batch数量</span><br>nb = <span class="hljs-built_in">len</span>(train_loader)  <span class="hljs-comment"># number of batches</span><br><span class="hljs-comment"># 获取热身训练的迭代次数</span><br>nw = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">round</span>(hyp[<span class="hljs-string">&quot;warmup_epochs&quot;</span>] * nb), <span class="hljs-number">100</span>)  <span class="hljs-comment"># number of warmup iterations, max(3 epochs, 100 iterations)</span><br><span class="hljs-comment"># nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to &lt; 1/2 of training</span><br>last_opt_step = -<span class="hljs-number">1</span><br><br><span class="hljs-comment"># 初始化 map和result，每个class都为0</span><br>maps = np.zeros(nc)  <span class="hljs-comment"># mAP per class</span><br>results = (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)  <span class="hljs-comment"># P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)</span><br><span class="hljs-comment"># 设置学习率衰减所进行到的轮次，即使打断训练，使用resume接着训练也能正常衔接之前的训练进行学习率衰减</span><br>scheduler.last_epoch = start_epoch - <span class="hljs-number">1</span>  <span class="hljs-comment"># do not move</span><br><span class="hljs-comment"># 设置amp混合精度训练</span><br>scaler = torch.cuda.amp.GradScaler(enabled=amp)<br><span class="hljs-comment"># 早停，不更新结束训练</span><br>stopper, stop = EarlyStopping(patience=opt.patience), <span class="hljs-literal">False</span><br><span class="hljs-comment"># 初始化损失函数</span><br>compute_loss = ComputeLoss(model)  <span class="hljs-comment"># init loss class</span><br>callbacks.run(<span class="hljs-string">&quot;on_train_start&quot;</span>)<br>LOGGER.info(<br>    <span class="hljs-string">f&#x27;Image sizes <span class="hljs-subst">&#123;imgsz&#125;</span> train, <span class="hljs-subst">&#123;imgsz&#125;</span> val\n&#x27;</span><br>    <span class="hljs-string">f&#x27;Using <span class="hljs-subst">&#123;train_loader.num_workers * WORLD_SIZE&#125;</span> dataloader workers\n&#x27;</span><br>    <span class="hljs-string">f&quot;Logging results to <span class="hljs-subst">&#123;colorstr(<span class="hljs-string">&#x27;bold&#x27;</span>, save_dir)&#125;</span>\n&quot;</span><br>    <span class="hljs-string">f&#x27;Starting training for <span class="hljs-subst">&#123;epochs&#125;</span> epochs...&#x27;</span><br>)<br></code></pre></td></tr></table></figure><p>开始训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start_epoch, epochs):  <span class="hljs-comment"># epoch ------------------------------------------------------------------</span><br>    callbacks.run(<span class="hljs-string">&quot;on_train_epoch_start&quot;</span>)<br>    model.train()<br><br>    <span class="hljs-comment"># Update image weights (optional, single-GPU only)</span><br>    <span class="hljs-comment"># 获取图片采样的权重</span><br>    <span class="hljs-keyword">if</span> opt.image_weights:<br>    <span class="hljs-comment"># 经过一轮训练，若哪一类的不精确度高，那么这个类就会被分配一个较高的权重，来增加它被采样的概率</span><br>        cw = model.class_weights.cpu().numpy() * (<span class="hljs-number">1</span> - maps) ** <span class="hljs-number">2</span> / nc  <span class="hljs-comment"># class weights</span><br>        <span class="hljs-comment"># 将计算出的权重换算到图片的维度，将类别的权重换算为图片的权重</span><br>        iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  <span class="hljs-comment"># image weights</span><br>        <span class="hljs-comment"># 通过random.choices生成图片索引indices从而进行采样，这时图像会包含一些难识别的样本</span><br>        dataset.indices = random.choices(<span class="hljs-built_in">range</span>(dataset.n), weights=iw, k=dataset.n)  <span class="hljs-comment"># rand weighted idx</span><br></code></pre></td></tr></table></figure><p>上面这段代码主要在做两件事：</p><ol><li>模型训练</li><li>更新图片权重：有些类的准确率难以识别，准确率并不会很高。在更新图片权重时就会把这些难以识别的类挑出来，并为这个类产生一些权重高的图片，以这种方式来增加识别率低的类别的数据量。提高准确率。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">mloss = torch.zeros(<span class="hljs-number">3</span>, device=device)  <span class="hljs-comment"># mean losses</span><br><span class="hljs-comment"># 分布式训练的设置</span><br><span class="hljs-comment"># DDP模式打乱数据，并且dpp.sampler的随机采样数据是基于epoch+seed作为随机种子，每次epoch不同，随机种子不同</span><br><span class="hljs-keyword">if</span> RANK != -<span class="hljs-number">1</span>:<br>    train_loader.sampler.set_epoch(epoch)<br>    <br><span class="hljs-comment"># 将训练数据迭代器做枚举，可以遍历出索引值</span><br>pbar = <span class="hljs-built_in">enumerate</span>(train_loader)<br>LOGGER.info((<span class="hljs-string">&quot;\n&quot;</span> + <span class="hljs-string">&quot;%11s&quot;</span> * <span class="hljs-number">7</span>) % (<span class="hljs-string">&quot;Epoch&quot;</span>, <span class="hljs-string">&quot;GPU_mem&quot;</span>, <span class="hljs-string">&quot;box_loss&quot;</span>, <span class="hljs-string">&quot;obj_loss&quot;</span>, <span class="hljs-string">&quot;cls_loss&quot;</span>, <span class="hljs-string">&quot;Instances&quot;</span>, <span class="hljs-string">&quot;Size&quot;</span>))<br><span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> &#123;-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;:<br><span class="hljs-comment"># 通过tqdm创建进度条，方便训练信息的展示</span><br>    pbar = tqdm(pbar, total=nb, bar_format=TQDM_BAR_FORMAT)  <span class="hljs-comment"># progress bar</span><br><span class="hljs-comment"># 优化器中所有参数清零</span><br>optimizer.zero_grad()<br></code></pre></td></tr></table></figure><p>接下来是对单个Batch的训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i, (imgs, targets, paths, _) <span class="hljs-keyword">in</span> pbar:  <span class="hljs-comment"># batch -------------------------------------------------------------</span><br>    callbacks.run(<span class="hljs-string">&quot;on_train_batch_start&quot;</span>)<br>    <span class="hljs-comment"># ni: 计算当前迭代次数 iteration</span><br>    ni = i + nb * epoch  <span class="hljs-comment"># number integrated batches (since train start)</span><br>    <span class="hljs-comment"># 将图片加载至设备 并做归一化</span><br>    imgs = imgs.to(device, non_blocking=<span class="hljs-literal">True</span>).<span class="hljs-built_in">float</span>() / <span class="hljs-number">255</span>  <span class="hljs-comment"># uint8 to float32, 0-255 to 0.0-1.0</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    热身训练(前nw次迭代),热身训练迭代的次数iteration范围[1:nw] </span><br><span class="hljs-string">    在前nw次迭代中, 根据以下方式选取accumulate和学习率</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># Warmup</span><br>    <span class="hljs-keyword">if</span> ni &lt;= nw:<br>        xi = [<span class="hljs-number">0</span>, nw]  <span class="hljs-comment"># x interp</span><br>        <span class="hljs-comment"># compute_loss.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)</span><br>        accumulate = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, np.interp(ni, xi, [<span class="hljs-number">1</span>, nbs / batch_size]).<span class="hljs-built_in">round</span>())<br>        <br>        <span class="hljs-comment"># 遍历优化器中的所有参数组</span><br>        <span class="hljs-keyword">for</span> j, x <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(optimizer.param_groups):<br>            <span class="hljs-comment"># bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0</span><br>            <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">            bias的学习率从0.1下降到基准学习率lr*lf(epoch)，</span><br><span class="hljs-string">            其他的参数学习率从0增加到lr*lf(epoch).</span><br><span class="hljs-string">            lf为上面设置的余弦退火的衰减函数</span><br><span class="hljs-string">            &quot;&quot;&quot;</span><br>            x[<span class="hljs-string">&quot;lr&quot;</span>] = np.interp(ni, xi, [hyp[<span class="hljs-string">&quot;warmup_bias_lr&quot;</span>] <span class="hljs-keyword">if</span> j == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>, x[<span class="hljs-string">&quot;initial_lr&quot;</span>] * lf(epoch)])<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;momentum&quot;</span> <span class="hljs-keyword">in</span> x:<br>                x[<span class="hljs-string">&quot;momentum&quot;</span>] = np.interp(ni, xi, [hyp[<span class="hljs-string">&quot;warmup_momentum&quot;</span>], hyp[<span class="hljs-string">&quot;momentum&quot;</span>]])<br><br>    <span class="hljs-comment"># Multi-scale 设置多尺度训练，从imgsz * 0.5, imgsz * 1.5 + gs随机选取尺寸</span><br>    <span class="hljs-comment"># imgsz: 默认训练尺寸   gs: 模型最大stride=32   [32 16 8]       </span><br>    <span class="hljs-keyword">if</span> opt.multi_scale:<br>        sz = random.randrange(<span class="hljs-built_in">int</span>(imgsz * <span class="hljs-number">0.5</span>), <span class="hljs-built_in">int</span>(imgsz * <span class="hljs-number">1.5</span>) + gs) // gs * gs  <span class="hljs-comment"># size</span><br>        sf = sz / <span class="hljs-built_in">max</span>(imgs.shape[<span class="hljs-number">2</span>:])  <span class="hljs-comment"># scale factor</span><br>        <span class="hljs-keyword">if</span> sf != <span class="hljs-number">1</span>:<br>            ns = [math.ceil(x * sf / gs) * gs <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> imgs.shape[<span class="hljs-number">2</span>:]]  <span class="hljs-comment"># new shape (stretched to gs-multiple)</span><br>            <span class="hljs-comment"># 下采样</span><br>            imgs = nn.functional.interpolate(imgs, size=ns, mode=<span class="hljs-string">&quot;bilinear&quot;</span>, align_corners=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>前向传播：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python">    <span class="hljs-comment"># Forward</span><br>    <span class="hljs-keyword">with</span> torch.cuda.amp.autocast(amp):<br>    <span class="hljs-comment"># 推理</span><br>        pred = model(imgs)  <span class="hljs-comment"># forward</span><br>        <span class="hljs-comment"># 计算三个损失：分类损失，置信度损失，框损失</span><br>        loss, loss_items = compute_loss(pred, targets.to(device))  <span class="hljs-comment"># loss scaled by batch_size</span><br>        <span class="hljs-keyword">if</span> RANK != -<span class="hljs-number">1</span>:<br>        <br>        <span class="hljs-comment"># 采用DDP训练,平均不同gpu之间的梯度</span><br>            loss *= WORLD_SIZE  <span class="hljs-comment"># gradient averaged between devices in DDP mode</span><br>        <span class="hljs-keyword">if</span> opt.quad:<br>            loss *= <span class="hljs-number">4.0</span><br><br>    <span class="hljs-comment"># Backward 反向传播 scale为使用自动混合精度运算</span><br>    scaler.scale(loss).backward()<br><br>    <span class="hljs-comment"># Optimize </span><br>    <span class="hljs-comment"># 模型会对多批数据进行累积，只有达到累计次数的时候才会更新参数，再还没有达到累积次数时 loss会不断的叠加 不会被新的反向传播替代</span><br>    <span class="hljs-keyword">if</span> ni - last_opt_step &gt;= accumulate:      <br>        scaler.unscale_(optimizer)  <span class="hljs-comment"># unscale gradients</span><br>        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="hljs-number">10.0</span>)  <span class="hljs-comment"># clip gradients</span><br>        <br>        <span class="hljs-comment"># 参数更新</span><br>        scaler.step(optimizer)  <span class="hljs-comment"># optimizer.step</span><br>        scaler.update()<br>        <br>        <span class="hljs-comment"># 梯度清零</span><br>        optimizer.zero_grad()<br>        <span class="hljs-keyword">if</span> ema:<br>            ema.update(model)<br>        <br>        <span class="hljs-comment"># 计数</span><br>        last_opt_step = ni<br><br>    <span class="hljs-comment"># Log</span><br>    <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> &#123;-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;:<br>        mloss = (mloss * i + loss_items) / (i + <span class="hljs-number">1</span>)  <span class="hljs-comment"># update mean losses</span><br>        mem = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;torch.cuda.memory_reserved() / <span class="hljs-number">1E9</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>:<span class="hljs-number">.3</span>g&#125;</span>G&quot;</span>  <span class="hljs-comment"># (GB)</span><br>        pbar.set_description(<br>            (<span class="hljs-string">&quot;%11s&quot;</span> * <span class="hljs-number">2</span> + <span class="hljs-string">&quot;%11.4g&quot;</span> * <span class="hljs-number">5</span>)<br>            % (<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;epoch&#125;</span>/<span class="hljs-subst">&#123;epochs - <span class="hljs-number">1</span>&#125;</span>&quot;</span>, mem, *mloss, targets.shape[<span class="hljs-number">0</span>], imgs.shape[-<span class="hljs-number">1</span>])<br>        )<br>        callbacks.run(<span class="hljs-string">&quot;on_train_batch_end&quot;</span>, model, ni, imgs, targets, paths, <span class="hljs-built_in">list</span>(mloss))<br>        <span class="hljs-keyword">if</span> callbacks.stop_training:<br>            <span class="hljs-keyword">return</span><br>    <span class="hljs-comment"># end batch ------------------------------------------------------------------------------------------------</span><br><br><span class="hljs-comment"># 进行学习率衰减</span><br>lr = [x[<span class="hljs-string">&quot;lr&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> optimizer.param_groups]  <span class="hljs-comment"># for loggers</span><br>scheduler.step()<br></code></pre></td></tr></table></figure><p>模型保存：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> &#123;-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;:<br>    <span class="hljs-comment"># mAP</span><br>    callbacks.run(<span class="hljs-string">&quot;on_train_epoch_end&quot;</span>, epoch=epoch)<br>    <br>    <span class="hljs-comment"># 将model中的属性赋值给ema</span><br>    ema.update_attr(model, include=[<span class="hljs-string">&quot;yaml&quot;</span>, <span class="hljs-string">&quot;nc&quot;</span>, <span class="hljs-string">&quot;hyp&quot;</span>, <span class="hljs-string">&quot;names&quot;</span>, <span class="hljs-string">&quot;stride&quot;</span>, <span class="hljs-string">&quot;class_weights&quot;</span>])<br>    <br>    <span class="hljs-comment"># 判断当前epoch是否是最后一轮</span><br>    final_epoch = (epoch + <span class="hljs-number">1</span> == epochs) <span class="hljs-keyword">or</span> stopper.possible_stop<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> noval <span class="hljs-keyword">or</span> final_epoch:  <span class="hljs-comment"># Calculate mAP</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        测试使用的是ema（指数移动平均 对模型的参数做平均）的模型</span><br><span class="hljs-string">               results: [1] Precision 所有类别的平均precision(最大f1时)</span><br><span class="hljs-string">                        [1] Recall 所有类别的平均recall</span><br><span class="hljs-string">                        [1] map@0.5 所有类别的平均mAP@0.5</span><br><span class="hljs-string">                        [1] map@0.5:0.95 所有类别的平均mAP@0.5:0.95</span><br><span class="hljs-string">                        [1] box_loss 验证集回归损失, obj_loss 验证集置信度损失, cls_loss 验证集分类损失</span><br><span class="hljs-string">               maps: [80] 所有类别的mAP@0.5:0.95</span><br><span class="hljs-string">        &quot;&quot;&quot;</span>            <br>        results, maps, _ = validate.run(<br>            data_dict, <span class="hljs-comment"># 数据集配置文件地址 包含数据集的路径、类别个数、类名、下载地址等信息</span><br>            batch_size=batch_size // WORLD_SIZE * <span class="hljs-number">2</span>, <span class="hljs-comment"># 要保证batch_size能整除卡数</span><br>            imgsz=imgsz,<br>            half=amp,<br>            model=ema.ema,<br>            single_cls=single_cls,<br>            dataloader=val_loader,<br>            save_dir=save_dir,<br>            plots=<span class="hljs-literal">False</span>,<br>            callbacks=callbacks,<br>            compute_loss=compute_loss,<br>        )<br><br>    <span class="hljs-comment"># 更新best_fitness</span><br>    <span class="hljs-comment"># fi: [P, R, mAP@.5, mAP@.5-.95]的一个加权值 = 0.1*mAP@.5 + 0.9*mAP@.5-.95</span><br>    fi = fitness(np.array(results).reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>))  <br>    <span class="hljs-comment"># 检查是否早停</span><br>    stop = stopper(epoch=epoch, fitness=fi)  <span class="hljs-comment"># early stop check</span><br>    <br>    <span class="hljs-comment"># 若当前的fitness大于最佳的fitness</span><br>    <span class="hljs-keyword">if</span> fi &gt; best_fitness:<br>    <span class="hljs-comment"># 将最佳fitness更新为当前fitness</span><br>        best_fitness = fi<br>        <br>    <span class="hljs-comment"># 保存验证结果</span><br>    log_vals = <span class="hljs-built_in">list</span>(mloss) + <span class="hljs-built_in">list</span>(results) + lr<br>    callbacks.run(<span class="hljs-string">&quot;on_fit_epoch_end&quot;</span>, log_vals, epoch, best_fitness, fi)<br></code></pre></td></tr></table></figure><p>保存模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python">        <span class="hljs-comment"># Save model</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        保存带checkpoint的模型用于inference或resuming training</span><br><span class="hljs-string">        保存模型, 还保存了epoch, results, optimizer等信息</span><br><span class="hljs-string">        optimizer将不会在最后一轮完成后保存</span><br><span class="hljs-string">        model保存的是EMA的模型</span><br><span class="hljs-string">        &quot;&quot;&quot;</span>            <br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> nosave) <span class="hljs-keyword">or</span> (final_epoch <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> evolve):  <span class="hljs-comment"># if save</span><br>        <span class="hljs-comment"># 将当前训练过程中的所有参数赋值给ckpt</span><br>            ckpt = &#123;<br>                <span class="hljs-string">&quot;epoch&quot;</span>: epoch,<br>                <span class="hljs-string">&quot;best_fitness&quot;</span>: best_fitness,<br>                <span class="hljs-string">&quot;model&quot;</span>: deepcopy(de_parallel(model)).half(),<br>                <span class="hljs-string">&quot;ema&quot;</span>: deepcopy(ema.ema).half(),<br>                <span class="hljs-string">&quot;updates&quot;</span>: ema.updates,<br>                <span class="hljs-string">&quot;optimizer&quot;</span>: optimizer.state_dict(),<br>                <span class="hljs-string">&quot;opt&quot;</span>: <span class="hljs-built_in">vars</span>(opt),<br>                <span class="hljs-string">&quot;git&quot;</span>: GIT_INFO,  <span class="hljs-comment"># &#123;remote, branch, commit&#125; if a git repo</span><br>                <span class="hljs-string">&quot;date&quot;</span>: datetime.now().isoformat(),<br>            &#125;<br><br>            <span class="hljs-comment"># Save last, best and delete 保存每轮的模型</span><br>            torch.save(ckpt, last)<br>            <br>            <span class="hljs-comment"># 如果这个模型的fitness是最佳的</span><br>            <span class="hljs-keyword">if</span> best_fitness == fi:<br>                torch.save(ckpt, best)<br>            <span class="hljs-keyword">if</span> opt.save_period &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> epoch % opt.save_period == <span class="hljs-number">0</span>:<br>                torch.save(ckpt, w / <span class="hljs-string">f&quot;epoch<span class="hljs-subst">&#123;epoch&#125;</span>.pt&quot;</span>)<br>                <br>            <span class="hljs-comment"># 模型保存完毕 将变量从内存中删除</span><br>            <span class="hljs-keyword">del</span> ckpt<br>            callbacks.run(<span class="hljs-string">&quot;on_model_save&quot;</span>, last, epoch, final_epoch, best_fitness, fi)<br><br>    <span class="hljs-comment"># EarlyStopping</span><br>    <span class="hljs-keyword">if</span> RANK != -<span class="hljs-number">1</span>:  <span class="hljs-comment"># if DDP training</span><br>        broadcast_list = [stop <span class="hljs-keyword">if</span> RANK == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>]<br>        dist.broadcast_object_list(broadcast_list, <span class="hljs-number">0</span>)  <span class="hljs-comment"># broadcast &#x27;stop&#x27; to all ranks</span><br>        <span class="hljs-keyword">if</span> RANK != <span class="hljs-number">0</span>:<br>            stop = broadcast_list[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">if</span> stop:<br>        <span class="hljs-keyword">break</span>  <span class="hljs-comment"># must break all DDP ranks</span><br><br>    <span class="hljs-comment"># end epoch ----------------------------------------------------------------------------------------------------</span><br><span class="hljs-comment"># end training -----------------------------------------------------------------------------------------------------</span><br></code></pre></td></tr></table></figure><p>总结一下训练过程，同样分为四块：</p><p>（1）初始化训练需要的模型参数：设置&#x2F;初始化一些训练要用的参数(<code>hyp[&#39;box&#39;]</code>、<code>hyp[&#39;cls&#39;]</code>、<code>hyp[&#39;obj&#39;]</code>、<code>hyp[&#39;label_smoothing&#39;]</code>）+ 从训练样本标签得到类别权重<code>model.class_weights</code>、<code>model.names</code>。</p><p>（2）热身部分：热身迭代的次数<code>iterationsnw</code>、<code>last_opt_step</code>、初始化maps和results、学习率衰减所进行到的轮次<code>scheduler.last_epoch</code> + 设置amp混合精度训练<code>scaler</code> + 初始化损失函数<code>compute_loss</code> + 打印日志信息)</p><p>（3）开始训练：图片采样策略 + <code>Warmup</code>热身训练 + <code>multi_scale</code>多尺度训练 + amp混合精度训练 +  <code>accumulate</code> 梯度更新策略+ 打印训练相关信息(包括当前epoch、显存、损失(box、obj、cls、total) + 当前batch的target的数量和图片的size等  + 调整学习率、<code>scheduler.step()</code>、<code>emp val.run()</code>得到results, maps相关信息</p><p>（4）训练完成保存模型：将测试结果results写入日志，更新best mAP，以加权mAP fitness为衡量标准+保存模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练结束/打印信息/保存结果</span><br><span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> &#123;-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;:<br>    LOGGER.info(<span class="hljs-string">f&quot;\n<span class="hljs-subst">&#123;epoch - start_epoch + <span class="hljs-number">1</span>&#125;</span> epochs completed in <span class="hljs-subst">&#123;(time.time() - t0) / <span class="hljs-number">3600</span>:<span class="hljs-number">.3</span>f&#125;</span> hours.&quot;</span>)<br>    <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> last, best:<br>        <span class="hljs-keyword">if</span> f.exists():<br>            strip_optimizer(f)  <span class="hljs-comment"># strip optimizers</span><br>            <span class="hljs-keyword">if</span> f <span class="hljs-keyword">is</span> best:<br>                LOGGER.info(<span class="hljs-string">f&quot;\nValidating <span class="hljs-subst">&#123;f&#125;</span>...&quot;</span>)<br>                results, _, _ = validate.run(<br>                    data_dict,<br>                    batch_size=batch_size // WORLD_SIZE * <span class="hljs-number">2</span>,<br>                    imgsz=imgsz,<br>                    model=attempt_load(f, device).half(),<br>                    iou_thres=<span class="hljs-number">0.65</span> <span class="hljs-keyword">if</span> is_coco <span class="hljs-keyword">else</span> <span class="hljs-number">0.60</span>,  <span class="hljs-comment"># best pycocotools at iou 0.65</span><br>                    single_cls=single_cls,<br>                    dataloader=val_loader,<br>                    save_dir=save_dir,<br>                    save_json=is_coco,<br>                    verbose=<span class="hljs-literal">True</span>,<br>                    plots=plots,<br>                    callbacks=callbacks,<br>                    compute_loss=compute_loss,<br>                )  <span class="hljs-comment"># val best model with plots</span><br>                <span class="hljs-keyword">if</span> is_coco:<br>                    callbacks.run(<span class="hljs-string">&quot;on_fit_epoch_end&quot;</span>, <span class="hljs-built_in">list</span>(mloss) + <span class="hljs-built_in">list</span>(results) + lr, epoch, best_fitness, fi)<br><br>    callbacks.run(<span class="hljs-string">&quot;on_train_end&quot;</span>, last, best, epoch, results)<br><br>torch.cuda.empty_cache()<br><span class="hljs-keyword">return</span> results<br></code></pre></td></tr></table></figure><h1 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h1><p><code>parse_opt</code>函数主要负责解析一些命令行参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_opt</span>(<span class="hljs-params">known=<span class="hljs-literal">False</span></span>):<br>    parser = argparse.ArgumentParser()<br>    <span class="hljs-comment"># 预训练权重文件</span><br>    parser.add_argument(<span class="hljs-string">&quot;--weights&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&quot;yolov5s.pt&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;initial weights path&quot;</span>)<br>    <span class="hljs-comment"># 训练模型</span><br>    parser.add_argument(<span class="hljs-string">&quot;--cfg&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;model.yaml path&quot;</span>)<br>    <span class="hljs-comment"># 训练路径，包括训练集，验证集，测试集的路径，类别总数等</span><br>    parser.add_argument(<span class="hljs-string">&quot;--data&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&quot;data/coco128.yaml&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;dataset.yaml path&quot;</span>)<br>    <span class="hljs-comment"># hpy超参数设置文件</span><br>    parser.add_argument(<span class="hljs-string">&quot;--hyp&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&quot;data/hyps/hyp.scratch-low.yaml&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;hyperparameters path&quot;</span>)<br>    <span class="hljs-comment"># epochs: 训练轮次， 默认轮次为300次</span><br>    parser.add_argument(<span class="hljs-string">&quot;--epochs&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">100</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;total training epochs&quot;</span>)<br>    <span class="hljs-comment"># batchsize: 训练批次， 默认bs=16</span><br>    parser.add_argument(<span class="hljs-string">&quot;--batch-size&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">16</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;total batch size for all GPUs, -1 for autobatch&quot;</span>)<br>    <span class="hljs-comment"># imagesize: 设置图片大小, 默认640*640</span><br>    parser.add_argument(<span class="hljs-string">&quot;--imgsz&quot;</span>, <span class="hljs-string">&quot;--img&quot;</span>, <span class="hljs-string">&quot;--img-size&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">640</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;train, val image size (pixels)&quot;</span>)<br>    <span class="hljs-comment"># rect: 是否采用矩形训练，默认为False</span><br>    <span class="hljs-comment"># 矩形训练：将比例相近的图片放在一个batch</span><br>    parser.add_argument(<span class="hljs-string">&quot;--rect&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;rectangular training&quot;</span>)<br>    <span class="hljs-comment"># resume: 是否接着上次的训练结果，继续训练</span><br>    parser.add_argument(<span class="hljs-string">&quot;--resume&quot;</span>, nargs=<span class="hljs-string">&quot;?&quot;</span>, const=<span class="hljs-literal">True</span>, default=<span class="hljs-literal">False</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;resume most recent training&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--nosave&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;only save final checkpoint&quot;</span>)<br>    <span class="hljs-comment"># noval: 最后进行测试, 设置了之后就是训练结束都测试一下</span><br>    parser.add_argument(<span class="hljs-string">&quot;--noval&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;only validate final epoch&quot;</span>)<br>    <span class="hljs-comment"># noautoanchor: 不自动调整anchor, 默认False</span><br>    parser.add_argument(<span class="hljs-string">&quot;--noautoanchor&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;disable AutoAnchor&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--noplots&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save no plot files&quot;</span>)<br>    <span class="hljs-comment"># 进化策略轮次</span><br>    parser.add_argument(<span class="hljs-string">&quot;--evolve&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, nargs=<span class="hljs-string">&quot;?&quot;</span>, const=<span class="hljs-number">300</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;evolve hyperparameters for x generations&quot;</span>)<br>    parser.add_argument(<br>        <span class="hljs-string">&quot;--evolve_population&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&quot;data/hyps&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;location for loading population&quot;</span><br>    )<br>    parser.add_argument(<span class="hljs-string">&quot;--resume_evolve&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-literal">None</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;resume evolve from last generation&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--bucket&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;gsutil bucket&quot;</span>)<br>    <span class="hljs-comment"># cache: 是否提前缓存图片到内存，以加快训练速度</span><br>    parser.add_argument(<span class="hljs-string">&quot;--cache&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, nargs=<span class="hljs-string">&quot;?&quot;</span>, const=<span class="hljs-string">&quot;ram&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;image --cache ram/disk&quot;</span>)<br>    <span class="hljs-comment"># image-weights: 使用图片采样策略，默认不使用</span><br>    parser.add_argument(<span class="hljs-string">&quot;--image-weights&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;use weighted image selection for training&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--device&quot;</span>, default=<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;cuda device, i.e. 0 or 0,1,2,3 or cpu&quot;</span>)<br>    <span class="hljs-comment"># multi-scale 是否进行多尺度训练</span><br>    parser.add_argument(<span class="hljs-string">&quot;--multi-scale&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;vary img-size +/- 50%%&quot;</span>)<br>    <span class="hljs-comment"># single-cls: 数据集是否多类/默认True</span><br>    parser.add_argument(<span class="hljs-string">&quot;--single-cls&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;train multi-class data as single-class&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--optimizer&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, choices=[<span class="hljs-string">&quot;SGD&quot;</span>, <span class="hljs-string">&quot;Adam&quot;</span>, <span class="hljs-string">&quot;AdamW&quot;</span>], default=<span class="hljs-string">&quot;SGD&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;optimizer&quot;</span>)<br>    <span class="hljs-comment"># 同步BatchNorm</span><br>    parser.add_argument(<span class="hljs-string">&quot;--sync-bn&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;use SyncBatchNorm, only available in DDP mode&quot;</span>)<br>    <span class="hljs-comment"># dataloader的最大worker数量 （使用多线程加载图片）</span><br>    parser.add_argument(<span class="hljs-string">&quot;--workers&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">8</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;max dataloader workers (per RANK in DDP mode)&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--project&quot;</span>, default=ROOT / <span class="hljs-string">&quot;runs/train&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save to project/name&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--name&quot;</span>, default=<span class="hljs-string">&quot;exp&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save to project/name&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--exist-ok&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;existing project/name ok, do not increment&quot;</span>)<br>    <span class="hljs-comment"># 四元数据加载器: 允许在较低 --img 尺寸下进行更高 --img 尺寸训练</span><br>    parser.add_argument(<span class="hljs-string">&quot;--quad&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;quad dataloader&quot;</span>)<br>    <span class="hljs-comment"># cos-lr: 余弦学习率</span><br>    parser.add_argument(<span class="hljs-string">&quot;--cos-lr&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;cosine LR scheduler&quot;</span>)<br>    <span class="hljs-comment"># 标签平滑 / 默认不增强</span><br>    parser.add_argument(<span class="hljs-string">&quot;--label-smoothing&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.0</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Label smoothing epsilon&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--patience&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">100</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;EarlyStopping patience (epochs without improvement)&quot;</span>)<br>    <span class="hljs-comment"># freeze冻结训练</span><br>    parser.add_argument(<span class="hljs-string">&quot;--freeze&quot;</span>, nargs=<span class="hljs-string">&quot;+&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=[<span class="hljs-number">0</span>], <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Freeze layers: backbone=10, first3=0 1 2&quot;</span>)<br>    <span class="hljs-comment"># 多少个epoch保存一次</span><br>    parser.add_argument(<span class="hljs-string">&quot;--save-period&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=-<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Save checkpoint every x epochs (disabled if &lt; 1)&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--seed&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">0</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Global training seed&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--local_rank&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=-<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Automatic DDP Multi-GPU argument, do not modify&quot;</span>)<br><br>    <span class="hljs-comment"># Logger arguments</span><br>    parser.add_argument(<span class="hljs-string">&quot;--entity&quot;</span>, default=<span class="hljs-literal">None</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Entity&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--upload_dataset&quot;</span>, nargs=<span class="hljs-string">&quot;?&quot;</span>, const=<span class="hljs-literal">True</span>, default=<span class="hljs-literal">False</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Upload data, &quot;val&quot; option&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--bbox_interval&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=-<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Set bounding-box image logging interval&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--artifact_alias&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;latest&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Version of dataset artifact to use&quot;</span>)<br><br>    <span class="hljs-comment"># NDJSON logging</span><br>    parser.add_argument(<span class="hljs-string">&quot;--ndjson-console&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Log ndjson to console&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--ndjson-file&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Log ndjson to file&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> parser.parse_known_args()[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> known <span class="hljs-keyword">else</span> parser.parse_args()<br></code></pre></td></tr></table></figure><h1 id="Main函数"><a href="#Main函数" class="headerlink" title="Main函数"></a>Main函数</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">opt, callbacks=Callbacks(<span class="hljs-params"></span>)</span>):<br>    <span class="hljs-comment"># 检查分布式训练环境</span><br>    <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> &#123;-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;: <br>        print_args(<span class="hljs-built_in">vars</span>(opt)) <span class="hljs-comment"># 输出所有训练参数</span><br>        check_git_status() <span class="hljs-comment"># 检查yolo v5的官方仓库状态</span><br>        check_requirements(ROOT / <span class="hljs-string">&quot;requirements.txt&quot;</span>)<br><br>    <span class="hljs-comment"># 是否进行断点续传</span><br>    <span class="hljs-comment"># 如果resume是True，则通过get_lastest_run()函数找到runs为文件夹中最近的权重文件last.pt</span><br>    <span class="hljs-keyword">if</span> opt.resume <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> check_comet_resume(opt) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> opt.evolve:<br>        last = Path(check_file(opt.resume) <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(opt.resume, <span class="hljs-built_in">str</span>) <span class="hljs-keyword">else</span> get_latest_run())<br>        opt_yaml = last.parent.parent / <span class="hljs-string">&quot;opt.yaml&quot;</span>  <span class="hljs-comment"># train options yaml</span><br>        opt_data = opt.data  <span class="hljs-comment"># original dataset</span><br>        <span class="hljs-keyword">if</span> opt_yaml.is_file():<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(opt_yaml, errors=<span class="hljs-string">&quot;ignore&quot;</span>) <span class="hljs-keyword">as</span> f:<br>                d = yaml.safe_load(f)<br>        <span class="hljs-keyword">else</span>:<br>            d = torch.load(last, map_location=<span class="hljs-string">&quot;cpu&quot;</span>)[<span class="hljs-string">&quot;opt&quot;</span>]<br>        opt = argparse.Namespace(**d)  <span class="hljs-comment"># replace</span><br>        opt.cfg, opt.weights, opt.resume = <span class="hljs-string">&quot;&quot;</span>, <span class="hljs-built_in">str</span>(last), <span class="hljs-literal">True</span>  <span class="hljs-comment"># reinstate</span><br>        <span class="hljs-keyword">if</span> is_url(opt_data):<br>            opt.data = check_file(opt_data)  <span class="hljs-comment"># avoid HUB resume auth timeout</span><br>    <span class="hljs-keyword">else</span>:<br>        opt.data, opt.cfg, opt.hyp, opt.weights, opt.project = (<br>            check_file(opt.data),<br>            check_yaml(opt.cfg),<br>            check_yaml(opt.hyp),<br>            <span class="hljs-built_in">str</span>(opt.weights),<br>            <span class="hljs-built_in">str</span>(opt.project),<br>        )  <span class="hljs-comment"># 如果模型文件和权重文件为空，弹出警告</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(opt.cfg) <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(opt.weights), <span class="hljs-string">&quot;either --cfg or --weights must be specified&quot;</span><br>        <br>        <span class="hljs-comment"># 如果要进行超参数进化，重建保存路径</span><br>        <span class="hljs-keyword">if</span> opt.evolve:<br>        <span class="hljs-comment"># 设置新的项目输出目录</span><br>            <span class="hljs-keyword">if</span> opt.project == <span class="hljs-built_in">str</span>(ROOT / <span class="hljs-string">&quot;runs/train&quot;</span>):  <span class="hljs-comment"># if default project name, rename to runs/evolve</span><br>                opt.project = <span class="hljs-built_in">str</span>(ROOT / <span class="hljs-string">&quot;runs/evolve&quot;</span>)<br>            <span class="hljs-comment"># 将resume传递给exist_ok</span><br>            opt.exist_ok, opt.resume = opt.resume, <span class="hljs-literal">False</span>  <span class="hljs-comment"># pass resume to exist_ok and disable resume</span><br>        <span class="hljs-keyword">if</span> opt.name == <span class="hljs-string">&quot;cfg&quot;</span>:<br>            opt.name = Path(opt.cfg).stem  <span class="hljs-comment"># use model.yaml as name</span><br>           <br>        <span class="hljs-comment"># 根据opt.project生成目录，并赋值给opt.save_dir  如: runs/train/exp1</span><br>        opt.save_dir = <span class="hljs-built_in">str</span>(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))<br></code></pre></td></tr></table></figure><p>分布式训练的判断部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 分布式训练 DDP mode</span><br>device = select_device(opt.device, batch_size=opt.batch_size)<br><span class="hljs-comment"># 当进程内的GPU编号不为-1时，才会进入DDP</span><br><span class="hljs-keyword">if</span> LOCAL_RANK != -<span class="hljs-number">1</span>:<br>    msg = <span class="hljs-string">&quot;is not compatible with YOLOv5 Multi-GPU DDP training&quot;</span><br>    <span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> opt.image_weights, <span class="hljs-string">f&quot;--image-weights <span class="hljs-subst">&#123;msg&#125;</span>&quot;</span><br>    <span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> opt.evolve, <span class="hljs-string">f&quot;--evolve <span class="hljs-subst">&#123;msg&#125;</span>&quot;</span><br>    <span class="hljs-keyword">assert</span> opt.batch_size != -<span class="hljs-number">1</span>, <span class="hljs-string">f&quot;AutoBatch with --batch-size -1 <span class="hljs-subst">&#123;msg&#125;</span>, please pass a valid --batch-size&quot;</span><br>    <span class="hljs-keyword">assert</span> opt.batch_size % WORLD_SIZE == <span class="hljs-number">0</span>, <span class="hljs-string">f&quot;--batch-size <span class="hljs-subst">&#123;opt.batch_size&#125;</span> must be multiple of WORLD_SIZE&quot;</span><br>    <span class="hljs-keyword">assert</span> torch.cuda.device_count() &gt; LOCAL_RANK, <span class="hljs-string">&quot;insufficient CUDA devices for DDP command&quot;</span><br>    torch.cuda.set_device(LOCAL_RANK)<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>, LOCAL_RANK)<br>    <br>    dist.init_process_group(<br>        backend=<span class="hljs-string">&quot;nccl&quot;</span> <span class="hljs-keyword">if</span> dist.is_nccl_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;gloo&quot;</span>, timeout=timedelta(seconds=<span class="hljs-number">10800</span>)<br>    )<br></code></pre></td></tr></table></figure><p>进化训练的判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br></pre></td><td class="code"><pre><code class="hljs python">    <span class="hljs-comment"># 如果不进行超参数进化，则直接调用train()函数，开始训练</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.evolve:<br>        train(opt.hyp, opt, device, callbacks)<br><br>    <span class="hljs-comment"># 是否进行进化训练/遗传算法调参</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 超参数列表(突变范围 - 最小值 - 最大值)</span><br>        meta = &#123;<br>            <span class="hljs-string">&quot;lr0&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">1e-5</span>, <span class="hljs-number">1e-1</span>),  <span class="hljs-comment"># initial learning rate (SGD=1E-2, Adam=1E-3)</span><br>            <span class="hljs-string">&quot;lrf&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># final OneCycleLR learning rate (lr0 * lrf)</span><br>            <span class="hljs-string">&quot;momentum&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">0.98</span>),  <span class="hljs-comment"># SGD momentum/Adam beta1</span><br>            <span class="hljs-string">&quot;weight_decay&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.001</span>),  <span class="hljs-comment"># optimizer weight decay</span><br>            <span class="hljs-string">&quot;warmup_epochs&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">5.0</span>),  <span class="hljs-comment"># warmup epochs (fractions ok)</span><br>            <span class="hljs-string">&quot;warmup_momentum&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.95</span>),  <span class="hljs-comment"># warmup initial momentum</span><br>            <span class="hljs-string">&quot;warmup_bias_lr&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.2</span>),  <span class="hljs-comment"># warmup initial bias lr</span><br>            <span class="hljs-string">&quot;box&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.02</span>, <span class="hljs-number">0.2</span>),  <span class="hljs-comment"># box loss gain</span><br>            <span class="hljs-string">&quot;cls&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">4.0</span>),  <span class="hljs-comment"># cls loss gain</span><br>            <span class="hljs-string">&quot;cls_pw&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span>),  <span class="hljs-comment"># cls BCELoss positive_weight</span><br>            <span class="hljs-string">&quot;obj&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">4.0</span>),  <span class="hljs-comment"># obj loss gain (scale with pixels)</span><br>            <span class="hljs-string">&quot;obj_pw&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span>),  <span class="hljs-comment"># obj BCELoss positive_weight</span><br>            <span class="hljs-string">&quot;iou_t&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.7</span>),  <span class="hljs-comment"># IoU training threshold</span><br>            <span class="hljs-string">&quot;anchor_t&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">8.0</span>),  <span class="hljs-comment"># anchor-multiple threshold</span><br>            <span class="hljs-string">&quot;anchors&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">10.0</span>),  <span class="hljs-comment"># anchors per output grid (0 to ignore)</span><br>            <span class="hljs-string">&quot;fl_gamma&quot;</span>: (<span class="hljs-literal">False</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">2.0</span>),  <span class="hljs-comment"># focal loss gamma (efficientDet default gamma=1.5)</span><br>            <span class="hljs-string">&quot;hsv_h&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.1</span>),  <span class="hljs-comment"># image HSV-Hue augmentation (fraction)</span><br>            <span class="hljs-string">&quot;hsv_s&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>),  <span class="hljs-comment"># image HSV-Saturation augmentation (fraction)</span><br>            <span class="hljs-string">&quot;hsv_v&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>),  <span class="hljs-comment"># image HSV-Value augmentation (fraction)</span><br>            <span class="hljs-string">&quot;degrees&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">45.0</span>),  <span class="hljs-comment"># image rotation (+/- deg)</span><br>            <span class="hljs-string">&quot;translate&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>),  <span class="hljs-comment"># image translation (+/- fraction)</span><br>            <span class="hljs-string">&quot;scale&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>),  <span class="hljs-comment"># image scale (+/- gain)</span><br>            <span class="hljs-string">&quot;shear&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">10.0</span>),  <span class="hljs-comment"># image shear (+/- deg)</span><br>            <span class="hljs-string">&quot;perspective&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.001</span>),  <span class="hljs-comment"># image perspective (+/- fraction), range 0-0.001</span><br>            <span class="hljs-string">&quot;flipud&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># image flip up-down (probability)</span><br>            <span class="hljs-string">&quot;fliplr&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># image flip left-right (probability)</span><br>            <span class="hljs-string">&quot;mosaic&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># image mixup (probability)</span><br>            <span class="hljs-string">&quot;mixup&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># image mixup (probability)</span><br>            <span class="hljs-string">&quot;copy_paste&quot;</span>: (<span class="hljs-literal">True</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),<br>        &#125;  <span class="hljs-comment"># segment copy-paste (probability)</span><br><br>        <span class="hljs-comment"># GA configs </span><br>        pop_size = <span class="hljs-number">50</span><br>        mutation_rate_min = <span class="hljs-number">0.01</span><br>        mutation_rate_max = <span class="hljs-number">0.5</span><br>        crossover_rate_min = <span class="hljs-number">0.5</span><br>        crossover_rate_max = <span class="hljs-number">1</span><br>        min_elite_size = <span class="hljs-number">2</span><br>        max_elite_size = <span class="hljs-number">5</span><br>        tournament_size_min = <span class="hljs-number">2</span><br>        tournament_size_max = <span class="hljs-number">10</span><br><br>        <span class="hljs-comment"># 加载默认超参数</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(opt.hyp, errors=<span class="hljs-string">&quot;ignore&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            hyp = yaml.safe_load(f)  <span class="hljs-comment"># load hyps dict</span><br>            <br>            <span class="hljs-comment"># 如果超参数文件中没有&#x27;anchors&#x27;，则设为3</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;anchors&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> hyp:  <span class="hljs-comment"># anchors commented in hyp.yaml</span><br>                hyp[<span class="hljs-string">&quot;anchors&quot;</span>] = <span class="hljs-number">3</span><br>        <span class="hljs-keyword">if</span> opt.noautoanchor:<br>            <span class="hljs-keyword">del</span> hyp[<span class="hljs-string">&quot;anchors&quot;</span>], meta[<span class="hljs-string">&quot;anchors&quot;</span>]<br>            <br>        <span class="hljs-comment"># 使用进化算法时，仅在最后的epoch测试和保存</span><br>        opt.noval, opt.nosave, save_dir = <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, Path(opt.save_dir)  <span class="hljs-comment"># only val/save final epoch</span><br>        <span class="hljs-comment"># ei = [isinstance(x, (int, float)) for x in hyp.values()]  # evolvable indices</span><br>        evolve_yaml, evolve_csv = save_dir / <span class="hljs-string">&quot;hyp_evolve.yaml&quot;</span>, save_dir / <span class="hljs-string">&quot;evolve.csv&quot;</span><br>        <span class="hljs-keyword">if</span> opt.bucket:<br>            <span class="hljs-comment"># download evolve.csv if exists</span><br>            subprocess.run(<br>                [<br>                    <span class="hljs-string">&quot;gsutil&quot;</span>,<br>                    <span class="hljs-string">&quot;cp&quot;</span>,<br>                    <span class="hljs-string">f&quot;gs://<span class="hljs-subst">&#123;opt.bucket&#125;</span>/evolve.csv&quot;</span>,<br>                    <span class="hljs-built_in">str</span>(evolve_csv),<br>                ]<br>            )<br><br>        <span class="hljs-comment"># Delete the items in meta dictionary whose first value is False</span><br>        del_ = [item <span class="hljs-keyword">for</span> item, value_ <span class="hljs-keyword">in</span> meta.items() <span class="hljs-keyword">if</span> value_[<span class="hljs-number">0</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>]<br>        hyp_GA = hyp.copy()  <span class="hljs-comment"># Make a copy of hyp dictionary</span><br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> del_:<br>            <span class="hljs-keyword">del</span> meta[item]  <span class="hljs-comment"># Remove the item from meta dictionary</span><br>            <span class="hljs-keyword">del</span> hyp_GA[item]  <span class="hljs-comment"># Remove the item from hyp_GA dictionary</span><br><br>        <span class="hljs-comment"># Set lower_limit and upper_limit arrays to hold the search space boundaries</span><br>        lower_limit = np.array([meta[k][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> hyp_GA.keys()])<br>        upper_limit = np.array([meta[k][<span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> hyp_GA.keys()])<br><br>        <span class="hljs-comment"># Create gene_ranges list to hold the range of values for each gene in the population</span><br>        gene_ranges = [(lower_limit[i], upper_limit[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(upper_limit))]<br><br>        <span class="hljs-comment"># Initialize the population with initial_values or random values</span><br>        initial_values = []<br><br>        <span class="hljs-comment"># If resuming evolution from a previous checkpoint</span><br>        <span class="hljs-keyword">if</span> opt.resume_evolve <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">assert</span> os.path.isfile(ROOT / opt.resume_evolve), <span class="hljs-string">&quot;evolve population path is wrong!&quot;</span><br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(ROOT / opt.resume_evolve, errors=<span class="hljs-string">&quot;ignore&quot;</span>) <span class="hljs-keyword">as</span> f:<br>                evolve_population = yaml.safe_load(f)<br>                <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> evolve_population.values():<br>                    value = np.array([value[k] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> hyp_GA.keys()])<br>                    initial_values.append(<span class="hljs-built_in">list</span>(value))<br><br>        <span class="hljs-comment"># If not resuming from a previous checkpoint, generate initial values from .yaml files in opt.evolve_population</span><br>        <span class="hljs-keyword">else</span>:<br>            yaml_files = [f <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> os.listdir(opt.evolve_population) <span class="hljs-keyword">if</span> f.endswith(<span class="hljs-string">&quot;.yaml&quot;</span>)]<br>            <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> yaml_files:<br>                <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(os.path.join(opt.evolve_population, file_name)) <span class="hljs-keyword">as</span> yaml_file:<br>                    value = yaml.safe_load(yaml_file)<br>                    value = np.array([value[k] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> hyp_GA.keys()])<br>                    initial_values.append(<span class="hljs-built_in">list</span>(value))<br><br>        <span class="hljs-comment"># Generate random values within the search space for the rest of the population</span><br>        <span class="hljs-keyword">if</span> initial_values <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            population = [generate_individual(gene_ranges, <span class="hljs-built_in">len</span>(hyp_GA)) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(pop_size)]<br>        <span class="hljs-keyword">elif</span> pop_size &gt; <span class="hljs-number">1</span>:<br>            population = [generate_individual(gene_ranges, <span class="hljs-built_in">len</span>(hyp_GA)) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(pop_size - <span class="hljs-built_in">len</span>(initial_values))]<br>            <span class="hljs-keyword">for</span> initial_value <span class="hljs-keyword">in</span> initial_values:<br>                population = [initial_value] + population<br><br>        <span class="hljs-comment"># Run the genetic algorithm for a fixed number of generations</span><br>        list_keys = <span class="hljs-built_in">list</span>(hyp_GA.keys())<br>        <span class="hljs-keyword">for</span> generation <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(opt.evolve):<br>            <span class="hljs-keyword">if</span> generation &gt;= <span class="hljs-number">1</span>:<br>                save_dict = &#123;&#125;<br>                <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(population)):<br>                    little_dict = &#123;list_keys[j]: <span class="hljs-built_in">float</span>(population[i][j]) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(population[i]))&#125;<br>                    save_dict[<span class="hljs-string">f&quot;gen<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(generation)&#125;</span>number<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(i)&#125;</span>&quot;</span>] = little_dict<br><br>                <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(save_dir / <span class="hljs-string">&quot;evolve_population.yaml&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> outfile:<br>                    yaml.dump(save_dict, outfile, default_flow_style=<span class="hljs-literal">False</span>)<br><br>            <span class="hljs-comment"># Adaptive elite size</span><br>            elite_size = min_elite_size + <span class="hljs-built_in">int</span>((max_elite_size - min_elite_size) * (generation / opt.evolve))<br>            <span class="hljs-comment"># Evaluate the fitness of each individual in the population</span><br>            fitness_scores = []<br>            <span class="hljs-keyword">for</span> individual <span class="hljs-keyword">in</span> population:<br>                <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(hyp_GA.keys(), individual):<br>                    hyp_GA[key] = value<br>                hyp.update(hyp_GA)<br>                results = train(hyp.copy(), opt, device, callbacks)<br>                callbacks = Callbacks()<br>                <span class="hljs-comment"># Write mutation results</span><br>                keys = (<br>                    <span class="hljs-string">&quot;metrics/precision&quot;</span>,<br>                    <span class="hljs-string">&quot;metrics/recall&quot;</span>,<br>                    <span class="hljs-string">&quot;metrics/mAP_0.5&quot;</span>,<br>                    <span class="hljs-string">&quot;metrics/mAP_0.5:0.95&quot;</span>,<br>                    <span class="hljs-string">&quot;val/box_loss&quot;</span>,<br>                    <span class="hljs-string">&quot;val/obj_loss&quot;</span>,<br>                    <span class="hljs-string">&quot;val/cls_loss&quot;</span>,<br>                )<br>                print_mutation(keys, results, hyp.copy(), save_dir, opt.bucket)<br>                fitness_scores.append(results[<span class="hljs-number">2</span>])<br><br>            <span class="hljs-comment"># Select the fittest individuals for reproduction using adaptive tournament selection</span><br>            selected_indices = []<br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(pop_size - elite_size):<br>                <span class="hljs-comment"># Adaptive tournament size</span><br>                tournament_size = <span class="hljs-built_in">max</span>(<br>                    <span class="hljs-built_in">max</span>(<span class="hljs-number">2</span>, tournament_size_min),<br>                    <span class="hljs-built_in">int</span>(<span class="hljs-built_in">min</span>(tournament_size_max, pop_size) - (generation / (opt.evolve / <span class="hljs-number">10</span>))),<br>                )<br>                <span class="hljs-comment"># Perform tournament selection to choose the best individual</span><br>                tournament_indices = random.sample(<span class="hljs-built_in">range</span>(pop_size), tournament_size)<br>                tournament_fitness = [fitness_scores[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> tournament_indices]<br>                winner_index = tournament_indices[tournament_fitness.index(<span class="hljs-built_in">max</span>(tournament_fitness))]<br>                selected_indices.append(winner_index)<br><br>            <span class="hljs-comment"># Add the elite individuals to the selected indices</span><br>            elite_indices = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(pop_size) <span class="hljs-keyword">if</span> fitness_scores[i] <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(fitness_scores)[-elite_size:]]<br>            selected_indices.extend(elite_indices)<br>            <span class="hljs-comment"># Create the next generation through crossover and mutation</span><br>            next_generation = []<br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(pop_size):<br>                parent1_index = selected_indices[random.randint(<span class="hljs-number">0</span>, pop_size - <span class="hljs-number">1</span>)]<br>                parent2_index = selected_indices[random.randint(<span class="hljs-number">0</span>, pop_size - <span class="hljs-number">1</span>)]<br>                <span class="hljs-comment"># Adaptive crossover rate</span><br>                crossover_rate = <span class="hljs-built_in">max</span>(<br>                    crossover_rate_min, <span class="hljs-built_in">min</span>(crossover_rate_max, crossover_rate_max - (generation / opt.evolve))<br>                )<br>                <span class="hljs-keyword">if</span> random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) &lt; crossover_rate:<br>                    crossover_point = random.randint(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(hyp_GA) - <span class="hljs-number">1</span>)<br>                    child = population[parent1_index][:crossover_point] + population[parent2_index][crossover_point:]<br>                <span class="hljs-keyword">else</span>:<br>                    child = population[parent1_index]<br>                <span class="hljs-comment"># Adaptive mutation rate</span><br>                mutation_rate = <span class="hljs-built_in">max</span>(<br>                    mutation_rate_min, <span class="hljs-built_in">min</span>(mutation_rate_max, mutation_rate_max - (generation / opt.evolve))<br>                )<br>                <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(hyp_GA)):<br>                    <span class="hljs-keyword">if</span> random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) &lt; mutation_rate:<br>                        child[j] += random.uniform(-<span class="hljs-number">0.1</span>, <span class="hljs-number">0.1</span>)<br>                        child[j] = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">max</span>(child[j], gene_ranges[j][<span class="hljs-number">0</span>]), gene_ranges[j][<span class="hljs-number">1</span>])<br>                next_generation.append(child)<br>            <span class="hljs-comment"># Replace the old population with the new generation</span><br>            population = next_generation<br>        <span class="hljs-comment"># Print the best solution found</span><br>        best_index = fitness_scores.index(<span class="hljs-built_in">max</span>(fitness_scores))<br>        best_individual = population[best_index]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Best solution found:&quot;</span>, best_individual)<br>        <span class="hljs-comment"># Plot results 将结果可视化 / 输出保存信息</span><br>        plot_evolve(evolve_csv)<br>        LOGGER.info(<br>            <span class="hljs-string">f&#x27;Hyperparameter evolution finished <span class="hljs-subst">&#123;opt.evolve&#125;</span> generations\n&#x27;</span><br>            <span class="hljs-string">f&quot;Results saved to <span class="hljs-subst">&#123;colorstr(<span class="hljs-string">&#x27;bold&#x27;</span>, save_dir)&#125;</span>\n&quot;</span><br>            <span class="hljs-string">f&#x27;Usage example: $ python train.py --hyp <span class="hljs-subst">&#123;evolve_yaml&#125;</span>&#x27;</span><br>        )<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_individual</span>(<span class="hljs-params">input_ranges, individual_length</span>):<br>    individual = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(individual_length):<br>        lower_bound, upper_bound = input_ranges[i]<br>        individual.append(random.uniform(lower_bound, upper_bound))<br>    <span class="hljs-keyword">return</span> individual<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">**kwargs</span>):<br>    <span class="hljs-comment"># Usage: import train; train.run(data=&#x27;coco128.yaml&#x27;, imgsz=320, weights=&#x27;yolov5m.pt&#x27;)</span><br>    opt = parse_opt(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> kwargs.items():<br>        <span class="hljs-comment"># setattr() 赋值属性，属性不存在则创建一个赋值</span><br>        <span class="hljs-built_in">setattr</span>(opt, k, v)<br>    main(opt)<br>    <span class="hljs-keyword">return</span> opt<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    opt = parse_opt()<br>    main(opt)<br><br></code></pre></td></tr></table></figure><p>2024&#x2F;4&#x2F;10 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>CV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CV</tag>
      
      <tag>工程实践</tag>
      
      <tag>Yolo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>闭包与回调函数：浅薄理解</title>
    <link href="/2024/04/02/%E9%97%AD%E5%8C%85%E4%B8%8E%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%EF%BC%9A%E6%B5%85%E8%96%84%E7%90%86%E8%A7%A3/"/>
    <url>/2024/04/02/%E9%97%AD%E5%8C%85%E4%B8%8E%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%EF%BC%9A%E6%B5%85%E8%96%84%E7%90%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>工作之后，逐渐接触到了回调函数的应用。一开始我始终无法理解回调函数的执行顺序和意义，并且认为从可读性和执行效果上，并没有优于顺序执行的代码。不过后面对设计模式有一些了解后，对回调函数的概念大概有了一些模糊的理解，因此在这里整理一下以供学习。</p><h1 id="回调函数"><a href="#回调函数" class="headerlink" title="回调函数"></a>回调函数</h1><p>回调函数的主要特点是，将一个函数作为参数传入另外一个函数。并且在主函数执行完之后再继续调用该函数。</p><p>它和普通顺序写的函数相比有什么不同呢？在我的理解中，主要是能够有更好的扩展性。</p><p>例如以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_processor</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    处理数据的函数。直接在函数内部处理成功和失败的逻辑。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Processing data: <span class="hljs-subst">&#123;data&#125;</span>&quot;</span>)<br>    <span class="hljs-comment"># 假设根据数据的某些属性决定是否处理成功</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data) &gt; <span class="hljs-number">5</span>:  <span class="hljs-comment"># 假设处理条件</span><br>        processed_data = data.upper()  <span class="hljs-comment"># 模拟数据处理</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Data processed successfully: <span class="hljs-subst">&#123;processed_data&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        error_message = <span class="hljs-string">&quot;Data is too short.&quot;</span>  <span class="hljs-comment"># 错误信息</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Error processing data: <span class="hljs-subst">&#123;error_message&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 调用data_processor，直接处理数据</span><br>data_processor(<span class="hljs-string">&quot;Hello World&quot;</span>)<br>data_processor(<span class="hljs-string">&quot;Hi&quot;</span>)<br></code></pre></td></tr></table></figure><p>上述代码在一个顺序执行的函数中判断是否处理数据。现在换成用回调函数来执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_processor</span>(<span class="hljs-params">data, success_callback, error_callback</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    处理数据的函数。根据数据处理的结果，调用相应的回调函数。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Processing data: <span class="hljs-subst">&#123;data&#125;</span>&quot;</span>)<br>    <span class="hljs-comment"># 假设我们根据数据的某些属性决定是否处理成功</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data) &gt; <span class="hljs-number">5</span>:  <span class="hljs-comment"># 假设条件</span><br>        processed_data = data.upper()  <span class="hljs-comment"># 模拟数据处理</span><br>        success_callback(processed_data)  <span class="hljs-comment"># 调用成功的回调函数</span><br>    <span class="hljs-keyword">else</span>:<br>        error_message = <span class="hljs-string">&quot;Data is too short.&quot;</span>  <span class="hljs-comment"># 错误信息</span><br>        error_callback(error_message)  <span class="hljs-comment"># 调用错误的回调函数</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">on_success</span>(<span class="hljs-params">result</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    数据处理成功时的回调函数。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Data processed successfully: <span class="hljs-subst">&#123;result&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">on_error</span>(<span class="hljs-params">error</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    数据处理失败时的回调函数。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Error processing data: <span class="hljs-subst">&#123;error&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 调用data_processor，根据处理结果调用不同的回调函数</span><br>data_processor(<span class="hljs-string">&quot;Hello World&quot;</span>, on_success, on_error)<br>data_processor(<span class="hljs-string">&quot;Hi&quot;</span>, on_success, on_error)<br></code></pre></td></tr></table></figure><p>这样有什么好处？</p><ol><li>可以灵活的修改各自情况下的回调函数，不然就需要一直在主函数中修改。</li><li>所有逻辑包含在主函数中，并不利于维护。改成回调函数后，更利于调整逻辑。</li></ol><h2 id="异步操作"><a href="#异步操作" class="headerlink" title="异步操作"></a>异步操作</h2><p>回调函数的另一个用法是在异步编程中使用，来避免操作阻塞程序。这种用法是在一个操作完成时（例如，网络请求、读取文件等），执行后续的操作。</p><p>以下是示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> asyncio<br><span class="hljs-keyword">import</span> aiohttp<br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">fetch_data</span>(<span class="hljs-params">url</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    异步获取URL的数据</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Starting to fetch data from <span class="hljs-subst">&#123;url&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> aiohttp.ClientSession() <span class="hljs-keyword">as</span> session:<br>        <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> session.get(url) <span class="hljs-keyword">as</span> response:<br>            data = <span class="hljs-keyword">await</span> response.text()<br>            <span class="hljs-keyword">return</span> data<br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_data_fetched</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    模拟回调函数：数据获取后被调用</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Data fetched: &quot;</span>)<br>    <span class="hljs-built_in">print</span>(data[:<span class="hljs-number">100</span>])  <span class="hljs-comment"># 假设只打印数据的前100个字符</span><br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    主函数，执行异步的数据获取操作，并在完成后处理数据</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    url = <span class="hljs-string">&quot;https://www.example.com&quot;</span><br>    data = <span class="hljs-keyword">await</span> fetch_data(url)<br>    <span class="hljs-keyword">await</span> on_data_fetched(data)<br><br><span class="hljs-comment"># 运行主函数</span><br>asyncio.run(main())<br></code></pre></td></tr></table></figure><p>上述代码中，<code>on_data_fetched</code>函数在<code>fetch_data</code>函数完成后被调用。它的好处是可以在等待执行的时候运行其他的程序部分。</p><h1 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h1><p>相比于回调函数，闭包这个概念更多的涉及到作用域。它允许函数访问并操作函数外部的变量。我的理解是，它的作用是创建一个定义作用域，这个作用域能够获取外部的变量。</p><p>以下是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">foo</span>():<br>a = <span class="hljs-string">&#x27;free var&#x27;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bar</span>():<br>    <span class="hljs-built_in">print</span>(a)<br><span class="hljs-keyword">return</span> bar<br><br>foo()()<br><span class="hljs-comment"># free var</span><br></code></pre></td></tr></table></figure><p>可以看到，<code>bar</code>函数能够读取到外部的<code>a</code>变量，这就是闭包。</p><p>它和之前看到的装饰器有什么区别？我在查阅了一些资料后得到以下的结论：</p><blockquote><p>装饰器是闭包思想的一种实现。而闭包的定义是在函数内定义另一个函数。内函数能够调用外函数的临时变量。</p></blockquote><p>例如给一个示例闭包函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">outfun</span>(<span class="hljs-params">outNum</span>):  <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---start outfun---&#x27;</span>)  <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">infun</span>(<span class="hljs-params">inNum</span>):             <br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---start infun---&#x27;</span>)  <br>        <span class="hljs-built_in">print</span>(outNum + inNum)  <br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---end infun---&#x27;</span>)  <br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---end outfun---&#x27;</span>)  <br>    <span class="hljs-keyword">return</span> infun  <br><br>ret = outfun(<span class="hljs-number">10</span>)  <br>ret(<span class="hljs-number">20</span>) <br><span class="hljs-comment"># ---start outfun---  </span><br><span class="hljs-comment"># ---end outfun---  </span><br><span class="hljs-comment"># ---start infun---  </span><br><span class="hljs-comment"># 30  </span><br><span class="hljs-comment"># ---end infun--- </span><br></code></pre></td></tr></table></figure><p>上面的<code>ret</code>本身是一个函数，它指向<code>infun()</code>，并且将其中的<code>outNum</code>定义为10。之后在调用<code>ret</code>时输入的参数则充当了<code>infun</code>的参数。</p><p>我们再来示范一下装饰器的用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func1</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Begin func1...&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func2</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Begin func2...&#x27;</span>)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check</span>(<span class="hljs-params">function</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">check_inner</span>():<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Checking Inner Function...&#x27;</span>)<br>        function()<br>  <span class="hljs-keyword">return</span> check_inner<br><br>check_test1 = check(test_func1)<br>check_test1()<br><br><span class="hljs-comment"># 也可以用语法糖实现</span><br><span class="hljs-meta">@check</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func1</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Begin func1...&#x27;</span>)<br><br><span class="hljs-meta">@check</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func2</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Begin func2...&#x27;</span>)<br><br>test_func1()<br>test_func2()<br></code></pre></td></tr></table></figure><p>在<code>check</code>函数中，我们设定了一个内函数，它接收外部的函数作为参数，指向内部的函数。在内部函数中对外部函数进行了一系列处理。这就是装饰器的简单用法。</p><p>更常用的用法是不定长参数的使用，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">deco</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">new_func</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        <span class="hljs-keyword">return</span> func(*args, **kwargs)<br>    <span class="hljs-keyword">return</span> new_func<br></code></pre></td></tr></table></figure><p>以及接收参数的装饰器工厂：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">deco_factory</span>(<span class="hljs-params">*args, **kwargs</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">deco</span>(<span class="hljs-params">func</span>):<br>        <span class="hljs-built_in">print</span>(args)<br>        <span class="hljs-keyword">return</span> func<br>    <span class="hljs-keyword">return</span> deco<br><br><span class="hljs-meta">@deco_factory(<span class="hljs-params"><span class="hljs-string">&#x27;factory&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">foo</span>():<br>    <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><p>这样就能灵活修改装饰器的方法。</p><p>最后，记录一个接收参数的装饰器用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">outer</span>(<span class="hljs-params">choose</span>): <span class="hljs-comment"># 在最外层函数中加入参数</span><br>  <span class="hljs-keyword">if</span> choose==<span class="hljs-number">1</span>: <span class="hljs-comment"># 通过choose参数，选择装饰器</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">deco</span>(<span class="hljs-params">func</span>):<br>      <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner</span>(<span class="hljs-params">*arg, **kwarg</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;decoration1&#x27;</span>)<br>        begin_time = time.time()<br>        time.sleep(<span class="hljs-number">2</span>) <span class="hljs-comment"># 睡眠2s</span><br>        a = func(*arg, **kwarg) <br>        end_time = time.time()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;运行时间1：&#x27;</span>, end_time - begin_time)<br>        <span class="hljs-keyword">return</span> a<br>      <span class="hljs-keyword">return</span> inner<br>    <span class="hljs-keyword">return</span> deco<br>  <br>  <span class="hljs-keyword">else</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">deco</span>(<span class="hljs-params">func</span>):<br>      <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner</span>(<span class="hljs-params">*arg, **kwarg</span>): <br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;decoration2&#x27;</span>)<br>        begin_time = time.time()<br>        time.sleep(<span class="hljs-number">5</span>) <span class="hljs-comment"># 睡眠5s</span><br>        a = func(*arg, **kwarg) <br>        end_time = time.time()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;运行时间2：&#x27;</span>, end_time - begin_time)<br>        <span class="hljs-keyword">return</span> a<br>      <span class="hljs-keyword">return</span> inner<br>    <span class="hljs-keyword">return</span> deco<br><br><span class="hljs-meta">@outer(<span class="hljs-params"><span class="hljs-number">1</span></span>) </span><span class="hljs-comment"># 由于outer中有参数，此处必须传入参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test1</span>(<span class="hljs-params">a</span>):<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;test function1:&#x27;</span>, a)<br>  <span class="hljs-keyword">return</span> a<br><br><span class="hljs-meta">@outer(<span class="hljs-params"><span class="hljs-number">5</span></span>) </span><span class="hljs-comment"># 传入另一个参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test2</span>(<span class="hljs-params">a</span>):<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;test function2:&#x27;</span>, a)<br>  <span class="hljs-keyword">return</span> a<br><br><br><span class="hljs-comment"># 分别调用2个函数（2个函数装饰器相同，装饰器参数不同）</span><br>test1(<span class="hljs-number">2</span>) <span class="hljs-comment"># 调用test1</span><br>  <br>decoration1<br>test function1: <span class="hljs-number">2</span><br>运行时间<span class="hljs-number">1</span>： <span class="hljs-number">2.000072717666626</span> <span class="hljs-comment"># 2秒</span><br> <span class="hljs-comment"># test1的返回值</span><br><br>test2(<span class="hljs-number">4</span>) <span class="hljs-comment"># 调用test2</span><br>  <br>decoration2<br>test function2: <span class="hljs-number">4</span><br>运行时间<span class="hljs-number">2</span>： <span class="hljs-number">5.000797986984253</span> <span class="hljs-comment"># 5秒</span><br> <span class="hljs-comment"># test2的返回值</span><br></code></pre></td></tr></table></figure><p>2024&#x2F;4&#x2F;3 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>闭包</tag>
      
      <tag>回调函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM推理与训练显存的计算方法</title>
    <link href="/2024/03/31/LLM%E6%8E%A8%E7%90%86%E4%B8%8E%E8%AE%AD%E7%BB%83%E6%98%BE%E5%AD%98%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95/"/>
    <url>/2024/03/31/LLM%E6%8E%A8%E7%90%86%E4%B8%8E%E8%AE%AD%E7%BB%83%E6%98%BE%E5%AD%98%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>值得一看的链接：</p><p><a href="https://zhuanlan.zhihu.com/p/624740065">分析transformer模型的参数量、计算量、中间激活、KV cache</a></p><p><a href="https://blog.csdn.net/weixin_44532170/article/details/134601507">大模型GPU显存占用计算_大模型显存计算-CSDN博客</a></p><p><a href="https://www.datalearner.com/blog/1051692326904222">需要多少GPU显存才能运行预训练大语言模型？大语言模型参数规模与显存大小的关系估算方法</a></p><p>众所周知，自从Transformer出现后，大语言模型基本上抛弃了原来的RNN&#x2F;LSTM的思路。然而Transformer类模型也有自己的不足之处，其中最被人诟病的可能就是大量的计算量。今天我就来学习一下，训练&#x2F;运行一个Transformer类的模型，究竟要占用多少显存？</p><h1 id="整数与浮点数"><a href="#整数与浮点数" class="headerlink" title="整数与浮点数"></a>整数与浮点数</h1><p>在开始之前，需要了解一下不同的数据格式占用的存储大小：</p><ul><li>FP64：双精度浮点数（64位），8字节&#x2F;单位</li><li>FP32：单精度浮点数（32位），4字节&#x2F;单位</li><li>FP16：半精度浮点数（16位），2字节&#x2F;单位</li><li>BF16：Google推出的半精度浮点数（16位）</li><li>INT16：整数（16位），2字节&#x2F;单位</li><li>INT8：整数（8位），1字节&#x2F;单位</li><li>INT4：整数（4位），0.5字节&#x2F;单位</li></ul><p>浮点数是如何变成整数的？下图是一个简单的演示。在这过程中，会出现精度和存储空间的取舍。</p><p><img src="/images/qualization.png"></p><h1 id="模型占用多大空间？"><a href="#模型占用多大空间？" class="headerlink" title="模型占用多大空间？"></a>模型占用多大空间？</h1><p>什么是B？B代表Billion，十亿参数。因此13B就是130亿参数，7B则是70亿参数。</p><p>我们以参数量13B大模型为例，13B是130亿参数。如果我们以全精度fp32运行，也就是float32，将会占用32位bit，也就是4byte字节。我们给出计算的公式：</p><p>$ 1\text{GB} &#x3D; 1024 \text{MB} &#x3D; 1024^{2}  \text{KB} &#x3D; 1024^{3} \text{Byte}$</p><p>那么全精度13B模型占用显存为 <code>数量 * 类型大小</code>：$13 \times 10^{9} \times 4 \text{Byte} \div 1024^{3} \approx 48.4 \text{GB}$</p><p>也就是说，我们只是单纯以全精度加载运行一个13B的模型，就需要大约48.4G的显存空间。</p><p>实际计算中，通常会把$1000^{3}$个字节估计为1G，而非$1024^{3}$个字节。以此类推，常见的13B模型，需要的显存约为：</p><ul><li>FP32 13*4 &#x3D; 52 GB</li><li>BF16 13*2 &#x3D; 26 GB</li><li>INT8 13*1 &#x3D; 13 GB</li><li>INT4 13*0.5 &#x3D; 6.5 GB</li></ul><h1 id="模型本身的参数量是怎么计算的？"><a href="#模型本身的参数量是怎么计算的？" class="headerlink" title="模型本身的参数量是怎么计算的？"></a>模型本身的参数量是怎么计算的？</h1><p>首先有一些符号需要给出定义：</p><ul><li>transformer模型的层数为 𝑙 </li><li>隐藏层维度为 ℎ </li><li>注意力头数为 𝑎 </li><li>词表大小为 𝑉 </li><li>训练数据的批次大小为 𝑏 </li><li>序列长度为 𝑠 。</li></ul><p>transformer模型由 𝑙 个相同的层组成，每个层分为两部分：<code>self-attention</code>块和<code>MLP</code>块。</p><p><code>self-attention块</code>的模型参数有 𝑄、𝐾、𝑉 的权重矩阵：$W_{Q}$、$W_{K}$、$W_{V}$ 和偏置，输出权重矩阵 $W_{O}$ 和偏置，4个权重矩阵的形状为 [ℎ,ℎ] ，4个偏置的形状为 [ℎ] 。<strong>self- attention块的参数量为 $4h^2 + 4h$ 。</strong></p><p>MLP块由2个线性层组成，第一个线性层一般将维度从 ℎ 映射到 4ℎ ，第二个线性层再将维度从4ℎ映射到ℎ。第一个线性层的权重矩阵 $W_{1}$ 的形状为 [ℎ,4ℎ] ，偏置的形状为 [4ℎ] 。第二个线性层权重矩阵 $W_{2}$ 的形状为 [4ℎ,ℎ] ，偏置形状为 [ℎ] 。<strong>MLP块的参数量为 $8h^2 + 5h$ 。</strong></p><p><code>self-attention</code>块和<code>MLP</code>块各有一个layer normalization，包含了2个可训练模型参数：缩放参数 𝛾 和平移参数 𝛽 ，形状都是 [ℎ] 。2个layer normalization的参数量为 4ℎ 。</p><p>总的，<strong>每个transformer层的参数量为$12h^2 + 3h$。</strong></p><p>除此之外，词嵌入矩阵的参数量也较多，词向量维度通常等于隐藏层维度 ℎ ，词嵌入矩阵的参数量为 𝑉ℎ 。最后的输出层的权重矩阵通常与词嵌入矩阵是参数共享的。</p><p>关于位置编码，如果采用可训练式的位置编码，会有一些可训练模型参数，数量比较少。如果采用相对位置编码，例如RoPE和ALiBi，则不包含可训练的模型参数。我们忽略这部分参数。</p><blockquote><p>综上， <strong>𝑙 层transformer模型的可训练模型参数量为</strong>$ l(12h^2 + 13h) + Vh $。当隐藏维度 ℎ 较大时，可以忽略一次项，<strong>模型参数量近似为</strong> $12lh^2$ 。</p></blockquote><p>估计不同版本LLaMA模型的参数量：</p><table><thead><tr><th>实际参数量</th><th>隐藏维度h</th><th>层数l</th><th>12lh^2</th></tr></thead><tbody><tr><td>6.7B</td><td>4096</td><td>32</td><td>6,442,450,944</td></tr><tr><td>13.0B</td><td>5120</td><td>40</td><td>12,582,912,000</td></tr><tr><td>32.5B</td><td>6656</td><td>60</td><td>31,897,681,920</td></tr><tr><td>65.2B</td><td>8192</td><td>80</td><td>64,424,509,440</td></tr></tbody></table><h1 id="模型训练所需的存储空间"><a href="#模型训练所需的存储空间" class="headerlink" title="模型训练所需的存储空间"></a>模型训练所需的存储空间</h1><p>当模型训练时，需要的存储空间就不止参数量本身了，因为反向传播当中处处需要计算和存储。我们只要记住：<strong>训练参数是模型参数的4倍</strong>就可以了。</p><p>在训练中，存储空间主要分为了三个部分：</p><ul><li>梯度：1$\times $参数量</li><li>参数：1$\times $参数量</li><li>优化器部分：Adam-2$\times$参数量 &#x2F;SGD-1$\times$参数量</li></ul><p>对于每个参数，都会有一个对应的梯度，因此梯度占据的内存和参数一样。</p><p>在训练过程中，优化器则会为存储额外的信息，例如一阶和二阶动量。以Adam为例，它会存储2倍参数量（即每个参数都有两个动量）的信息。而对于SGD则只需要1倍的参数量。</p><h1 id="LoRA微调参数量"><a href="#LoRA微调参数量" class="headerlink" title="LoRA微调参数量"></a>LoRA微调参数量</h1><p>此前了解过LoRA的微调方法，是利用低秩矩阵来训练一个Adaptor，对原有模型的参数进行调整。LoRA训练的参数量取决于秩Rank的大小。</p><p>假如全量微调时需要$1024\times 512$的模型参数量，使用LoRA时，就只需要$1024\times8+512\times8+$原始模型参数量的总合参数量，这大大降低了的训练所需的显存占用。</p><p>2024&#x2F;3&#x2F;31 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker必备指南</title>
    <link href="/2024/03/16/Docker%E5%BF%85%E5%A4%87%E6%8C%87%E5%8D%97/"/>
    <url>/2024/03/16/Docker%E5%BF%85%E5%A4%87%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p>此前写过的Docker相关的博文：</p><ul><li><p><a href="https://zerolovesea.github.io/2024/01/19/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E4%BD%BF%E7%94%A8Docker%E6%89%93%E5%8C%85%E8%87%AA%E5%B7%B1%E7%9A%84%E9%A1%B9%E7%9B%AE/">工程实践：使用Docker打包自己的项目</a></p></li><li><p><a href="https://zerolovesea.github.io/2024/01/23/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9ADocker%E5%85%A5%E9%97%A8%E6%8A%80%E5%B7%A7/">工程实践：Docker入门技巧</a></p></li><li><p><a href="https://zerolovesea.github.io/2024/01/25/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%AE%9E%E6%93%8D%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84Docker%E6%93%8D%E4%BD%9C/">工程实践：实操项目中的Docker操作</a></p></li><li><p><a href="https://zerolovesea.github.io/2024/01/27/Docker%E5%AE%9E%E8%B7%B5%E6%8C%96%E5%9D%91%E7%BB%86%E8%8A%82/">Docker实践挖坑细节</a></p></li><li><p><a href="https://zerolovesea.github.io/2024/01/27/Dockfile%E7%BC%96%E5%86%99%E6%8C%87%E5%8D%97/">Dockfile编写指南</a></p></li><li><p><a href="https://zerolovesea.github.io/2024/02/07/Docker%E9%83%A8%E7%BD%B2CUDA-CUDANN/">Docker部署CUDA&#x2F;CUDANN </a></p></li><li><p><a href="https://zerolovesea.github.io/2024/04/20/Docker-Compose%E7%BC%96%E5%86%99%E6%8C%87%E5%8D%97/">Docker Compose编写指南</a></p></li><li><p><a href="https://zerolovesea.github.io/2024/04/20/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%AF%B9%E5%B7%B2%E6%9C%89%E7%9A%84Docker%E9%95%9C%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%A2%9E%E9%87%8F%E6%9B%B4%E6%96%B0/">工程实践：对已有的Docker镜像进行增量更新</a></p></li></ul><h1 id="如何安装Docker？"><a href="#如何安装Docker？" class="headerlink" title="如何安装Docker？"></a>如何安装Docker？</h1><p><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">Installing the NVIDIA Container Toolkit — NVIDIA Container Toolkit 1.14.5 documentation</a></p><h1 id="如何配置深度学习的Docker环境？"><a href="#如何配置深度学习的Docker环境？" class="headerlink" title="如何配置深度学习的Docker环境？"></a>如何配置深度学习的Docker环境？</h1><p>以下是一个简单的演示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --gpus all -it --<span class="hljs-built_in">rm</span> -p 8888:8888 -v /home/whaow:/workspace nvcr.io/nvidia/pytorch:xx.xx-py3<br></code></pre></td></tr></table></figure><p>其中<code>--rm</code>指运行后删除，<code>--gpus all</code>指将所有显卡都映射到docker中，<code>xx.xx</code>指的是docker –version的版本。这会拉取英伟达的pytorch镜像。</p><h1 id="Docker读写文件操作"><a href="#Docker读写文件操作" class="headerlink" title="Docker读写文件操作"></a>Docker读写文件操作</h1><p><code>docker cp</code>能够实现容器内和宿主机的文件读写：</p><p><code>docker cp 容器中的文件路径:宿主机的文件路径</code></p><p>也可以互换来拷贝宿主机的文件进容器。</p><p>2024&#x2F;3&#x2F;16 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git：常用指令汇总</title>
    <link href="/2024/03/16/Git%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E6%B1%87%E6%80%BB/"/>
    <url>/2024/03/16/Git%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E6%B1%87%E6%80%BB/</url>
    
    <content type="html"><![CDATA[<p>此前在<a href="https://zerolovesea.github.io/2023/12/29/%E9%A1%B9%E7%9B%AE%E5%8D%8F%E5%90%8C%E5%BC%80%E5%8F%91-Git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/">项目协同开发-Git基础操作</a>一文中简单写了一些常用的git的基础操作，这次增加了一些其他的指令。</p><h1 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h1><p>如果要查看Git中配置的用户名和邮箱地址，使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git config --global user.name<br>git config --global user.email<br></code></pre></td></tr></table></figure><p>在后面加上用户名和邮箱地址，即可修改，例如<code>git config --global user.name &quot;Your Name&quot;</code>。</p><h1 id="修改远程仓库地址"><a href="#修改远程仓库地址" class="headerlink" title="修改远程仓库地址"></a>修改远程仓库地址</h1><p>如果要修改本地仓库管理的远程仓库地址，需要使用以下指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git remote remove origin  <span class="hljs-comment"># 删除该远程路径  </span><br>git remote add origin git@jslite.github.com:JSLite/JSLite.git  <span class="hljs-comment"># 添加远程路径 </span><br></code></pre></td></tr></table></figure><h1 id="撤销提交记录"><a href="#撤销提交记录" class="headerlink" title="撤销提交记录"></a>撤销提交记录</h1><p>如果撤销本地的提交记录，并在远程进行同步，需要执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">git reset --hard HEAD~1 <span class="hljs-comment"># 撤销一条记录   </span><br>git push -f origin HEAD:master <span class="hljs-comment"># 同步到远程仓库的master分支</span><br><br>git push -f origin HEAD:dev <span class="hljs-comment"># 如果想撤销远程仓库的dev分支</span><br></code></pre></td></tr></table></figure><h1 id="reset和revert的区别是什么？"><a href="#reset和revert的区别是什么？" class="headerlink" title="reset和revert的区别是什么？"></a>reset和revert的区别是什么？</h1><p>简单一句话总结：</p><ul><li><code>git reset</code> 用于在本地修改提交历史，可能会导致丢失提交历史。</li><li><code>git revert</code> 用于在提交历史中创建新的提交，以撤销之前的更改，而不会修改提交历史。</li></ul><p>如果要回退到某个版本，需要执行以下指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">git reset --hard &lt;<span class="hljs-built_in">hash</span>&gt;<br><span class="hljs-comment"># 例如 git reset --hard a3hd73r</span><br><span class="hljs-comment"># --hard代表丢弃工作区的修改，让工作区与版本代码一模一样，与之对应，</span><br><span class="hljs-comment"># --soft参数代表保留工作区的修改。</span><br></code></pre></td></tr></table></figure><p>如果要回滚到某个commit提交：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git revert HEAD~1 <span class="hljs-comment"># 撤销一条记录 会弹出 commit 编辑</span><br>git push <span class="hljs-comment"># 提交回滚</span><br></code></pre></td></tr></table></figure><p>需要更保守的去除某个commit：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 实质是新建了一个与原来完全相反的commit，抵消了原来commit的效果</span><br>git revert &lt;commit-hash&gt; <br></code></pre></td></tr></table></figure><h1 id="将A分支的某一commit提交至B分支"><a href="#将A分支的某一commit提交至B分支" class="headerlink" title="将A分支的某一commit提交至B分支"></a>将A分支的某一commit提交至B分支</h1><p>有的时候，两个分支同时都拥有同一个文件。进行修改后，可以同时commit到这两个分支，比如 <code>master</code> 分支和 <code>dev</code> 分支，都拥有文件 <code>.env</code> ，在 <code>master</code> 或者 <code>dev</code> 分支下对 <code>.env</code> 进行修改后，把修改的文件同时提交到 <code>master</code> 分支和 <code>dev</code> 分支。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xml">git checkout <span class="hljs-tag">&lt;<span class="hljs-name">branch-name</span>&gt;</span> &amp;&amp; git cherry-pick <span class="hljs-tag">&lt;<span class="hljs-name">commit-id</span>&gt;</span><br></code></pre></td></tr></table></figure><h1 id="查看提交历史"><a href="#查看提交历史" class="headerlink" title="查看提交历史"></a>查看提交历史</h1><p>使用以下命令来查看提交日志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">log</span><br></code></pre></td></tr></table></figure><p>如果要在一行进行查看，则加上<code>--oneline</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">log</span> --oneline -5 <span class="hljs-comment"># 查看最近的5个提交日志</span><br></code></pre></td></tr></table></figure><h1 id="查看某一文件的历史"><a href="#查看某一文件的历史" class="headerlink" title="查看某一文件的历史"></a>查看某一文件的历史</h1><p>有时候需要查看某一个文件的所有历史改动，可以使用以下的这些指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">log</span> --pretty=oneline 文件名  <span class="hljs-comment"># 列出文件的所有改动历史  </span><br>git show c178bf49   <span class="hljs-comment"># 某次的改动的修改记录  </span><br>git <span class="hljs-built_in">log</span> -p c178bf49 <span class="hljs-comment"># 某次的改动的修改记录  </span><br>git blame 文件名     <span class="hljs-comment"># 显示文件的每一行是在那个版本最后修改。  </span><br>git whatchanged 文件名  <span class="hljs-comment"># 显示某个文件的每个版本提交信息：提交日期，提交人员，版本号，提交备注（没有修改细节）  </span><br></code></pre></td></tr></table></figure><h1 id="合并多个commit"><a href="#合并多个commit" class="headerlink" title="合并多个commit"></a>合并多个commit</h1><p>有时候需要将多个commit历史合并成一个，让提交记录更加简洁：</p><p>首先输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git rebase -i HEAD~5 <span class="hljs-comment"># 合并最近的5个提交</span><br></code></pre></td></tr></table></figure><p>这将会打开文本编辑器，你可以选择是否进行保留和合并。将除第一个提交之外的行前面的单词改为 <code>squash</code>（或 <code>s</code>），这样 Git 将会把这些提交合并到第一个提交中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">pick &lt;commit_hash&gt; Commit message 1<br>squash &lt;commit_hash&gt; Commit message 2<br>squash &lt;commit_hash&gt; Commit message 3<br>squash &lt;commit_hash&gt; Commit message 4<br>squash &lt;commit_hash&gt; Commit message 5<br></code></pre></td></tr></table></figure><p>保存并关闭后，进行提交：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git push -f origin HEAD:branch_name<br></code></pre></td></tr></table></figure><h1 id="删除分支"><a href="#删除分支" class="headerlink" title="删除分支"></a>删除分支</h1><p>删除分支包括以下常用指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">git push origin :branchName  <span class="hljs-comment"># 删除远程分支  </span><br>git push origin --delete new <span class="hljs-comment"># 删除远程分支new   </span><br>git branch -d branchName     <span class="hljs-comment"># 删除本地分支，强制删除用-D  </span><br>git branch -d <span class="hljs-built_in">test</span>      <span class="hljs-comment"># 删除本地test分支   </span><br>git branch -D <span class="hljs-built_in">test</span>      <span class="hljs-comment"># 强制删除本地test分支   </span><br>git remote prune origin <span class="hljs-comment"># 远程删除了，本地还能看到远程存在，这条命令删除远程不存在的分支</span><br></code></pre></td></tr></table></figure><p>2024&#x2F;3&#x2F;16 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>It&#39;s just business</title>
    <link href="/2024/03/13/It-s-just-business/"/>
    <url>/2024/03/13/It-s-just-business/</url>
    
    <content type="html"><![CDATA[<p>春节后的工作变得愈加紧张，我的加班次数也随之逐渐变多。今天中午在客户现场的时候和同事在聊天，大家各自表达了不同的观点，但是最终达成一致的是：互联网公司和软件公司现在越来越卷了。不光是前端，后端和算法，整个计算机行业的竞争都很激烈。</p><p>距离我开始上班已经过去了半年，我不得不开始仔细审视这是不是我心仪的工作。在过去的几个月了，我学到了相当多且非常实用的知识，包括Docker，Linux以及最有价值的程序设计思路。这让我受益匪浅。</p><p>然而正如我之前常常思考的，我的职业规划到底是什么，这段时间的工作并没有让我理清思路。我现在究竟是在做软件开发？算法？还是数据挖掘？Kaggle也很久没有参加比赛了，我似乎离我一开始设想的职业方向越来越远。</p><p>我们总把大多数的不如意归咎于“大环境不好”，然而对此我们又无能为力，这实在是这个时代的一种悲哀。</p><p>回家的路上看到一句话，写在这里聊以自嘲：</p><p>Don’t worry! It’s just business.</p><p>2024&#x2F;3&#x2F;13 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最精简的搜索系统实现：倒排索引</title>
    <link href="/2024/03/10/%E6%9C%80%E7%B2%BE%E7%AE%80%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0%EF%BC%9A%E9%80%86%E5%90%91%E7%B4%A2%E5%BC%95/"/>
    <url>/2024/03/10/%E6%9C%80%E7%B2%BE%E7%AE%80%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0%EF%BC%9A%E9%80%86%E5%90%91%E7%B4%A2%E5%BC%95/</url>
    
    <content type="html"><![CDATA[<p>众所周知，搜推广业务在机器学习中一直都属于是应用面最广的部分，也是最直接为公司带来收益的数据科学业务。毕业之后我的第一个实习就是做简单的推荐系统，因此有过一些浅显的了解。如今尽管已经走上了另外一个方向，我仍然会偶尔看一下相关的内容。</p><p>今天带来一个简单的搜索引擎实现，只有短短几行代码。其中用到了<code>jieba</code>这个经典的中文python库，核心的思想则是倒排索引。</p><h1 id="什么是倒排索引？"><a href="#什么是倒排索引？" class="headerlink" title="什么是倒排索引？"></a>什么是倒排索引？</h1><p>要记住倒排索引，关键就是<strong>文档–&gt;ID</strong>。</p><p>搜索引擎中，每个文件都对应一个文件ID，而文件内容又被表示为一系列关键词的集合。例如“文档1”经过分词，提取了20个关键词，每个关键词都会记录它在文档中的出现次数和出现位置。</p><p>倒排索引的基本原理就是将文档中的词汇作为索引项，记录每个词汇所在的文档集合以及该词汇在每个文档中的位置信息。</p><p>过程如下：</p><ol><li>预处理：对每个文档进行分词处理，将文档分割成一个个独立的词汇。</li><li>创建词汇表：将所有文档中的词汇汇总到一个词汇表中，去除重复的词汇。</li><li>构建索引：对于词汇表中的每个词汇，记录其所在的文档集合以及在每个文档中的位置信息。</li><li>存储索引：存储构建好的倒排索引以便后续的搜索查询。</li></ol><p>假设商品A包含了以下特征：<code>AAA</code>，<code>蓝色</code>，<code>M码</code>，<code>猴子</code>。那么这几个特征就是商品A的索引项（Value），当用户检索了其中任何一个特征，就会返回这个商品的ID（Key）。这样用户通过搜“AAA”，“蓝色”，“M码”，“猴子”，均可找到该商品。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>下面是具体的代码实现。首先我们先构建一系列的文档：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><span class="hljs-keyword">import</span> jieba<br><br>forward_index = [<br>    <span class="hljs-string">&quot;苹果发布新款iPhone&quot;</span>,<br>    <span class="hljs-string">&quot;iPhone6s发布&quot;</span>,<br>    <span class="hljs-string">&quot;苹果发布iPhone6s&quot;</span>,<br>    <span class="hljs-string">&quot;苹果公布2023年财报&quot;</span>,<br>    <span class="hljs-string">&quot;苹果发布全新M3芯片的MacBook Pro&quot;</span>,<br>]<br></code></pre></td></tr></table></figure><p>随后构建一个生成索引表的字典：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_invert_index</span>(<span class="hljs-params">docs: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]]:<br>    invert_index: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]] = defaultdict(<span class="hljs-built_in">list</span>)<br>    <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> docs:<br>        words = jieba.cut_for_search(doc)<br>        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>            invert_index[word].append(docs.index(doc))<br>    <span class="hljs-keyword">return</span> invert_index<br></code></pre></td></tr></table></figure><p>最后就是检索的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">retrive</span>(<span class="hljs-params">query: <span class="hljs-built_in">str</span>, inverted_index: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>    words = jieba.cut_for_search(query)<br>    result = <span class="hljs-built_in">set</span>()<br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>        <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> inverted_index:<br>            result.update(inverted_index[word])<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(result)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    invert_index = build_invert_index(forward_index)<br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        query = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;请输入查询词：&quot;</span>)<br>        <span class="hljs-keyword">if</span> query == <span class="hljs-string">&quot;q&quot;</span>:<br>            <span class="hljs-keyword">break</span><br>        result = retrive(query, invert_index)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;查询词：<span class="hljs-subst">&#123;query&#125;</span>的结果为：&quot;</span>)<br>        <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> result:  <br>            <span class="hljs-built_in">print</span>(forward_index[doc])<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;=&quot;</span> * <span class="hljs-number">20</span>)<br></code></pre></td></tr></table></figure><p><img src="/images/171958.png"></p><p>2024&#x2F;3&#x2F;10 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>搜索系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>搜索系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MiniBPE：探究Github上最简单的BPE实现代码</title>
    <link href="/2024/03/09/MiniBPE%EF%BC%9A%E6%8E%A2%E7%A9%B6Github%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84BPE%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81/"/>
    <url>/2024/03/09/MiniBPE%EF%BC%9A%E6%8E%A2%E7%A9%B6Github%E4%B8%8A%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84BPE%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<p>之前在<a href="https://zerolovesea.github.io/2024/01/01/%E5%9F%BA%E4%BA%8E%E5%AD%97%E8%AF%8D%E7%9A%84%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95%EF%BC%9ABPE%E7%AE%97%E6%B3%95/">基于子词的分词方法：BPE算法</a>一文中简单实现了BPE的算法，上个月前OpenAI数据科学家Andrej Karpathy大神在Github上实现了目前最精简的BPE算法的代码，这一项目瞬间冲到了Github日榜并连续霸榜了一周。目前该项目已经拥有7.6k颗星。今天就来探究一下他写的代码细节，学习一下大神的代码规范。</p><h1 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h1><p>项目由四个文件组成：一个<code>base.py</code>实现<code>Tokenizer</code>的抽象化基类。一个<code>Tokenizer</code>通常包含三个方法：训练，编码和解码。</p><p><code>basic.py</code>继承了<code>base.py</code>，里面的<code>BasicTokenizer</code>类是BPE算法的核心实现模块。</p><p>第三个文件是<code>regex.py</code>，里面的<code>RegexTokenizer</code>类的作用是使用正则表达式更好的拆分文本。这一部分一般出现在预处理阶段，让文本按照不同类别（字母，数字，标点）进行拆分。</p><p>最后一个文件是<code>gpt4.py</code>，它实现了<code>GPT4Tokenizer</code>类，复现了<code>tiktoken</code>库中的<code>GPT-4</code>的<code>Tokenizer</code>。</p><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><h2 id="调用方法"><a href="#调用方法" class="headerlink" title="调用方法"></a>调用方法</h2><p>先上使用方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> minbpe <span class="hljs-keyword">import</span> BasicTokenizer<br>tokenizer = BasicTokenizer()<br>text = <span class="hljs-string">&quot;aaabdaaabac&quot;</span><br>tokenizer.train(text, <span class="hljs-number">256</span> + <span class="hljs-number">3</span>) <span class="hljs-comment"># 256 are the byte tokens, then do 3 merges</span><br><span class="hljs-built_in">print</span>(tokenizer.encode(text))<br><span class="hljs-comment"># [258, 100, 258, 97, 99]</span><br><span class="hljs-built_in">print</span>(tokenizer.decode([<span class="hljs-number">258</span>, <span class="hljs-number">100</span>, <span class="hljs-number">258</span>, <span class="hljs-number">97</span>, <span class="hljs-number">99</span>]))<br><span class="hljs-comment"># aaabdaaabac</span><br>tokenizer.save(<span class="hljs-string">&quot;toy&quot;</span>)<br></code></pre></td></tr></table></figure><p>它的作用是将aaabdaaabac进行三次的合并。它会输出一个新的字符串XdXac，其中X&#x3D;ZY、Y&#x3D;ab 和 Z&#x3D;aa。minbpe将单独的256个字节分配为Token，因此合并后的新字节将从257开始。</p><p>上述的例子中，a&#x3D;97、b&#x3D;98、c&#x3D;99、d&#x3D;100（它们的 ASCII 值）。然后，当 （a，a） 合并到 Z 时，Z 将变为 256。同样，Y 将变为 257 和 X 258。因此，我们从 256 个字节开始，进行 3 次合并以获得上述结果，预期输出为 [258， 100， 258， 97， 99]。</p><p>再用项目实现的<code>GPT4Tokenizer</code>和<code>tiktoken</code>实现的<code>GPT-4 tokenizer</code>进行对比：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">text = <span class="hljs-string">&quot;hello123!!!? (안녕하세요!) 😉&quot;</span><br><br><span class="hljs-comment"># tiktoken</span><br><span class="hljs-keyword">import</span> tiktoken<br>enc = tiktoken.get_encoding(<span class="hljs-string">&quot;cl100k_base&quot;</span>)<br><span class="hljs-built_in">print</span>(enc.encode(text))<br><span class="hljs-comment"># [15339, 4513, 12340, 30, 320, 31495, 230, 75265, 243, 92245, 16715, 57037]</span><br><br><span class="hljs-comment"># ours</span><br><span class="hljs-keyword">from</span> minbpe <span class="hljs-keyword">import</span> GPT4Tokenizer<br>tokenizer = GPT4Tokenizer()<br><span class="hljs-built_in">print</span>(tokenizer.encode(text))<br><span class="hljs-comment"># [15339, 4513, 12340, 30, 320, 31495, 230, 75265, 243, 92245, 16715, 57037]</span><br></code></pre></td></tr></table></figure><h2 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h2><p>这个项目里实现了两种方法，一种方法是不使用正则来处理原文本，这时候直接使用<code>BasicTokenizer</code>进行训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> minbpe <span class="hljs-keyword">import</span> BasicTokenizer<br>tokenizer = BasicTokenizer()<br>tokenizer.train(very_long_training_string, vocab_size=<span class="hljs-number">4096</span>)<br>tokenizer.encode(<span class="hljs-string">&quot;hello world&quot;</span>) <span class="hljs-comment"># string -&gt; tokens</span><br>tokenizer.decode([<span class="hljs-number">1000</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">3000</span>]) <span class="hljs-comment"># tokens -&gt; string</span><br>tokenizer.save(<span class="hljs-string">&quot;mymodel&quot;</span>) <span class="hljs-comment"># writes mymodel.model and mymodel.vocab</span><br>tokenizer.load(<span class="hljs-string">&quot;mymodel.model&quot;</span>) <span class="hljs-comment"># loads the model back, the vocab is just for vis</span><br></code></pre></td></tr></table></figure><p>如果要使用正则方法来按类别拆分文本，就使用以下方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> minbpe <span class="hljs-keyword">import</span> RegexTokenizer<br>tokenizer = RegexTokenizer()<br>tokenizer.train(very_long_training_string, vocab_size=<span class="hljs-number">32768</span>)<br>tokenizer.encode(<span class="hljs-string">&quot;hello world&quot;</span>) <span class="hljs-comment"># string -&gt; tokens</span><br>tokenizer.decode([<span class="hljs-number">1000</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">3000</span>]) <span class="hljs-comment"># tokens -&gt; string</span><br>tokenizer.save(<span class="hljs-string">&quot;tok32k&quot;</span>) <span class="hljs-comment"># writes tok32k.model and tok32k.vocab</span><br>tokenizer.load(<span class="hljs-string">&quot;tok32k.model&quot;</span>) <span class="hljs-comment"># loads the model back from disk</span><br></code></pre></td></tr></table></figure><p>如果要添加<code>special tokens</code>，代码里也实现了一个方法来注册：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> minbpe <span class="hljs-keyword">import</span> RegexTokenizer<br>tokenizer = RegexTokenizer()<br>tokenizer.train(very_long_training_string, vocab_size=<span class="hljs-number">32768</span>)<br>tokenizer.register_special_tokens(&#123;<span class="hljs-string">&quot;&lt;|endoftext|&gt;&quot;</span>: <span class="hljs-number">32768</span>&#125;)<br>tokenizer.encode(<span class="hljs-string">&quot;&lt;|endoftext|&gt;hello world&quot;</span>, allowed_special=<span class="hljs-string">&quot;all&quot;</span>)<br></code></pre></td></tr></table></figure><h1 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h1><h2 id="base-py"><a href="#base-py" class="headerlink" title="base.py"></a>base.py</h2><p>该文件实现了Toknizer的基类以及其他需要的工具函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> unicodedata<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_stats</span>(<span class="hljs-params">ids, counts=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    输入一个整数列表，返回一个连续对的计数字典</span><br><span class="hljs-string">    例如：[1, 2, 3, 1, 2] -&gt; &#123;(1, 2): 2, (2, 3): 1, (3, 1): 1&#125;</span><br><span class="hljs-string">    可以选择更新一个已存在的计数字典</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 如果没有传入counts，则初始化一个空字典</span><br>    counts = &#123;&#125; <span class="hljs-keyword">if</span> counts <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> counts  <br>    <br>    <span class="hljs-comment"># 遍历列表的前后连续对：不断迭代前一个和后一个字符对</span><br>    <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(ids, ids[<span class="hljs-number">1</span>:]): <br>        counts[pair] = counts.get(pair, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span> <span class="hljs-comment"># 不断增加统计数</span><br>    <span class="hljs-keyword">return</span> counts<br></code></pre></td></tr></table></figure><p><code>get_stats</code>实际上是一个比较核心的函数，下面是<code>merge</code>函数，将所有的pair都用指定的idx来代替。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">merge</span>(<span class="hljs-params">ids, pair, idx</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    在整数列表中，用新的整数idx替换所有连续出现的pair</span><br><span class="hljs-string">    例如：ids=[1, 2, 3, 1, 2], pair=(1, 2), idx=4 -&gt; [4, 3, 4]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    newids = []<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i &lt; <span class="hljs-built_in">len</span>(ids):<br>        <span class="hljs-comment"># 如果不是在最后一个位置，并且pair匹配，就替换</span><br>        <span class="hljs-keyword">if</span> ids[i] == pair[<span class="hljs-number">0</span>] <span class="hljs-keyword">and</span> i &lt; <span class="hljs-built_in">len</span>(ids) - <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> ids[i+<span class="hljs-number">1</span>] == pair[<span class="hljs-number">1</span>]:<br>            newids.append(idx) <span class="hljs-comment"># 新列表添加</span><br>            i += <span class="hljs-number">2</span> <span class="hljs-comment"># 指针增加2位</span><br>        <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 如果找不到匹配的，就把原字符加入新列表</span><br>            newids.append(ids[i]) <br>            i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> newids<br></code></pre></td></tr></table></figure><p>接下来是一个辅助函数。在Unicode中，包含一系列控制字符。这是一组特殊的字符，用于控制文本的显示和处理，这些字符通常不可见。控制字符的Unicode范围是U+0000至U+001F和U+007F至U+009F。由于我们将字符编码位Unicode，目标词表中，不需要这些控制字符，所以需要删除它们。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">replace_control_characters</span>(<span class="hljs-params">s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">将输入文本中，所有的控制字符删除，并返回处理过后的字符串。</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>    chars = []<br>    <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> s:<br>        <span class="hljs-keyword">if</span> unicodedata.category(ch)[<span class="hljs-number">0</span>] != <span class="hljs-string">&quot;C&quot;</span>:<br>            chars.append(ch) <span class="hljs-comment"># 只要不是控制字符就添加</span><br>        <span class="hljs-keyword">else</span>:<br>            chars.append(<span class="hljs-string">f&quot;\\u<span class="hljs-subst">&#123;<span class="hljs-built_in">ord</span>(ch):04x&#125;</span>&quot;</span>) <span class="hljs-comment"># 其转换为Unicode转义序列</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>.join(chars)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">render_token</span>(<span class="hljs-params">t: <span class="hljs-built_in">bytes</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    将bytes转为字符串，并清理控制字符</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    s = t.decode(<span class="hljs-string">&#x27;utf-8&#x27;</span>, errors=<span class="hljs-string">&#x27;replace&#x27;</span>)<br>    s = replace_control_characters(s)<br>    <span class="hljs-keyword">return</span> s<br></code></pre></td></tr></table></figure><p>工具函数写完了，下面是<code>Tokenizer</code>的抽象类，抽象类包含了训练，编码，解码，构建词表，保存和加载方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tokenizer</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;Base class for Tokenizers&quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># default: vocab size of 256 (all bytes), no merges, no patterns</span><br>        self.merges = &#123;&#125; <span class="hljs-comment"># (int, int) -&gt; int</span><br>        self.pattern = <span class="hljs-string">&quot;&quot;</span> <span class="hljs-comment"># str</span><br>        self.special_tokens = &#123;&#125; <span class="hljs-comment"># str -&gt; int, e.g. &#123;&#x27;&lt;|endoftext|&gt;&#x27;: 100257&#125;</span><br>        self.vocab = self._build_vocab() <span class="hljs-comment"># int -&gt; bytes</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, text, vocab_size, verbose=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, text</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, ids</span>):<br> <br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_build_vocab</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 构建词表，基础词表是256个字节</span><br>        vocab = &#123;idx: <span class="hljs-built_in">bytes</span>([idx]) <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>)&#125;<br>        <br>        <span class="hljs-comment"># (p0,p1) 是pairs</span><br>        <span class="hljs-keyword">for</span> (p0, p1), idx <span class="hljs-keyword">in</span> self.merges.items():<br>            vocab[idx] = vocab[p0] + vocab[p1]<br>        <span class="hljs-keyword">for</span> special, idx <span class="hljs-keyword">in</span> self.special_tokens.items():<br>            vocab[idx] = special.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)<br>        <span class="hljs-keyword">return</span> vocab<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">self, file_prefix</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        保存两个文件：file_prefix.vocab 和 file_prefix.model</span><br><span class="hljs-string">        - model文件用于load()</span><br><span class="hljs-string">        - vocab文件只是一个打印版本，仅供人类检查</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 写入文件</span><br>        model_file = file_prefix + <span class="hljs-string">&quot;.model&quot;</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(model_file, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-comment"># 写入版本，模式和合并</span><br>            f.write(<span class="hljs-string">&quot;minbpe v1\n&quot;</span>)<br>            f.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;self.pattern&#125;</span>\n&quot;</span>)<br>            <span class="hljs-comment"># 写入特殊字符</span><br>            f.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(self.special_tokens)&#125;</span>\n&quot;</span>)<br>            <span class="hljs-keyword">for</span> special, idx <span class="hljs-keyword">in</span> self.special_tokens.items():<br>                f.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;special&#125;</span> <span class="hljs-subst">&#123;idx&#125;</span>\n&quot;</span>)<br>            <span class="hljs-comment"># 合并字典</span><br>            <span class="hljs-keyword">for</span> idx1, idx2 <span class="hljs-keyword">in</span> self.merges:<br>                f.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;idx1&#125;</span> <span class="hljs-subst">&#123;idx2&#125;</span>\n&quot;</span>)<br>                <br>        <span class="hljs-comment"># 写入词表，这个只是用来看的</span><br>        vocab_file = file_prefix + <span class="hljs-string">&quot;.vocab&quot;</span><br>        inverted_merges = &#123;idx: pair <span class="hljs-keyword">for</span> pair, idx <span class="hljs-keyword">in</span> self.merges.items()&#125;<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(vocab_file, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> idx, token <span class="hljs-keyword">in</span> self.vocab.items():<br>                s = render_token(token)<br>              <br>                <span class="hljs-keyword">if</span> idx <span class="hljs-keyword">in</span> inverted_merges:<br>                    idx0, idx1 = inverted_merges[idx]<br>                    s0 = render_token(self.vocab[idx0])<br>                    s1 = render_token(self.vocab[idx1])<br>                    f.write(<span class="hljs-string">f&quot;[<span class="hljs-subst">&#123;s0&#125;</span>][<span class="hljs-subst">&#123;s1&#125;</span>] -&gt; [<span class="hljs-subst">&#123;s&#125;</span>] <span class="hljs-subst">&#123;idx&#125;</span>\n&quot;</span>)<br>                <span class="hljs-keyword">else</span>:<br>                    f.write(<span class="hljs-string">f&quot;[<span class="hljs-subst">&#123;s&#125;</span>] <span class="hljs-subst">&#123;idx&#125;</span>\n&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load</span>(<span class="hljs-params">self, model_file</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;读取模型文件&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">assert</span> model_file.endswith(<span class="hljs-string">&quot;.model&quot;</span>)<br>        <span class="hljs-comment"># 读取模型文件</span><br>        merges = &#123;&#125;<br>        special_tokens = &#123;&#125;<br>        idx = <span class="hljs-number">256</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(model_file, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            version = f.readline().strip()<br>            <span class="hljs-keyword">assert</span> version == <span class="hljs-string">&quot;minbpe v1&quot;</span><br>            self.pattern = f.readline().strip()<br><br>            num_special = <span class="hljs-built_in">int</span>(f.readline().strip())<br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_special):<br>                special, special_idx = f.readline().strip().split()<br>                special_tokens[special] = <span class="hljs-built_in">int</span>(special_idx)<br><br>            <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>                idx1, idx2 = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, line.split())<br>                merges[(idx1, idx2)] = idx<br>                idx += <span class="hljs-number">1</span><br>        self.merges = merges<br>        self.special_tokens = special_tokens<br>        self.vocab = self._build_vocab()<br></code></pre></td></tr></table></figure><h2 id="basic-py"><a href="#basic-py" class="headerlink" title="basic.py"></a>basic.py</h2><p>该文件实现了基本的<code>Tokenizer</code>类。首先断言词表的大小大于256，并计算要进行几次merge，也就是去掉256个基本字节后，词表还剩下几个。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> .base <span class="hljs-keyword">import</span> Tokenizer, get_stats, merge<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, text, vocab_size, verbose=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-keyword">assert</span> vocab_size &gt;= <span class="hljs-number">256</span><br>        <span class="hljs-comment"># 计算merge次数</span><br>        num_merges = vocab_size - <span class="hljs-number">256</span><br><br>        <span class="hljs-comment"># 输入文本预处理</span><br>        text_bytes = text.encode(<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-comment"># 将文本解码为Utf-8格式</span><br>        ids = <span class="hljs-built_in">list</span>(text_bytes) <span class="hljs-comment"># 每个元素都是0-255之间的整数的列表</span><br><br>        <span class="hljs-comment"># 迭代地合并最常见的pair，创建新的token</span><br>        merges = &#123;&#125; <span class="hljs-comment"># (int, int) -&gt; int</span><br>        vocab = &#123;idx: <span class="hljs-built_in">bytes</span>([idx]) <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>)&#125; <span class="hljs-comment"># int -&gt; bytes</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_merges):<br>            <span class="hljs-comment"># 统计每个pair出现的次数，返回字典，key是pair，value是出现的次数</span><br>            stats = get_stats(ids)<br>            <span class="hljs-comment"># 找到出现次数最多的pair</span><br>            pair = <span class="hljs-built_in">max</span>(stats, key=stats.get)<br>            <span class="hljs-comment"># 为新的token分配一个新的id</span><br>            idx = <span class="hljs-number">256</span> + i<br>            <span class="hljs-comment"># 用idx替换ids中所有的pair</span><br>            ids = merge(ids, pair, idx)<br>            <span class="hljs-comment"># 保存合并</span><br>            merges[pair] = idx<br>            vocab[idx] = vocab[pair[<span class="hljs-number">0</span>]] + vocab[pair[<span class="hljs-number">1</span>]]<br>            <span class="hljs-comment"># 打印</span><br>            <span class="hljs-keyword">if</span> verbose:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;merge <span class="hljs-subst">&#123;i+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_merges&#125;</span>: <span class="hljs-subst">&#123;pair&#125;</span> -&gt; <span class="hljs-subst">&#123;idx&#125;</span> (<span class="hljs-subst">&#123;vocab[idx]&#125;</span>) had <span class="hljs-subst">&#123;stats[pair]&#125;</span> occurrences&quot;</span>)<br><br>        <span class="hljs-comment"># 保存类变量</span><br>        self.merges = merges <span class="hljs-comment"># used in encode()</span><br>        self.vocab = vocab   <span class="hljs-comment"># used in decode()</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, ids</span>):<br>        <span class="hljs-comment"># 解码，输入int组成的列表，返回字符串</span><br>        text_bytes = <span class="hljs-string">b&quot;&quot;</span>.join(self.vocab[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> ids)<br>        text = text_bytes.decode(<span class="hljs-string">&quot;utf-8&quot;</span>, errors=<span class="hljs-string">&quot;replace&quot;</span>)<br>        <span class="hljs-keyword">return</span> text<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, text</span>):<br>        <span class="hljs-comment"># 编码，输入字符串，返回int列表</span><br>        text_bytes = text.encode(<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-comment"># raw bytes</span><br>        ids = <span class="hljs-built_in">list</span>(text_bytes) <span class="hljs-comment"># 0-255 int值的列表</span><br>        <span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(ids) &gt;= <span class="hljs-number">2</span>:<br>            <span class="hljs-comment"># 找到pair中merge index最小的pair</span><br>            stats = get_stats(ids)<br>            pair = <span class="hljs-built_in">min</span>(stats, key=<span class="hljs-keyword">lambda</span> p: self.merges.get(p, <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;inf&quot;</span>)))<br>            <span class="hljs-comment"># 如果没有更多的merge可用，那么key将给每个pair一个inf，min将是列表中的第一个pair</span><br>            <span class="hljs-keyword">if</span> pair <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.merges:<br>                <span class="hljs-keyword">break</span> <span class="hljs-comment"># 没有可以继续merge的情况下中断</span><br>            <span class="hljs-comment"># 否则继续merge当前最佳的pair（最少merge次数的index） </span><br>            idx = self.merges[pair]<br>            ids = merge(ids, pair, idx)<br>        <span class="hljs-keyword">return</span> ids<br></code></pre></td></tr></table></figure><h2 id="regex-py"><a href="#regex-py" class="headerlink" title="regex.py"></a>regex.py</h2><p>该文件实现了<code>RegexTokenizer</code>，是一个正则处理的类，用于预处理文本，并处理<code>special tokens</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> regex <span class="hljs-keyword">as</span> re<br><span class="hljs-keyword">from</span> .base <span class="hljs-keyword">import</span> Tokenizer, get_stats, merge<br><br><span class="hljs-comment"># GPT文本的分词处理模式</span><br><span class="hljs-comment"># https://github.com/openai/tiktoken/blob/main/tiktoken_ext/openai_public.py</span><br>GPT2_SPLIT_PATTERN = <span class="hljs-string">r&quot;&quot;&quot;&#x27;(?:[sdmt]|ll|ve|re)| ?\p&#123;L&#125;+| ?\p&#123;N&#125;+| ?[^\s\p&#123;L&#125;\p&#123;N&#125;]+|\s+(?!\S)|\s+&quot;&quot;&quot;</span><br>GPT4_SPLIT_PATTERN = <span class="hljs-string">r&quot;&quot;&quot;&#x27;(?i:[sdmt]|ll|ve|re)|[^\r\n\p&#123;L&#125;\p&#123;N&#125;]?+\p&#123;L&#125;+|\p&#123;N&#125;&#123;1,3&#125;| ?[^\s\p&#123;L&#125;\p&#123;N&#125;]++[\r\n]*|\s*[\r\n]|\s+(?!\S)|\s+&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RegexTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, pattern=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        - pattern: 可选的字符串，用于覆盖默认的（GPT-4分割模式）</span><br><span class="hljs-string">        - special_tokens: 特殊token的str -&gt; int字典</span><br><span class="hljs-string">          例如：&#123;&#x27;&lt;|endoftext|&gt;&#x27;: 100257&#125;</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.pattern = GPT4_SPLIT_PATTERN <span class="hljs-keyword">if</span> pattern <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> pattern<br>        self.compiled_pattern = re.<span class="hljs-built_in">compile</span>(self.pattern)<br>        self.special_tokens = &#123;&#125; <span class="hljs-comment"># str -&gt; int</span><br>        self.inverse_special_tokens = &#123;&#125; <span class="hljs-comment"># int -&gt; str</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, text, vocab_size, verbose=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-keyword">assert</span> vocab_size &gt;= <span class="hljs-number">256</span><br>        num_merges = vocab_size - <span class="hljs-number">256</span><br><br>        <span class="hljs-comment"># 分割文本为文本块</span><br>        text_chunks = re.findall(self.compiled_pattern, text)<br><br>        <span class="hljs-comment"># 输入文本预处理</span><br>        ids = [<span class="hljs-built_in">list</span>(ch.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)) <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> text_chunks]<br><br>        <span class="hljs-comment"># 迭代将最常见的组合合并为新的标记</span><br>        merges = &#123;&#125; <span class="hljs-comment"># (int, int) -&gt; int</span><br>        vocab = &#123;idx: <span class="hljs-built_in">bytes</span>([idx]) <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>)&#125; <span class="hljs-comment"># idx -&gt; bytes</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_merges):<br>           <span class="hljs-comment"># 计算每个连续组合出现的次数</span><br>            stats = &#123;&#125;<br>            <span class="hljs-keyword">for</span> chunk_ids <span class="hljs-keyword">in</span> ids:<br>                <span class="hljs-comment"># 传入stats将在原地更新它，累加计数</span><br>                get_stats(chunk_ids, stats)<br>            <span class="hljs-comment"># 找到计数最高的组合</span><br>            pair = <span class="hljs-built_in">max</span>(stats, key=stats.get)<br>            <span class="hljs-comment"># 铸造一个新的标记：分配下一个可用的id</span><br>            idx = <span class="hljs-number">256</span> + i<br>            <span class="hljs-comment"># 用idx替换ids中所有pair的出现</span><br>            ids = [merge(chunk_ids, pair, idx) <span class="hljs-keyword">for</span> chunk_ids <span class="hljs-keyword">in</span> ids]<br>            <span class="hljs-comment"># 保存merge</span><br>            merges[pair] = idx<br>            vocab[idx] = vocab[pair[<span class="hljs-number">0</span>]] + vocab[pair[<span class="hljs-number">1</span>]]<br>            <span class="hljs-comment"># 打印</span><br>            <span class="hljs-keyword">if</span> verbose:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;merge <span class="hljs-subst">&#123;i+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_merges&#125;</span>: <span class="hljs-subst">&#123;pair&#125;</span> -&gt; <span class="hljs-subst">&#123;idx&#125;</span> (<span class="hljs-subst">&#123;vocab[idx]&#125;</span>) had <span class="hljs-subst">&#123;stats[pair]&#125;</span> occurrences&quot;</span>)<br><br>        <span class="hljs-comment"># 保存</span><br>        self.merges = merges <span class="hljs-comment"># used in encode()</span><br>        self.vocab = vocab   <span class="hljs-comment"># used in decode()</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">register_special_tokens</span>(<span class="hljs-params">self, special_tokens</span>):<br>        <span class="hljs-comment"># special_tokens: 一个特殊的字典 str -&gt; int</span><br>        <span class="hljs-comment"># 例如: &#123;&quot;&lt;|endoftext|&gt;&quot;: 100257&#125;</span><br>        self.special_tokens = special_tokens<br>        self.inverse_special_tokens = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> special_tokens.items()&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, ids</span>):<br>        part_bytes = []<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> ids:<br>            <span class="hljs-keyword">if</span> idx <span class="hljs-keyword">in</span> self.vocab:<br>                part_bytes.append(self.vocab[idx])<br>            <span class="hljs-keyword">elif</span> idx <span class="hljs-keyword">in</span> self.inverse_special_tokens:<br>                part_bytes.append(self.inverse_special_tokens[idx].encode(<span class="hljs-string">&quot;utf-8&quot;</span>))<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;invalid token id: <span class="hljs-subst">&#123;idx&#125;</span>&quot;</span>)<br>        text_bytes = <span class="hljs-string">b&quot;&quot;</span>.join(part_bytes)<br>        text = text_bytes.decode(<span class="hljs-string">&quot;utf-8&quot;</span>, errors=<span class="hljs-string">&quot;replace&quot;</span>)<br>        <span class="hljs-keyword">return</span> text<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_encode_chunk</span>(<span class="hljs-params">self, text_bytes</span>):<br>        <span class="hljs-comment"># 返回 token ids</span><br>        <span class="hljs-comment"># 将所有字节转换为0..255范围内的整数</span><br>        ids = <span class="hljs-built_in">list</span>(text_bytes)<br>        <span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(ids) &gt;= <span class="hljs-number">2</span>:<br>            <span class="hljs-comment"># 找到pair中merge index最小的pair</span><br>            stats = get_stats(ids)<br>            pair = <span class="hljs-built_in">min</span>(stats, key=<span class="hljs-keyword">lambda</span> p: self.merges.get(p, <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;inf&quot;</span>)))<br>            <span class="hljs-keyword">if</span> pair <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.merges:<br>                <span class="hljs-keyword">break</span> <br><br>            idx = self.merges[pair]<br>            ids = merge(ids, pair, idx)<br>        <span class="hljs-keyword">return</span> ids<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_ordinary</span>(<span class="hljs-params">self, text</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;编码并忽略任何special token。&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 按照正则表达式模式中定义的类别将文本分割为文本块</span><br>        text_chunks = re.findall(self.compiled_pattern, text)<br>        <span class="hljs-comment"># 所有字符块被单独编码，并在最后合并</span><br>        ids = []<br>        <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> text_chunks:<br>            chunk_bytes = chunk.encode(<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-comment"># raw bytes</span><br>            chunk_ids = self._encode_chunk(chunk_bytes)<br>            ids.extend(chunk_ids)<br>        <span class="hljs-keyword">return</span> ids<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, text, allowed_special=<span class="hljs-string">&quot;none_raise&quot;</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        与encode_ordinary不同，此函数处理特殊token。</span><br><span class="hljs-string">        allowed_special: 可以是&quot;all&quot;|&quot;none&quot;|&quot;none_raise&quot;或特殊token的自定义集合</span><br><span class="hljs-string">        如果none_raise，则在文本中遇到任何特殊token时会引发错误</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># decode the user desire w.r.t. handling of special tokens</span><br>        special = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> allowed_special == <span class="hljs-string">&quot;all&quot;</span>:<br>            special = self.special_tokens<br>        <span class="hljs-keyword">elif</span> allowed_special == <span class="hljs-string">&quot;none&quot;</span>:<br>            special = &#123;&#125;<br>        <span class="hljs-keyword">elif</span> allowed_special == <span class="hljs-string">&quot;none_raise&quot;</span>:<br>            special = &#123;&#125;<br>            <span class="hljs-keyword">assert</span> <span class="hljs-built_in">all</span>(token <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> text <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> self.special_tokens)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(allowed_special, <span class="hljs-built_in">set</span>):<br>            special = &#123;k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self.special_tokens.items() <span class="hljs-keyword">if</span> k <span class="hljs-keyword">in</span> allowed_special&#125;<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;allowed_special=<span class="hljs-subst">&#123;allowed_special&#125;</span> not understood&quot;</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> special:<br>            <span class="hljs-comment"># 如果没有special token,就使用ordinary encoding</span><br>            <span class="hljs-keyword">return</span> self.encode_ordinary(text)<br>        <span class="hljs-comment"># 否则，我们必须小心处理文本中可能的特殊token</span><br>        <span class="hljs-comment"># 我们通过在文本中出现任何特殊token的确切匹配来处理特殊token</span><br>        <span class="hljs-comment"># 我们可以使用re.split来实现这一点。请注意，将模式括在()中</span><br>        <span class="hljs-comment"># 使其成为捕获组，因此特殊token将被包括在内</span><br>        special_pattern = <span class="hljs-string">&quot;(&quot;</span> + <span class="hljs-string">&quot;|&quot;</span>.join(re.escape(k) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> special) + <span class="hljs-string">&quot;)&quot;</span><br>        special_chunks = re.split(special_pattern, text)<br>        <span class="hljs-comment"># 现在所有特殊字符都与文本的其余部分分开</span><br>        <span class="hljs-comment"># 所有文本块都是分开编码的，然后结果是连接的</span><br>        ids = []<br>        <span class="hljs-keyword">for</span> part <span class="hljs-keyword">in</span> special_chunks:<br>            <span class="hljs-keyword">if</span> part <span class="hljs-keyword">in</span> special:<br>                <span class="hljs-comment"># 这是一个特殊的标记，将其单独编码为特殊情况</span><br>                ids.append(special[part])<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># 这是一个普通的序列，正常编码</span><br>                ids.extend(self.encode_ordinary(part))<br>        <span class="hljs-keyword">return</span> ids<br></code></pre></td></tr></table></figure><h2 id="gpt4-py"><a href="#gpt4-py" class="headerlink" title="gpt4.py"></a>gpt4.py</h2><p>最后一个文件是<code>gpt4.py</code>，实现了基于<code>RegexTokenizer</code>的<code>GPT4Tokenizer</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tiktoken<br><span class="hljs-keyword">from</span> .regex <span class="hljs-keyword">import</span> RegexTokenizer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bpe</span>(<span class="hljs-params">mergeable_ranks, token, max_rank</span>):<br>    <span class="hljs-comment"># 辅助函数，用于在get_gpt4_merges()中重构合并树</span><br>    parts = [<span class="hljs-built_in">bytes</span>([b]) <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> token]<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        min_idx = <span class="hljs-literal">None</span><br>        min_rank = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">for</span> i, pair <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(parts[:-<span class="hljs-number">1</span>], parts[<span class="hljs-number">1</span>:])):<br>            rank = mergeable_ranks.get(pair[<span class="hljs-number">0</span>] + pair[<span class="hljs-number">1</span>])<br>            <span class="hljs-keyword">if</span> rank <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> (min_rank <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> rank &lt; min_rank):<br>                min_idx = i<br>                min_rank = rank<br>        <span class="hljs-keyword">if</span> min_rank <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> (max_rank <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> min_rank &gt;= max_rank):<br>            <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">assert</span> min_idx <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span><br>        parts = parts[:min_idx] + [parts[min_idx] + parts[min_idx + <span class="hljs-number">1</span>]] + parts[min_idx + <span class="hljs-number">2</span>:]<br>    <span class="hljs-keyword">return</span> parts<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">recover_merges</span>(<span class="hljs-params">mergeable_ranks</span>):<br>    <span class="hljs-comment"># `merges`已经是它们合并状态的字节序列。</span><br>    <span class="hljs-comment"># 因此，我们必须恢复原始的配对。我们可以通过对所有token进行一次小型BPE训练来实现这一点，按顺序进行。</span><br>  <br>    merges = &#123;&#125;<br>    <span class="hljs-keyword">for</span> token, rank <span class="hljs-keyword">in</span> mergeable_ranks.items():<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(token) == <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">continue</span> <span class="hljs-comment"># skip raw bytes</span><br>        pair = <span class="hljs-built_in">tuple</span>(bpe(mergeable_ranks, token, max_rank=rank))<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(pair) == <span class="hljs-number">2</span><br>        <span class="hljs-comment"># 恢复对的整数等级</span><br>        ix0 = mergeable_ranks[pair[<span class="hljs-number">0</span>]]<br>        ix1 = mergeable_ranks[pair[<span class="hljs-number">1</span>]]<br>        merges[(ix0, ix1)] = rank<br><br>    <span class="hljs-keyword">return</span> merges<br></code></pre></td></tr></table></figure><p>下面是<code>GPT4Tokenizer</code>的具体实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><code class="hljs python">GPT4_SPLIT_PATTERN = <span class="hljs-string">r&quot;&quot;&quot;&#x27;(?i:[sdmt]|ll|ve|re)|[^\r\n\p&#123;L&#125;\p&#123;N&#125;]?+\p&#123;L&#125;+|\p&#123;N&#125;&#123;1,3&#125;| ?[^\s\p&#123;L&#125;\p&#123;N&#125;]++[\r\n]*|\s*[\r\n]|\s+(?!\S)|\s+&quot;&quot;&quot;</span><br>GPT4_SPECIAL_TOKENS = &#123;<br>    <span class="hljs-string">&#x27;&lt;|endoftext|&gt;&#x27;</span>: <span class="hljs-number">100257</span>,<br>    <span class="hljs-string">&#x27;&lt;|fim_prefix|&gt;&#x27;</span>: <span class="hljs-number">100258</span>,<br>    <span class="hljs-string">&#x27;&lt;|fim_middle|&gt;&#x27;</span>: <span class="hljs-number">100259</span>,<br>    <span class="hljs-string">&#x27;&lt;|fim_suffix|&gt;&#x27;</span>: <span class="hljs-number">100260</span>,<br>    <span class="hljs-string">&#x27;&lt;|endofprompt|&gt;&#x27;</span>: <span class="hljs-number">100276</span><br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GPT4Tokenizer</span>(<span class="hljs-title class_ inherited__">RegexTokenizer</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;RegexTokenizer的轻量级包装器，匹配GPT-4的分词器。&quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__(pattern=GPT4_SPLIT_PATTERN)<br>        <span class="hljs-comment"># 获取官方tokenizer和merges</span><br>        enc = tiktoken.get_encoding(<span class="hljs-string">&quot;cl100k_base&quot;</span>)<br>        mergeable_ranks = enc._mergeable_ranks<br>        <span class="hljs-comment"># the merges are those of gpt4, but we have to recover them</span><br>        self.merges = recover_merges(mergeable_ranks)<br>        <span class="hljs-comment"># 从merges重建vocab</span><br>        vocab = &#123;idx: <span class="hljs-built_in">bytes</span>([idx]) <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>)&#125;<br>        <span class="hljs-keyword">for</span> (p0, p1), idx <span class="hljs-keyword">in</span> self.merges.items():<br>            vocab[idx] = vocab[p0] + vocab[p1]<br>        self.vocab = vocab<br>        <br>        <span class="hljs-comment"># 由于某种原因，与单个字节对应的标记以不同的顺序排列。</span><br>        self.byte_shuffle = &#123;i: mergeable_ranks[<span class="hljs-built_in">bytes</span>([i])] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>)&#125;<br>        self.inverse_byte_shuffle = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self.byte_shuffle.items()&#125;<br><span class="hljs-comment"># 注册special tokens</span><br>        self.register_special_tokens(GPT4_SPECIAL_TOKENS)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_encode_chunk</span>(<span class="hljs-params">self, text_bytes</span>):<br>    <span class="hljs-comment"># 在我们开始处理字节之前，我们必须对它们进行排列</span><br>        text_bytes = <span class="hljs-built_in">bytes</span>(self.byte_shuffle[b] <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> text_bytes)<br>        ids = <span class="hljs-built_in">super</span>()._encode_chunk(text_bytes)<br>        <span class="hljs-keyword">return</span> ids<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, ids</span>):<br>    <span class="hljs-comment"># 我们必须在解码之前对字节进行反排列</span><br>        text_bytes = <span class="hljs-string">b&quot;&quot;</span>.join(self.vocab[idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> ids)<br>        text_bytes = <span class="hljs-built_in">bytes</span>(self.inverse_byte_shuffle[b] <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> text_bytes)<br>        text = text_bytes.decode(<span class="hljs-string">&quot;utf-8&quot;</span>, errors=<span class="hljs-string">&quot;replace&quot;</span>)<br>        <span class="hljs-keyword">return</span> text<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, text, vocab_size, verbose=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">self, file_prefix</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&quot;GPT4Tokenizer cannot be saved.&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load</span>(<span class="hljs-params">self, model_file</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&quot;GPT4Tokenizer cannot be loaded.&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save_vocab</span>(<span class="hljs-params">self, vocab_file</span>):<br>        <span class="hljs-comment"># 仅用于可视化目的，让我们以与基类完全相同的格式输出GPT-4标记。</span><br>        <span class="hljs-comment"># 简单运行：</span><br>        <span class="hljs-comment"># python -c &quot;from minbpe import GPT4Tokenizer; GPT4Tokenizer().save_vocab(&#x27;gpt4.vocab&#x27;)&quot;</span><br>    <br>        <span class="hljs-keyword">from</span> .base <span class="hljs-keyword">import</span> render_token<br>        vocab = &#123;idx: <span class="hljs-built_in">bytes</span>([self.inverse_byte_shuffle[idx]]) <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>)&#125;<br>        <span class="hljs-keyword">for</span> (p0, p1), idx <span class="hljs-keyword">in</span> self.merges.items():<br>            vocab[idx] = vocab[p0] + vocab[p1]<br><br>        inverted_merges = &#123;idx: pair <span class="hljs-keyword">for</span> pair, idx <span class="hljs-keyword">in</span> self.merges.items()&#125;<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(vocab_file, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> idx, token <span class="hljs-keyword">in</span> vocab.items():<br>                s = render_token(token)<br>                <span class="hljs-keyword">if</span> idx <span class="hljs-keyword">in</span> inverted_merges:<br>                    idx0, idx1 = inverted_merges[idx]<br>                    s0 = render_token(vocab[idx0])<br>                    s1 = render_token(vocab[idx1])<br>                    f.write(<span class="hljs-string">f&quot;[<span class="hljs-subst">&#123;s0&#125;</span>][<span class="hljs-subst">&#123;s1&#125;</span>] -&gt; [<span class="hljs-subst">&#123;s&#125;</span>] <span class="hljs-subst">&#123;idx&#125;</span>\n&quot;</span>)<br>                <span class="hljs-keyword">else</span>:<br>                    f.write(<span class="hljs-string">f&quot;[<span class="hljs-subst">&#123;s&#125;</span>] <span class="hljs-subst">&#123;idx&#125;</span>\n&quot;</span>)<br></code></pre></td></tr></table></figure><p>2024&#x2F;3&#x2F;10 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
      <tag>BPE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式训练：Distributed Data Parallel</title>
    <link href="/2024/03/07/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%EF%BC%9ADistributed-Data-Parallel/"/>
    <url>/2024/03/07/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%EF%BC%9ADistributed-Data-Parallel/</url>
    
    <content type="html"><![CDATA[<p>前一篇博客讲了已经被淘汰的数据并行，这次学习一下目前用的比较多的分布式数据并行（Distributed Data Parallel）。对比DP，DDP能够使用于单机多卡和多机多卡，并且对GPU的利用率更佳。</p><p><strong>和DP有什么不同？</strong></p><p>使用<code>torch.distributed</code>，编写一份训练代码，torch会将代码分配给每个进程。此时就没有主GPU的区别，每个GPU都执行相同的工作。此外，每个GPU加载自己的数据，并且对比DP，反向传播这个过程是在每个GPU上实现的，而不是汇集到主GPU上执行。</p><h1 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h1><p>分布式数据并行的流程如下所示：</p><ul><li>Step 1 使用多进程，每个进程加载模型和数据</li><li>Step2 各进程前向传播，得到输出</li><li>Step3 各进程计算Loss，反向传播并得到梯度</li><li>Step4 各进程通信，梯度在各卡进行同步</li><li>Step5 各进程更新模型</li></ul><h1 id="分布式训练中的基本概念"><a href="#分布式训练中的基本概念" class="headerlink" title="分布式训练中的基本概念"></a>分布式训练中的基本概念</h1><p>分布式训练中包含了几个基本的概念：</p><ul><li><code>group</code>： 进程组。一个分布式任务对应一个进程组。一般所有的显卡都在一个组里。一个 任务即为一个组，也即一个 world。</li><li><code>world_size</code>：全局并行数，一般是总卡数。</li><li><code>node</code>：节点。一般是一台机器，或是一个容器。里面会包含多个GPU。</li><li><code>rank(global_rank)</code>：整个分布式训练任务内的进程序号，一般<code>rank</code>为0指的是主进程。</li><li><code>local_rank</code>：区别于<code>rank</code>，是每个节点内部的相对的进程的序号。可以理解为进程内的GPU 编号，例如 rank &#x3D; 3，local_rank &#x3D; 0 表示第 3 个进程内的第 1 块 GPU。</li></ul><p>例如下图是一个示例：2机4卡的分布式训练。此时<code>node</code>为2，<code>world_size</code>为4。</p><p><img src="/images/205819.png"></p><h1 id="分布式训练中的通信"><a href="#分布式训练中的通信" class="headerlink" title="分布式训练中的通信"></a>分布式训练中的通信</h1><p>分布式训练中，不同节点一般都需要进行信息交换，这就叫做通信。通信被分为两个大类：点对点通信就是将数据从一个进程传输到另一个进程。</p><p>集合通信则是指一个分组内所有进程的通信，也就是多卡之间的通信。包含了六种通信类型：</p><ul><li><code>Scatter</code>:  分发。将主进程上Rank 0 上的数据平均分发给其他Rank。</li><li><code>Gather</code>: 与<code>Scatter</code>相反，将子进程的数据汇集在主进程。</li><li><code>Reduce</code>: 将子进程上的数据合并后，进行某种计算（加减乘除，平均等等）后传到主进程。</li><li><code>All Reduce</code>: 将多个进程的信息先汇总并处理&#x2F;计算后，在将结果发送回每个进程。</li><li><code>Broadcast</code>: 将Rank 0上的完整数据广播到各个Rank。</li><li><code>All Gather</code>: 将所有进程上的数据汇总（不计算）后，分发到每个进程。这样每个进程都会有一样的完整数据。</li></ul><h1 id="Pytorch单机多卡代码实现"><a href="#Pytorch单机多卡代码实现" class="headerlink" title="Pytorch单机多卡代码实现"></a>Pytorch单机多卡代码实现</h1><p>使用分布式数据并行需要用python文件进行执行，运行文件也需要使用<code>torchrun</code>的方式来执行。例如下面这个示例代码，需要在命令行运行<code>torchrun --nproc_per_node=2 ddp.py</code>来运行，这代表着使用两个卡来进行训练。<code>nproc_per_node</code> 参数指定为当前主机创建的进程数。一般设定为当前主机的 GPU 数量。</p><p>还有一些需要注意的参数：</p><ul><li><p><code>nproc_per_node</code> 指的是每个阶段的进程数</p></li><li><p><code>nnodes</code> 节点数，也就是机器的数量</p></li><li><p><code>node_rank</code> 节点rank，对于第一台机器是0，第二台机器是1</p></li><li><p><code>master_addr</code> 主节点的ip</p></li><li><p><code>master_port</code> 主节点的端口号</p></li></ul><p>首先需要进行初始化和导入依赖项：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertForSequenceClassification<br><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist <br><br>dist.init_process_group(backend=<span class="hljs-string">&quot;nccl&quot;</span>) <span class="hljs-comment"># 初始化分布式处理组</span><br></code></pre></td></tr></table></figure><p>参数<code>backend=&quot;nccl&quot;</code>指定了使用NCCL（Nvidia Collective Communications Library）作为后端来实现分布式处理。</p><p>接下来是导入数据和准备Dataset等前置工作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>data = pd.read_csv(<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>)<br>data = data.dropna()<br><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.data = pd.read_csv(<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>)<br>        self.data = self.data.dropna()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">return</span> self.data.iloc[index][<span class="hljs-string">&quot;review&quot;</span>], self.data.iloc[index][<span class="hljs-string">&quot;label&quot;</span>]<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br><br>dataset = MyDataset()<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> random_split<br><br>trainset, validset = random_split(dataset, lengths=[<span class="hljs-number">0.9</span>, <span class="hljs-number">0.1</span>], generator=torch.Generator().manual_seed(<span class="hljs-number">42</span>)) <span class="hljs-comment"># 设置种子，在不同进程的数据切分保持一致</span><br><span class="hljs-built_in">len</span>(trainset), <span class="hljs-built_in">len</span>(validset)<br></code></pre></td></tr></table></figure><p>在准备一下Tokenizer和DataLoader。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;/gemini/code/model&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_func</span>(<span class="hljs-params">batch</span>):<br>    texts, labels = [], []<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> batch:<br>        texts.append(item[<span class="hljs-number">0</span>])<br>        labels.append(item[<span class="hljs-number">1</span>])<br>    inputs = tokenizer(texts, max_length=<span class="hljs-number">128</span>, padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    inputs[<span class="hljs-string">&quot;labels&quot;</span>] = torch.tensor(labels)<br>    <span class="hljs-keyword">return</span> inputs<br><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.data.distributed <span class="hljs-keyword">import</span> DistributedSampler<br><br>trainloader = DataLoader(trainset, batch_size=<span class="hljs-number">32</span>, collate_fn=collate_func, sampler=DistributedSampler(trainset))<br>validloader = DataLoader(validset, batch_size=<span class="hljs-number">64</span>, collate_fn=collate_func, sampler=DistributedSampler(validset))<br></code></pre></td></tr></table></figure><p>这里的<code>DistributedSampler</code>能够将不同进程上的数据进行分配，并且不会出现重复。对比之前，<code>DataLoader</code>里少了<code>shuffle</code>这个参数，取而代之的是<code>sampler</code>。</p><p>接下来是设置模型，我们需要将模型传到各自的GPU上。为了获取当前机器的GPU参数，我们需要从环境变量导入一下参数。</p><p>随后用<code>DDP</code>包装一下模型。这样模型就准备好了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> Adam<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><br>model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;/gemini/code/model&quot;</span>)<br><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    model = model.to(<span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>]))<br><br>model = DDP(model)<br>optimizer = Adam(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br></code></pre></td></tr></table></figure><p>模型准备完，就可以准备训练了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_rank_0</span>(<span class="hljs-params">info</span>):<br><span class="hljs-comment"># 在主进程上打印信息</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;RANK&quot;</span>]) == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(info)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>():<br>    model.<span class="hljs-built_in">eval</span>()<br>    acc_num = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.inference_mode():<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> validloader:<br>            <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>                batch = &#123;k: v.to(<span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()&#125; <span class="hljs-comment"># 将数据传到显卡</span><br>            output = model(**batch)<br>            pred = torch.argmax(output.logits, dim=-<span class="hljs-number">1</span>)<br>            acc_num += (pred.long() == batch[<span class="hljs-string">&quot;labels&quot;</span>].long()).<span class="hljs-built_in">float</span>().<span class="hljs-built_in">sum</span>()<br>    dist.all_reduce(acc_num, op=dist.ReduceOP.SUM) <span class="hljs-comment"># 将各卡的数据汇总到主进程，没有这步会导致精度非常低</span><br>    <span class="hljs-keyword">return</span> acc_num / <span class="hljs-built_in">len</span>(validset) <span class="hljs-comment"># 得到评估得分</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch=<span class="hljs-number">3</span>, log_step=<span class="hljs-number">100</span></span>):<br>    global_step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> ep <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        model.train()<br>        trainloader.sampler.set_epoch(ep)<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainloader:<br>            <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>                batch = &#123;k: v.to(<span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()&#125;<br>            optimizer.zero_grad()<br>            output = model(**batch)<br>            <br>            loss = output.loss<br>            loss.backward()<br>            optimizer.step()<br>            <br>            <span class="hljs-keyword">if</span> global_step % log_step == <span class="hljs-number">0</span>:<br>            <span class="hljs-comment"># Loss的通信部分，将Loss求均值，即Opreation为AVG</span><br>                dist.all_reduce(loss, op=dist.ReduceOp.AVG)<br>                <br>                <span class="hljs-comment"># 在主进程打印损失信息</span><br>                print_rank_0(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, global_step: <span class="hljs-subst">&#123;global_step&#125;</span>, loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&quot;</span>)<br>            global_step += <span class="hljs-number">1</span><br>        acc = evaluate()<br>        print_rank_0(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, acc: <span class="hljs-subst">&#123;acc&#125;</span>&quot;</span>)<br><br>train()<br><br></code></pre></td></tr></table></figure><h1 id="Trainer单机多卡代码实现"><a href="#Trainer单机多卡代码实现" class="headerlink" title="Trainer单机多卡代码实现"></a>Trainer单机多卡代码实现</h1><p>HuggingFace的Trainer代码中同样封装了分布式数据并行，下面是示例代码。运行时也是一样的使用<code>torchrun --nproc_per_node=2 ddp_trainer.py</code>。可以看到其实并没有在代码层面进行修改太多，这是因为Trainer类本身已经内置了分布式训练的判断。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification<br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br>dataset = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;review&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)<br>dataset<br><br>datasets = dataset.train_test_split(test_size=<span class="hljs-number">0.1</span>, seed=<span class="hljs-number">42</span>) <span class="hljs-comment"># 随机种子一定要设置，否则不同进程会用混数据</span><br>datasets<br><br><span class="hljs-keyword">import</span> torch<br><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;/gemini/code/model&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_function</span>(<span class="hljs-params">examples</span>):<br>    tokenized_examples = tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], max_length=<span class="hljs-number">128</span>, truncation=<span class="hljs-literal">True</span>)<br>    tokenized_examples[<span class="hljs-string">&quot;labels&quot;</span>] = examples[<span class="hljs-string">&quot;label&quot;</span>]<br>    <span class="hljs-keyword">return</span> tokenized_examples<br><br>tokenized_datasets = datasets.<span class="hljs-built_in">map</span>(process_function, batched=<span class="hljs-literal">True</span>, remove_columns=datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names)<br>tokenized_datasets<br><br>model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;/gemini/code/model&quot;</span>)<br><br>model.config<br><br><span class="hljs-keyword">import</span> evaluate<br>acc_metric = evaluate.load(<span class="hljs-string">&quot;./metric_accuracy.py&quot;</span>)<br>f1_metirc = evaluate.load(<span class="hljs-string">&quot;./metric_f1.py&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">eval_metric</span>(<span class="hljs-params">eval_predict</span>):<br>    predictions, labels = eval_predict<br>    predictions = predictions.argmax(axis=-<span class="hljs-number">1</span>)<br>    acc = acc_metric.compute(predictions=predictions, references=labels)<br>    f1 = f1_metirc.compute(predictions=predictions, references=labels)<br>    acc.update(f1)<br>    <span class="hljs-keyword">return</span> acc<br><br>train_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;./checkpoints&quot;</span>,      <span class="hljs-comment"># 输出文件夹</span><br>                               per_device_train_batch_size=<span class="hljs-number">32</span>,  <span class="hljs-comment"># 训练时的batch_size</span><br>                               per_device_eval_batch_size=<span class="hljs-number">128</span>,  <span class="hljs-comment"># 验证时的batch_size</span><br>                               logging_steps=<span class="hljs-number">10</span>,                <span class="hljs-comment"># log 打印的频率</span><br>                               evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,     <span class="hljs-comment"># 评估策略</span><br>                               save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,           <span class="hljs-comment"># 保存策略</span><br>                               save_total_limit=<span class="hljs-number">3</span>,              <span class="hljs-comment"># 最大保存数</span><br>                               learning_rate=<span class="hljs-number">2e-5</span>,              <span class="hljs-comment"># 学习率</span><br>                               weight_decay=<span class="hljs-number">0.01</span>,               <span class="hljs-comment"># weight_decay</span><br>                               metric_for_best_model=<span class="hljs-string">&quot;f1&quot;</span>,      <span class="hljs-comment"># 设定评估指标</span><br>                               load_best_model_at_end=<span class="hljs-literal">True</span>)     <span class="hljs-comment"># 训练完成后加载最优模型</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding<br>trainer = Trainer(model=model, <br>                  args=train_args, <br>                  train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>], <br>                  eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>], <br>                  data_collator=DataCollatorWithPadding(tokenizer=tokenizer),<br>                  compute_metrics=eval_metric)<br><br>trainer.train()<br></code></pre></td></tr></table></figure><h1 id="Pytorch多机多卡代码实现"><a href="#Pytorch多机多卡代码实现" class="headerlink" title="Pytorch多机多卡代码实现"></a>Pytorch多机多卡代码实现</h1><p>上面的代码是在单机多卡的环境下实现并行训练，只需要在<code>--nproc-per-node</code>这个参数设置任务的并行数量。在多机环境下就不一样了，我们需要解决多机的通信问题。</p><p>我们需要指定一台机器作为主节点，这个设置由参数<code>MASTER_ADDR</code>决定。</p><p>这里我放上两段代码，一个是Pytorch的官方教程，使用了<code>torchrun</code>执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ToyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(ToyModel, self).__init__()<br>        self.net1 = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)<br>        self.relu = nn.ReLU()<br>        self.net2 = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.net2(self.relu(self.net1(x)))<br></code></pre></td></tr></table></figure><p>接下来是重点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">demo_basic</span>():<br>    dist.init_process_group(<span class="hljs-string">&quot;nccl&quot;</span>)<br>    rank = dist.get_rank()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Start running basic DDP example on rank <span class="hljs-subst">&#123;rank&#125;</span>.&quot;</span>)<br><br>    <span class="hljs-comment"># create model and move it to GPU with id rank</span><br>    device_id = rank % torch.cuda.device_count()<br>    model = ToyModel().to(device_id)<br>    ddp_model = DDP(model, device_ids=[device_id])<br><br>    loss_fn = nn.MSELoss()<br>    optimizer = optim.SGD(ddp_model.parameters(), lr=<span class="hljs-number">0.001</span>)<br><br>    optimizer.zero_grad()<br>    outputs = ddp_model(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>))<br>    labels = torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">5</span>).to(device_id)<br>    loss_fn(outputs, labels).backward()<br>    optimizer.step()<br>    dist.destroy_process_group()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    demo_basic()<br></code></pre></td></tr></table></figure><p>在执行时，需要每个节点上都在命令行执行同样的命令，下述代码是一个例子，代表在两个机器（节点）上训练，每个机器各8个进程（GPU），共计16张GPU。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> MASTER_ADDR=localhost <span class="hljs-comment"># 这里需要放上主节点IP</span><br><br>torchrun --nnodes=2 --nproc_per_node=8 --rdzv_id=100 --rdzv_backend=c10d --rdzv_endpoint=<span class="hljs-variable">$MASTER_ADDR</span>:29400 elastic_ddp.py<br></code></pre></td></tr></table></figure><p>执行完成后即可开始训练。</p><p>接下来是知乎上找的代码，也记录一下：</p><p>首先构建模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ToyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(ToyModel, self).__init__()<br>        self.net1 = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)<br>        self.relu = nn.ReLU()<br>        self.net2 = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.net2(self.relu(self.net1(x)))<br></code></pre></td></tr></table></figure><p>随后进入训练流程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br><span class="hljs-comment"># 获取当前显卡的LOCAL_RANK和RANK</span><br>    local_rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])<br>    rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;RANK&quot;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[<span class="hljs-subst">&#123;os.getpid()&#125;</span>] (rank = <span class="hljs-subst">&#123;rank&#125;</span>, local_rank = <span class="hljs-subst">&#123;local_rank&#125;</span>) training...&quot;</span>)<br>    <br>    <span class="hljs-comment"># 构建DDP模型</span><br>    model = ToyModel().cuda(local_rank)<br>    ddp_model = DDP(model, [local_rank])<br><br><span class="hljs-comment"># 损失函数和优化器</span><br>    loss_fn = nn.MSELoss()<br>    optimizer = optim.SGD(ddp_model.parameters(), lr=<span class="hljs-number">0.001</span>)<br><br><span class="hljs-comment"># 前向传播并计算损失</span><br>    optimizer.zero_grad()<br>    outputs = ddp_model(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>).to(local_rank))<br>    labels = torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">5</span>).to(local_rank)<br>    loss = loss_fn(outputs, labels)<br>    <br>    <span class="hljs-comment"># 后向传播，梯度更新</span><br>    loss.backward()<br>    optimizer.step()<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[<span class="hljs-subst">&#123;os.getpid()&#125;</span>] (rank = <span class="hljs-subst">&#123;rank&#125;</span>, local_rank = <span class="hljs-subst">&#123;local_rank&#125;</span>) loss = <span class="hljs-subst">&#123;loss.item()&#125;</span>\n&quot;</span>)    <br></code></pre></td></tr></table></figure><p>接下来是调用部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>():<br>    env_dict = &#123;<br>        key: os.environ[key]<br>        <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> (<span class="hljs-string">&quot;MASTER_ADDR&quot;</span>, <span class="hljs-string">&quot;MASTER_PORT&quot;</span>, <span class="hljs-string">&quot;WORLD_SIZE&quot;</span>, <span class="hljs-string">&quot;LOCAL_WORLD_SIZE&quot;</span>)<br>    &#125;<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[<span class="hljs-subst">&#123;os.getpid()&#125;</span>] Initializing process group with: <span class="hljs-subst">&#123;env_dict&#125;</span>&quot;</span>)<br>    dist.init_process_group(backend=<span class="hljs-string">&quot;nccl&quot;</span>)<br>    train()<br>    dist.destroy_process_group()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    run()<br></code></pre></td></tr></table></figure><p>在主节点上执行如下脚本：</p><ul><li><code>--nproc_per_node=4</code>： 表示在一个node上启动4个process</li><li><code>--nnodes=2</code> ：表示一共有2个node进行分布式训练</li><li><code>--node_rank=0 </code>：当前node的id为0</li><li><code>--master_addr=&quot;192.0.0.1</code>“：主节点的地址</li><li><code>--master_port=1234</code>：主节点的port</li><li><code>trian_multi_node.py</code>：训练代码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">torchrun --nproc_per_node=<span class="hljs-number">4</span> \<br>         --nnodes=<span class="hljs-number">2</span> \<br>         --node_rank=<span class="hljs-number">0</span>  \ <br>         --master_addr=<span class="hljs-string">&quot;192.0.0.1&quot;</span> \<br>         --master_port=<span class="hljs-number">1234</span> \<br>         trian_multi_node.py<br></code></pre></td></tr></table></figure><p>在子节点上执行如下脚本，唯一的区别是–node_rank设置为1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">torchrun --nproc_per_node=<span class="hljs-number">4</span> \<br>         --nnodes=<span class="hljs-number">2</span> \<br>         --node_rank=<span class="hljs-number">1</span>\<br>         --master_addr=<span class="hljs-string">&quot;192.0.0.1&quot;</span> \<br>         --master_port=<span class="hljs-number">1234</span>\<br>         trian_multi_node.py<br></code></pre></td></tr></table></figure><p>运行结果如下：</p><p>主节点的执行结果:</p><ul><li>2~4行：node0上四个进程的显示的全局信息</li><li>6~9行：node0上四个进程准备开始训练</li><li>10~13行：node0上四个进程完成训练，并输出loss信息</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs text">/workspace/DDP# sh run_node0.sh<br>[594] Initializing process group with: &#123;&#x27;MASTER_ADDR&#x27;: &#x27;192.0.0.1&#x27;, &#x27;MASTER_PORT&#x27;: &#x27;1234&#x27;, &#x27;WORLD_SIZE&#x27;: &#x27;8&#x27;, &#x27;LOCAL_WORLD_SIZE&#x27;: &#x27;4&#x27;&#125;<br>[595] Initializing process group with: &#123;&#x27;MASTER_ADDR&#x27;: &#x27;192.0.0.1&#x27;, &#x27;MASTER_PORT&#x27;: &#x27;1234&#x27;, &#x27;WORLD_SIZE&#x27;: &#x27;8&#x27;, &#x27;LOCAL_WORLD_SIZE&#x27;: &#x27;4&#x27;&#125;<br>[593] Initializing process group with: &#123;&#x27;MASTER_ADDR&#x27;: &#x27;192.0.0.1&#x27;, &#x27;MASTER_PORT&#x27;: &#x27;1234&#x27;, &#x27;WORLD_SIZE&#x27;: &#x27;8&#x27;, &#x27;LOCAL_WORLD_SIZE&#x27;: &#x27;4&#x27;&#125;<br>[592] Initializing process group with: &#123;&#x27;MASTER_ADDR&#x27;: &#x27;192.0.0.1&#x27;, &#x27;MASTER_PORT&#x27;: &#x27;1234&#x27;, &#x27;WORLD_SIZE&#x27;: &#x27;8&#x27;, &#x27;LOCAL_WORLD_SIZE&#x27;: &#x27;4&#x27;&#125;<br>[593] (rank = 1, local_rank = 1) training...<br>[595] (rank = 3, local_rank = 3) training...<br>[592] (rank = 0, local_rank = 0) training...<br>[594] (rank = 2, local_rank = 2) training...<br>[595] (rank = 3, local_rank = 3) loss = 1.12112295627594<br>[592] (rank = 0, local_rank = 0) loss = 1.5381203889846802<br>[593] (rank = 1, local_rank = 1) loss = 1.1606591939926147<br>[594] (rank = 2, local_rank = 2) loss = 0.973732590675354<br></code></pre></td></tr></table></figure><p>子节点的执行结果:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs text">/workspace/DDP# sh run_node1.sh<br>[292] Initializing process group with: &#123;&#x27;MASTER_ADDR&#x27;: &#x27;192.0.0.1&#x27;, &#x27;MASTER_PORT&#x27;: &#x27;1234&#x27;, &#x27;WORLD_SIZE&#x27;: &#x27;8&#x27;, &#x27;LOCAL_WORLD_SIZE&#x27;: &#x27;4&#x27;&#125;<br>[294] Initializing process group with: &#123;&#x27;MASTER_ADDR&#x27;: &#x27;192.0.0.1&#x27;, &#x27;MASTER_PORT&#x27;: &#x27;1234&#x27;, &#x27;WORLD_SIZE&#x27;: &#x27;8&#x27;, &#x27;LOCAL_WORLD_SIZE&#x27;: &#x27;4&#x27;&#125;<br>[293] Initializing process group with: &#123;&#x27;MASTER_ADDR&#x27;: &#x27;192.0.0.1&#x27;, &#x27;MASTER_PORT&#x27;: &#x27;1234&#x27;, &#x27;WORLD_SIZE&#x27;: &#x27;8&#x27;, &#x27;LOCAL_WORLD_SIZE&#x27;: &#x27;4&#x27;&#125;<br>[295] Initializing process group with: &#123;&#x27;MASTER_ADDR&#x27;: &#x27;192.0.0.1&#x27;, &#x27;MASTER_PORT&#x27;: &#x27;1234&#x27;, &#x27;WORLD_SIZE&#x27;: &#x27;8&#x27;, &#x27;LOCAL_WORLD_SIZE&#x27;: &#x27;4&#x27;&#125;<br>[295] (rank = 7, local_rank = 3) training...<br>[292] (rank = 4, local_rank = 0) training...<br>[294] (rank = 6, local_rank = 2) training...<br>[293] (rank = 5, local_rank = 1) training...<br>[292] (rank = 4, local_rank = 0) loss = 1.3587342500686646<br>[294] (rank = 6, local_rank = 2) loss = 1.0895851850509644<br>[295] (rank = 7, local_rank = 3) loss = 1.1472846269607544<br>[293] (rank = 5, local_rank = 1) loss = 1.1993836164474487<br></code></pre></td></tr></table></figure><h1 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h1><p>分布式数据并行在实现中需要注意几个细节：</p><ol><li>数据内一定要注意数据划分的一致，不然其他进程会用验证集去训练。因此需要设置随机种子。</li><li>需要用分布式采样器。</li><li>查看全局信息时需要记住使用通信，否则只能看到某一个进程内的信息。</li><li>将数据放置在设备上时需要注意使用正确的<code>device_id</code>，通常会使用<code>local_rank</code>来指定。</li></ol><p>2024&#x2F;3&#x2F;7 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式训练</tag>
      
      <tag>DP</tag>
      
      <tag>DDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式训练：Data Parallel</title>
    <link href="/2024/03/06/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%AE%9E%E6%88%98/"/>
    <url>/2024/03/06/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[<blockquote><p>什么是数据并行？<br>每个GPU加载完整模型，训练时每个GPU训练不同的数据</p></blockquote><h1 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h1><p>数据并行的流程如下所示：</p><ul><li>Step1 GPU0加载模型和Batch的数据</li><li>Step2 将Batch数据从GPU0分发至各卡</li><li>Step3 将模型从GPU0复制到各卡</li><li>Step4 各卡进行前向传播</li><li>Step5 GPU0收集各卡输出，并统一计算Loss</li><li>Step6 将Loss分发，在各卡反向传播并计算梯度</li><li>Step7 GPU0收集梯度并进行汇总</li><li>Step8 在GPU0上更新模型</li></ul><p>pytorch的源码部分展示了这一过程，以下是<code>nn.parallel.data_parallel</code>中<code>DataParallel</code>类的<code>forward</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, *inputs: <span class="hljs-type">Any</span>, **kwargs: <span class="hljs-type">Any</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>    <span class="hljs-keyword">with</span> torch.autograd.profiler.record_function(<span class="hljs-string">&quot;DataParallel.forward&quot;</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.device_ids:<br>            <span class="hljs-keyword">return</span> self.module(*inputs, **kwargs)<br><br>        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> chain(self.module.parameters(), self.module.buffers()):<br>            <span class="hljs-keyword">if</span> t.device != self.src_device_obj:<br>                <span class="hljs-keyword">raise</span> RuntimeError(<span class="hljs-string">&quot;module must have its parameters and buffers &quot;</span><br>                                   <span class="hljs-string">f&quot;on device <span class="hljs-subst">&#123;self.src_device_obj&#125;</span> (device_ids[0]) but found one of &quot;</span><br>                                   <span class="hljs-string">f&quot;them on device: <span class="hljs-subst">&#123;t.device&#125;</span>&quot;</span>)<br><br>        inputs, module_kwargs = self.scatter(inputs, kwargs, self.device_ids) <span class="hljs-comment"># 将数据分发到不同GPU</span><br>        <span class="hljs-comment"># for forward function without any inputs, empty list and dict will be created</span><br>        <span class="hljs-comment"># so the module can be executed on one device which is the first one in device_ids</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> inputs <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> module_kwargs:<br>            inputs = ((),)<br>            module_kwargs = (&#123;&#125;,)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.device_ids) == <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">return</span> self.module(*inputs[<span class="hljs-number">0</span>], **module_kwargs[<span class="hljs-number">0</span>])<br>        replicas = self.replicate(self.module, self.device_ids[:<span class="hljs-built_in">len</span>(inputs)]) <span class="hljs-comment"># 对模型进行复制</span><br>        outputs = self.parallel_apply(replicas, inputs, module_kwargs) <span class="hljs-comment"># 并行调用模型</span><br>        <span class="hljs-keyword">return</span> self.gather(outputs, self.output_device) <span class="hljs-comment"># 拿到结果</span><br></code></pre></td></tr></table></figure><p>在<code>parallel_apply</code>方法中，使用了多线程的方法调用不同训练任务。</p><h1 id="使用Pytorch进行数据并行"><a href="#使用Pytorch进行数据并行" class="headerlink" title="使用Pytorch进行数据并行"></a>使用Pytorch进行数据并行</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertForSequenceClassification<br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>data = pd.read_csv(<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>)<br>data = data.dropna()<br><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><br><span class="hljs-comment"># 创建Dataset</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.data = pd.read_csv(<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>)<br>        self.data = self.data.dropna()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">return</span> self.data.iloc[index][<span class="hljs-string">&quot;review&quot;</span>], self.data.iloc[index][<span class="hljs-string">&quot;label&quot;</span>]<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br><br>dataset = MyDataset()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>    <span class="hljs-built_in">print</span>(dataset[i])<br>    <br><span class="hljs-comment"># 划分数据集</span><br><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> random_split<br><br>trainset, validset = random_split(dataset, lengths=[<span class="hljs-number">0.9</span>, <span class="hljs-number">0.1</span>])<br><span class="hljs-built_in">len</span>(trainset), <span class="hljs-built_in">len</span>(validset)<br><br><span class="hljs-comment"># 创建DataLoader</span><br><span class="hljs-keyword">import</span> torch<br><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;./model&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_func</span>(<span class="hljs-params">batch</span>):<br>    texts, labels = [], []<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> batch:<br>        texts.append(item[<span class="hljs-number">0</span>])<br>        labels.append(item[<span class="hljs-number">1</span>])<br>    inputs = tokenizer(texts, max_length=<span class="hljs-number">128</span>, padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    inputs[<span class="hljs-string">&quot;labels&quot;</span>] = torch.tensor(labels)<br>    <span class="hljs-keyword">return</span> inputs<br>    <br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>trainloader = DataLoader(trainset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>, collate_fn=collate_func)<br>validloader = DataLoader(validset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">False</span>, collate_fn=collate_func)<br></code></pre></td></tr></table></figure><p>前面准备工作完成之后，就到了模型创建的部分。这里只需要使用<code>torch.nn.DataParallel</code>来包装一下模型。这时如果需要查看模型本身的结构，就需要使用<code>model.module</code>进行查看。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建模型及优化器</span><br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> Adam<br><br>model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./model&quot;</span>)<br><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    model = model.cuda()<br>    <br>model = torch.nn.DataParallel(model, device_ids=<span class="hljs-literal">None</span>) <span class="hljs-comment"># 加载模型（单卡时则无需这一步）</span><br>optimizer = Adam(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br></code></pre></td></tr></table></figure><p>模型加载完后，就需要修改一下训练时的损失计算，因为每个卡都有一个损失，因此需要使用<code>mean()</code>方法来求一下均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练与验证</span><br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>():<br>    model.<span class="hljs-built_in">eval</span>()<br>    acc_num = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.inference_mode():<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> validloader:<br>            <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>                batch = &#123;k: v.cuda() <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()&#125;<br>            output = model(**batch)<br>            pred = torch.argmax(output.logits, dim=-<span class="hljs-number">1</span>)<br>            acc_num += (pred.long() == batch[<span class="hljs-string">&quot;labels&quot;</span>].long()).<span class="hljs-built_in">float</span>().<span class="hljs-built_in">sum</span>()<br>    <span class="hljs-keyword">return</span> acc_num / <span class="hljs-built_in">len</span>(validset)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch=<span class="hljs-number">3</span>, log_step=<span class="hljs-number">100</span></span>):<br>    global_step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> ep <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        model.train()<br>        start = time.time()<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainloader:<br>            <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>                batch = &#123;k: v.cuda() <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()&#125;<br>            optimizer.zero_grad()<br>            output = model(**batch)<br>            loss = output.loss.mean() <span class="hljs-comment"># 多卡时需要计算损失的均值</span><br>            <span class="hljs-comment"># loss = output.loss 单卡时损失只有一个</span><br>            loss.backward()<br>            optimizer.step()<br>            <span class="hljs-keyword">if</span> global_step % log_step == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, global_step: <span class="hljs-subst">&#123;global_step&#125;</span>, loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&quot;</span>)<br>            global_step += <span class="hljs-number">1</span><br>        acc = evaluate()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ep: <span class="hljs-subst">&#123;ep&#125;</span>, acc: <span class="hljs-subst">&#123;acc&#125;</span>, time: <span class="hljs-subst">&#123;time.time() - start&#125;</span>&quot;</span>)<br>        <br>train()<br></code></pre></td></tr></table></figure><p>完成训练后就可以进行推理预测了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型预测</span><br><br>sen = <span class="hljs-string">&quot;我觉得这家酒店不错，饭很好吃！&quot;</span><br>id2_label = &#123;<span class="hljs-number">0</span>: <span class="hljs-string">&quot;差评！&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;好评！&quot;</span>&#125;<br>model.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">with</span> torch.inference_mode():<br>    inputs = tokenizer(sen, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    inputs = &#123;k: v.cuda() <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> inputs.items()&#125;<br>    logits = model(**inputs).logits<br>    pred = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;输入：<span class="hljs-subst">&#123;sen&#125;</span>\n模型预测结果:<span class="hljs-subst">&#123;id2_label.get(pred.item())&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>model.config.id2label = id2_label<br>pipe = pipeline(<span class="hljs-string">&quot;text-classification&quot;</span>, model=model, tokenizer=tokenizer, device=<span class="hljs-number">0</span>)<br><br>pipe(sen)<br></code></pre></td></tr></table></figure><p>使用这种方法，在Batch Size比较小的时候（32），无法和单卡运行拉开差距，当提高BS时，才能体现多卡的优势。</p><h1 id="使用Trainer进行数据并行"><a href="#使用Trainer进行数据并行" class="headerlink" title="使用Trainer进行数据并行"></a>使用Trainer进行数据并行</h1><p>在HuggingFace的Trainer类中，提供了较为便捷的数据并行的方法。在<code>TrainingArguments</code>类中，包含了一个私有属性<code>_n_gpu</code>，会自动识别主机的显卡数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">train_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;./checkpoints&quot;</span>,      <span class="hljs-comment"># 输出文件夹</span><br>                               per_device_train_batch_size=<span class="hljs-number">64</span>,  <span class="hljs-comment"># 训练时的batch_size</span><br>                               per_device_eval_batch_size=<span class="hljs-number">128</span>,  <span class="hljs-comment"># 验证时的batch_size</span><br>                               logging_steps=<span class="hljs-number">10</span>,                <span class="hljs-comment"># log 打印的频率</span><br>                               evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,     <span class="hljs-comment"># 评估策略</span><br>                               save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,           <span class="hljs-comment"># 保存策略</span><br>                               save_total_limit=<span class="hljs-number">3</span>,              <span class="hljs-comment"># 最大保存数</span><br>                               learning_rate=<span class="hljs-number">2e-5</span>,              <span class="hljs-comment"># 学习率</span><br>                               weight_decay=<span class="hljs-number">0.01</span>,               <span class="hljs-comment"># weight_decay</span><br>                               metric_for_best_model=<span class="hljs-string">&quot;f1&quot;</span>,      <span class="hljs-comment"># 设定评估指标</span><br>                               load_best_model_at_end=<span class="hljs-literal">True</span>)     <span class="hljs-comment"># 训练完成后加载最优模型</span><br>train_args<br><br><span class="hljs-comment"># 创建Trainner</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding<br>trainer = Trainer(model=model, <br>                  args=train_args, <br>                  train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>], <br>                  eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>], <br>                  data_collator=DataCollatorWithPadding(tokenizer=tokenizer),<br>                  compute_metrics=eval_metric)<br>                  <br><span class="hljs-comment"># 训练</span><br>trainer.train()<br></code></pre></td></tr></table></figure><h1 id="DP的优点"><a href="#DP的优点" class="headerlink" title="DP的优点"></a>DP的优点</h1><ul><li>并行化多个GPU上的训练，因此与累积梯度相比，它减少了训练时间。</li><li>代码简单。</li></ul><h1 id="DP的不足"><a href="#DP的不足" class="headerlink" title="DP的不足"></a>DP的不足</h1><p><code>nn.DataParallel</code>由于自身的不足，目前已经被淘汰了。淘汰的原因主要如下：</p><ul><li>Data Parallel实际上是单进程，多线程的工作模式。然而由于GIL锁，无法发挥多线程在多卡的优势。</li><li>训练策略问题导致主节点占用更高，GPU利用率不高。</li><li>效率低，每次训练开始都需要同步模型，对于大模型，通信时间是一个问题</li><li>只适用于单机训练，而非多机训练。</li></ul><p>2024&#x2F;3&#x2F;6 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式训练</tag>
      
      <tag>DP</tag>
      
      <tag>DDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式训练初识：什么是分布式训练</title>
    <link href="/2024/03/05/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E5%88%9D%E8%AF%86%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"/>
    <url>/2024/03/05/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E5%88%9D%E8%AF%86%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/</url>
    
    <content type="html"><![CDATA[<p>近期学习了一下分布式训练，因此出一篇博客记录。</p><p>首先，如果我们只有一张显卡，我们在训练模型时能怎么解决爆显存的问题？</p><ul><li>一个是从训练的参数量来处理，例如可以使用Prompt Tuning，LoRA等方法来只训练大大小于模型原参数量的参数，常用的库是PEFT。</li><li>另一种则是调整模型的精度，可以用半精度，Int8，Int4来让模型的大小减小，常用的库是Bitsandbytes。</li></ul><p>当这两种方法都使用了以后还无法解决显存资源的时候，就需要使用分布式训练，利用多个节点来加速训练。通常会将计算任务和数据分发到多个节点来训练。分布式训练也通常来解决数据过大，模型过大的难题。</p><h1 id="分布式训练"><a href="#分布式训练" class="headerlink" title="分布式训练"></a>分布式训练</h1><p>常见的分布式训练包含了几种：</p><ul><li>数据并行：Data Parrallel(DP)。在每个GPU上复制一份完整的模型，但是每个GPU的训练数据不同。这也要求每张显卡都能够完整的执行训练。</li><li>流水线并行：Pipeline Parrallel(PP)。将模型按层拆开，每个GPU包含了部分层。这就不要求每个显卡能够完整执行训练过程。</li></ul><p><img src="/images/213136.png" alt="流水线并行"></p><ul><li>张量并行：Tensor Parrallel(TP)。把模型的每层权重拆开，每个GPU上放一部分权重。</li></ul><p><img src="/images/213646.png" alt="张量并行"></p><p>我们可以同时使用这三种策略，这时候就称为3D并行。</p><h1 id="使用Trainer进行单机多卡训练"><a href="#使用Trainer进行单机多卡训练" class="headerlink" title="使用Trainer进行单机多卡训练"></a>使用Trainer进行单机多卡训练</h1><p>transformers的traner库默认是支持自动进行多卡训练的，下面给出代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification<br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br><span class="hljs-comment"># 加载数据集</span><br>dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=<span class="hljs-string">&quot;./ChnSentiCorp_htl_all.csv&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br>dataset = dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;review&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)<br>dataset<br><br><span class="hljs-comment"># 划分数据集</span><br>datasets = dataset.train_test_split(test_size=<span class="hljs-number">0.1</span>)<br><br><span class="hljs-comment"># 数据预处理</span><br><span class="hljs-keyword">import</span> torch<br><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;./model&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_function</span>(<span class="hljs-params">examples</span>):<br>    tokenized_examples = tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], max_length=<span class="hljs-number">128</span>, truncation=<span class="hljs-literal">True</span>)<br>    tokenized_examples[<span class="hljs-string">&quot;labels&quot;</span>] = examples[<span class="hljs-string">&quot;label&quot;</span>]<br>    <span class="hljs-keyword">return</span> tokenized_examples<br><br>tokenized_datasets = datasets.<span class="hljs-built_in">map</span>(process_function, batched=<span class="hljs-literal">True</span>, remove_columns=datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names)<br>tokenized_datasets<br><br><span class="hljs-comment"># 创建模型</span><br>model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./model&quot;</span>)<br><br><span class="hljs-comment"># 创建评估函数</span><br><span class="hljs-keyword">import</span> evaluate<br><br>acc_metric = evaluate.load(<span class="hljs-string">&quot;./metric_accuracy.py&quot;</span>)<br>f1_metirc = evaluate.load(<span class="hljs-string">&quot;./metric_f1.py&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">eval_metric</span>(<span class="hljs-params">eval_predict</span>):<br>    predictions, labels = eval_predict<br>    predictions = predictions.argmax(axis=-<span class="hljs-number">1</span>)<br>    acc = acc_metric.compute(predictions=predictions, references=labels)<br>    f1 = f1_metirc.compute(predictions=predictions, references=labels)<br>    acc.update(f1)<br>    <span class="hljs-keyword">return</span> acc<br><br><span class="hljs-comment"># 构建TrainingArguments</span><br>train_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;./checkpoints&quot;</span>,      <span class="hljs-comment"># 输出文件夹</span><br>                               per_device_train_batch_size=<span class="hljs-number">64</span>,  <span class="hljs-comment"># 训练时的batch_size</span><br>                               per_device_eval_batch_size=<span class="hljs-number">128</span>,  <span class="hljs-comment"># 验证时的batch_size</span><br>                               logging_steps=<span class="hljs-number">10</span>,                <span class="hljs-comment"># log 打印的频率</span><br>                               evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,     <span class="hljs-comment"># 评估策略</span><br>                               save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,           <span class="hljs-comment"># 保存策略</span><br>                               save_total_limit=<span class="hljs-number">3</span>,              <span class="hljs-comment"># 最大保存数</span><br>                               learning_rate=<span class="hljs-number">2e-5</span>,              <span class="hljs-comment"># 学习率</span><br>                               weight_decay=<span class="hljs-number">0.01</span>,               <span class="hljs-comment"># weight_decay</span><br>                               metric_for_best_model=<span class="hljs-string">&quot;f1&quot;</span>,      <span class="hljs-comment"># 设定评估指标</span><br>                               load_best_model_at_end=<span class="hljs-literal">True</span>)     <span class="hljs-comment"># 训练完成后加载最优模型</span><br>train_args<br><br><span class="hljs-comment"># 创建Trainner</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding<br>trainer = Trainer(model=model, <br>                  args=train_args, <br>                  train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>], <br>                  eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>], <br>                  data_collator=DataCollatorWithPadding(tokenizer=tokenizer),<br>                  compute_metrics=eval_metric)<br>                  <br><span class="hljs-comment"># 训练</span><br>trainer.train()<br></code></pre></td></tr></table></figure><p>当开始训练时，可以看到本地的多卡都被占用了，这是因为Trainer类自己识别的本地的显卡并调用。</p><p>最后还可以评估一下模型，并进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型评估</span><br>trainer.evaluate(tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>])<br><br><span class="hljs-comment"># 模型预测</span><br>trainer.predict(tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>])<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>id2_label = &#123;<span class="hljs-number">0</span>: <span class="hljs-string">&quot;差评！&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;好评！&quot;</span>&#125;<br>model.config.id2label = id2_label<br>pipe = pipeline(<span class="hljs-string">&quot;text-classification&quot;</span>, model=model, tokenizer=tokenizer, device=<span class="hljs-number">0</span>)<br>sen = <span class="hljs-string">&quot;我觉得不错！&quot;</span><br>pipe(sen)<br></code></pre></td></tr></table></figure><p>2024&#x2F;3&#x2F;5 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式训练</tag>
      
      <tag>DP</tag>
      
      <tag>DDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开发者必备技巧：VIM常用操作</title>
    <link href="/2024/03/03/%E5%BC%80%E5%8F%91%E8%80%85%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%EF%BC%9AVIM%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <url>/2024/03/03/%E5%BC%80%E5%8F%91%E8%80%85%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%EF%BC%9AVIM%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<p>Vim作为一个服务器上常用的编辑器，很多开发者都免不了与它打交道。当我刚刚接触它的时候，简直一头雾水尽管后面稍微了解了一些基本操作，但是还是有大量的操作指令相当不熟悉。这篇博客就总结一些常用的操作，已备不时之需。</p><p><strong>光标移动</strong>：<br><code>h</code>：左<br><code>j</code>：下<br><code>k</code>：上<br><code>l</code>：右</p><blockquote><p>以下内容比较实用，最好记住：</p></blockquote><p><code>w</code>：跳到下一个单词的开头<br><code>b</code>：跳到上一个单词的开头<br><code>gg</code>：跳到文件的开头<br><code>G</code>：跳到文件的末尾<br><code>0</code>：跳到行首<br><code>$</code>：跳到行尾</p><p>数字加字母则可以快速跳到指定的地方，例如：</p><p><code>50G</code>：跳到第五十行<br><code>20j</code>： 向下移动 20 行</p><p>了解如何快捷移动光标，已经满足工作中大部分的Vim操作了。</p><p><strong>查找</strong><br><code>/text</code>：向下查找文本<br><code>n</code>：跳到下一个匹配项<br><code>N</code>：跳到上一个匹配项</p><p>命令模式下，斜杠加文本即可检索内容。随后n是跳到下一个，N是跳到上一个。</p><p><strong>复制与删除</strong><br><code>yy</code>：复制一行<br><code>dd</code>：删除一行</p><p>加上数字则可以删除指定的行数，例如：<br><code>100dd</code>：删除100行</p><p>在实际用的时候，有时候会使用<code>gg</code>+<code>10000dd</code>来删除完整的文件。</p><p><strong>撤销</strong><br><code>u</code>：撤销最后一次操作</p><p><strong>翻页</strong><br><code>Ctrl</code>+<code>f</code>：向下翻页<br><code>Ctrl</code>+<code>b</code>：向上翻页</p><p><strong>一些神奇操作</strong><br><code>Ctrl</code>+<code>z</code>：将Vim切换到后台，在命令行输入<code>fg</code>切回<br><code>zt</code>： 把当前行置于屏幕顶端<br><code>zb</code> ： 把当前行置于屏幕底<br><code>zz</code> ：把当前行置于屏幕中央</p><p>2024&#x2F;3&#x2F;3 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Vim</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2024/2/29 记搬家</title>
    <link href="/2024/02/29/2024-2-29-%E8%AE%B0%E6%90%AC%E5%AE%B6/"/>
    <url>/2024/02/29/2024-2-29-%E8%AE%B0%E6%90%AC%E5%AE%B6/</url>
    
    <content type="html"><![CDATA[<p>2024年的2月28日，匆匆完成了回到苏州的第一次搬家。收拾完桌搭后，我习惯性的拍下一张纪念照，此时距离上一次我在朋友圈发下我辛苦装饰的桌面，时间匆匆流去，时间已过去了六年。</p><p>在过去的十年里，我搬过六七次家，唯独这次的心境与此前都不尽相同。过去不管搬到哪里，身边总有朋友与我一起。回忆起前几次搬家的兴奋劲，不禁哑然失笑：不知不觉中，我也成为了城市里一个混迹人群的打拼生活的路人。</p><p>这次的搬家也是一个曲折的故事。Anyway，在长久的争吵和妥协后，我也算是有了一个落脚之地。我终于可以坐在自己的桌前，敲下我的新家第一篇博客。</p><p>2024，2月28日，纪念一下。</p><p>2024&#x2F;2&#x2F;28 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CV的Hello World：MNIST/Cifar10手写数字识别</title>
    <link href="/2024/02/24/CV%E7%9A%84Hello-World%EF%BC%9AMNIST-Cifar10%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <url>/2024/02/24/CV%E7%9A%84Hello-World%EF%BC%9AMNIST-Cifar10%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<p>MNIST和Cifar10分类任务可谓是CV界的Hello World。要熟悉Pytorch框架免不了多写几遍代码。这里实现一下代码。</p><h1 id="Cifar10数据集"><a href="#Cifar10数据集" class="headerlink" title="Cifar10数据集"></a>Cifar10数据集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br></code></pre></td></tr></table></figure><p>定义一下<code>transforms</code>，把像素归一化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">transform = transforms.Compose(<br>[transforms.ToTensor(),<br>transforms.Normlize((<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>),(<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>))])<br><br>trainset = torchvision.dataset.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>,train=<span class="hljs-literal">True</span>,download=<span class="hljs-literal">True</span>,transform=transform)<br>testset = torchvision.dataset.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>,train=<span class="hljs-literal">False</span>,download=<span class="hljs-literal">True</span>,transform=transform)<br><br>classes = (<span class="hljs-string">&#x27;plane&#x27;</span>, <span class="hljs-string">&#x27;car&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;deer&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;frog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;ship&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>)<br></code></pre></td></tr></table></figure><p>接下来定义<code>dataloader</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">trainloader = DataLoader(trainset, batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">True</span>)<br>testloader = DataLoader(testset, batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>做一下可视化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">12</span>):<br>    plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, i+<span class="hljs-number">1</span>)<br>    plt.imshow(trainset[i][<span class="hljs-number">0</span>].permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)) <span class="hljs-comment"># [channels, heights, weights] ==&gt; [heights, weights, channels]</span><br>    plt.title(classes[trainset[i][<span class="hljs-number">1</span>]])<br>    plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/images/200529.png"></p><p>接下来就是简单的模型架构：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>)<br>        self.pool = nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        self.fc1 = nn.Linear(<span class="hljs-number">16</span>*<span class="hljs-number">5</span>*<span class="hljs-number">5</span>, <span class="hljs-number">120</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.pool(F.relu(self.conv1(x)))<br>        x = self.pool(F.relu(self.conv2(x)))<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = self.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br>    <br>net = Net()<br></code></pre></td></tr></table></figure><p>接下来定义损失函数和优化器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.SGD(net.parameters(), lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure><p>开始训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):<br>    running_loss = <span class="hljs-number">0.0</span><br>    <br>    <span class="hljs-keyword">for</span> i, (inputs, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader):<br>        optimizer.zero_grad()<br>        outputs = net(inputs)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br>        <br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">2000</span> == <span class="hljs-number">1999</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;epoch: <span class="hljs-subst">&#123;epoch&#125;</span>, mini batch: <span class="hljs-subst">&#123;i+<span class="hljs-number">1</span>:5d&#125;</span>, loss: <span class="hljs-subst">&#123;running_loss / <span class="hljs-number">2000</span>:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>            <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Finish Training.&#x27;</span>)<br></code></pre></td></tr></table></figure><p>保存一下模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(net.state_dict(), <span class="hljs-string">&#x27;./cifar_net.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><p>用测试集验证一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">dataiter = <span class="hljs-built_in">iter</span>(testloader)<br>images, labels = <span class="hljs-built_in">next</span>(dataiter)<br><br>imshow(torchvision.utils.make_grid(images))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;GroundTruth: &#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;classes[labels[j]]:5s&#125;</span>&#x27;</span> <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> testloader:<br>        img, labels = data<br>        outputs = net(images)<br>        _, prediction = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (prediction == labels).<span class="hljs-built_in">sum</span>().item()<br>        <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy on test set: <span class="hljs-subst">&#123;<span class="hljs-number">100</span> * correct // total&#125;</span>%&#x27;</span>)<br></code></pre></td></tr></table></figure><p>也可以对每一类的准确度进行验证：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">correct_pred = &#123;classname: <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> classname <span class="hljs-keyword">in</span> classes&#125;<br>total_pred = &#123;classname: <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> classname <span class="hljs-keyword">in</span> classes&#125;<br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> testloader:<br>        images, labels = data<br>        outputs = net(images)<br>        _, prediction = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">for</span> label, prediction <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(labels, predictions):<br>            <span class="hljs-keyword">if</span> label == predictions:<br>                correct_pred[classes[label]] += <span class="hljs-number">1</span><br>            total_pred[classes[label]] += <span class="hljs-number">1</span><br>            <br><span class="hljs-keyword">for</span> classname, correct_count <span class="hljs-keyword">in</span> correct_pred.items():<br>    accuracy = <span class="hljs-number">100</span> * <span class="hljs-built_in">float</span>(correct_count) / total_pred[classname]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy for class: <span class="hljs-subst">&#123;classname&#125;</span> is <span class="hljs-subst">&#123;accuracy:<span class="hljs-number">.1</span>f&#125;</span> %&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h1><p>直接上代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">train_dataset = torchvision.datasets.MNIST(root=<span class="hljs-string">&quot;./data&quot;</span>, train=<span class="hljs-literal">True</span>, transform=transforms.ToTensor(), download=<span class="hljs-literal">True</span>)<br>test_dataset = torchvision.datasets.MNIST(root=<span class="hljs-string">&quot;./data&quot;</span>, train=<span class="hljs-literal">False</span>, transform=transforms.ToTensor(), download=<span class="hljs-literal">True</span>)<br><br>train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>)<br>test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>定义模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">5</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, kernel_size=<span class="hljs-number">5</span>)<br>        self.pool = nn.MaxPool2d(<span class="hljs-number">2</span>)<br>        self.fc = nn.Linear(<span class="hljs-number">320</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.pool(nn.functional.relu(self.conv1(x)))<br>        x = self.pool(nn.functional.relu(self.conv2(x)))<br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">320</span>)<br>        x = self.fc(x)<br>        <span class="hljs-keyword">return</span> x<br><br>net = Net()<br></code></pre></td></tr></table></figure><p>定义损失函数与优化器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">criterion = nn.CrossEntropyLoss()<br>optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>)<br></code></pre></td></tr></table></figure><p>训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>    <span class="hljs-keyword">for</span> i, (images, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        outputs = model(images)<br>        loss = criterion(outputs, labels)<br><br>        optimizer.zero_grad()<br>        loss.backward()<br>        optimizer.step()<br><br>        <span class="hljs-keyword">if</span> (i+<span class="hljs-number">1</span>) % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span> (<span class="hljs-string">f&#x27;Epoch: <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span> , Loss:<span class="hljs-subst">&#123;loss.item():<span class="hljs-number">.4</span>f&#125;</span>&#x27;</span>)           <br></code></pre></td></tr></table></figure><p>验证：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():<br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> test_loader:<br>        images = images.to(device)<br>        labels = labels.to(device)<br>        outputs = model(images)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy: <span class="hljs-subst">&#123;<span class="hljs-number">100</span> * correct / total&#125;</span> %&#x27;</span>)<br></code></pre></td></tr></table></figure><p>2024&#x2F;2&#x2F;24 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>CV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CV</tag>
      
      <tag>代码实战</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从零开始训练自己的GPT</title>
    <link href="/2024/02/13/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84GPT/"/>
    <url>/2024/02/13/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84GPT/</url>
    
    <content type="html"><![CDATA[<p>之前研究LLM的时候，都只是看架构原理，以及MultiAttention的实现代码，但是对于大模型完整的训练过程没有太多仔细的了解。正好放假，就抽了点时间在研究了一下。这次，用网络小说“诛仙”为例，训练一个能写网文的语言模型。</p><h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><p>首先需要导入一些必要的库，以及设置一些必要的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> mmap<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> argparse<br><br>device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br><br>batch_size = <span class="hljs-number">32</span> <span class="hljs-comment"># 训练/预测时的Batch样本个数</span><br>block_size = <span class="hljs-number">128</span>  <span class="hljs-comment"># 训练/预测时的每个样本长度</span><br>max_iters = <span class="hljs-number">200</span> <span class="hljs-comment"># 最大生成字符数</span><br>learning_rate = <span class="hljs-number">3e-4</span><br>eval_iters = <span class="hljs-number">100</span><br>n_embd = <span class="hljs-number">384</span><br>n_head = <span class="hljs-number">4</span><br>n_layer = <span class="hljs-number">4</span><br>dropout = <span class="hljs-number">0.2</span><br></code></pre></td></tr></table></figure><h2 id="准备词表"><a href="#准备词表" class="headerlink" title="准备词表"></a>准备词表</h2><p>训练模型的第一步是需要从语料中提取出词表字典。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;诛仙.txt&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;gbk&#x27;</span>,errors=<span class="hljs-string">&#x27;replace&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    text = f.read()<br><br>chars = <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(text)))<br>vocab_size = <span class="hljs-built_in">len</span>(char) <span class="hljs-comment"># 词表长度</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;共有<span class="hljs-subst">&#123;vocab_size&#125;</span>个不同的字符&#x27;</span>)<br><span class="hljs-comment"># 共有3591个不同的字符</span><br><br><span class="hljs-built_in">print</span>(text[:<span class="hljs-number">10</span>])<br><span class="hljs-comment"># 诛仙</span><br><span class="hljs-comment"># 作者：萧鼎</span><br></code></pre></td></tr></table></figure><p>词典提取完之后，就需要弄一个解码器和编码器。这两者的作用是将字符映射为数字Index，以及将Index反映射为字符。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">string_to_int = &#123; ch:i <span class="hljs-keyword">for</span> i,ch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(chars) &#125;<br>int_to_string = &#123; i:ch <span class="hljs-keyword">for</span> i,ch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(chars) &#125;<br>encode = <span class="hljs-keyword">lambda</span> s: [string_to_int[c] <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s]<br>decode = <span class="hljs-keyword">lambda</span> l: <span class="hljs-string">&#x27;&#x27;</span>.join([int_to_string[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> l])<br><br>encode(<span class="hljs-string">&#x27;天地不仁，以万物为刍狗。&#x27;</span>)<br><span class="hljs-comment"># [808, 732, 47, 130, 3587, 146, 42, 2094, 71, 351, 2111, 32]</span><br><br>decode([<span class="hljs-number">808</span>, <span class="hljs-number">732</span>, <span class="hljs-number">47</span>, <span class="hljs-number">130</span>, <span class="hljs-number">3587</span>, <span class="hljs-number">146</span>, <span class="hljs-number">42</span>, <span class="hljs-number">2094</span>, <span class="hljs-number">71</span>, <span class="hljs-number">351</span>, <span class="hljs-number">2111</span>, <span class="hljs-number">32</span>])<br><span class="hljs-comment"># &#x27;天地不仁，以万物为刍狗。&#x27;</span><br></code></pre></td></tr></table></figure><h1 id="获取批数据"><a href="#获取批数据" class="headerlink" title="获取批数据"></a>获取批数据</h1><p>接下来，需要定义一个获取批数据的方法。我们定义了80%的数据作为训练集，20%作为验证集。<code>get_batch</code>方法会随机选择一个index，然后逐层叠加数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">n = <span class="hljs-built_in">int</span>(<span class="hljs-number">0.8</span>*<span class="hljs-built_in">len</span>(data))<br>train_data = data[:n]<br>val_data = data[n:]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_batch</span>(<span class="hljs-params">split</span>):<br>    data = train_data <span class="hljs-keyword">if</span> split == <span class="hljs-string">&#x27;train&#x27;</span> <span class="hljs-keyword">else</span> val_data<br>    ix = torch.randint(<span class="hljs-built_in">len</span>(data) - block_size, (batch_size,))<br>    x = torch.stack([data[i:i+block_size] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ix])<br>    y = torch.stack([data[i+<span class="hljs-number">1</span>:i+block_size+<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ix])<br>    x, y = x.to(device), y.to(device)<br>    <span class="hljs-keyword">return</span> x, y<br><br>x, y = get_batch(<span class="hljs-string">&#x27;train&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;inputs:&#x27;</span>)<br><span class="hljs-built_in">print</span>(x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;targets:&#x27;</span>)<br><span class="hljs-built_in">print</span>(y)<br></code></pre></td></tr></table></figure><p>打印看一下，这里<code>batch_size</code>是4，这说明一个批次里有四个样本对。输入是一个长度为8的句子，而输出则是从第二个字之后，预测下一个字。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">inputs:<br>tensor([[73,  1, 54, 72,  1, 58, 75, 58],<br>        [58, 69, 65, 62, 58, 57,  1, 28],<br>        [56, 58, 72, 72, 11,  0,  0,  3],<br>        [26, 74, 73,  1, 33,  1, 54, 66]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br>targets:<br>tensor([[ 1, 54, 72,  1, 58, 75, 58, 71],<br>        [69, 65, 62, 58, 57,  1, 28, 68],<br>        [58, 72, 72, 11,  0,  0,  3, 40],<br>        [74, 73,  1, 33,  1, 54, 66,  1]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="评估函数"><a href="#评估函数" class="headerlink" title="评估函数"></a>评估函数</h1><p>接下来定义一个评估的函数。当评估时，不需要计算梯度。模型也需要切换到<code>eval</code>模式。随后迭代地取batch样本，计算概率和损失。最后输出损失的均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@torch.no_grad()</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">estimate_loss</span>():<br>    out = &#123;&#125;<br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;val&#x27;</span>]:<br>        losses = torch.zeros(eval_iters)<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(eval_iters):<br>            X, Y = get_batch(split)<br>            logits, loss = model(X, Y)<br>            losses[k] = loss.item()<br>        out[split] = losses.mean()<br>    model.train()<br>    <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><h1 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h1><p>随后就是最重要的模型部分。这里采用了最通用的多头注意力构成的模型。首先定义一个注意力头。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Head</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; one head of self-attention &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, head_size</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.key = nn.Linear(n_embd, head_size, bias=<span class="hljs-literal">False</span>)<br>        self.query = nn.Linear(n_embd, head_size, bias=<span class="hljs-literal">False</span>)<br>        self.value = nn.Linear(n_embd, head_size, bias=<span class="hljs-literal">False</span>)<br>        self.register_buffer(<span class="hljs-string">&#x27;tril&#x27;</span>, torch.tril(torch.ones(block_size, block_size)))<br><br>        self.dropout = nn.Dropout(dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># input of size (batch, time-step, channels)</span><br>        <span class="hljs-comment"># output of size (batch, time-step, head size)</span><br>        B,T,C = x.shape<br>        k = self.key(x)   <span class="hljs-comment"># (B,T,hs)</span><br>        q = self.query(x) <span class="hljs-comment"># (B,T,hs)</span><br>        <span class="hljs-comment"># compute attention scores (&quot;affinities&quot;)</span><br>        wei = q @ k.transpose(-<span class="hljs-number">2</span>,-<span class="hljs-number">1</span>) * k.shape[-<span class="hljs-number">1</span>]**-<span class="hljs-number">0.5</span> <span class="hljs-comment"># (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)</span><br>        wei = wei.masked_fill(self.tril[:T, :T] == <span class="hljs-number">0</span>, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;-inf&#x27;</span>)) <span class="hljs-comment"># (B, T, T)</span><br>        wei = F.softmax(wei, dim=-<span class="hljs-number">1</span>) <span class="hljs-comment"># (B, T, T)</span><br>        wei = self.dropout(wei)<br>        <span class="hljs-comment"># perform the weighted aggregation of the values</span><br>        v = self.value(x) <span class="hljs-comment"># (B,T,hs)</span><br>        out = wei @ v <span class="hljs-comment"># (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)</span><br>        <span class="hljs-keyword">return</span> out<br><br><span class="hljs-comment"># [1, 0, 0]</span><br><span class="hljs-comment"># [1, 0.6, 0]</span><br><span class="hljs-comment"># [1, 0.6, 0.4]</span><br></code></pre></td></tr></table></figure><p>随后，我们组一个多头注意力模板。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiHeadAttention</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; multiple heads of self-attention in parallel &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_heads, head_size</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.heads = nn.ModuleList([Head(head_size) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_heads)])<br>        self.proj = nn.Linear(head_size * num_heads, n_embd)<br>        self.dropout = nn.Dropout(dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = torch.cat([h(x) <span class="hljs-keyword">for</span> h <span class="hljs-keyword">in</span> self.heads], dim=-<span class="hljs-number">1</span>) <span class="hljs-comment"># (B, T, F) -&gt; (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])</span><br>        out = self.dropout(self.proj(out))<br>        <span class="hljs-keyword">return</span> out   <br></code></pre></td></tr></table></figure><p>然后是前向传播层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeedFoward</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; a simple linear layer followed by a non-linearity &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_embd</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.net = nn.Sequential(<br>            nn.Linear(n_embd, <span class="hljs-number">4</span> * n_embd),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">4</span> * n_embd, n_embd),<br>            nn.Dropout(dropout),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.net(x)<br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Block</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; Transformer block: communication followed by computation &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_embd, n_head</span>):<br>        <span class="hljs-comment"># n_embd: embedding dimension, n_head: the number of heads we&#x27;d like</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        head_size = n_embd // n_head<br>        self.sa = MultiHeadAttention(n_head, head_size)<br>        self.ffwd = FeedFoward(n_embd)<br>        self.ln1 = nn.LayerNorm(n_embd)<br>        self.ln2 = nn.LayerNorm(n_embd)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        y = self.sa(x)<br>        x = self.ln1(x + y)<br>        y = self.ffwd(x)<br>        x = self.ln2(x + y)<br>        <span class="hljs-keyword">return</span> x<br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GPTLanguageModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)<br>        self.position_embedding_table = nn.Embedding(block_size, n_embd)<br>        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layer)])<br>        self.ln_f = nn.LayerNorm(n_embd) <span class="hljs-comment"># final layer norm</span><br>        self.lm_head = nn.Linear(n_embd, vocab_size)<br>        <br>        self.apply(self._init_weights)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_weights</span>(<span class="hljs-params">self, module</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(module, nn.Linear):<br>            torch.nn.init.normal_(module.weight, mean=<span class="hljs-number">0.0</span>, std=<span class="hljs-number">0.02</span>)<br>            <span class="hljs-keyword">if</span> module.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                torch.nn.init.zeros_(module.bias)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(module, nn.Embedding):<br>            torch.nn.init.normal_(module.weight, mean=<span class="hljs-number">0.0</span>, std=<span class="hljs-number">0.02</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, index, targets=<span class="hljs-literal">None</span></span>):<br>        B, T = index.shape<br>        <br>        <span class="hljs-comment"># idx and targets are both (B,T) tensor of integers</span><br>        tok_emb = self.token_embedding_table(index) <span class="hljs-comment"># (B,T,C)</span><br>        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) <span class="hljs-comment"># (T,C)</span><br>        x = tok_emb + pos_emb <span class="hljs-comment"># (B,T,C)</span><br>        x = self.blocks(x) <span class="hljs-comment"># (B,T,C)</span><br>        x = self.ln_f(x) <span class="hljs-comment"># (B,T,C)</span><br>        logits = self.lm_head(x) <span class="hljs-comment"># (B,T,vocab_size)</span><br>        <br>        <span class="hljs-keyword">if</span> targets <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            loss = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">else</span>:<br>            B, T, C = logits.shape<br>            logits = logits.view(B*T, C)<br>            targets = targets.view(B*T)<br>            loss = F.cross_entropy(logits, targets)<br>        <br>        <span class="hljs-keyword">return</span> logits, loss<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generate</span>(<span class="hljs-params">self, index, max_new_tokens</span>):<br>        <span class="hljs-comment"># index is (B, T) array of indices in the current context</span><br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_new_tokens):<br>            <span class="hljs-comment"># crop idx to the last block_size tokens</span><br>            index_cond = index[:, -block_size:]<br>            <span class="hljs-comment"># get the predictions</span><br>            logits, loss = self.forward(index_cond)<br>            <span class="hljs-comment"># focus only on the last time step</span><br>            logits = logits[:, -<span class="hljs-number">1</span>, :] <span class="hljs-comment"># becomes (B, C)</span><br>            <span class="hljs-comment"># apply softmax to get probabilities</span><br>            probs = F.softmax(logits, dim=-<span class="hljs-number">1</span>) <span class="hljs-comment"># (B, C)</span><br>            <span class="hljs-comment"># sample from the distribution</span><br>            index_next = torch.multinomial(probs, num_samples=<span class="hljs-number">1</span>) <span class="hljs-comment"># (B, 1)</span><br>            <span class="hljs-comment"># append sampled index to the running sequence</span><br>            index = torch.cat((index, index_next), dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># (B, T+1)</span><br>        <span class="hljs-keyword">return</span> index<br><br>model = GPTLanguageModel(vocab_size)<br><span class="hljs-comment"># print(&#x27;loading model parameters...&#x27;)</span><br><span class="hljs-comment"># with open(&#x27;model-01.pkl&#x27;, &#x27;rb&#x27;) as f:</span><br><span class="hljs-comment">#     model = pickle.load(f)</span><br><span class="hljs-comment"># print(&#x27;loaded successfully!&#x27;)</span><br>m = model.to(device)<br></code></pre></td></tr></table></figure><h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>我们创建一个Optimizer，随后开始训练模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># create a PyTorch optimizer</span><br>optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)<br><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">iter</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_iters):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">iter</span> % eval_iters == <span class="hljs-number">0</span>:<br>        losses = estimate_loss()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;step: <span class="hljs-subst">&#123;<span class="hljs-built_in">iter</span>&#125;</span>, train loss: <span class="hljs-subst">&#123;losses[<span class="hljs-string">&#x27;train&#x27;</span>]:<span class="hljs-number">.3</span>f&#125;</span>, val loss: <span class="hljs-subst">&#123;losses[<span class="hljs-string">&#x27;val&#x27;</span>]:<span class="hljs-number">.3</span>f&#125;</span>&quot;</span>)<br><br>    <span class="hljs-comment"># sample a batch of data</span><br>    xb, yb = get_batch(<span class="hljs-string">&#x27;train&#x27;</span>)<br><br>    <span class="hljs-comment"># evaluate the loss</span><br>    logits, loss = model.forward(xb, yb)<br>    optimizer.zero_grad(set_to_none=<span class="hljs-literal">True</span>)<br>    loss.backward()<br>    optimizer.step()<br><span class="hljs-built_in">print</span>(loss.item())<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;model-01.pkl&#x27;</span>, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    pickle.dump(model, f)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;model saved&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h1><p>训练完成后就可以测试模型了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">&#x27;Hello! Can you see me?&#x27;</span><br>context = torch.tensor(encode(prompt), dtype=torch.long, device=device)<br>generated_chars = decode(m.generate(context.unsqueeze(<span class="hljs-number">0</span>), max_new_tokens=<span class="hljs-number">100</span>)[<span class="hljs-number">0</span>].tolist())<br><span class="hljs-built_in">print</span>(generated_chars)<br></code></pre></td></tr></table></figure><p>2024&#x2F;2&#x2F;17 于连江</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>代码实战</tag>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
      <tag>GPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>代码实战：Word2Vec的Pytorch实现</title>
    <link href="/2024/02/11/%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98%EF%BC%9AWord2Vec%E7%9A%84Pytorch%E5%AE%9E%E7%8E%B0/"/>
    <url>/2024/02/11/%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98%EF%BC%9AWord2Vec%E7%9A%84Pytorch%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<blockquote><p>重点引用：</p><p><a href="https://hzaubionlp.files.wordpress.com/2020/09/5e38081word2vece59fbae4ba8epytorche5ae9ee78eb0word2vece8af8de5b58ce585a5.pdf">Word2Vec精讲及代码实现</a>。</p><p><a href="https://angel-hair.github.io/2021/05/20/Word2Vec%E7%9A%84PyTorch%E5%AE%9E%E7%8E%B0%EF%BC%88%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE%EF%BC%89%EF%BC%88%E5%8F%82%E8%80%83%E7%89%88%EF%BC%89/">Word2Vec的PyTorch实现（中文数据）（参考版）</a></p></blockquote><p>话不多说，先上介绍：Word2Vec是由谷歌团队于2013年发布的词嵌入工具，主要包含了两种模型：<code>Skip-gram</code>和<code>CBOW</code>模型。论文为<a href="https://arxiv.org/pdf/1301.3781.pdf">Efficient Estimation of Word Representations in Vector Space</a>。</p><ul><li>Skip-gram：根据目标词去预测周围词来训练得到词向量。</li><li>CBOW：根据上下文取预测目标词来训练得到词向量。</li></ul><p>Word2Vec在独热编码的基础上对词向量进行升维，因此获得了更高的维度，也代表着更深的语义，它主要的思想是<code>单词的含义由其上下文定义</code>。</p><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><p><code>Skip-gram</code>和<code>CBOW</code>分别代表了两种训练方式，不过他们的训练思想是容易理解的。例如，<code>CBOW</code> 模型将 “machine”、“learning”、“a”、“method” 作为输入，并返回 “is” 作为输出。<code>Skip-Gram</code> 模型则相反。：</p><p><img src="https://miro.medium.com/v2/resize:fit:963/1*ETcgajy5s0KNIfMgE5xOqg.png" alt="CBOW 方法"></p><p><img src="https://miro.medium.com/v2/resize:fit:963/1*SVs6xTpD7AYviP24UTOYUA.png" alt="Skip-gram方法"></p><p>上图是一个示例，<code>Skip-gram</code>通过建立大小为2的滑动窗口，来基于前后两个词预测中间的词。实际上，这两者都是一个多分类模型，对于输入的每个字进行输出。</p><p>整个模型的结构如下：</p><p><img src="https://miro.medium.com/v2/resize:fit:963/1*ualmmjPyasihGaddtrXvig.png" alt="Skipgram 模型架构"></p><p>整个模型中包含了几个部分：</p><ol><li>对所有单词进行编码。</li><li>嵌入层，将所有单词变为300维向量。</li><li>使用Softmax的线性层，用来输出概率。</li></ol><p><code>CBOW</code> 和 <code>Skip-Gram</code> 模型的区别在于输入字的数量。<code>CBOW</code> 模型采用多个单词，每个单词经过相同的嵌入层，然后在进入线性层之前对单词嵌入向量进行平均。<code>Skip-Gram</code>模型改用一个单词。详细的架构如下图所示。</p><p><img src="https://miro.medium.com/v2/resize:fit:963/1*mLDM3PH12CjhaFoUm5QTow.png" alt="CBOW模型"></p><p><img src="https://miro.medium.com/v2/resize:fit:963/1*eHh1_t8Wms_hqDNBLuAnFg.png" alt="Skip-Gram模型"></p><p>在训练结束后，我们将使用嵌入层的权重，而不是直接使用训练的模型，这就是我们得到的嵌入向量。</p><h2 id="模型的输入"><a href="#模型的输入" class="headerlink" title="模型的输入"></a>模型的输入</h2><p>对于<code>CBOW</code>来说，模型的输入是上下文单词的独热编码。假设单词向量空间维度为 V（总词表大小），上下文单词个数为C，那么第i个词的就是一个维度为V，第i个元素值非零，其余元素全为0的向量，一共有C个这样的向量。</p><p>输入到隐藏层之间包含了一个权重矩阵W。</p><p>隐藏层输出层包含了第二权重矩阵W’。</p><p>最终输出经过softmax函数，进行归一化。</p><h1 id="训练代码"><a href="#训练代码" class="headerlink" title="训练代码"></a>训练代码</h1><p>以下是训练代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> torchtext.vocab <span class="hljs-keyword">import</span> vocab<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter, OrderedDict<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> torchtext.transforms <span class="hljs-keyword">import</span> VocabTransform  <span class="hljs-comment"># 注意：torchtext版本0.12+</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_text</span>():<br>    sentence_list = [  <span class="hljs-comment"># 假设这是全部的训练语料</span><br>        <span class="hljs-string">&quot;nlp drives computer programs that translate text from one language to another&quot;</span>,<br>        <span class="hljs-string">&quot;nlp combines computational linguistics rule based modeling of human language with statistical&quot;</span>,<br>        <span class="hljs-string">&quot;nlp model respond to text or voice data and respond with text&quot;</span>,<br>    ]<br>    <span class="hljs-keyword">return</span> sentence_list<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CbowDataSet</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, text_list, side_window=<span class="hljs-number">3</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        构造Word2vec的CBOW采样Dataset</span><br><span class="hljs-string">        :param text_list: 语料</span><br><span class="hljs-string">        :param side_window: 单侧正例（构造背景词）采样数，总正例是：2 * side_window</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(CbowDataSet, self).__init__()<br>        self.side_window = side_window<br>        text_vocab, vocab_transform = self.reform_vocab(text_list)<br>        self.text_list = text_list  <span class="hljs-comment"># 原始文本</span><br>        self.text_vocab = text_vocab  <span class="hljs-comment"># torchtext的vocab</span><br>        self.vocab_transform = vocab_transform  <span class="hljs-comment"># torchtext的vocab_transform</span><br>        self.cbow_data = self.generate_cbow()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.cbow_data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        data_row = self.cbow_data[idx]<br>        <span class="hljs-keyword">return</span> data_row[<span class="hljs-number">0</span>], data_row[<span class="hljs-number">1</span>]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reform_vocab</span>(<span class="hljs-params">self, text_list</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;根据语料构造torchtext的vocab&quot;&quot;&quot;</span><br>        total_word_list = []<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> text_list:  <span class="hljs-comment"># 将嵌套的列表([[xx,xx],[xx,xx]...])拉平 ([xx,xx,xx...])</span><br>            total_word_list += _.split(<span class="hljs-string">&quot; &quot;</span>)<br>        counter = Counter(total_word_list)  <span class="hljs-comment"># 统计计数</span><br>        sorted_by_freq_tuples = <span class="hljs-built_in">sorted</span>(counter.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 构造成可接受的格式：[(单词,num), ...]</span><br>        ordered_dict = OrderedDict(sorted_by_freq_tuples)<br>        <span class="hljs-comment"># 开始构造 vocab</span><br>        special_token = [<span class="hljs-string">&quot;&lt;UNK&gt;&quot;</span>, <span class="hljs-string">&quot;&lt;SEP&gt;&quot;</span>]  <span class="hljs-comment"># 特殊字符</span><br>        text_vocab = vocab(ordered_dict, specials=special_token)  <span class="hljs-comment"># 单词转token，specials里是特殊字符，可以为空</span><br>        text_vocab.set_default_index(<span class="hljs-number">0</span>)<br>        vocab_transform = VocabTransform(text_vocab)<br>        <span class="hljs-keyword">return</span> text_vocab, vocab_transform<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_cbow</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;生成CBOW的训练数据&quot;&quot;&quot;</span><br>        cbow_data = []<br>        <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> self.text_list:<br>            sentence_id_list = np.array(self.vocab_transform(sentence.split(<span class="hljs-string">&#x27; &#x27;</span>)))<br>            <span class="hljs-keyword">for</span> center_index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<br>                    self.side_window, <span class="hljs-built_in">len</span>(sentence_id_list) - self.side_window):  <span class="hljs-comment"># 防止前面或后面取不到足够的值，这是取index的上下界</span><br>                pos_index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(center_index - self.side_window, center_index + self.side_window + <span class="hljs-number">1</span>))<br>                <span class="hljs-keyword">del</span> pos_index[self.side_window]<br>                cbow_data.append([sentence_id_list[center_index], sentence_id_list[pos_index]])<br>        <span class="hljs-keyword">return</span> cbow_data<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_vocab_transform</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.vocab_transform<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_vocab_size</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.text_vocab)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Word2VecModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, batch_size, word_embedding_size=<span class="hljs-number">100</span>, hidden=<span class="hljs-number">64</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Word2vec模型CBOW实现</span><br><span class="hljs-string">        :param vocab_size: 单词个数</span><br><span class="hljs-string">        :param word_embedding_size: 每个词的词向量维度</span><br><span class="hljs-string">        :param hidden: 隐层维度</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(Word2VecModel, self).__init__()<br>        self.vocab_size = vocab_size<br>        self.word_embedding_size = word_embedding_size<br>        self.hidden = hidden<br>        self.batch_size = batch_size<br>        self.word_embedding = nn.Embedding(self.vocab_size, self.word_embedding_size)  <span class="hljs-comment"># token对应的embedding</span><br>        <span class="hljs-comment"># 建模</span><br>        self.linear_in = nn.Linear(self.word_embedding_size, self.hidden)<br>        self.linear_out = nn.Linear(self.hidden, self.vocab_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_labels</span>):<br>        around_embedding = self.word_embedding(input_labels)<br>        avg_around_embedding = torch.mean(around_embedding, dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 1. 输入的词向量对应位置求平均</span><br>        in_emb = F.relu(self.linear_in(avg_around_embedding))  <span class="hljs-comment"># 2. 过第一个linear，使用relu激活函数</span><br>        out_emb = F.log_softmax(self.linear_out(in_emb))  <span class="hljs-comment"># 3. 过第二个linear，得到维度是：[batch_size, 单词总数]</span><br>        <span class="hljs-keyword">return</span> out_emb<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_embedding</span>(<span class="hljs-params">self, token_list: <span class="hljs-built_in">list</span></span>):<br>        <span class="hljs-keyword">return</span> self.word_embedding(torch.Tensor(token_list).long())<br></code></pre></td></tr></table></figure><p>然后是开始训练的部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">7</span><br>sentence_list = get_text()<br>cbow_data_set = CbowDataSet(sentence_list)  <span class="hljs-comment"># 构造 DataSet</span><br>data_loader = DataLoader(cbow_data_set, batch_size=batch_size, drop_last=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 将DataSet封装成DataLoader</span><br><span class="hljs-comment"># 开始训练</span><br>model = Word2VecModel(cbow_data_set.get_vocab_size(), batch_size)<br>optimizer = torch.optim.Adam(model.parameters())<br>criterion = nn.CrossEntropyLoss()<br><span class="hljs-keyword">for</span> _epoch_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    loss_list = []<br>    <span class="hljs-keyword">for</span> center_token, back_token <span class="hljs-keyword">in</span> data_loader:<br>        <span class="hljs-comment"># 开始训练</span><br>        optimizer.zero_grad()<br>        model_out = model(back_token)<br>        loss = criterion(model_out, center_token)<br>        loss.backward()<br>        optimizer.step()<br>        loss_list.append(loss.item())<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;训练中：&quot;</span>, _epoch_i, <span class="hljs-string">&quot;Loss:&quot;</span>, np.<span class="hljs-built_in">sum</span>(loss_list))<br></code></pre></td></tr></table></figure><p>简单测试一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">sentence = <span class="hljs-string">&quot;nlp can translate text from one language to another&quot;</span><br>vocab_transform = cbow_data_set.get_vocab_transform()<br>sentence_ids = vocab_transform(sentence.split(<span class="hljs-string">&#x27; &#x27;</span>))<br>sentence_embedding = model.get_embedding(sentence_ids)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这个是句向量的维度：&quot;</span>, sentence_embedding.shape)<br><br><span class="hljs-comment"># 这个是句向量的维度： torch.Size([9, 100])</span><br></code></pre></td></tr></table></figure><h1 id="调用权重"><a href="#调用权重" class="headerlink" title="调用权重"></a>调用权重</h1><p>在训练完之后，我们需要的是Embedding层的权重，我们可以用之前写好的<code>get embedding</code>方法来获得权重，或者直接使用<code>model.word_embedding.weight</code>也可以实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.nn.functional <span class="hljs-keyword">import</span> cosine_similarity<br><br><span class="hljs-comment"># 获取嵌入权重</span><br>embedding_weights = model.word_embedding.weight<br><br><span class="hljs-comment"># 获取词汇表</span><br>vocab_transform = cbow_data_set.get_vocab_transform()<br>vocab = vocab_transform.vocab<br><br><span class="hljs-comment"># 获取两个词的索引</span><br>word1_index = vocab[<span class="hljs-string">&#x27;nlp&#x27;</span>]<br>word2_index = vocab[<span class="hljs-string">&#x27;translate&#x27;</span>]<br><br><span class="hljs-comment"># 获取两个词的嵌入向量</span><br>word1_embedding = embedding_weights[word1_index].unsqueeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 添加额外的维度使其成为 1xembedding_size</span><br>word2_embedding = embedding_weights[word2_index].unsqueeze(<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 计算余弦相似度</span><br>similarity = cosine_similarity(word1_embedding, word2_embedding)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;余弦相似度 between &#x27;nlp&#x27; and &#x27;translate&#x27;: <span class="hljs-subst">&#123;similarity.item()&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 余弦相似度 between &#x27;nlp&#x27; and &#x27;translate&#x27;: 0.013783279806375504</span><br></code></pre></td></tr></table></figure><p>2024&#x2F;2&#x2F;11 于汕头</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>代码实战</tag>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
      <tag>Embedding</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker部署CUDA/CUDANN</title>
    <link href="/2024/02/07/Docker%E9%83%A8%E7%BD%B2CUDA-CUDANN/"/>
    <url>/2024/02/07/Docker%E9%83%A8%E7%BD%B2CUDA-CUDANN/</url>
    
    <content type="html"><![CDATA[<p>最近的项目中，大规模使用了Docker，随着项目发展，萌生了把推理服务也打包容器化的想法，因此就有了这篇博客。操作系统使用的是Centos7.9，Cuda版本为11.6.1。</p><p>首先，容器的主要原理就是在构建一个轻量级的操作系统，并在这个独立的操作系统中搭建想要的容器。通常来说，如果不需要调用宿主机硬件的话，可以直接构建容器。</p><h1 id="安装Nvidia-Container-Toolkit"><a href="#安装Nvidia-Container-Toolkit" class="headerlink" title="安装Nvidia-Container-Toolkit"></a>安装Nvidia-Container-Toolkit</h1><p>如果需要用到显卡的话，就需要安装Nvidia的容器套件<a href="https://github.com/NVIDIA/nvidia-container-toolkit">nvidia-container-toolkit</a>。</p><p>我们通过curl来下载并安装套件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \<br>sudo <span class="hljs-built_in">tee</span> /etc/yum.repos.d/nvidia-container-toolkit.repo<br><br>sudo yum install -y nvidia-container-toolkit<br></code></pre></td></tr></table></figure><h1 id="Docker拉取镜像"><a href="#Docker拉取镜像" class="headerlink" title="Docker拉取镜像"></a>Docker拉取镜像</h1><p>安装完套件后，需要去DockerHub拉取对应版本的cuda镜像，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull nvidia/cuda:11.6.1-cudnn8-devel-centos7<br></code></pre></td></tr></table></figure><p>其中Cuda镜像除了本身的版本以外，还有多个版本：base, runtime, devel。它们的大小均不同。解释如下：</p><ul><li>base版本：只包含了预构建cuda应用程序的最低要求的包。如果用户需要自定义安装需要的cuda包，可以选择使用这个镜像版本，但如果想省事儿，别用。</li><li>runtime版本：只涵盖了运行环境的最小集合，例如动态库等。</li><li>devel版本：涵盖了开发所需的所有工具，包含编译、debug等，以及编译需要的头文件、静态库。</li></ul><p><strong>如果想用docker镜像做开发环境，建议使用devel版本的image。</strong></p><h1 id="编写Dockerfile"><a href="#编写Dockerfile" class="headerlink" title="编写Dockerfile"></a>编写Dockerfile</h1><p>前面拉取完cuda的镜像后就可以直接编写Dockerfile了，这里给一个示例。这里的场景是需要在Docker中构建一个能够调用显卡的python环境，因此需要分成多个阶段进行构建：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 第一阶段：使用Miniconda镜像</span><br><span class="hljs-keyword">FROM</span> continuumio/miniconda3:latest as miniconda_stage                                           <br><span class="hljs-comment"># 设置环境变量                                                                                 </span><br><span class="hljs-keyword">ENV</span> PATH=<span class="hljs-string">&quot;/opt/conda/bin:$PATH&quot;</span>                                                               <br><span class="hljs-comment"># 安装 Python 3.10.13                                                                       </span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> conda install -y python=3.10.13                                                             </span><br><span class="hljs-comment"># 第二阶段：使用 CUDA 镜像                                                                     </span><br><span class="hljs-keyword">FROM</span> nvidia/cuda:<span class="hljs-number">11.6</span>.<span class="hljs-number">1</span>-cudnn8-devel-centos7 as cuda_image                                        <br><span class="hljs-comment"># 从 Miniconda 阶段复制环境                                                                   </span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> --from=miniconda_stage /opt/conda /opt/conda                                                </span><br><span class="hljs-comment"># 设置环境变量                                                                                 </span><br><span class="hljs-keyword">ENV</span> PATH=<span class="hljs-string">&quot;/opt/conda/bin:$PATH&quot;</span>                                                                  <br><span class="hljs-comment"># 第三阶段：构建项目                                                                           </span><br><span class="hljs-keyword">FROM</span> cuda_image                                                                                 <br><span class="hljs-comment"># 设置工作目录                                                                             </span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /infer_app                                                                               </span><br><span class="hljs-comment"># 复制项目文件                                                                                 </span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./ /infer_app                                                                             </span><br><span class="hljs-comment"># 安装 mesa-libGL                                                                           </span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> yum install -y mesa-libGL                                                                </span><br><span class="hljs-comment"># 安装 vim                                                                                   </span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> yum install -y vim                                                                        </span><br><span class="hljs-comment"># 安装项目依赖                                                                                 </span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install -r requirements.txt                                                            </span><br><span class="hljs-comment"># 暴露端口                                                                                   </span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">58090</span> <span class="hljs-number">58091</span>                                                                                                                                                                       <br><span class="hljs-comment"># 默认命令                                                                                   </span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;/bin/bash&quot;</span>]               </span><br></code></pre></td></tr></table></figure><p>在编写完之后，就可以构建一下容器，这里我写了个脚本来构建镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">rm</span> -f <span class="hljs-built_in">test</span>:v0.0.1<br>docker rmi -f <span class="hljs-built_in">test</span>:v0.0.1<br>docker build -t <span class="hljs-built_in">test</span>:v0.0.1<br></code></pre></td></tr></table></figure><h1 id="部署容器"><a href="#部署容器" class="headerlink" title="部署容器"></a>部署容器</h1><p>镜像构建完之后，就可以部署容器了，需要注意的是，如果要调用显卡，需要设置<code>--gpus all</code>来使用，否则会报错。这里给一个示例命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it --gpus all --network host -v /app/:/app/ -p 58090:58090 -p 58091:58091 <span class="hljs-built_in">test</span>:v0.0.1 bash<br></code></pre></td></tr></table></figure><p>进入容器以后就可以直接运行需要运行的程序了。你也可以直接使用nvidia-smi来查看是否成功调用显卡。</p><p>2024&#x2F;2&#x2F;7 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
      <tag>CUDA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python并发编程：多进程实现</title>
    <link href="/2024/02/03/Python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%AE%9E%E7%8E%B0/"/>
    <url>/2024/02/03/Python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>上一篇博客大致讲了怎么用Python实现多线程编程，这次写下怎么实现多进程。</p><p>首先，进程之间是相互隔离的，因此进程之间的数据默认是不会相互交换的。如果想要利用CPU的多核优势，就可以使用多进程编程。</p><h1 id="基础用法"><a href="#基础用法" class="headerlink" title="基础用法"></a>基础用法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> multiprocessing<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>():<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Start...&#x27;</span>) <span class="hljs-comment"># 主进程</span><br>    p1 = multiprocessing(target=task) <span class="hljs-comment"># 子进程</span><br>    p1.start()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> multiprocessing<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">args</span>):<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>();<br>p1 = multiprocessing(target=task, arg=(<span class="hljs-string">&#x27;xxx&#x27;</span>,))<br>    p.start()<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    run()<br></code></pre></td></tr></table></figure><p>这里我们可以区分一下主进程和子进程。主进程就是直接执行的那部分，而子进程是被放入multiprocessing方法中的那部分。由于进程之间是隔离的，所以数据不会共享。</p><p>我们可以实验一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> multiprocessing<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>():<br>    name = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br>        name.append(i)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;子进程的name&#x27;</span>, name)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    name = []<br><br>    p1 = multiprocessing.Process(target=task)<br>    p1.start()<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;主进程的name&#x27;</span>, name)<br>    <br>    <span class="hljs-comment"># 主进程的name []</span><br></code></pre></td></tr></table></figure><p>我们在子进程和主线程分别有一个name的列表，但是最后只打印了主进程的name，这是因为主进程取不到子进程的值。</p><h1 id="子进程获取主进程数据"><a href="#子进程获取主进程数据" class="headerlink" title="子进程获取主进程数据"></a>子进程获取主进程数据</h1><p>可以在子进程中获取到外部的一些信息。</p><p>例如通过<code>multiprocessing.current_process()</code>方法，能够获取当前进程的名字：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, current_process<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">args</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission start.&#x27;</span>)<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <span class="hljs-built_in">print</span>(current_process().name)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission end.&#x27;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    p = Process(target=task, args=(<span class="hljs-number">1</span>,))<br>    p.name = <span class="hljs-string">&#x27;subprocess&#x27;</span><br>    p.start()<br>    p.join()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;End&#x27;</span>)<br><br>    <span class="hljs-comment"># mission start.</span><br><span class="hljs-comment"># subprocess</span><br><span class="hljs-comment"># mission end.</span><br><span class="hljs-comment"># End</span><br></code></pre></td></tr></table></figure><p>除此之外，还可以获取进程的pid：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, current_process<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">args</span>):<br>    <span class="hljs-built_in">print</span>(os.getpid())<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission start.&#x27;</span>)<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <span class="hljs-built_in">print</span>(current_process().name)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission end.&#x27;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    p = Process(target=task, args=(<span class="hljs-number">1</span>,))<br>    p.name = <span class="hljs-string">&#x27;subprocess&#x27;</span><br>    p.start()<br>    p.join()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;End&#x27;</span>)<br>    <br><span class="hljs-comment"># 51862</span><br>    <span class="hljs-comment"># mission start.</span><br><span class="hljs-comment"># subprocess</span><br><span class="hljs-comment"># mission end.</span><br><span class="hljs-comment"># End</span><br></code></pre></td></tr></table></figure><p>以及获取线程个数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, current_process<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">args</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission start.&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;线程个数:<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(threading.<span class="hljs-built_in">enumerate</span>())&#125;</span>&#x27;</span>)<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <span class="hljs-built_in">print</span>(current_process().name)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission end.&#x27;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    p = Process(target=task, args=(<span class="hljs-number">1</span>,))<br>    p.name = <span class="hljs-string">&#x27;subprocess&#x27;</span><br>    p.start()<br>    p.join()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;End&#x27;</span>)<br><br>    <span class="hljs-comment"># mission start.</span><br>    <span class="hljs-comment"># 线程个数：1</span><br><span class="hljs-comment"># subprocess</span><br><span class="hljs-comment"># mission end.</span><br><span class="hljs-comment"># End</span><br></code></pre></td></tr></table></figure><p>同样还能获取CPU个数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> multiprocessing<br><br>cpu_count = multiprocessing.cpu_count()<br><span class="hljs-built_in">print</span>(cpu_count)<br><br><span class="hljs-comment"># 8</span><br></code></pre></td></tr></table></figure><p>通过这种方式，可以控制进程数以达到更高的效率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> multiprocessing<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    cpu_count = multiprocessing.cpu_count()<br>    <span class="hljs-built_in">print</span>(cpu_count)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cpu_count, -<span class="hljs-number">1</span>):<br>        p = multiprocessing.Process(target=task)<br>        p.start()<br></code></pre></td></tr></table></figure><h1 id="自定义进程类"><a href="#自定义进程类" class="headerlink" title="自定义进程类"></a>自定义进程类</h1><p>和多线程一样，可以通过继承Process类来自定义自己的进程类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> multiprocessing<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyProcess</span>(multiprocessing.Process):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;执行此进程...&#x27;</span>)<br>        <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    p = MyProcess(args=(<span class="hljs-number">0</span>,))<br>    p.start()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;继续执行...&#x27;</span>)<br>    <br>    <span class="hljs-comment"># 继续执行...</span><br>    <span class="hljs-comment"># 执行此进程...</span><br></code></pre></td></tr></table></figure><h1 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h1><p>默认进程间的数据是独立存在的，无法共享，但是有办法使他们进行通信。</p><h2 id="基于Manager"><a href="#基于Manager" class="headerlink" title="基于Manager"></a>基于Manager</h2><p>可以通过Manger构建上下文管理，在子进程里修改主进程的内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, Manager<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">d,l</span>):<br>    d[<span class="hljs-number">1</span>] = <span class="hljs-string">&#x27;1&#x27;</span><br>    d[<span class="hljs-string">&#x27;2&#x27;</span>] = <span class="hljs-number">2</span><br>    d[<span class="hljs-number">0.25</span>] = <span class="hljs-literal">None</span><br>    l.append(<span class="hljs-number">666</span>)<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">with</span> Manager() <span class="hljs-keyword">as</span> manager:<br>        d = manager.<span class="hljs-built_in">dict</span>()<br>        l = manager.<span class="hljs-built_in">list</span>()<br>        <br>        p = Process(target=f, args=(d,l))<br>        p.start()<br>        p.join()<br>        <br>        <span class="hljs-built_in">print</span>(d)<br>        <span class="hljs-built_in">print</span>(l)<br>        <br>        <span class="hljs-comment"># &#123;1: &#x27;1&#x27;, &#x27;2&#x27;: 2, 0.25: None&#125;</span><br><span class="hljs-comment"># [666]</span><br></code></pre></td></tr></table></figure><p>上面的代码中，主进程使用了Manager维护了两个对象：一个字典一个列表。子进程对其进行了修改，在Manager的作用域里，d和l被子进程修改了。</p><h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h1><p>同样，主进程和子进程也可以共同维护一个队列：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> multiprocessing<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">q</span>):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        q.put(i)<br>        <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    queue = multiprocessing.Queue()<br>    <br>    p = multiprocessing.Process(target=task,args=(queue,))<br>    p.start()<br>    p.join()<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;主进程：&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(queue.get())<br>    <span class="hljs-built_in">print</span>(queue.get())<br>    <span class="hljs-built_in">print</span>(queue.get())<br>    <br>    <span class="hljs-comment"># 主进程：</span><br>    <span class="hljs-comment"># 0</span><br>    <span class="hljs-comment"># 1</span><br>    <span class="hljs-comment"># 2</span><br></code></pre></td></tr></table></figure><h1 id="进程锁"><a href="#进程锁" class="headerlink" title="进程锁"></a>进程锁</h1><p>和线程锁一样，多进程也提供了进程锁，防止多线程共享一个数据导致数据混乱：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, RLock, Manager<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">n, d, l, lock</span>):<br>    lock.acquire()<br>    d[<span class="hljs-built_in">str</span>(n)] = n<br>    l[n] = -<span class="hljs-number">99</span><br>    lock.release()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    lock = RLock()<br>    <span class="hljs-keyword">with</span> Manager() <span class="hljs-keyword">as</span> manager:<br>        d = manager.<span class="hljs-built_in">dict</span>() <br>        l = manager.<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))  <span class="hljs-comment"># [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br>        <br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>            p = Process(target=f, args=(i, d, l, lock))<br>            p.start()<br>            p.join()<br><br>        <span class="hljs-built_in">print</span>(d)<br>        <span class="hljs-built_in">print</span>(l)<br></code></pre></td></tr></table></figure><p>通过将锁作为一个参数传入子进程，就可以锁住子进程需要的数据防止被其他进程篡改。</p><h2 id="进程锁的实际用例"><a href="#进程锁的实际用例" class="headerlink" title="进程锁的实际用例"></a>进程锁的实际用例</h2><p>这里有一个实际的案例，使用多进程进行抢票操作。假设我们有一个文件<code>f1.txt</code>，里面只有一个数字50，代表剩余还有50张票。现在需要写一个多进程的代码，让多进程抢票的同时不会让数据混乱：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time <br><span class="hljs-keyword">import</span> multiprocessing<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">lock</span>):<br>    lock.acquire()<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;f1.txt&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>,encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        current_num = <span class="hljs-built_in">int</span>(f.read())<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;开始排队抢票&#x27;</span>)<br>    time.sleep(<span class="hljs-number">1</span>)<br>    current_num -= <span class="hljs-number">1</span><br>    <br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;f1.txt&#x27;</span>,<span class="hljs-string">&#x27;w&#x27;</span>,encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(current_num)<br>    lock.release()<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    lock = multiprocessing.RLock()<br>    <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>        p = multiprocessing.Process(target=task, args=(lock,))<br>        p.start()<br>        <br>    time.sleep(<span class="hljs-number">7</span>)    <br></code></pre></td></tr></table></figure><p>也可以通过维护一个进程的列表，统一执行进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    lock = multiprocessing.RLock()<br>    <br>    process_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>        p = multiprocessing.Process(target=task, args=(lock,))<br>        p.start()<br>        process_list.append(p)<br>    <br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> process_list:<br>        p.join()   <br></code></pre></td></tr></table></figure><h1 id="进程池"><a href="#进程池" class="headerlink" title="进程池"></a>进程池</h1><p>与多线程类似，进程数多于CPU核心数，反而会导致性能降低，因此需要进程池来进行维护多进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ProcessPoolExecutor<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">num</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;执行&#x27;</span>)<br>    time.sleep(<span class="hljs-number">2</span>)<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    pool = ProcessPoolExecutor(<span class="hljs-number">4</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        pool.submit(task, i)<br>    pool.shutdowm(<span class="hljs-literal">True</span>) <span class="hljs-comment"># 等待进程池中的任务都完成后，再继续执行</span><br></code></pre></td></tr></table></figure><p>还可以执行回调函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ProcessPoolExecutor<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">num</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;执行&#x27;</span>)<br>    time.sleep(<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> num<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">done</span>(<span class="hljs-params">res</span>):<br>    <span class="hljs-built_in">print</span>(res.result())<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    pool = ProcessPoolExecutor(<span class="hljs-number">4</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        fur = pool.submit(task, i)<br>        fur.add_done_callback(done) <span class="hljs-comment"># 执行回调函数</span><br>    <br>    <span class="hljs-built_in">print</span>(multiprocessing.current_process())<br>    pool.shutdowm(<span class="hljs-literal">True</span>) <span class="hljs-comment"># 等待进程池中的任务都完成后，再继续执行</span><br></code></pre></td></tr></table></figure><div class="note note-warning">            <p>在进程池之中，无法使用<code>multiprocessing</code>提供的Lock和RLock。只能使用<code>Manager</code>提供的RLock和Lock，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">lock = Manager.RLock()<br></code></pre></td></tr></table></figure>          </div><p>2024&#x2F;2&#x2F;3 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>多进程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python并发编程：多线程实现</title>
    <link href="/2024/01/31/Python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0/"/>
    <url>/2024/01/31/Python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>首先上定义：</p><div class="note note-warning">            <p>进程：可以简单的理解为一个可以独立运行的程序单位，它是线程的集合，进程就是有一个或多个线程构成的。</p><p>线程：进程中的实际运行单位，是操作系统进行运算调度的最小单位。可理解为线程是进程中的一个最小运行单元。</p>          </div><p>当我们运行一个程序时，相当于运行了一个进程，在这个进程中包含了一个或多个线程。当我们需要同时运行多个程序时，就需要用到多进程，而需要更优的运行一个程序时，就需要多线程。</p><blockquote><p>多线程共享同一进程的资源。</p></blockquote><p>我们假设有两段代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time <br>result = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>):<br>result+=<span class="hljs-number">1</span><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> requests<br><br>url_list = [<br>    (<span class="hljs-string">&#x27;视频1&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=ZKwIInkZK90&#x27;</span>),<br>    (<span class="hljs-string">&#x27;视频2&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=Ts2wussx4Js&#x27;</span>),<br>    (<span class="hljs-string">&#x27;视频3&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=zDWO7EMFBkQ&#x27;</span>)<br>]<br><br><span class="hljs-built_in">print</span>(time.time())<br><span class="hljs-keyword">for</span> file_name, url <span class="hljs-keyword">in</span> url_list:<br>    res = requests.get(url)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_name,mode=<span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(res.content)<br>    <span class="hljs-built_in">print</span>(time.time())<br></code></pre></td></tr></table></figure><p>上面两段代码代表着程序中的两个任务：高计算量和高IO读写。前者需要CPU的计算能力，后者不需要这么高的计算能力，而是高磁盘读写需求。</p><h1 id="使用多线程实现下载任务"><a href="#使用多线程实现下载任务" class="headerlink" title="使用多线程实现下载任务"></a>使用多线程实现下载任务</h1><p>可以使用多线程实现上面的下载任务，这样程序可以在更优的分配任务。这里需要使用<code>threading</code>库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> threading<br><br>url_list = [<br>    (<span class="hljs-string">&#x27;视频1&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=ZKwIInkZK90&#x27;</span>),<br>    (<span class="hljs-string">&#x27;视频2&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=Ts2wussx4Js&#x27;</span>),<br>    (<span class="hljs-string">&#x27;视频3&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=zDWO7EMFBkQ&#x27;</span>)<br>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">file_name,url</span>):<br>    res = requests.get(url)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_name,mode=<span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(res.content)<br>    <span class="hljs-built_in">print</span>(time.time())<br><br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(time.time())<br>    <span class="hljs-keyword">for</span> name, url <span class="hljs-keyword">in</span> url_list:<br>        t = threading.Thread(target=task, args=(name,url))<br>        t.start()<br></code></pre></td></tr></table></figure><p>在for遍历的时候，会不断的创建线程。当运行<code>t.start()</code>的时候，将开始启动所有线程。参数需要在<code>Thread</code>方法中传入。</p><h1 id="使用多进程实现下载任务"><a href="#使用多进程实现下载任务" class="headerlink" title="使用多进程实现下载任务"></a>使用多进程实现下载任务</h1><p>同样的可以创建多个进程来实现上面的下载任务，需要用到<code>multiprocessing</code>库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> multiprocessing<br><br>url_list = [<br>    (<span class="hljs-string">&#x27;视频1&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=ZKwIInkZK90&#x27;</span>),<br>    (<span class="hljs-string">&#x27;视频2&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=Ts2wussx4Js&#x27;</span>),<br>    (<span class="hljs-string">&#x27;视频3&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=zDWO7EMFBkQ&#x27;</span>)<br>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">file_name,url</span>):<br>    res = requests.get(url)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_name,mode=<span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(res.content)<br>    <span class="hljs-built_in">print</span>(time.time())<br>    <br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(time.time())<br>    <span class="hljs-keyword">for</span> name, url <span class="hljs-keyword">in</span> url_list:<br>        t = multiprocessing.Process(target=task, args=(name,url))<br>        t.start()<br></code></pre></td></tr></table></figure><p>在使用for进行遍历时，会不断加上进程。多进程的开销会更大，因为每次调用进程都相当于启动了一个新程序。</p><h1 id="使用多进程处理高计算任务"><a href="#使用多进程处理高计算任务" class="headerlink" title="使用多进程处理高计算任务"></a>使用多进程处理高计算任务</h1><p>在面对高计算量的任务时，就可以利用多核优势计算结果，例如前面的累加计算任务：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> multiprocessing<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">start, end, queue</span>):<br>    result = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start, end):<br>        result += <span class="hljs-number">1</span><br>    queue.put(result)<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    queue = multiprocessing.Queue()<br>    <br>    start_time = time.time()<br>    <br>    p1 = multiprocessing.Process(target=task, args=(<span class="hljs-number">0</span>, <span class="hljs-number">50000</span>, queue))<br>    p1.start()<br>    <br>    p2 = multiprocessing.Process(target=task, args=(<span class="hljs-number">50000</span>, <span class="hljs-number">100000</span>, queue))<br>    p2.start()<br>    <br>    v1 = queue.get(block=<span class="hljs-literal">True</span>)<br>    v2 = queue.get(block=<span class="hljs-literal">True</span>)<br>    <span class="hljs-built_in">print</span>(v1+v2)<br>    <br>    end_time = time.time()<br></code></pre></td></tr></table></figure><p>上面相当于利用多进程创建了两个任务，分开计算，最后将两个任务的结果相加得到总和。</p><h1 id="如何选择？"><a href="#如何选择？" class="headerlink" title="如何选择？"></a>如何选择？</h1><p>在只运行一个任务的时候，多线程的开销会更少一些，不过在Python的CPython解释器中有一个全局解释器锁(GIL)，它要求一个进程中，同时只能有一个线程被CPU调用。这就导致多线程的优势在Python中消失了。</p><p>那么如何从这两者之间进行选择？如果程序想要利用计算机的多核优势，则使用多进程开发，让CPU同时处理任务。如果不利于多核优势，那就使用多线程开发。</p><p>多线程适用于：</p><ol><li><strong>I&#x2F;O 密集型任务：</strong> 当程序中的主要瓶颈是等待外部资源读写的时候，使用多线程可以提高效率。一个线程在等待时，其他线程可以继续执行，例如爬虫。</li><li><strong>共享数据：</strong> 如果多个任务需要共享数据，且这些任务不需要同时修改共享数据，那么可以选择多线程。</li></ol><p>多进程适用于：</p><ol><li><strong>CPU 密集型任务：</strong> 当程序中的主要任务是进行大量计算，而不涉及太多的 I&#x2F;O 操作时，选择多进程。</li><li><strong>独立性要求：</strong> 如果任务之间需要高度的独立性，以避免由于一个任务的问题导致整个程序崩溃，选择多进程。</li><li><strong>并行性需求：</strong> 多进程可以在多核处理器上并行执行，从而提高整体性能。</li></ol><h1 id="多线程常用方法"><a href="#多线程常用方法" class="headerlink" title="多线程常用方法"></a>多线程常用方法</h1><h2 id="t-start"><a href="#t-start" class="headerlink" title="t.start()"></a>t.start()</h2><p><code>t.start()</code>用于将线程准备就绪。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br>loop = <span class="hljs-number">1000000</span><br>number = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_add</span>(<span class="hljs-params">count</span>):<br>    <span class="hljs-keyword">global</span> number<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(count):<br>        number += <span class="hljs-number">1</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    t = threading.Thread(target=_add, args=(loop,))<br>    t.start()<br><br>    <span class="hljs-built_in">print</span>(number)<br></code></pre></td></tr></table></figure><p>上面的number不一定为100000，这是因为程序在执行子线程的时候，可能执行t的子线程到一半，就跑去把print(number)执行了，这恰恰体现了多线程的作用，会跳着执行代码。为了解决这个问题，就用到了<code>join</code>方法。</p><h2 id="t-join"><a href="#t-join" class="headerlink" title="t.join()"></a>t.join()</h2><p><code>t.join()</code>用于等待当前子线程结束，主线程再继续往下执行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br>loop = <span class="hljs-number">1000000</span><br>number = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_add</span>(<span class="hljs-params">count</span>):<br>    <span class="hljs-keyword">global</span> number<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(count):<br>        number += <span class="hljs-number">1</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    t = threading.Thread(target=_add, args=(loop))<br>    t.start()<br>    t.join() <br>    <span class="hljs-built_in">print</span>(number)<br></code></pre></td></tr></table></figure><p>当程序运行到<code>t.join</code>时，就会停下来等<code>t</code>这个子线程运行完，然后继续往下走。还有一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br>number = <span class="hljs-number">0</span><br>count = <span class="hljs-number">5</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_add</span>():<br>    <span class="hljs-keyword">global</span> number<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(count):<br>        number += <span class="hljs-number">1</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_sub</span>():<br>    <span class="hljs-keyword">global</span> number<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(count):<br>        number += <span class="hljs-number">1</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:        <br>    t1 = threading.Thread(target=_add)<br>    t2 = threading.Thread(target=_sub)<br>    t1.start()<br>    t1.join() <br><br>    t2.start()<br>    t2.join()<br><br>    <span class="hljs-built_in">print</span>(number)<br>    <span class="hljs-comment"># 10</span><br></code></pre></td></tr></table></figure><p>上面这个例子实际上等同于串行执行。主线程会等待<code>t1</code>子线程运行完后才会运行<code>t2</code>子线程。</p><h2 id="t-setDaemon-布尔值"><a href="#t-setDaemon-布尔值" class="headerlink" title="t.setDaemon(布尔值)"></a>t.setDaemon(布尔值)</h2><p><code>t.setDaemon()</code>用于设置守护线程，判断主线程是否等待子线程运行完。<strong>它必须被设置在线程被start之前。</strong></p><ul><li><code>t.setDaemon(True)</code>: 设置为守护线程，当主线程被执行完毕后，子线程自动关闭。</li><li><code>t.setDaemon(False)</code>: 默认非守护线程，主线程等待子线程运行完毕后才会关闭。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>():<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission&#x27;</span>)<br>    <br>t = threading.Thread(target=task)<br>t.daemon = <span class="hljs-literal">True</span><br>t.start()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;End&#x27;</span>)<br><br>---<br><span class="hljs-comment"># END</span><br><span class="hljs-comment"># mission</span><br></code></pre></td></tr></table></figure><p>当主线程运行到<code>print</code>的时候，就会等待子线程运行结束。当设置为False时，就会直接结束子线程。</p><h2 id="自定义线程类"><a href="#自定义线程类" class="headerlink" title="自定义线程类"></a>自定义线程类</h2><p>通过直接继承<code>threading.Thread</code>类，并重写<code>run</code>方法，可以直接定义多线程类。这在很多项目中都被用到了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyThread</span>(threading.Thread):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, delay</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.name = name<br>        self.delay = delay<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Thread <span class="hljs-subst">&#123;self.name&#125;</span> starting...&quot;</span>)<br>        self.print_numbers()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Thread <span class="hljs-subst">&#123;self.name&#125;</span> exiting...&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">print_numbers</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>            time.sleep(self.delay)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Thread <span class="hljs-subst">&#123;self.name&#125;</span>: <span class="hljs-subst">&#123;i&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 创建两个线程的实例</span><br>thread1 = MyThread(name=<span class="hljs-string">&quot;Thread-1&quot;</span>, delay=<span class="hljs-number">1</span>)<br>thread2 = MyThread(name=<span class="hljs-string">&quot;Thread-2&quot;</span>, delay=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 启动线程</span><br>thread1.start()<br>thread2.start()<br><br><span class="hljs-comment"># 等待线程结束</span><br>thread1.join()<br>thread2.join()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Main thread exiting.&quot;</span>)<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> threading<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VideoThread</span>(threading.Thread):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):<br>        file_name, url = self._args<br>        res = requests.get(url)<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_name,mode=<span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>           f.write(res.content)       <br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:  <br>    url_list = [<br>        (<span class="hljs-string">&#x27;视频1&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=ZKwIInkZK90&#x27;</span>),<br>        (<span class="hljs-string">&#x27;视频2&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=Ts2wussx4Js&#x27;</span>),<br>        (<span class="hljs-string">&#x27;视频3&#x27;</span>,<span class="hljs-string">&#x27;https://www.youtube.com/watch?v=zDWO7EMFBkQ&#x27;</span>)<br>    ]<br>    <br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> url_list:<br>        t = VideoThread(args=(item[<span class="hljs-number">0</span>],item[<span class="hljs-number">1</span>]))<br>        t.start()<br></code></pre></td></tr></table></figure><h1 id="多线程的线程安全"><a href="#多线程的线程安全" class="headerlink" title="多线程的线程安全"></a>多线程的线程安全</h1><p>在多线程环境中，共享数据可能会被某个线程修改，导致其他线程拿到的数据是不准确的，这种情况被称为竞态条件，为此，<code>threading</code>库提供了锁(Lock)来实现数据保护。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br>lock = threading.RLock()<br>loop = <span class="hljs-number">1000000</span><br>number = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_add</span>(<span class="hljs-params">count</span>):<br>    lock.acquire() <span class="hljs-comment"># 第一个进入的线程会上锁</span><br>    <span class="hljs-keyword">global</span> number<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(count):<br>        number += <span class="hljs-number">1</span><br>    lock.release() <span class="hljs-comment"># 释放锁</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_sum</span>(<span class="hljs-params">count</span>):<br>    lock.acquire() <span class="hljs-comment"># 申请锁</span><br>    <span class="hljs-keyword">global</span> number<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(count):<br>        number -= <span class="hljs-number">1</span><br>    lock.release() <span class="hljs-comment"># 释放锁    </span><br>    <br><span class="hljs-comment"># 创建多个线程来修改共享数据</span><br>t1 = threading.Thread(target=_add. args=(loop))<br>t2 = threading.Thread(target=_sub, args=(loop))<br><br>t1.start()<br>t2.start()<br><br>t1.join()<br>t2.join()<br><br><span class="hljs-built_in">print</span>(shared_data)<br></code></pre></td></tr></table></figure><p>在上面这个任务中，进程任务里带了一个锁。当运行一个进程时，数据是被锁住的，其他线程无法访问，需要等待锁被释放。当它被释放后，其他线程才可以继续对其中的数据进行修改。</p><p><code>threading</code>提供了两种锁，<code>Lock</code>和<code>RLock</code>。唯一的区别是<code>RLock</code>中可以继续上<code>RLock</code>锁，但是<code>Lock</code>锁不能这样做。可以重复锁的好处在于协调开发时，当调用其他人的上锁的方法时，可以继续上锁来保证线程安全。</p><p>同样也可以使用上下文来上锁，这样更方便：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br>number = <span class="hljs-number">0</span><br>lock = threading.RLock()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>():<br>    <span class="hljs-keyword">with</span> lock: <span class="hljs-comment"># 基于上下文管理，自动执行申请锁和释放锁</span><br>        <span class="hljs-keyword">global</span> number<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>):<br>            number += i<br>    <span class="hljs-built_in">print</span>(number)<br> <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):<br>    t = threading.Thread(target=task)<br>    t.start()<br></code></pre></td></tr></table></figure><h1 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h1><p>当多线程中出现了线程相互等待对方释放资源时会卡死，这被称为死锁。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> threading<br><br>resource1 = threading.Lock()<br>resource2 = threading.Lock()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">thread1</span>():<br>    <span class="hljs-keyword">with</span> resource1:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Thread 1 acquired resource 1&quot;</span>)<br>        <span class="hljs-keyword">with</span> resource2:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Thread 1 acquired resource 2&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">thread2</span>():<br>    <span class="hljs-keyword">with</span> resource2:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Thread 2 acquired resource 2&quot;</span>)<br>        <span class="hljs-keyword">with</span> resource1:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Thread 2 acquired resource 1&quot;</span>)<br><br>t1 = threading.Thread(target=thread1)<br>t2 = threading.Thread(target=thread2)<br><br>t1.start()<br>t2.start()<br><br>t1.join()<br>t2.join()<br></code></pre></td></tr></table></figure><p>这两个线程分别尝试获取<code>resource1</code>和<code>resource2</code>，但由于它们的获取顺序不同，可能导致死锁。如果<code>thread1</code>先获取<code>resource1</code>，而<code>thread2</code>先获取<code>resource2</code>，那么两个线程将陷入相互等待的状态，导致死锁。</p><h1 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h1><h2 id="线程池示例"><a href="#线程池示例" class="headerlink" title="线程池示例"></a>线程池示例</h2><p>线程并非越多越好，因此需要有线程池加以控制。Python在<code>concurrent</code>库中提供了<code>ThreadPoolExecutor</code>来实现线程池。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> concurrent.future <span class="hljs-keyword">import</span> ThreadPoolExecutor<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">url</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission start.&#x27;</span>)<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <br>pool = ThreadPoolExecutor(<span class="hljs-number">10</span>) <span class="hljs-comment"># 最多维护10个线程</span><br><br>url_list = [<span class="hljs-string">&#x27;www.xxx_&#123;&#125;.com&#x27;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)]<br><span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> url_list:<br>    pool.submit(task, url)<br></code></pre></td></tr></table></figure><p>在上面这段代码中，向线程池<code>pool</code>不断提交<code>submit</code>任务。如果线程池为空，则将任务加入，否则进行等待。</p><h2 id="主线程等待线程池"><a href="#主线程等待线程池" class="headerlink" title="主线程等待线程池"></a>主线程等待线程池</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ThreadPoolExecutor<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">url</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission start.&#x27;</span>)<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <br>pool = ThreadPoolExecutor(<span class="hljs-number">10</span>) <span class="hljs-comment"># 最多维护10个线程</span><br><br>url_list = [<span class="hljs-string">&#x27;www.xxx_&#123;&#125;.com&#x27;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)]<br><span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> url_list:<br>    pool.submit(task, url)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Working...&#x27;</span>)<br>pool.shutdown(<span class="hljs-literal">True</span>) <span class="hljs-comment"># 等待线程池中的任务执行完成，再继续执行</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Keep going&#x27;</span>)<br></code></pre></td></tr></table></figure><p>上面这段代码加入了<code>pool.shutdown()</code>这个方法，用于让主线程等待线程池执行，类似于线程的<code>join()</code>方法。</p><h2 id="执行Pipeline"><a href="#执行Pipeline" class="headerlink" title="执行Pipeline"></a>执行Pipeline</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ThreadPoolExecutor, Future<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">url</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission start.&#x27;</span>)<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <span class="hljs-keyword">return</span> random.ranint(<span class="hljs-number">0</span>,<span class="hljs-number">10</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">done</span>(<span class="hljs-params">response</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;response number&#x27;</span>, response.result())<br>    <br>pool = ThreadPoolExecutor(<span class="hljs-number">10</span>) <span class="hljs-comment"># 最多维护10个线程</span><br><br>url_list = [<span class="hljs-string">&#x27;www.xxx_&#123;&#125;.com&#x27;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)]<br><span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> url_list:<br>    future = pool.submit(task, url) <span class="hljs-comment"># 提交任务</span><br>    future.add_done_callback(done) <span class="hljs-comment"># 子线程继续执行</span><br></code></pre></td></tr></table></figure><p>上面这段函数对线程池进行了实例化，并使用了<code>add_done_callback</code>方法，将线程的结果放入下一个函数进行执行。这相当于构建了一个pipeline。例如，task可以执行下载任务，done函数执行写入任务。</p><h2 id="显示线程结果"><a href="#显示线程结果" class="headerlink" title="显示线程结果"></a>显示线程结果</h2><p>如果要获取线程的结果，只需要使用线程的<code>result</code>这个方法即可提取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ThreadPoolExecutor, Future<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">task</span>(<span class="hljs-params">url</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mission start.&#x27;</span>)<br>    time.sleep(<span class="hljs-number">5</span>)<br>    <span class="hljs-keyword">return</span> random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">10</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">done</span>(<span class="hljs-params">response</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;response number&#x27;</span>, response.result())<br><br>pool = ThreadPoolExecutor(<span class="hljs-number">10</span>) <span class="hljs-comment"># 最多维护10个线程</span><br><br>future_list = []<br><br>url_list = [<span class="hljs-string">&#x27;www.xxx_&#123;&#125;.com&#x27;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)]<br><span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> url_list:<br>    future = pool.submit(task, url) <span class="hljs-comment"># 提交任务</span><br>    future_list.append(future)<br>    <br>pool.shutdown(<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">for</span> fu <span class="hljs-keyword">in</span> future_list:<br>    <span class="hljs-built_in">print</span>(fu.result())<br></code></pre></td></tr></table></figure><p>2024&#x2F;2&#x2F;1 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>多线程</tag>
      
      <tag>多进程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Dockfile编写指南</title>
    <link href="/2024/01/27/Dockfile%E7%BC%96%E5%86%99%E6%8C%87%E5%8D%97/"/>
    <url>/2024/01/27/Dockfile%E7%BC%96%E5%86%99%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p>Docker篇的第五篇，学习一下怎么编写Dockerfile。</p><h1 id="不要过多的叠加层数"><a href="#不要过多的叠加层数" class="headerlink" title="不要过多的叠加层数"></a>不要过多的叠加层数</h1><p>Docker 镜像是分层的，Dockerfile 中的每个指令都会创建一个新的镜像层。每一层都是前一层变化的增量。</p><p>以下是一个Dockerfile的例子：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">FROM ubuntu<br><br>ADD . /app<br><br>RUN apt-get update<br>RUN apt-get upgrade -y<br>RUN apt-get install -y nodejs ssh mysql<br>RUN <span class="hljs-built_in">cd</span> /app &amp;&amp; npm install<br><br>CMD mysql &amp; sshd &amp; npm start<br></code></pre></td></tr></table></figure><p>在上面这个Dockerfile里，每执行一次<code>RUN</code>，就会在镜像中多增加一层，最高层是127层。如果添加过多的层数会导致镜像过大。因此应当尽可能的将<code>RUN</code>指令写成一行，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">FROM ubuntu<br><br>ADD . /app<br><br>RUN apt-get update \<br>    &amp;&amp; apt-get install -y nodejs \<br>    &amp;&amp; <span class="hljs-built_in">cd</span> /app \<br>    &amp;&amp; npm install<br><br>CMD npm start<br></code></pre></td></tr></table></figure><h1 id="使用-dockerignore忽略文件"><a href="#使用-dockerignore忽略文件" class="headerlink" title="使用.dockerignore忽略文件"></a>使用.dockerignore忽略文件</h1><p>和.gitignore一样，有时候在打包时，不需要将一些文件拷贝进镜像以防止镜像过大，例如一些Readme，或者.git文件，这时候就需要用到.dockerignore。语法是类似的，例如要忽略后缀是“swp”“sh”的文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># docker ignore</span><br>*.swp<br>*.sh<br></code></pre></td></tr></table></figure><p>例如不需要.git目录，或者某个文件夹，则如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">.git/<br>node_modules/<br></code></pre></td></tr></table></figure><h1 id="Dockerfile命令"><a href="#Dockerfile命令" class="headerlink" title="Dockerfile命令"></a>Dockerfile命令</h1><p>下面是Dockerfile的一些常用命令</p><table><thead><tr><th>FROM</th><th>基于哪个镜像来实现</th></tr></thead><tbody><tr><td>LABEL</td><td>给构建的镜像打标签</td></tr><tr><td>ENV</td><td>声明环境变量</td></tr><tr><td>ARG</td><td>指定了用户在 <code>docker build --build-arg</code> 时可以使用的参数</td></tr><tr><td>RUN</td><td>执行的命令</td></tr><tr><td>CMD</td><td>run后面跟启动命令会被覆盖掉</td></tr><tr><td>ENTRYPOINT</td><td>与CMD功能相同，但需docker run 不会覆盖，如果需要覆盖可增加参数-entrypoint来覆盖</td></tr><tr><td>ADD</td><td>添加宿主机文件到容器里，有需要解压的文件会自动解压</td></tr><tr><td>COPY</td><td>添加宿主机文件到容器里</td></tr><tr><td>WORKDIR</td><td>工作目录</td></tr><tr><td>EXPOSE</td><td>容器内应用可使用的端口容器启动后所执行的程序，如果执行docker</td></tr><tr><td>VOLUME</td><td>将宿主机的目录挂载到容器里</td></tr><tr><td>USER</td><td>为接下来的Dockerfile指令指定用户</td></tr></tbody></table><h1 id="ARG指令"><a href="#ARG指令" class="headerlink" title="ARG指令"></a>ARG指令</h1><p><code>ARG</code> 指令用于定义构建参数，用来在构建过程中被使用，但在运行时不会保留在最终的镜像中。这对于在构建过程中传递一些动态值是非常有用的。</p><p>以下是一个例子：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用 ARG 指令定义构建参数</span><br><span class="hljs-keyword">ARG</span> BASE_IMAGE=alpine:latest<br><br><span class="hljs-comment"># 使用构建参数作为基础镜像</span><br><span class="hljs-keyword">FROM</span> $BASE_IMAGE<br><br><span class="hljs-comment"># 在容器中创建一个文件，内容为构建参数值</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;The base image is: <span class="hljs-variable">$BASE_IMAGE</span>&quot;</span> &gt; /output.txt</span><br></code></pre></td></tr></table></figure><p>上面的Dockerfile中，我们设定了默认的<code>BASE_IMAGE</code>为<code>alpine:latest</code>，因此当我们执行<code>docker build -t my-image .</code>时，会使用默认的<code>alphine:latest</code>构建镜像。如果要从外部传入自定义的参数，可以执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t my-image --build-arg BASE_IMAGE=ubuntu:latest .<br></code></pre></td></tr></table></figure><p>可以看到，<code>--build-arg</code>这个指令将会解析传入的参数。</p><h1 id="ENV指令"><a href="#ENV指令" class="headerlink" title="ENV指令"></a>ENV指令</h1><p><code>ENV</code> 指令用于设置环境变量。这些环境变量可以在构建过程中以及运行容器时使用。</p><p>以下是一个例子：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用基础镜像</span><br><span class="hljs-keyword">FROM</span> ubuntu:<span class="hljs-number">20.04</span><br><br><span class="hljs-comment"># 设置环境变量</span><br><span class="hljs-keyword">ENV</span> MY_VAR=<span class="hljs-string">&quot;Hello Docker&quot;</span> \<br>    ANOTHER_VAR=<span class="hljs-number">42</span><br><br><span class="hljs-comment"># 执行一些操作</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;My variable is: <span class="hljs-variable">$MY_VAR</span>&quot;</span></span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Another variable is: <span class="hljs-variable">$ANOTHER_VAR</span>&quot;</span></span><br><br><span class="hljs-comment"># 在容器启动时执行的命令</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;echo&quot;</span>, <span class="hljs-string">&quot;Container is running!&quot;</span>]</span><br></code></pre></td></tr></table></figure><p>其中，<code>ENV</code> 指令用于设置两个环境变量，<code>MY_VAR</code> 和 <code>ANOTHER_VAR</code>。当运行时，需要执行<code>-e</code>来输入环境变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -e MY_VAR=<span class="hljs-string">&quot;Custom Value&quot;</span> -e ANOTHER_VAR=99 my-image<br></code></pre></td></tr></table></figure><div class="note note-warning">            <p><code>ARG</code>和<code>ENV</code>的区别主要在，<code>ARG</code> 用于在构建过程中传递参数，而这些参数仅在构建时有效。而<code>ENV</code> 用于设置环境变量，可以在容器启动时访问。</p><p>也就是说，在<code>RUN</code>时，Docker只会使用<code>ARG</code>的默认值，而不是传入的值。但是会使用<code>ENV</code>传入的值。</p><p>因此，<code>ARG</code>常被用在设置软件版本、构建路径。而<code>ENV</code>被用在配置应用程序、传递参数（例如数据库密码，用户名等）。</p>          </div><h1 id="RUN和CMD的区别是什么"><a href="#RUN和CMD的区别是什么" class="headerlink" title="RUN和CMD的区别是什么"></a>RUN和CMD的区别是什么</h1><p><code>RUN</code>指令在Dockerfile的作用主要是执行一些构建Docker时必要的动作，例如下载，安装等等，例如：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 安装</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y \</span><br><span class="language-bash">    package1 \</span><br><span class="language-bash">    package2 \</span><br><span class="language-bash">    &amp;&amp; <span class="hljs-built_in">rm</span> -rf /var/lib/apt/lists/*</span><br><br><span class="hljs-comment"># 下载软件</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> curl -O https://example.com/file.tar.gz \</span><br><span class="language-bash">    &amp;&amp; tar -xzvf file.tar.gz \</span><br><span class="language-bash">    &amp;&amp; <span class="hljs-built_in">rm</span> file.tar.gz</span><br><br><span class="hljs-comment"># 执行编译</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> make</span><br><br><span class="hljs-comment"># 结合ARG执行</span><br><span class="hljs-keyword">ARG</span> VERSION=latest<br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Version is <span class="hljs-variable">$VERSION</span>&quot;</span></span><br></code></pre></td></tr></table></figure><p>而<code>CMD</code>则用于最后容器启动时要进行的操作，例如：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;./start.sh&quot;</span>]</span><br></code></pre></td></tr></table></figure><h1 id="VOLUME指令"><a href="#VOLUME指令" class="headerlink" title="VOLUME指令"></a>VOLUME指令</h1><p><code>VOLUME</code> 指令用于在容器中创建挂载，并指定容器中的目录应该被挂载到主机的哪个位置。也就是说，将容器内的数据关联到外部的文件，例如，修改配置文件时就不需要进入容器进行修改，以下是一个例子：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> ubuntu:<span class="hljs-number">20.04</span><br><br><span class="hljs-comment"># 创建挂载点</span><br><span class="hljs-keyword">VOLUME</span><span class="language-bash"> [<span class="hljs-string">&quot;/app/data&quot;</span>]</span><br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><br><span class="hljs-comment"># 复制应用程序代码到容器中</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> . /app</span><br></code></pre></td></tr></table></figure><p>上述操作中的<code>VOLUME [&quot;/app/data&quot;]</code>实际上是在容器内部的 <code>/app/data</code> 目录创建一个卷（Volume）。当在命令行执行以下代码时：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -v /host/path:/app/data my-image<br></code></pre></td></tr></table></figure><p>就会把容器中的 <code>/app/data</code> 映射到主机上的 <code>/host/path</code>。这意味着容器中写入 <code>/app/data</code> 的数据将实际上存储在主机的 <code>/host/path</code> 目录中。</p><h2 id="在容器内读取宿主机的配置文件"><a href="#在容器内读取宿主机的配置文件" class="headerlink" title="在容器内读取宿主机的配置文件"></a>在容器内读取宿主机的配置文件</h2><p>我们可以通过运行以下指令来挂载卷：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -v /host/config:/container/config my-image<br></code></pre></td></tr></table></figure><p>上述指令会将宿主机的&#x2F;host&#x2F;config与容器的&#x2F;config进行映射。假设宿主机的路径下的配置文件是 <code>my-config.conf</code>，在容器内读取该配置文件的路径是 <code>/container/config/my-config.conf</code>。容器内的应用程序应该使用这个路径来访问配置文件。</p><p>2024&#x2F;1&#x2F;27 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker实践挖坑细节</title>
    <link href="/2024/01/27/Docker%E5%AE%9E%E8%B7%B5%E6%8C%96%E5%9D%91%E7%BB%86%E8%8A%82/"/>
    <url>/2024/01/27/Docker%E5%AE%9E%E8%B7%B5%E6%8C%96%E5%9D%91%E7%BB%86%E8%8A%82/</url>
    
    <content type="html"><![CDATA[<p>前面写了一些Docker的基础使用的东西，不过真正要学会还是得实际上手，这篇博客就记录一下我实际使用Docker时遇到的一些问题。</p><p>这里是之前几篇Docker相关的博文地址：</p><ul><li><p><a href="https://zerolovesea.github.io/2024/01/19/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E4%BD%BF%E7%94%A8Docker%E6%89%93%E5%8C%85%E8%87%AA%E5%B7%B1%E7%9A%84%E9%A1%B9%E7%9B%AE/">工程实践：使用Docker打包自己的项目 - 我不是算法工程师</a></p></li><li><p><a href="https://zerolovesea.github.io/2024/01/23/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9ADocker%E5%85%A5%E9%97%A8%E6%8A%80%E5%B7%A7/">工程实践：Docker入门技巧 - 我不是算法工程师 </a></p></li><li><p><a href="https://zerolovesea.github.io/2024/01/25/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%AE%9E%E6%93%8D%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84Docker%E6%93%8D%E4%BD%9C/">工程实践：实操项目中的Docker操作 - 我不是算法工程师 </a></p></li></ul><hr><h1 id="Windows终端查看Docker出现报错"><a href="#Windows终端查看Docker出现报错" class="headerlink" title="Windows终端查看Docker出现报错"></a>Windows终端查看Docker出现报错</h1><p>我在windows直接使用<code>docker ps -a</code>会出现报错<code>error during connect</code>。以下是完整报错内容；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">error during connect: this error may indicate that the docker daemon is not running: Get <span class="hljs-string">&quot;http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/containers/json?all=1&quot;</span>: open //./pipe/docker_engine: The system cannot find the file specified.<br></code></pre></td></tr></table></figure><p>实际遇到时，启动Docker的应用就可以解决，这是因为没有开启守护进程。在Linux上可以用以下方式设置开机自动启动Docker：<code>sudo systemctl enable docker</code>。</p><h1 id="报错：repository-name-must-be-lowercase"><a href="#报错：repository-name-must-be-lowercase" class="headerlink" title="报错：repository name must be lowercase"></a>报错：repository name must be lowercase</h1><p>这个报错源自于Dockerfile的编写，执行<code> docker build -t qa_system:v0.1 .</code>时出现报错，完整报错如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">Dockerfile:1<br>--------------------<br>   1 | &gt;&gt;&gt; FROM Python:3.10<br>   2 |<br>   3 |     WORKDIR /app<br>--------------------<br>ERROR: failed to solve: failed to parse stage name <span class="hljs-string">&quot;Python:3.10&quot;</span>: invalid reference format: repository name must be lowercase<br></code></pre></td></tr></table></figure><p>原来是需要都是小写，把<code>Python</code>改成<code>python</code>即可。</p><h1 id="下载Python依赖库时的路径选择"><a href="#下载Python依赖库时的路径选择" class="headerlink" title="下载Python依赖库时的路径选择"></a>下载Python依赖库时的路径选择</h1><p>当我在执行<code>pip download -r .\requirements.txt --dest \downloaded_packages</code>时，并没有在根目录下找到文件夹。这是因为需要在路径前面加一个<code>.</code>来指定当前目录。解决方法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 相对路径</span><br>pip download -r .\requirements.txt --dest <span class="hljs-string">&#x27;.\downloaded_packages&#x27;</span><br><br><span class="hljs-comment"># 绝对路径</span><br>pip download -r .\requirements.txt --dest C:\path\to\downloaded_packages<br></code></pre></td></tr></table></figure><h1 id="命令行参数顺序出错导致无法启动Docker"><a href="#命令行参数顺序出错导致无法启动Docker" class="headerlink" title="命令行参数顺序出错导致无法启动Docker"></a>命令行参数顺序出错导致无法启动Docker</h1><p>当<code>build</code>完容器后，就是<code>run</code>这个容器，我一开始输的命令是<code> docker run qa_system:v0.1 -p 8501:8501</code>，出现了报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker: Error response from daemon: failed to create task <span class="hljs-keyword">for</span> container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: <span class="hljs-built_in">exec</span>: <span class="hljs-string">&quot;-p&quot;</span>: executable file not found <span class="hljs-keyword">in</span> <span class="hljs-variable">$PATH</span>: unknown.<br></code></pre></td></tr></table></figure><p>这是因为命令行应该把容器放在最后写，端口等参数应在前面。正确的应该是<code>docker run -p 8501:8501 qa_system:v0.1</code>。</p><p><img src="/images/083343.png"></p><p>完美！现在可以在本地的<code>8501</code>访问容器的<code>8501</code>了！</p><h1 id="stop容器报错"><a href="#stop容器报错" class="headerlink" title="stop容器报错"></a>stop容器报错</h1><p>当我使用<code>Ctrl C</code>停止了容器的服务后，我想在命令行停止容器，于是我执行了<code>docker stop qa_system:v0.1</code>，出现报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">Error response from daemon: No such container: qa_system:v0.1<br></code></pre></td></tr></table></figure><p>这是因为需要指定容器的id。修改后即可正确stop。</p><h1 id="保存镜像为tar文件并发送给其他人"><a href="#保存镜像为tar文件并发送给其他人" class="headerlink" title="保存镜像为tar文件并发送给其他人"></a>保存镜像为tar文件并发送给其他人</h1><p>这个是我单纯记不住指令，所以在这写一下。前面我们在本地已经有了镜像，现在我需要把它打包发给别人，需要执行以下指令<code>docker save -o qa_system.tar qa_system:v0.1</code>。<code>-o</code>是声明保存后的文件名，后面则附上镜像的版本号。</p><p>保存完后将tar文件发送给目标用户，对方只需要执行<code>docker load -i qa_system.tar</code>即可在对方环境加载镜像。</p><h1 id="删除本地的镜像"><a href="#删除本地的镜像" class="headerlink" title="删除本地的镜像"></a>删除本地的镜像</h1><p>看了一眼镜像有1.9G，所以打算删一下。执行<code>docker remove qa_system</code>会报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">Error response from daemon: No such container: qa_system<br></code></pre></td></tr></table></figure><p>这是因为这个指令只是用来删除容器。删除镜像需要使用<code>rmi</code>。完整指令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker rmi qa_system:v0.1<br></code></pre></td></tr></table></figure><p>这样就可以顺利删除了。</p><p>2024&#x2F;1&#x2F;27 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>工程实践：实操项目中的Docker操作</title>
    <link href="/2024/01/25/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%AE%9E%E6%93%8D%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84Docker%E6%93%8D%E4%BD%9C/"/>
    <url>/2024/01/25/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%AE%9E%E6%93%8D%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84Docker%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<p>工作的时候，接触到的就不是<a href="https://zerolovesea.github.io/2024/01/23/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9ADocker%E5%85%A5%E9%97%A8%E6%8A%80%E5%B7%A7/">上一篇</a>中提到的Docker用法了，而是更复杂的镜像文件，这一篇博客就讲一下一些工程上的Docker用例。</p><h1 id="打包项目镜像"><a href="#打包项目镜像" class="headerlink" title="打包项目镜像"></a>打包项目镜像</h1><p>前面其实已经提过了如何打包项目镜像，不过这里再细讲一遍：</p><p>我们的项目结构大致如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">project/<br>|-- frontend/<br>|   |-- Dockerfile<br>|   |-- ... (其他前端项目文件)<br>|-- docker/<br>|   |-- Dockerfile<br>|   |-- ... (其他与Docker构建相关的文件)<br>|-- ... (其他项目文件)<br><br></code></pre></td></tr></table></figure><p>这里，我们希望把前后端文件夹打包成镜像，以迁移到新的环境。那么我们需要再项目根目录执行以下指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ../frontend<br>docker build -t project-frontend -f Dockerfile . --no-cache<br><br><span class="hljs-built_in">cd</span> ../docker<br>docker build -t project-detector:v0.1 -f Dockerfile ../ --no-cache<br></code></pre></td></tr></table></figure><p>解读一下上面做了什么：</p><ul><li>首先，将前端打包成镜像，使用<code>-t</code>命名tag为<code>project-frontend</code>，然后使用<code>-f</code>指定使用的是当前目录[frontend]的Dockerfile。</li><li>然后进入docker文件夹，并使用该目录[docker]的Dockerfile构建镜像。</li></ul><h1 id="编写Dockerfile"><a href="#编写Dockerfile" class="headerlink" title="编写Dockerfile"></a>编写Dockerfile</h1><blockquote><p>什么是Dockerfile？</p><p>Dockerfile是构建镜像的蓝图。 <code>docker pull</code> 用于获取已有的基础镜像，<code>docker run</code> 用于基于镜像运行容器。</p></blockquote><p>我们简单看下Dockerfile怎么写，首先是前端的Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用官方的 Node.js 镜像作为基础镜像</span><br><span class="hljs-keyword">FROM</span> node:lts-alpine as builder<br><br><span class="hljs-comment"># 设置环境变量，并设置为工作目录</span><br><span class="hljs-keyword">ENV</span> PROJECT_DIR=/project-admin<br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> <span class="hljs-variable">$PROJECT_DIR</span></span><br><br><span class="hljs-comment"># 安装pnpm</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> npm install -g pnpm</span><br><br><span class="hljs-comment"># 构建项目</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./ <span class="hljs-variable">$PROJECT_DIR</span></span><br><br><span class="hljs-comment"># 删除.env并执行pnpm build</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">rm</span> -rf .<span class="hljs-built_in">env</span>.* &amp;&amp; pnpm build</span><br></code></pre></td></tr></table></figure><p>然后是docker目录的Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用官方 Python 3 镜像作为基础镜像</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.11</span>-bookworm<br><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./docker/debian-sources.list /etc/apt/sources.list</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">rm</span> -rf /etc/apt/sources.list.d/debian.sources \</span><br><span class="language-bash">    &amp;&amp; apt-get update \</span><br><span class="language-bash">    &amp;&amp; apt-get install -y vim \</span><br><span class="language-bash">    &amp;&amp; apt-get install -y libgl1-mesa-glx \</span><br><span class="language-bash"></span><br><span class="hljs-keyword">COPY</span><span class="language-bash">  --from=project-frontend:latest /project-admin/dist/ /var/www/html</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./docker/nginx.default.conf /etc/nginx/sites-available/default</span><br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><span class="hljs-comment"># 复制当前目录下的所有文件到容器的 /app 目录</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./backend /app/</span><br><br><span class="hljs-comment"># 安装项目依赖</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install -r requirements.txt</span><br><br><span class="hljs-comment"># 暴露端口号</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">80</span><br><span class="hljs-comment"># 暴露python服务的端口号</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">7091</span><br><br><span class="hljs-comment"># 执行命令行</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;bash&quot;</span>, <span class="hljs-string">&quot;start.sh&quot;</span>, <span class="hljs-string">&quot;prod&quot;</span>]</span><br></code></pre></td></tr></table></figure><h1 id="将Docker镜像进行保存迁移"><a href="#将Docker镜像进行保存迁移" class="headerlink" title="将Docker镜像进行保存迁移"></a>将Docker镜像进行保存迁移</h1><p>在客户无网环境的时候，无法直接使用Dockerfile来下载镜像，这时候就需要将镜像进行打包，指令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker save -o project-v0.1.tar project:v0.1<br><br>zip -r project-v0.1.tar.zip project-v0.1.tar<br></code></pre></td></tr></table></figure><p>上面的指令进行了两个操作：</p><ul><li><code>docker save</code>: 将 Docker 镜像保存为一个 tar 归档文件。</li><li><code>-o </code>: 指定输出文件的名称。</li></ul><p>在打包完毕之后，就可以将zip压缩包移动至生产环境进行解压。</p><p>在生产环境解压后加载tar文件，这将在目标环境中还原，指令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker load -i project-v0.1.tar<br></code></pre></td></tr></table></figure><h1 id="使用Docker-Compose启动Docker"><a href="#使用Docker-Compose启动Docker" class="headerlink" title="使用Docker Compose启动Docker"></a>使用Docker Compose启动Docker</h1><p>加载完成后，就需要启动Docker，这里的代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker compose -f docker-compose.service.prod.yaml up -d<br></code></pre></td></tr></table></figure><p>这里用到了<code>docker compose</code>指令，该指令能够读取yaml配置文件来批量加载镜像文件，我们可以看一下这个配置文件是怎么写的：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">&#x27;3&#x27;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">project:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">project</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/logs:/app/logs</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/captures:/app/captures</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/targets:/app/targets</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">/app/html:/app/html</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./envs/prod/env.prod.ini:/app/env.prod.ini</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./envs/prod/config:/app/config</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;7901:80&quot;</span><br>      <br>  <span class="hljs-attr">db:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">postgres:15-alpine</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-comment"># The password for the default postgres user.</span><br>      <span class="hljs-attr">POSTGRES_PASSWORD:</span> <span class="hljs-string">Fzd_1qaz2wsx</span><br>      <span class="hljs-comment"># The name of the default postgres database.</span><br>      <span class="hljs-attr">POSTGRES_DB:</span> <span class="hljs-string">postgres</span><br>      <span class="hljs-comment"># postgres data directory</span><br>      <span class="hljs-attr">PGDATA:</span> <span class="hljs-string">/var/lib/postgresql/data/pgdata</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./volumes/db/data:/var/lib/postgresql/data</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;52345:5432&quot;</span><br><br>  <span class="hljs-comment"># The redis cache.</span><br>  <span class="hljs-attr">redis:</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">redis:6-alpine</span><br>    <span class="hljs-attr">restart:</span> <span class="hljs-string">always</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-comment"># Mount the redis data directory to the container.</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./volumes/redis/data:/data</span><br>    <span class="hljs-comment"># Set the redis password when startup redis server.</span><br>    <span class="hljs-attr">command:</span> <span class="hljs-string">redis-server</span> <span class="hljs-string">--requirepass</span> <span class="hljs-string">Fzd_1qaz2wsx</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;56379:6379&quot;</span><br></code></pre></td></tr></table></figure><p>这里实际上是声明了不同镜像的版本和卷管理，具体解释如下：</p><ul><li><code>version: &#39;3&#39;</code>: 指定 Docker Compose 文件的版本，改变它会改变Compose文件的语法。目前3是最流行的版本。</li><li><code>services</code>: 定义了一个或多个服务。在这里，只定义了一个服务名为 “project”。</li><li><code>project</code>: 这是服务的名称。<ul><li><code>image: project:v0.1</code>: 指定了 Docker 镜像的名称。</li><li><code>restart: always</code>: 设置容器在退出时总是重新启动。</li><li><code>volumes</code>: 定义了容器和主机之间的数据卷映射。这些映射用于将容器内的路径映射到主机上的相应路径。<ul><li><code>/app/logs:/app/logs</code>: 将容器内的 “&#x2F;app&#x2F;logs” 路径映射到主机上的 “&#x2F;app&#x2F;logs”，实现数据的持久化。</li><li>其他类似的 <code>volumes</code> 条目也是为了将容器内的路径映射到主机上，以实现数据的持久化。</li></ul></li><li><code>ports</code>: 定义了容器和主机之间的端口映射。<ul><li><code>&quot;7901:80&quot;</code>: 将容器的 80 端口映射到主机的 7901 端口。这意味着，通过访问主机的 7901 端口，可以访问容器内运行的服务的 80 端口。</li></ul></li></ul></li></ul><p>2024&#x2F;1&#x2F;25 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>工程实践：Docker入门技巧</title>
    <link href="/2024/01/23/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9ADocker%E5%85%A5%E9%97%A8%E6%8A%80%E5%B7%A7/"/>
    <url>/2024/01/23/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9ADocker%E5%85%A5%E9%97%A8%E6%8A%80%E5%B7%A7/</url>
    
    <content type="html"><![CDATA[<p><a href="https://zerolovesea.github.io/2024/01/19/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E4%BD%BF%E7%94%A8Docker%E6%89%93%E5%8C%85%E8%87%AA%E5%B7%B1%E7%9A%84%E9%A1%B9%E7%9B%AE/">前面</a>介绍了如何用Docker打包自己的项目，这次要讲一下Docker的一些基本操作。</p><h1 id="查看Docker版本"><a href="#查看Docker版本" class="headerlink" title="查看Docker版本"></a>查看Docker版本</h1><p>首先是如何查看Docker的版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker --version<br></code></pre></td></tr></table></figure><h1 id="获取镜像"><a href="#获取镜像" class="headerlink" title="获取镜像"></a>获取镜像</h1><p>Docker的基础用法之一就是从官方库拉取镜像来创建容器，只要执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull image_name:tag<br></code></pre></td></tr></table></figure><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull ubuntu:latest<br><br>docker pull python:3.8<br></code></pre></td></tr></table></figure><h1 id="运行容器"><a href="#运行容器" class="headerlink" title="运行容器"></a>运行容器</h1><p>要运行容器，则需要执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run options image_name:tag<br></code></pre></td></tr></table></figure><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it ubuntu:latest /bin/bash<br></code></pre></td></tr></table></figure><h2 id="Docker-run命令"><a href="#Docker-run命令" class="headerlink" title="Docker run命令"></a>Docker run命令</h2><p>Docker的run命令包含多个命令：</p><ul><li><code>--name</code>为容器命名，<code>-d</code>在后台运行：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --name mynginx -d nginx:latest<br></code></pre></td></tr></table></figure><ul><li><code>-P</code>指定随机端口映射，容器内部端口<strong>随机</strong>映射到主机的端口，<code>-p</code>指定端口映射，语法是 <code>-p &lt;host-port&gt;:&lt;container-port&gt;</code>：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 将容器内部的端口80随机映射到主机的任意端口</span><br>docker run -P -d nginx:latest<br><br><span class="hljs-comment"># 将在容器内部的端口 80 映射到主机上的端口 8080</span><br><span class="hljs-comment"># 当你通过浏览器访问 http://localhost:8080 时，实际上是访问了容器内运行的 Nginx 服务</span><br>docker run -p 8080:80 nginx <br></code></pre></td></tr></table></figure><p>也可以同时映射多个端口：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -p 8080:80 -p 5000:5000 my_custom_image<br></code></pre></td></tr></table></figure><ul><li><code>-v</code>挂载目录，挂载卷允许你将主机上的文件或目录与容器内的文件或目录进行关联，从而实现数据的持久化和共享。语法是 <code>-v &lt;host-path&gt;:&lt;container-path&gt;</code>。假设有一个名为 <code>my_app</code> 的容器，它需要访问主机上的 <code>/data</code> 目录中的数据文件，则需要输入以下指令：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -v /host/path:/container/path my_app<br></code></pre></td></tr></table></figure><p>上述指令中，<code>/host/path</code> 是主机上的路径，例如 <code>/data</code>。<code>/container/path</code> 是容器内的路径，例如容器中的应用程序期望的路径。</p><ul><li><code>-rm</code>删除容器后自动删除卷，这个指令会运行容器，并在停止后自动删除：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --<span class="hljs-built_in">rm</span> my_custom_image<br></code></pre></td></tr></table></figure><ul><li><code>-i</code>，<code>-t</code>交互式选项。有的时候需要在容器内有一些交互操作，就需要使用这两个选项：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -i -t ubuntu:latest /bin/bash<br></code></pre></td></tr></table></figure><p>上述例子中，启动了一个交互式的 Ubuntu 容器，并将其连接到 Bash 终端。这允许直接在容器内执行命令，输入数据等。如果省略了 <code>-i</code> 和 <code>-t</code>，那么容器可能会在后台运行，并且无法直接与其进行交互。因此，如果只是希望在后台运行一个服务，而不需要直接与容器进行交互，那么可以省略这两个选项。</p><h1 id="启动已停止的容器"><a href="#启动已停止的容器" class="headerlink" title="启动已停止的容器"></a>启动已停止的容器</h1><p>要启动已经停止的容器，首先要查看容器的ID，随后使用<code>start</code>指令来启动，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker ps -a <span class="hljs-comment"># 查看所有的docker</span><br><br>docker start &lt;docker <span class="hljs-built_in">id</span>&gt; <span class="hljs-comment"># 启动docker</span><br></code></pre></td></tr></table></figure><h1 id="停止和重启Docker"><a href="#停止和重启Docker" class="headerlink" title="停止和重启Docker"></a>停止和重启Docker</h1><p>要停止docker，需要使用<code>stop</code>指令。重启docker，则使用<code>restart</code>指令。如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker stop &lt;docker <span class="hljs-built_in">id</span>&gt;<br><br>docker restart &lt;docker <span class="hljs-built_in">id</span>&gt;<br></code></pre></td></tr></table></figure><h1 id="进入后台的Docker"><a href="#进入后台的Docker" class="headerlink" title="进入后台的Docker"></a>进入后台的Docker</h1><p>使用<code>run -d</code>会让docker在后台运行，此时只要使用<code>exec</code>+<code>/bin/bash</code>就可以进入后台docker：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -i -t &lt;docker <span class="hljs-built_in">id</span>&gt; /bin/bash<br></code></pre></td></tr></table></figure><p>后面加上的<code>/bin/bash</code>是指在容器内打开一个交互式的Bash终端。</p><h2 id="Docker-exec命令"><a href="#Docker-exec命令" class="headerlink" title="Docker exec命令"></a>Docker exec命令</h2><p>Docker exec主要用于在运行中的容器内执行命令。这有很多种用法，例如:</p><ul><li><strong>容器内部命令执行：</strong> 你可以使用 <code>docker exec</code> 在容器内执行命令，而不必进入容器的交互式终端。这对于执行一次性任务或调试容器内的问题非常有用。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 在 my_container 容器内部执行 ls /app 命令，显示容器内 /app 目录下的文件和子目录</span><br>docker <span class="hljs-built_in">exec</span> -it my_container <span class="hljs-built_in">ls</span> /app<br></code></pre></td></tr></table></figure><ul><li><strong>进入容器内部交互式 Shell：</strong> 通过执行交互式 Shell（例如 Bash），你可以进入容器内部的终端，以便在容器内部执行多个命令。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -it my_container /bin/bash<br></code></pre></td></tr></table></figure><ul><li><strong>查看容器日志：</strong> 使用 <code>docker exec</code> 可以查看容器的日志，而无需停止容器。这对于实时监控容器的运行状态非常有用。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -it my_container <span class="hljs-built_in">tail</span> -f /var/log/app.log<br></code></pre></td></tr></table></figure><ul><li><strong>在运行中的服务中执行管理命令：</strong> 对于运行中的服务，你可以使用 <code>docker exec</code> 执行一些管理命令，例如数据库操作、Web 服务器的重新加载配置等。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 在名为 database_container 的 Docker 容器内使用 psql 命令连接到 PostgreSQL 数据库</span><br>docker <span class="hljs-built_in">exec</span> -it database_container psql -U username -d dbname<br></code></pre></td></tr></table></figure><ul><li><strong>容器内部文件操作：</strong> 你可以使用 <code>docker exec</code> 在容器内部进行文件操作，例如查看、复制或修改文件。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -it my_container <span class="hljs-built_in">cat</span> /app/config.txt<br></code></pre></td></tr></table></figure><h1 id="删除容器与镜像"><a href="#删除容器与镜像" class="headerlink" title="删除容器与镜像"></a>删除容器与镜像</h1><p>删除容器就是<code>rm</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">rm</span> -f &lt;docker <span class="hljs-built_in">id</span>&gt;<br></code></pre></td></tr></table></figure><p>要清理所有停止的容器，则需要执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 方法1</span><br>docker container prune <br><span class="hljs-comment"># 方法2</span><br>docker <span class="hljs-built_in">rm</span> $(docker ps -a -q)<br></code></pre></td></tr></table></figure><h2 id="强制杀死容器"><a href="#强制杀死容器" class="headerlink" title="强制杀死容器"></a>强制杀死容器</h2><p>有时候可能会遇到应用崩溃的情况，这时候需要使用<code>kill</code>指令杀死容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">kill</span> my_container<br></code></pre></td></tr></table></figure><h2 id="Docker-rm命令"><a href="#Docker-rm命令" class="headerlink" title="Docker rm命令"></a>Docker rm命令</h2><ul><li>-f :通过 SIGKILL 信号强制删除一个运行中的容器。</li><li>-l :移除容器间的网络连接，而非容器本身。</li><li>-v :删除与容器关联的卷。</li></ul><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 强制删除容器</span><br>docker <span class="hljs-built_in">rm</span> -f db01 db02<br></code></pre></td></tr></table></figure><p>删除镜像则是<code>rmi</code>命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker rmi my_image1 my_image2<br></code></pre></td></tr></table></figure><h1 id="使用Python的简单用例"><a href="#使用Python的简单用例" class="headerlink" title="使用Python的简单用例"></a>使用Python的简单用例</h1><p>可以使用 Docker Hub 上提供的官方 Python 镜像来创建一个 Python 3.9 的容器。以下是步骤：</p><ol><li><p><strong>拉取 Python 3.9 镜像：</strong> 打开终端或命令提示符，并执行以下命令来拉取 Python 3.9 镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull python:3.9<br></code></pre></td></tr></table></figure><p>这会从 Docker Hub 下载 Python 3.9 镜像到你的本地系统。</p></li><li><p><strong>运行 Python 3.9 容器：</strong> 一旦下载完成，你可以通过以下命令运行一个 Python 3.9 容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it python:3.9 /bin/bash<br></code></pre></td></tr></table></figure><p>这个命令使用 <code>-it</code> 选项进入交互模式，并在容器内启动 Bash 终端。</p></li><li><p><strong>验证 Python 版本：</strong> 在容器内部，你可以使用以下命令验证 Python 版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python --version<br></code></pre></td></tr></table></figure></li></ol><h2 id="想要在这个Python容器中写对外开放的服务？"><a href="#想要在这个Python容器中写对外开放的服务？" class="headerlink" title="想要在这个Python容器中写对外开放的服务？"></a>想要在这个Python容器中写对外开放的服务？</h2><p>和之前一样，需要运行python容器时开放端口：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -d -p 8080:80 python:3.9 <br></code></pre></td></tr></table></figure><p>这是一个更具体的例子，在python3.9的容器运行了<code>your_flask_app.py</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -d -p 8080:5000 python:3.9 python your_flask_app.py<br></code></pre></td></tr></table></figure><p>2024&#x2F;1&#x2F;23 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Yolo v5的工程代码实现：detect.py</title>
    <link href="/2024/01/21/Yolo-v5%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%9Adetect-py/"/>
    <url>/2024/01/21/Yolo-v5%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%9Adetect-py/</url>
    
    <content type="html"><![CDATA[<h1 id="Yolo简史"><a href="#Yolo简史" class="headerlink" title="Yolo简史"></a>Yolo简史</h1><p>Yolo系列可谓是无数CVer的入门之作，也是广大研究生，小厂商的救命稻草。我原先也精读过Yolo v1的论文，不过今天先逐步解析一下Yolo v5的工程代码。</p><p>Yolo v1-v3都是由原作者Joseph Redmon开发，2020年，他宣称拒绝该技术被美国军方使用，停止了个人开发。后续的开发由各个企业&#x2F;开发者维系。</p><p>Yolo v4由Yolo Darknet的维护者Alexy Bochkoviskiy发布；Yolo v5&#x2F;v8由西班牙公司Ulterlytics开发；Yolo v6由美团发布，Yolo v7则继续由Alexy Bochkoviskiy发布。事实上，Alexy Bochkoviskiy目前被广泛认为是Yolo的官方开发者。</p><h1 id="代码架构"><a href="#代码架构" class="headerlink" title="代码架构"></a>代码架构</h1><p>Yolo v5的官方仓库中主要由以下架构组成：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">/yolov5<br>│<br>├── classify <span class="hljs-comment"># 分类模型的训练/推理/验证/教程代码</span><br>├── data <span class="hljs-comment"># 数据集配置文件/超参数配置文件/测试图片</span><br>├── models <span class="hljs-comment"># 模型配置文件</span><br>├── segment <span class="hljs-comment"># 图形分割模型的训练/推理/验证/教程代码</span><br>├── utils <span class="hljs-comment"># 工具代码</span><br>├── benchmarks.py <span class="hljs-comment"># 评估代码</span><br>├── detect.py <span class="hljs-comment"># 预测代码</span><br>├── export.py <span class="hljs-comment"># 模型转换代码</span><br>├── hubconf.py <span class="hljs-comment"># 从torch.hub导入模型的代码</span><br>├── train.py <span class="hljs-comment"># 训练代码</span><br>├── val.py <span class="hljs-comment"># 验证代码</span><br>└── tutorial.ipynb <span class="hljs-comment"># 教程代码</span><br></code></pre></td></tr></table></figure><p>今天分析的是其中的<code>detect.py</code>，这是yolo v5的推理代码，总共只有200多行代码，所以并不复杂。</p><h2 id="依赖包"><a href="#依赖包" class="headerlink" title="依赖包"></a>依赖包</h2><p>首先是导入依赖包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> csv<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> platform<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment">#获取detect.py在电脑中的绝对路径</span><br>FILE = Path(__file__).resolve() <br><br><span class="hljs-comment"># 获取detect.py的父目录（绝对路径）：YOLOv5 root directory</span><br>ROOT = FILE.parents[<span class="hljs-number">0</span>]  <br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(ROOT) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sys.path: <br><span class="hljs-comment"># 添加yolov5根目录到系统路径中</span><br>    sys.path.append(<span class="hljs-built_in">str</span>(ROOT))  <br>    <br><span class="hljs-comment"># 将绝对路径转换为相对路径</span><br>ROOT = Path(os.path.relpath(ROOT, Path.cwd())) <br></code></pre></td></tr></table></figure><p>这里值得学习的是路径的导入：通过当前文件的路径找到项目母路径，添加到系统变量，并转化为相对路径。这时，ROOT就变成了项目根目录的相对路径，引用的时候需要从根目录考虑位置。</p><p>接下来是导入自定义的库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> ultralytics.utils.plotting <span class="hljs-keyword">import</span> Annotator, colors, save_one_box<br><br><span class="hljs-keyword">from</span> models.common <span class="hljs-keyword">import</span> DetectMultiBackend<br><span class="hljs-keyword">from</span> utils.dataloaders <span class="hljs-keyword">import</span> IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams<br><span class="hljs-keyword">from</span> utils.general <span class="hljs-keyword">import</span> (<br>    LOGGER,<br>    Profile,<br>    check_file,<br>    check_img_size,<br>    check_imshow,<br>    check_requirements,<br>    colorstr,<br>    cv2,<br>    increment_path,<br>    non_max_suppression,<br>    print_args,<br>    scale_boxes,<br>    strip_optimizer,<br>    xyxy2xywh,<br>)<br><span class="hljs-keyword">from</span> utils.torch_utils <span class="hljs-keyword">import</span> select_device, smart_inference_mode<br></code></pre></td></tr></table></figure><p>这些自定义库的内容如下：</p><ul><li><strong>models.common.py：</strong> 这个文件定义了模型的层结构，以及一些通用的函数和类，比如图像的处理、非极大值抑制等等。</li><li><strong>utils.dataloaders.py：</strong> 这个文件定义了dataloader和dataset。其中定义了一些常用的类：LoadStream，LoadImages，LoadScreenshots，LoadImagesAndLabels，这些是用来导入数据的类。</li><li><strong>utils.general.py：</strong> 这个文件定义了一些常用的工具函数，比如判断语句、检查文件是否存在、检查图像大小是否符合要求、打印命令行参数等等。</li><li><strong>utils.plots.py：</strong> 这个文件定义了Annotator类，可以在图像上绘制矩形框和标注信息。</li><li><strong>utils.torch_utils.py：</strong> 这个文件定义了一些与PyTorch有关的工具函数，比如选择设备、同步时间等等。</li></ul><h2 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@smart_inference_mode()</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params"></span><br><span class="hljs-params">    weights=ROOT / <span class="hljs-string">&quot;yolov5s.pt&quot;</span>,  <span class="hljs-comment"># 权重路径</span></span><br><span class="hljs-params">    source=ROOT / <span class="hljs-string">&quot;data/images&quot;</span>,  <span class="hljs-comment"># file/dir/URL/glob/screen/0(本机的摄像头)</span></span><br><span class="hljs-params">    data=ROOT / <span class="hljs-string">&quot;data/coco128.yaml&quot;</span>,  <span class="hljs-comment"># 配置数据文件路径，包括image/label/classes等信息，训练自己的文件，需要作相应更改</span></span><br><span class="hljs-params">    imgsz=(<span class="hljs-params"><span class="hljs-number">640</span>, <span class="hljs-number">640</span></span>),  <span class="hljs-comment"># 预测时网络输入图片的尺寸大小 (height, width)</span></span><br><span class="hljs-params">    conf_thres=<span class="hljs-number">0.25</span>,  <span class="hljs-comment"># 置信度阈值</span></span><br><span class="hljs-params">    iou_thres=<span class="hljs-number">0.45</span>,  <span class="hljs-comment"># 非极大值抑制的阈值</span></span><br><span class="hljs-params">    max_det=<span class="hljs-number">1000</span>,  <span class="hljs-comment"># 每张图片最大保留的检测框数量</span></span><br><span class="hljs-params">    device=<span class="hljs-string">&quot;&quot;</span>,  <span class="hljs-comment"># cuda device, i.e. 0 or 0,1,2,3 or cpu</span></span><br><span class="hljs-params">    view_img=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否展示预测之后的图片/视频</span></span><br><span class="hljs-params">    save_txt=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否将预测的框坐标以txt文件形式保存，使用--save-txt 将会在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span><br><span class="hljs-params">    save_csv=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否将预测结果保存到csv文件</span></span><br><span class="hljs-params">    save_conf=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否保存检测结果的置信度到 txt文件</span></span><br><span class="hljs-params">    save_crop=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否保存裁剪预测框图片，使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span><br><span class="hljs-params">    nosave=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 不保存图片、视频，使用--nosave 在runs/detect/exp*/就不会出现预测的结果</span></span><br><span class="hljs-params">    classes=<span class="hljs-literal">None</span>,  <span class="hljs-comment"># 可以过滤检测结果，只检测指定类别</span></span><br><span class="hljs-params">    agnostic_nms=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否使用类别不敏感的非极大抑制（即不考虑类别信息）</span></span><br><span class="hljs-params">    augment=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否使用数据增强进行推理</span></span><br><span class="hljs-params">    visualize=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否可视化特征图</span></span><br><span class="hljs-params">    update=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 如果为True，则对所有模型进行strip_optimizer操作，去除pt文件中的优化器等信息</span></span><br><span class="hljs-params">    project=ROOT / <span class="hljs-string">&quot;runs/detect&quot;</span>,  <span class="hljs-comment"># 结果保存的项目目录路径，默认为 &#x27;ROOT/runs/detect&#x27;</span></span><br><span class="hljs-params">    name=<span class="hljs-string">&quot;exp&quot;</span>,  <span class="hljs-comment"># 结果保存的子目录名称，默认为 &#x27;exp&#x27;</span></span><br><span class="hljs-params">    exist_ok=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否覆盖已有结果，默认为 False</span></span><br><span class="hljs-params">    line_thickness=<span class="hljs-number">3</span>,  <span class="hljs-comment">#  画 bounding box 时的线条宽度</span></span><br><span class="hljs-params">    hide_labels=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否隐藏标签信息</span></span><br><span class="hljs-params">    hide_conf=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否隐藏置信度信息</span></span><br><span class="hljs-params">    half=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否使用 FP16 半精度进行推理</span></span><br><span class="hljs-params">    dnn=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 是否使用 OpenCV DNN 进行 ONNX 推理</span></span><br><span class="hljs-params">    vid_stride=<span class="hljs-number">1</span>,  <span class="hljs-comment"># 视频流的帧步</span></span><br><span class="hljs-params"></span>):<br><br></code></pre></td></tr></table></figure><h2 id="初始设置"><a href="#初始设置" class="headerlink" title="初始设置"></a>初始设置</h2><p>接下来进入代码块，第一个部分是推理的基础设置，代码如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># 将source转换为字符串</span><br><span class="hljs-comment"># source 为命令行传入的图片或者视频，例如：python detect.py --source data/images/bus.jpg</span><br>source = <span class="hljs-built_in">str</span>(source) <span class="hljs-comment"># 图片路径 &#x27;data/images&#x27;</span><br><br><span class="hljs-comment"># 是否保存预测后的图片，nosave为false，则not nosave为true</span><br><span class="hljs-comment"># source传入的是照片而不是txt则为true，最后则表示需要存储最后的预测结果</span><br>save_img = <span class="hljs-keyword">not</span> nosave <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> source.endswith(<span class="hljs-string">&#x27;.txt&#x27;</span>)  <br><br><span class="hljs-comment"># Path(source)：为文件地址，例如：data/images/bus.jpg</span><br><span class="hljs-comment"># suffix[1:]：截取文件后缀，即为bus.jpg，而[1:]则为jpg后，最后输出为jpg</span><br><span class="hljs-comment"># 判断该jpg是否在(IMG_FORMATS + VID_FORMATS) 该列表内，该列表可参照下一个代码模块。最后输出为true</span><br>is_file = Path(source).suffix[<span class="hljs-number">1</span>:] <span class="hljs-keyword">in</span> (IMG_FORMATS + VID_FORMATS)<br><br><span class="hljs-comment"># 判断是否为网络流地址或者是网络的图片地址</span><br><span class="hljs-comment"># 将其地址转换为小写，并且判断开头是否包括如下网络流开头的</span><br>is_url = source.lower().startswith((<span class="hljs-string">&#x27;rtsp://&#x27;</span>, <span class="hljs-string">&#x27;rtmp://&#x27;</span>, <span class="hljs-string">&#x27;http://&#x27;</span>, <span class="hljs-string">&#x27;https://&#x27;</span>))<br><br><span class="hljs-comment"># 是否是使用webcam数据，一般为false</span><br><span class="hljs-comment"># 判断source是否为数值（0为摄像头路径）或者 txt文件 或者 网络流并且不是文件地址</span><br>webcam = source.isnumeric() <span class="hljs-keyword">or</span> source.endswith(<span class="hljs-string">&#x27;.txt&#x27;</span>) <span class="hljs-keyword">or</span> (is_url <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> is_file)<br><br><span class="hljs-comment"># 是否传入的为屏幕快照文件</span><br>screenshot = source.lower().startswith(<span class="hljs-string">&#x27;screen&#x27;</span>)<br><br><span class="hljs-comment"># 如果是网络流地址 以及文件，则对应下载该文件</span><br><span class="hljs-keyword">if</span> is_url <span class="hljs-keyword">and</span> is_file:<br>    <span class="hljs-comment"># 下载，该函数在下文中有所讲解</span><br>    source = check_file(source) <br></code></pre></td></tr></table></figure><p>图片和视频的格式分别如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 包括的图片后缀</span><br>IMG_FORMATS = <span class="hljs-string">&#x27;bmp&#x27;</span>, <span class="hljs-string">&#x27;dng&#x27;</span>, <span class="hljs-string">&#x27;jpeg&#x27;</span>, <span class="hljs-string">&#x27;jpg&#x27;</span>, <span class="hljs-string">&#x27;mpo&#x27;</span>, <span class="hljs-string">&#x27;png&#x27;</span>, <span class="hljs-string">&#x27;tif&#x27;</span>, <span class="hljs-string">&#x27;tiff&#x27;</span>, <span class="hljs-string">&#x27;webp&#x27;</span>, <span class="hljs-string">&#x27;pfm&#x27;</span>  <br><br><span class="hljs-comment"># 包括的视频后缀</span><br>VID_FORMATS = <span class="hljs-string">&#x27;asf&#x27;</span>, <span class="hljs-string">&#x27;avi&#x27;</span>, <span class="hljs-string">&#x27;gif&#x27;</span>, <span class="hljs-string">&#x27;m4v&#x27;</span>, <span class="hljs-string">&#x27;mkv&#x27;</span>, <span class="hljs-string">&#x27;mov&#x27;</span>, <span class="hljs-string">&#x27;mp4&#x27;</span>, <span class="hljs-string">&#x27;mpeg&#x27;</span>, <span class="hljs-string">&#x27;mpg&#x27;</span>, <span class="hljs-string">&#x27;ts&#x27;</span>, <span class="hljs-string">&#x27;wmv&#x27;</span> <br></code></pre></td></tr></table></figure><p>根据source的类型，会确定输入数据的类型：</p><ul><li>如果source的后缀是图像或视频格式之一，那么将is_file设置为True；</li><li>如果source以rtsp等开头，那么将is_url设置为True；</li><li>如果source是数字或以.txt结尾或是一个URL，那么将webcam设置为True；</li><li>如果source既是文件又是URL，那么会调用check_file函数下载文件。</li></ul><p><code>check_file(source)</code>的函数代码如下，如果输入不是url地址，可以忽略：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 该函数主要的核心功能为：找到文件或者下载文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_file</span>(<span class="hljs-params">file, suffix=<span class="hljs-string">&#x27;&#x27;</span></span>):<br>    <span class="hljs-comment"># 如果文件后缀符合指定的后缀列表，则没有任何返回</span><br>    <span class="hljs-comment"># 如果文件后缀不符合指定的后缀列表，会抛出一个AssertionError</span><br>    check_suffix(file, suffix) <br>    <span class="hljs-comment"># 转换文件为字符串</span><br>    file = <span class="hljs-built_in">str</span>(file) <br><br><span class="hljs-comment"># 如果文件存在 或者 不是一个文件，则直接返回文件</span><br>    <span class="hljs-keyword">if</span> os.path.isfile(file) <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> file:  <span class="hljs-comment"># exists</span><br>        <span class="hljs-keyword">return</span> file<br>        <br><span class="hljs-comment"># 如果文件的前缀为网络流信息，则对应进行下载</span><br>    <span class="hljs-keyword">elif</span> file.startswith((<span class="hljs-string">&#x27;http:/&#x27;</span>, <span class="hljs-string">&#x27;https:/&#x27;</span>)): <br>        url = file  <br>        <span class="hljs-comment"># urllib.parse.unquote(file) 相当于JS中的urldecode()，对url进行解码</span><br>        <span class="hljs-comment"># 类似https://url.com/file.txt?auth 结果为https://url.com/file.txt</span><br>        file = Path(urllib.parse.unquote(file).split(<span class="hljs-string">&#x27;?&#x27;</span>)[<span class="hljs-number">0</span>]).name  <br>        <span class="hljs-comment"># 如果文件存在，则输出logger日志</span><br>        <span class="hljs-keyword">if</span> os.path.isfile(file):<br>            LOGGER.info(<span class="hljs-string">f&#x27;Found <span class="hljs-subst">&#123;url&#125;</span> locally at <span class="hljs-subst">&#123;file&#125;</span>&#x27;</span>) <br>       <span class="hljs-comment"># 如果文件不存在，则对应下载文件</span><br>        <span class="hljs-keyword">else</span>:<br>            LOGGER.info(<span class="hljs-string">f&#x27;Downloading <span class="hljs-subst">&#123;url&#125;</span> to <span class="hljs-subst">&#123;file&#125;</span>...&#x27;</span>)<br>            torch.hub.download_url_to_file(url, file)<br>            <span class="hljs-keyword">assert</span> Path(file).exists() <span class="hljs-keyword">and</span> Path(file).stat().st_size &gt; <span class="hljs-number">0</span>, <span class="hljs-string">f&#x27;File download failed: <span class="hljs-subst">&#123;url&#125;</span>&#x27;</span>  <span class="hljs-comment"># check</span><br>        <span class="hljs-keyword">return</span> file<br><br><span class="hljs-comment"># 如果文件前缀为ClearML Dataset，设置断言，表明没有安装，需要用pip进行安装</span><br>    <span class="hljs-keyword">elif</span> file.startswith(<span class="hljs-string">&#x27;clearml://&#x27;</span>):  <span class="hljs-comment"># ClearML Dataset ID</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-string">&#x27;clearml&#x27;</span> <span class="hljs-keyword">in</span> sys.modules, <span class="hljs-string">&quot;ClearML is not installed, so cannot use ClearML dataset. Try running &#x27;pip install clearml&#x27;.&quot;</span><br>        <span class="hljs-keyword">return</span> file<br><br><span class="hljs-comment"># 都不是以上的情况，则对应搜索目录，找到该文件，并且返回该文件</span><br>    <span class="hljs-keyword">else</span>:  <br>        files = []<br>        <span class="hljs-comment"># 搜索这些目录</span><br>        <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> <span class="hljs-string">&#x27;data&#x27;</span>, <span class="hljs-string">&#x27;models&#x27;</span>, <span class="hljs-string">&#x27;utils&#x27;</span>:  <br>        <span class="hljs-comment"># 模糊搜索，并且添加到files的列表中</span><br>            files.extend(glob.glob(<span class="hljs-built_in">str</span>(ROOT / d / <span class="hljs-string">&#x27;**&#x27;</span> / file), recursive=<span class="hljs-literal">True</span>))  <br>        <span class="hljs-comment"># 设置断言</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(files), <span class="hljs-string">f&#x27;File not found: <span class="hljs-subst">&#123;file&#125;</span>&#x27;</span>  <span class="hljs-comment"># assert file was found</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(files) == <span class="hljs-number">1</span>, <span class="hljs-string">f&quot;Multiple files match &#x27;<span class="hljs-subst">&#123;file&#125;</span>&#x27;, specify exact path: <span class="hljs-subst">&#123;files&#125;</span>&quot;</span>  <span class="hljs-comment"># assert unique</span><br>        <span class="hljs-keyword">return</span> files[<span class="hljs-number">0</span>]  <span class="hljs-comment"># return file</span><br></code></pre></td></tr></table></figure><p><code>check_suffix(file, suffix)</code>代码如下，这个函数的主要作用是判断文件后缀是否符合指定的后缀列表。如果符合就不会返回任何信息，否则会报错：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 默认按照传参进行设置，如果不传参则赋以下默认值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_suffix</span>(<span class="hljs-params">file=<span class="hljs-string">&#x27;yolov5s.pt&#x27;</span>, suffix=(<span class="hljs-params"><span class="hljs-string">&#x27;.pt&#x27;</span>,</span>), msg=<span class="hljs-string">&#x27;&#x27;</span></span>):<br>    <span class="hljs-comment"># 在可用的文件后缀中检查后缀</span><br>    <span class="hljs-keyword">if</span> file <span class="hljs-keyword">and</span> suffix:<br>    <span class="hljs-comment"># 如果文件后缀为str字符串，则转换为列表</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(suffix, <span class="hljs-built_in">str</span>):<br>            suffix = [suffix]<br><br><span class="hljs-comment"># 如果文件为列表或者元组则遍历文件，否则将其文件变为列表来遍历</span><br>        <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> file <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(file, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)) <span class="hljs-keyword">else</span> [file]:<br>        <span class="hljs-comment"># 找到文件后缀 并且小写</span><br>            s = Path(f).suffix.lower()  <br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(s):<br>                <span class="hljs-keyword">assert</span> s <span class="hljs-keyword">in</span> suffix, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;msg&#125;</span><span class="hljs-subst">&#123;f&#125;</span> acceptable suffix is <span class="hljs-subst">&#123;suffix&#125;</span>&quot;</span><br></code></pre></td></tr></table></figure><p>接下来是创建保存输出结果文件夹的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建文件夹</span><br><br><span class="hljs-comment"># Path(project) 为一开始定义的：   project=ROOT / &#x27;runs/detect&#x27;</span><br><span class="hljs-comment"># name为保存的项目名：   name=&#x27;exp&#x27;</span><br><span class="hljs-comment"># 表示两者的拼接 ：runs/detect/exp</span><br>save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  <br><span class="hljs-built_in">print</span>(save_dir) <span class="hljs-comment"># runs/detect/exp</span><br><br><span class="hljs-comment"># 传入的命令参数save_txt 为false，则直接创建exp文件夹</span><br><span class="hljs-comment"># 传入的命令参数save_txt 为 true，则直接拼接一个/ &#x27;labels 创建文件夹</span><br>(save_dir / <span class="hljs-string">&#x27;labels&#x27;</span> <span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">else</span> save_dir).mkdir(parents=<span class="hljs-literal">True</span>, exist_ok=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># make dir</span><br></code></pre></td></tr></table></figure><p>这里用到的<code>increment_path</code>的函数如下，其实就是创建组合一下创建文件夹：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 递增路径 如 run/train/exp --&gt; runs/train/exp&#123;sep&#125;0, runs/exp&#123;sep&#125;1 etc.</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">increment_path</span>(<span class="hljs-params">path, exist_ok=<span class="hljs-literal">False</span>, sep=<span class="hljs-string">&#x27;&#x27;</span>, mkdir=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-comment"># string/win路径 -&gt; win路径</span><br>    path = Path(path) <br><br><span class="hljs-comment">#如果文件路径存在</span><br>    <span class="hljs-keyword">if</span> path.exists() <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> exist_ok:<br>    <span class="hljs-comment"># 文件path路径为：.with_suffix 将路径添加一个后缀 &#x27;&#x27;</span><br>    <span class="hljs-comment"># 文件后缀为：path的后缀 </span><br>        path, suffix = (path.with_suffix(<span class="hljs-string">&#x27;&#x27;</span>), path.suffix) <span class="hljs-keyword">if</span> path.is_file() <span class="hljs-keyword">else</span> (path, <span class="hljs-string">&#x27;&#x27;</span>)<br><br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, <span class="hljs-number">9999</span>):<br>        <span class="hljs-comment"># f开头表示字符串内支持大括号的python表达式</span><br>        <span class="hljs-comment"># increment</span><br>            p = <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;path&#125;</span><span class="hljs-subst">&#123;sep&#125;</span><span class="hljs-subst">&#123;n&#125;</span><span class="hljs-subst">&#123;suffix&#125;</span>&#x27;</span><br>            <span class="hljs-comment"># 如果不存在该路径，则break退出  </span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(p):  <br>                <span class="hljs-keyword">break</span><br>        path = Path(p)<br><br><span class="hljs-comment"># 默认mkdir为false，先不创建dir</span><br>    <span class="hljs-keyword">if</span> mkdir:<br>        path.mkdir(parents=<span class="hljs-literal">True</span>, exist_ok=<span class="hljs-literal">True</span>)  <br><br>    <span class="hljs-keyword">return</span> path<br></code></pre></td></tr></table></figure><h2 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h2><p>接下来是加载模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型加载</span><br><br><span class="hljs-comment"># 选择CPU或者GPU，主要为逻辑判断</span><br><span class="hljs-comment"># 此处的device 为 None or &#x27;cpu&#x27; or 0 or &#x27;0&#x27; or &#x27;0,1,2,3&#x27;</span><br>device = select_device(device)<br><br><span class="hljs-comment"># 模型后端框架，传入对应的参数</span><br>model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)<br><br><span class="hljs-comment">#加载完模型之后，对应读取模型的步长、类别名、pytorch模型类型</span><br>stride, names, pt = model.stride, model.names, model.pt<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;stride:<span class="hljs-subst">&#123;stride&#125;</span>,names:<span class="hljs-subst">&#123;names&#125;</span>,pt:<span class="hljs-subst">&#123;pt&#125;</span>&#x27;</span>) <span class="hljs-comment"># stride 32, name &#123;0:&#x27;person&#x27;, 1:&#x27;bicycle&#x27;&#125;, pt True</span><br><br><span class="hljs-comment"># 判断模型步长是否为32的倍数</span><br>imgsz = check_img_size(imgsz, s=stride) <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;imgsz:<span class="hljs-subst">&#123;imgsz&#125;</span>&#x27;</span>) <span class="hljs-comment"># imgsz 640</span><br></code></pre></td></tr></table></figure><p>上面这段代码主要是使用DetectMultiBackend类来加载模型，从模型中提取了三个参数是：</p><ul><li>stride：推理时所用到的步长，默认为32， 大步长适合于大目标，小步长适合于小目标</li><li>names：保存推理结果名的列表，比如默认模型的值是[‘person’, ‘bicycle’, ‘car’, …]</li><li>pt: 加载的是否是pytorch模型（也就是pt格式的文件）</li></ul><p>最后确保输入图片的尺寸imgsz能整除stride&#x3D;32 如果不能则调整为能被整除并返回。</p><p>看一下<code>DetectMultiBackend</code>的源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DetectMultiBackend</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, weights=<span class="hljs-string">&#x27;yolov5s.pt&#x27;</span>, device=torch.device(<span class="hljs-params"><span class="hljs-string">&#x27;cpu&#x27;</span></span>), dnn=<span class="hljs-literal">False</span>, data=<span class="hljs-literal">None</span>, fp16=<span class="hljs-literal">False</span>, fuse=<span class="hljs-literal">True</span></span>):<br><span class="hljs-comment"># 限定了作用域以避免循环导入</span><br>        <span class="hljs-keyword">from</span> models.experimental <span class="hljs-keyword">import</span> attempt_download, attempt_load  <br><span class="hljs-comment"># 父函数初始化</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 如果weights权重为列表则取出第一个，否则直接取出weights</span><br>        w = <span class="hljs-built_in">str</span>(weights[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(weights, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> weights)<br>        <span class="hljs-comment"># 判断框架模型，本身就是pt了</span><br>        pt, jit, onnx, xml, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle, triton = self._model_type(w)<br>        fp16 &amp;= pt <span class="hljs-keyword">or</span> jit <span class="hljs-keyword">or</span> onnx <span class="hljs-keyword">or</span> engine  <br>        <span class="hljs-comment"># BHWC formats (vs torch BCWH)</span><br>        nhwc = coreml <span class="hljs-keyword">or</span> saved_model <span class="hljs-keyword">or</span> pb <span class="hljs-keyword">or</span> tflite <span class="hljs-keyword">or</span> edgetpu  <br>        <span class="hljs-comment"># 初始步长为32</span><br>        stride = <span class="hljs-number">32</span>  <br>        cuda = torch.cuda.is_available() <span class="hljs-keyword">and</span> device.<span class="hljs-built_in">type</span> != <span class="hljs-string">&#x27;cpu&#x27;</span>  <span class="hljs-comment"># use CUDA</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (pt <span class="hljs-keyword">or</span> triton):<br>        <span class="hljs-comment"># 如果不在本地会在网络进行下载，如果存在本地则加载权重文件</span><br>            w = attempt_download(w)<br><br>        <span class="hljs-keyword">if</span> pt:  <span class="hljs-comment"># PyTorch</span><br>        <span class="hljs-comment"># 加载模型权重</span><br>            model = attempt_load(weights <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(weights, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> w, device=device, inplace=<span class="hljs-literal">True</span>, fuse=fuse)<br><span class="hljs-comment"># 模型的最大权重</span><br>            stride = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">int</span>(model.stride.<span class="hljs-built_in">max</span>()), <span class="hljs-number">32</span>)  <br>            <span class="hljs-comment"># 如果不用COCO数据集或者ImageNet数据集的标签，加载模型pt权重</span><br>            names = model.module.names <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(model, <span class="hljs-string">&#x27;module&#x27;</span>) <span class="hljs-keyword">else</span> model.names  <br>            <span class="hljs-comment"># 用fp16则用半精度推理，没有则用float</span><br>            model.half() <span class="hljs-keyword">if</span> fp16 <span class="hljs-keyword">else</span> model.<span class="hljs-built_in">float</span>()<br>            <span class="hljs-comment"># 得到加载好的模型</span><br>            self.model = model  <span class="hljs-comment"># explicitly assign for to(), cpu(), cuda(), half()</span><br><span class="hljs-keyword">elif</span> ...<br><span class="hljs-comment"># 省略其他情况（大同小异）</span><br><br>     <span class="hljs-comment"># 生成class name</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;names&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">locals</span>():<br>    <span class="hljs-comment"># 生成对应的 999个标签</span><br>        names = yaml_load(data)[<span class="hljs-string">&#x27;names&#x27;</span>] <span class="hljs-keyword">if</span> data <span class="hljs-keyword">else</span> &#123;i: <span class="hljs-string">f&#x27;class<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">999</span>)&#125;<br>    <span class="hljs-keyword">if</span> names[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;n01440764&#x27;</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(names) == <span class="hljs-number">1000</span>:  <span class="hljs-comment"># ImageNet</span><br>        names = yaml_load(ROOT / <span class="hljs-string">&#x27;data/ImageNet.yaml&#x27;</span>)[<span class="hljs-string">&#x27;names&#x27;</span>]  <span class="hljs-comment"># human-readable names</span><br><br>    self.__dict__.update(<span class="hljs-built_in">locals</span>())  <span class="hljs-comment"># assign all variables to self</span><br></code></pre></td></tr></table></figure><p>加载数据配置文件的方法是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">yaml_load</span>(<span class="hljs-params">file=<span class="hljs-string">&quot;data.yaml&quot;</span></span>):<br>    <span class="hljs-comment"># Single-line safe yaml loading</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file, errors=<span class="hljs-string">&quot;ignore&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">return</span> yaml.safe_load(f)        <br></code></pre></td></tr></table></figure><p>对应的COCO128.yaml文件长这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数据集源路径root、训练集、验证集、测试集地址</span><br><br><span class="hljs-comment"># 数据集源路径root dir</span><br>path: ../datasets/coco128  <br><span class="hljs-comment"># root下的训练集地址 128 images</span><br>train: images/train2017 <br><span class="hljs-comment"># root下的验证集地址 128 images</span><br>val: images/train2017  <br><span class="hljs-comment"># root下的验证集地址 128 images</span><br>test:                <br><br><span class="hljs-comment"># 数据集类别信息</span><br>nc: <span class="hljs-number">80</span>  <span class="hljs-comment"># 数据集类别数量</span><br>names: [ <span class="hljs-string">&#x27;person&#x27;</span>, <span class="hljs-string">&#x27;bicycle&#x27;</span>, <span class="hljs-string">&#x27;car&#x27;</span>, <span class="hljs-string">&#x27;motorcycle&#x27;</span>, <span class="hljs-string">&#x27;airplane&#x27;</span>, <span class="hljs-string">&#x27;bus&#x27;</span>, <span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>, <span class="hljs-string">&#x27;boat&#x27;</span>, <span class="hljs-string">&#x27;traffic light&#x27;</span>,<br>         <span class="hljs-string">&#x27;fire hydrant&#x27;</span>, <span class="hljs-string">&#x27;stop sign&#x27;</span>, <span class="hljs-string">&#x27;parking meter&#x27;</span>, <span class="hljs-string">&#x27;bench&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;sheep&#x27;</span>, <span class="hljs-string">&#x27;cow&#x27;</span>,<br>         <span class="hljs-string">&#x27;elephant&#x27;</span>, <span class="hljs-string">&#x27;bear&#x27;</span>, <span class="hljs-string">&#x27;zebra&#x27;</span>, <span class="hljs-string">&#x27;giraffe&#x27;</span>, <span class="hljs-string">&#x27;backpack&#x27;</span>, <span class="hljs-string">&#x27;umbrella&#x27;</span>, <span class="hljs-string">&#x27;handbag&#x27;</span>, <span class="hljs-string">&#x27;tie&#x27;</span>, <span class="hljs-string">&#x27;suitcase&#x27;</span>, <span class="hljs-string">&#x27;frisbee&#x27;</span>,<br>         <span class="hljs-string">&#x27;skis&#x27;</span>, <span class="hljs-string">&#x27;snowboard&#x27;</span>, <span class="hljs-string">&#x27;sports ball&#x27;</span>, <span class="hljs-string">&#x27;kite&#x27;</span>, <span class="hljs-string">&#x27;baseball bat&#x27;</span>, <span class="hljs-string">&#x27;baseball glove&#x27;</span>, <span class="hljs-string">&#x27;skateboard&#x27;</span>, <span class="hljs-string">&#x27;surfboard&#x27;</span>,<br>         <span class="hljs-string">&#x27;tennis racket&#x27;</span>, <span class="hljs-string">&#x27;bottle&#x27;</span>, <span class="hljs-string">&#x27;wine glass&#x27;</span>, <span class="hljs-string">&#x27;cup&#x27;</span>, <span class="hljs-string">&#x27;fork&#x27;</span>, <span class="hljs-string">&#x27;knife&#x27;</span>, <span class="hljs-string">&#x27;spoon&#x27;</span>, <span class="hljs-string">&#x27;bowl&#x27;</span>, <span class="hljs-string">&#x27;banana&#x27;</span>, <span class="hljs-string">&#x27;apple&#x27;</span>,<br>         <span class="hljs-string">&#x27;sandwich&#x27;</span>, <span class="hljs-string">&#x27;orange&#x27;</span>, <span class="hljs-string">&#x27;broccoli&#x27;</span>, <span class="hljs-string">&#x27;carrot&#x27;</span>, <span class="hljs-string">&#x27;hot dog&#x27;</span>, <span class="hljs-string">&#x27;pizza&#x27;</span>, <span class="hljs-string">&#x27;donut&#x27;</span>, <span class="hljs-string">&#x27;cake&#x27;</span>, <span class="hljs-string">&#x27;chair&#x27;</span>, <span class="hljs-string">&#x27;couch&#x27;</span>,<br>         <span class="hljs-string">&#x27;potted plant&#x27;</span>, <span class="hljs-string">&#x27;bed&#x27;</span>, <span class="hljs-string">&#x27;dining table&#x27;</span>, <span class="hljs-string">&#x27;toilet&#x27;</span>, <span class="hljs-string">&#x27;tv&#x27;</span>, <span class="hljs-string">&#x27;laptop&#x27;</span>, <span class="hljs-string">&#x27;mouse&#x27;</span>, <span class="hljs-string">&#x27;remote&#x27;</span>, <span class="hljs-string">&#x27;keyboard&#x27;</span>, <span class="hljs-string">&#x27;cell phone&#x27;</span>,<br>         <span class="hljs-string">&#x27;microwave&#x27;</span>, <span class="hljs-string">&#x27;oven&#x27;</span>, <span class="hljs-string">&#x27;toaster&#x27;</span>, <span class="hljs-string">&#x27;sink&#x27;</span>, <span class="hljs-string">&#x27;refrigerator&#x27;</span>, <span class="hljs-string">&#x27;book&#x27;</span>, <span class="hljs-string">&#x27;clock&#x27;</span>, <span class="hljs-string">&#x27;vase&#x27;</span>, <span class="hljs-string">&#x27;scissors&#x27;</span>, <span class="hljs-string">&#x27;teddy bear&#x27;</span>,<br>         <span class="hljs-string">&#x27;hair drier&#x27;</span>, <span class="hljs-string">&#x27;toothbrush&#x27;</span> ]  <span class="hljs-comment"># 数据集类别名</span><br></code></pre></td></tr></table></figure><p><code>check_img_size</code>的源码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 验证图像大小是每个维度步幅的倍数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_img_size</span>(<span class="hljs-params">imgsz, s=<span class="hljs-number">32</span>, floor=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-comment"># 如果尺寸类型为int</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(imgsz, <span class="hljs-built_in">int</span>):  <br>    <span class="hljs-comment"># 返回能被除数整除的最接近的x</span><br>        new_size = <span class="hljs-built_in">max</span>(make_divisible(imgsz, <span class="hljs-built_in">int</span>(s)), floor)<br>        <br>    <span class="hljs-comment"># 尺寸类型为其他，转换为列表：img_size=[640, 480]</span><br>    <span class="hljs-keyword">else</span>:  <br>        imgsz = <span class="hljs-built_in">list</span>(imgsz)  <span class="hljs-comment"># convert to list if tuple</span><br>        <span class="hljs-comment"># 新的尺寸对应for遍历循环</span><br>        new_size = [<span class="hljs-built_in">max</span>(make_divisible(x, <span class="hljs-built_in">int</span>(s)), floor) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> imgsz]<br>    <span class="hljs-keyword">if</span> new_size != imgsz:<br>        LOGGER.warning(<span class="hljs-string">f&#x27;WARNING ⚠️ --img-size <span class="hljs-subst">&#123;imgsz&#125;</span> must be multiple of max stride <span class="hljs-subst">&#123;s&#125;</span>, updating to <span class="hljs-subst">&#123;new_size&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">return</span> new_size<br>    <br><span class="hljs-comment"># 返回能被除数整除的最接近的x</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_divisible</span>(<span class="hljs-params">x, divisor</span>):<br><span class="hljs-comment"># 本身传入的参数为32，32为torch.Tensor的类型，则将其转换为int类型  </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(divisor, torch.Tensor):<br>        divisor = <span class="hljs-built_in">int</span>(divisor.<span class="hljs-built_in">max</span>())  <span class="hljs-comment"># to int</span><br>   <br>    <span class="hljs-keyword">return</span> math.ceil(x / divisor) * divisor<br></code></pre></td></tr></table></figure><h2 id="加载预测数据"><a href="#加载预测数据" class="headerlink" title="加载预测数据"></a>加载预测数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数据加载</span><br>bs = <span class="hljs-number">1</span>  <span class="hljs-comment"># batch_size</span><br><span class="hljs-keyword">if</span> webcam:<br><br><span class="hljs-comment"># 检测cv2.imshow()方法是否可以执行，不能执行则抛出异常</span><br>    view_img = check_imshow(warn=<span class="hljs-literal">True</span>)  <br>    <br>    <span class="hljs-comment"># 加载输入的数据集</span><br>    dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride) <br>    <br>    <span class="hljs-comment"># 如果是加载进来的，就根据视频流的帧数设置bs</span><br>    bs = <span class="hljs-built_in">len</span>(dataset) <br><span class="hljs-keyword">elif</span> screenshot:<br>    dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt) <br><span class="hljs-keyword">else</span>:<br>    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)<br>    <br><span class="hljs-comment"># 保存视频的路径</span><br>vid_path, vid_writer = [<span class="hljs-literal">None</span>] * bs, [<span class="hljs-literal">None</span>] * bs <span class="hljs-comment"># 前者是视频路径,后者是一个cv2.VideoWriter对象</span><br></code></pre></td></tr></table></figure><p>这段代码根据输入的 source 参数来判断是否是通过 webcam 摄像头捕捉视频流：</p><ul><li>如果是，则使用 LoadStreams 加载视频流</li><li>如果是截屏，则使用LoadScreenshots加载截屏</li><li>否则，使用 LoadImages 加载图像<br>bs 表示 batch_size（批量大小），这里是 1 或视频流中的帧数。vid_path 和 vid_writer 分别是视频路径和视频编写器，初始化为长度为 batch_size 的空列表。</li></ul><p>vid_path 和 vid_writer 分别是视频路径和视频编写器，初始化为长度为 batch_size 的空列表。</p><p>其中用到的<code>LoadImages</code>函数是这样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LoadImages</span>:<br>    <span class="hljs-comment"># 执行代码：python detect.py --source image.jpg/vid.mp4</span><br>    <br>    <span class="hljs-comment"># 初始化字段，本身传入的参数如下：</span><br>    <span class="hljs-comment"># path：data\images\bus.jpg, img_size：传入的为【640，640】列表, stride步长32</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, path, img_size=<span class="hljs-number">640</span>, stride=<span class="hljs-number">32</span>, auto=<span class="hljs-literal">True</span>, transforms=<span class="hljs-literal">None</span>, vid_stride=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-comment"># 定义一个文件的空列表</span><br>        files = []<br>        <span class="hljs-comment"># 遍历path路径</span><br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(path) <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(path, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)) <span class="hljs-keyword">else</span> [path]:<br>        <span class="hljs-comment"># 通过相对路径得到绝对路径</span><br>            p = <span class="hljs-built_in">str</span>(Path(p).resolve())<br>            <span class="hljs-comment"># 判断路径是否有带*</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;*&#x27;</span> <span class="hljs-keyword">in</span> p:<br>            <span class="hljs-comment"># 如果p是采样正则化表达式提取图片/视频, 可以使用glob获取文件路径</span><br>                files.extend(<span class="hljs-built_in">sorted</span>(glob.glob(p, recursive=<span class="hljs-literal">True</span>)))  <br>            <span class="hljs-comment"># 判断路径是否为文件夹</span><br>            <span class="hljs-keyword">elif</span> os.path.isdir(p):<br>            <span class="hljs-comment"># 如果p是一个文件夹，使用glob获取全部文件路径</span><br>                files.extend(<span class="hljs-built_in">sorted</span>(glob.glob(os.path.join(p, <span class="hljs-string">&#x27;*.*&#x27;</span>))))  <br>            <span class="hljs-comment"># 判断路径是否为文件</span><br>            <span class="hljs-keyword">elif</span> os.path.isfile(p):<br>            <span class="hljs-comment"># 对应添加文件到列表中，本身也是转化为列表</span><br>                files.append(p) <br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">raise</span> FileNotFoundError(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;p&#125;</span> does not exist&#x27;</span>)<br><br><span class="hljs-comment"># 图片后缀判断是否在IMG_FORMATS，视频后缀判断是否在VID_FORMATS </span><br>        images = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> files <span class="hljs-keyword">if</span> x.split(<span class="hljs-string">&#x27;.&#x27;</span>)[-<span class="hljs-number">1</span>].lower() <span class="hljs-keyword">in</span> IMG_FORMATS]<br>        videos = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> files <span class="hljs-keyword">if</span> x.split(<span class="hljs-string">&#x27;.&#x27;</span>)[-<span class="hljs-number">1</span>].lower() <span class="hljs-keyword">in</span> VID_FORMATS]<br>        <span class="hljs-comment"># 图片与视频数量</span><br>        ni, nv = <span class="hljs-built_in">len</span>(images), <span class="hljs-built_in">len</span>(videos)<br><br>        self.img_size = img_size<br>        self.stride = stride<br>        self.files = images + videos<br>        self.nf = ni + nv  <span class="hljs-comment"># number of files</span><br>        <span class="hljs-comment"># 此处为标志， 是不是video</span><br>        self.video_flag = [<span class="hljs-literal">False</span>] * ni + [<span class="hljs-literal">True</span>] * nv<br>        self.mode = <span class="hljs-string">&#x27;image&#x27;</span><br>        <span class="hljs-comment"># 默认值为true</span><br>        self.auto = auto<br>        self.transforms = transforms  <span class="hljs-comment"># optional</span><br>        self.vid_stride = vid_stride  <span class="hljs-comment"># video frame-rate stride</span><br>        <span class="hljs-comment"># 判断videos有无值（此处明显为空）</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(videos):<br>        <span class="hljs-comment"># 判断有没有video文件  如果包含video文件，则初始化opencv中的视频模块，cap=cv2.VideoCapture等</span><br>            self._new_video(videos[<span class="hljs-number">0</span>])  <br>        <span class="hljs-keyword">else</span>:<br>            self.cap = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">assert</span> self.nf &gt; <span class="hljs-number">0</span>, <span class="hljs-string">f&#x27;No images or videos found in <span class="hljs-subst">&#123;p&#125;</span>. &#x27;</span> \<br>                            <span class="hljs-string">f&#x27;Supported formats are:\nimages: <span class="hljs-subst">&#123;IMG_FORMATS&#125;</span>\nvideos: <span class="hljs-subst">&#123;VID_FORMATS&#125;</span>&#x27;</span><br><br><span class="hljs-comment"># 迭代器</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-comment"># 调用该类别的时候都会执行一次count计数</span><br>       self.count = <span class="hljs-number">0</span><br>       <span class="hljs-keyword">return</span> self<br><br><span class="hljs-comment"># 与iter一起用</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__next__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-comment"># 判断计数是否与总文件数一样，如果一样则表明已经迭代结束</span><br>        <span class="hljs-keyword">if</span> self.count == self.nf:<br>            <span class="hljs-keyword">raise</span> StopIteration<br>        <span class="hljs-comment"># 读取当前文件路径</span><br>        path = self.files[self.count]<br><br><span class="hljs-comment"># 判断当前文件是否是视频</span><br>        <span class="hljs-keyword">if</span> self.video_flag[self.count]:<br>            <span class="hljs-comment"># Read video</span><br>            self.mode = <span class="hljs-string">&#x27;video&#x27;</span><br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.vid_stride):<br>                self.cap.grab()<br>            <span class="hljs-comment"># 获取当前帧画面，ret_val为一个bool变量，直到视频读取完毕之前都为True</span><br>            ret_val, im0 = self.cap.retrieve()<br>            <span class="hljs-comment"># 如果当前视频读取结束，则读取下一个视频</span><br>            <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> ret_val:<br>                self.count += <span class="hljs-number">1</span><br>                self.cap.release()<br>                <span class="hljs-comment"># 表明已经读取完</span><br>                <span class="hljs-keyword">if</span> self.count == self.nf:  <span class="hljs-comment"># last video</span><br>                    <span class="hljs-keyword">raise</span> StopIteration<br>                path = self.files[self.count]<br>                self._new_video(path)<br>                ret_val, im0 = self.cap.read()<br><br><span class="hljs-comment"># 当前读取视频的帧数</span><br>            self.frame += <span class="hljs-number">1</span><br>            <span class="hljs-comment"># im0 = self._cv2_rotate(im0)  # for use if cv2 autorotation is False</span><br>            s = <span class="hljs-string">f&#x27;video <span class="hljs-subst">&#123;self.count + <span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;self.nf&#125;</span> (<span class="hljs-subst">&#123;self.frame&#125;</span>/<span class="hljs-subst">&#123;self.frames&#125;</span>) <span class="hljs-subst">&#123;path&#125;</span>: &#x27;</span><br><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># Read image</span><br>            self.count += <span class="hljs-number">1</span><br>            im0 = cv2.imread(path)  <span class="hljs-comment"># BGR</span><br>            <span class="hljs-keyword">assert</span> im0 <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>, <span class="hljs-string">f&#x27;Image Not Found <span class="hljs-subst">&#123;path&#125;</span>&#x27;</span><br>            s = <span class="hljs-string">f&#x27;image <span class="hljs-subst">&#123;self.count&#125;</span>/<span class="hljs-subst">&#123;self.nf&#125;</span> <span class="hljs-subst">&#123;path&#125;</span>: &#x27;</span><br><br>        <span class="hljs-keyword">if</span> self.transforms:<br>            im = self.transforms(im0)  <span class="hljs-comment"># transforms</span><br>        <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 填充resize，将其原图变为resize后的图片</span><br>            im = letterbox(im0, self.img_size, stride=self.stride, auto=self.auto)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># padded resize</span><br>            <br>            <span class="hljs-comment"># 转换，习惯把通道数放置在前面</span><br>            im = im.transpose((<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))[::-<span class="hljs-number">1</span>]  <span class="hljs-comment"># HWC to CHW, BGR to RGB</span><br>            im = np.ascontiguousarray(im)  <span class="hljs-comment"># contiguous</span><br><br><span class="hljs-comment"># 返回最后的路径、resize + pad的图片、原始图片、视频对象、s为字符串（后续方便输出）</span><br>        <span class="hljs-keyword">return</span> path, im, im0, self.cap, s<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">new_video</span>(<span class="hljs-params">self, path</span>):<br>        <span class="hljs-comment"># 记录帧数</span><br>        self.frame = <span class="hljs-number">0</span><br>        <span class="hljs-comment"># 初始化视频对象</span><br>        self.cap = cv2.VideoCapture(path)<br>        <span class="hljs-comment"># 得到视频文件中的总帧数</span><br>        self.frames = <span class="hljs-built_in">int</span>(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_cv2_rotate</span>(<span class="hljs-params">self, im</span>):<br>       <span class="hljs-comment"># Rotate a cv2 video manually</span><br>       <span class="hljs-keyword">if</span> self.orientation == <span class="hljs-number">0</span>:<br>           <span class="hljs-keyword">return</span> cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)<br>       <span class="hljs-keyword">elif</span> self.orientation == <span class="hljs-number">180</span>:<br>           <span class="hljs-keyword">return</span> cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE)<br>       <span class="hljs-keyword">elif</span> self.orientation == <span class="hljs-number">90</span>:<br>           <span class="hljs-keyword">return</span> cv2.rotate(im, cv2.ROTATE_180)<br>       <span class="hljs-keyword">return</span> im<br>       <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.nf  <span class="hljs-comment"># number of files</span><br></code></pre></td></tr></table></figure><p>其中使用了一个填充函数<code>letterbox</code>，例如<code>im = letterbox(im0, self.img_size, stride=self.stride, auto=self.auto)[0]</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将图片缩放到指定大小</span><br><br><span class="hljs-comment"># img: 原图 hwc</span><br><span class="hljs-comment"># new_shape: 缩放后的最长边大小</span><br><span class="hljs-comment"># color: 填充的颜色</span><br><br><span class="hljs-comment"># auto: True，保证缩放后的图片保持原图的比例 即 将原图最长边缩放到指定大小，再将原图较短边按原图比例缩放（不会失真）</span><br>  <span class="hljs-comment"># False，将原图最长边缩放到指定大小，再将原图较短边按原图比例缩放,最后将较短边两边pad操作缩放到最长边大小（不会失真）</span><br><br><span class="hljs-comment"># scale_fill: True 直接将原图resize到指定的大小，没有pad操作（失真）</span><br><br><span class="hljs-comment"># scale_up: True  对于小于new_shape的原图进行缩放,大于的不变</span><br>          <span class="hljs-comment"># False 对于大于new_shape的原图进行缩放,小于的不变</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">letterbox</span>(<span class="hljs-params">im, new_shape=(<span class="hljs-params"><span class="hljs-number">640</span>, <span class="hljs-number">640</span></span>), color=(<span class="hljs-params"><span class="hljs-number">114</span>, <span class="hljs-number">114</span>, <span class="hljs-number">114</span></span>), auto=<span class="hljs-literal">True</span>, scaleFill=<span class="hljs-literal">False</span>, scaleup=<span class="hljs-literal">True</span>, stride=<span class="hljs-number">32</span></span>):<br>    <span class="hljs-comment"># （1000，810）</span><br>    shape = im.shape[:<span class="hljs-number">2</span>]  <span class="hljs-comment"># current shape [height, width]</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(new_shape, <span class="hljs-built_in">int</span>):<br>    <span class="hljs-comment"># (512, 512)</span><br>        new_shape = (new_shape, new_shape)<br><br>    <span class="hljs-comment"># 也就是640 /1000 以及 640 / 810 求出最小</span><br>    <span class="hljs-comment"># 对于大于new_shape（r&lt;1）的原图进行缩放,小于new_shape（r&gt;1）的不变</span><br>    <span class="hljs-comment"># 总的来说，就是按照长边缩放，短边补零</span><br>    r = <span class="hljs-built_in">min</span>(new_shape[<span class="hljs-number">0</span>] / shape[<span class="hljs-number">0</span>], new_shape[<span class="hljs-number">1</span>] / shape[<span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> scaleup:  <span class="hljs-comment"># only scale down, do not scale up (for better val mAP)</span><br>    <span class="hljs-comment"># 只进行下采样 因为上采样会让图片模糊</span><br>        r = <span class="hljs-built_in">min</span>(r, <span class="hljs-number">1.0</span>)<br><br>    <span class="hljs-comment"># Compute padding</span><br>    <span class="hljs-comment"># 此时按照长边的比例进行缩放</span><br>    ratio = r, r  <span class="hljs-comment"># width, height ratios，(1, 1)</span><br>    <span class="hljs-comment"># 缩放过后的图片尺寸为width, height：（480，640）</span><br>    <span class="hljs-comment"># shape[1]在前，shape[0]在后，大致将其宽和高颠倒过来</span><br>    new_unpad = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">round</span>(shape[<span class="hljs-number">1</span>] * r)), <span class="hljs-built_in">int</span>(<span class="hljs-built_in">round</span>(shape[<span class="hljs-number">0</span>] * r))<br>    dw, dh = new_shape[<span class="hljs-number">1</span>] - new_unpad[<span class="hljs-number">0</span>], new_shape[<span class="hljs-number">0</span>] - new_unpad[<span class="hljs-number">1</span>]  <span class="hljs-comment"># 用原图减去缩放后的图，也就是160，0</span><br>    <br>    <span class="hljs-comment"># 输入的只要是32倍的系数，就可输入到图形预测</span><br>    <span class="hljs-comment"># 保证原图比例不变，将图像最大边缩放到指定大小</span><br>    <span class="hljs-keyword">if</span> auto:  <span class="hljs-comment"># minimum rectangle</span><br>    <span class="hljs-comment"># 取余操作可保证padding后的图片是32的整数倍</span><br>        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  <span class="hljs-comment"># wh padding</span><br>    <span class="hljs-comment"># stretch 直接将图片缩放到指定尺寸</span><br>    <span class="hljs-keyword">elif</span> scaleFill:  <span class="hljs-comment"># stretch</span><br>        dw, dh = <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span><br>        new_unpad = (new_shape[<span class="hljs-number">1</span>], new_shape[<span class="hljs-number">0</span>])<br>        ratio = new_shape[<span class="hljs-number">1</span>] / shape[<span class="hljs-number">1</span>], new_shape[<span class="hljs-number">0</span>] / shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># width, height ratios</span><br><br><span class="hljs-comment"># 此时的宽和高是32的倍数，所以不用进行填充</span><br>    dw /= <span class="hljs-number">2</span>  <span class="hljs-comment"># divide padding into 2 sides</span><br>    dh /= <span class="hljs-number">2</span><br>    <br><span class="hljs-comment"># shape:[h, w]  new_unpad:[w, h]</span><br>    <span class="hljs-keyword">if</span> shape[::-<span class="hljs-number">1</span>] != new_unpad:  <span class="hljs-comment"># resize</span><br>    <span class="hljs-comment"># 将原图resize到new_unpad（长边相同，比例相同的新图）</span><br>        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)<br>    <span class="hljs-comment"># 计算上下两侧的padding  # top=0 bottom=0     </span><br>    top, bottom = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">round</span>(dh - <span class="hljs-number">0.1</span>)), <span class="hljs-built_in">int</span>(<span class="hljs-built_in">round</span>(dh + <span class="hljs-number">0.1</span>))<br>    <span class="hljs-comment"># 计算左右两侧的padding  # left=0 right=0</span><br>    left, right = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">round</span>(dw - <span class="hljs-number">0.1</span>)), <span class="hljs-built_in">int</span>(<span class="hljs-built_in">round</span>(dw + <span class="hljs-number">0.1</span>))<br>    <span class="hljs-comment"># 也就是此处的值没有padding</span><br>    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  <span class="hljs-comment"># add border</span><br><br><span class="hljs-comment"># img: (480, 640, 3)</span><br>    <span class="hljs-keyword">return</span> im, ratio, (dw, dh)<br></code></pre></td></tr></table></figure><p>返回到主体函数即为 <code>640 * 480 * 3</code>。</p><h2 id="推理代码"><a href="#推理代码" class="headerlink" title="推理代码"></a>推理代码</h2><p>推理代码作为核心部分，会通过for循环对加载的数据进行遍历，一帧一帧地推理，进行NMS非极大值抑制、绘制bounding box、预测类别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 通过运行一次推理来预热模型（内部初始化一张空白图预热模型）</span><br>model.warmup(imgsz=(<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> pt <span class="hljs-keyword">or</span> model.triton <span class="hljs-keyword">else</span> bs, <span class="hljs-number">3</span>, *imgsz))  <br><br><br>seen, windows, dt = <span class="hljs-number">0</span>, [], (Profile(device=device), Profile(device=device), Profile(device=device))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;seen:<span class="hljs-subst">&#123;seen&#125;</span>,windows:<span class="hljs-subst">&#123;windows&#125;</span>,dt:<span class="hljs-subst">&#123;dt&#125;</span>&#x27;</span>) <span class="hljs-comment"># seen 0 windows [] dt (Profile(device=&#x27;cpu&#x27;), Profile(device=&#x27;cpu&#x27;), Profile(device=&#x27;cpu&#x27;))</span><br><br><span class="hljs-comment"># dataset数据集遍历，path为图片路径</span><br><span class="hljs-comment"># im为压缩后的图片， 640 * 480 * 3</span><br><span class="hljs-comment"># im0s为原图，1080 * 810 </span><br><span class="hljs-comment"># vid_cap 空</span><br><span class="hljs-comment"># s 打印图片的信息</span><br><span class="hljs-keyword">for</span> path, im, im0s, vid_cap, s <span class="hljs-keyword">in</span> dataset:<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;path:<span class="hljs-subst">&#123;path&#125;</span>&#x27;</span>) <span class="hljs-comment"># path data/images/bus.jpg</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;im:<span class="hljs-subst">&#123;im&#125;</span>&#x27;</span>) <span class="hljs-comment"># [[[]]] </span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;im0s:<span class="hljs-subst">&#123;im0s&#125;</span>&#x27;</span>) <span class="hljs-comment"># [[[]]]</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;vid_cap:<span class="hljs-subst">&#123;vid_cap&#125;</span>&#x27;</span>) <span class="hljs-comment"># None</span><br>    <br>    <span class="hljs-keyword">with</span> dt[<span class="hljs-number">0</span>]:<br>    <span class="hljs-comment"># numpy array to tensor and device</span><br>    <span class="hljs-comment"># 在模型中运算，需要转换成pytorch，从numpy转成pytorch，再将其数据放入cpu或者gpu中</span><br>        im = torch.from_numpy(im).to(model.device)<br>        <span class="hljs-comment"># 半精度训练 uint8 to fp16/32</span><br>        im = im.half() <span class="hljs-keyword">if</span> model.fp16 <span class="hljs-keyword">else</span> im.<span class="hljs-built_in">float</span>() <br>        <span class="hljs-comment"># 归一化</span><br>        im /= <span class="hljs-number">255</span>  <span class="hljs-comment"># 0 - 255 to 0.0 - 1.0</span><br><span class="hljs-comment"># 图片为3维(RGB)，在前面添加一个维度，batch_size=1。本身输入网络的图片需要是4维， [batch_size, channel, w, h]</span><br><span class="hljs-comment"># [1，3，640，480]</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(im.shape) == <span class="hljs-number">3</span>:<br>            im = im[<span class="hljs-literal">None</span>]  <span class="hljs-comment"># expand for batch dim</span><br>            <br>        <span class="hljs-comment"># 检查模型的xml属性是否为真，且第一个维度是否大于1</span><br>        <span class="hljs-comment"># 如果条件满足，会使用torch.chunk函数将im按行分割成多个张量，并将这些张量存储在名为ims的列表中</span><br>        <span class="hljs-keyword">if</span> model.xml <span class="hljs-keyword">and</span> im.shape[<span class="hljs-number">0</span>] &gt; <span class="hljs-number">1</span>:<br>            ims = torch.chunk(im, im.shape[<span class="hljs-number">0</span>], <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># Inference</span><br>    <span class="hljs-comment"># visualize 一开始为false，如果为true则对应会保存一些特征</span><br>    <span class="hljs-keyword">with</span> dt[<span class="hljs-number">1</span>]:<br>        visualize = increment_path(save_dir / Path(path).stem, mkdir=<span class="hljs-literal">True</span>) <span class="hljs-keyword">if</span> visualize <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>        <span class="hljs-comment"># 数据的推断增强，但也会降低速度。最后检测出的结果为18900个框</span><br>        <span class="hljs-comment"># 结果为[1，18900，85]，预训练有85个预测信息，4个坐标 + 1个置信度 +80各类别</span><br>        pred = model(im, augment=augment, visualize=visualize)<br><br><span class="hljs-comment"># NMS非极大值阈值过滤</span><br><span class="hljs-comment"># conf_thres: 置信度阈值；iou_thres: iou阈值</span><br>    <span class="hljs-comment"># classes: 是否只保留特定的类别 默认为None</span><br>    <span class="hljs-comment"># agnostic_nms: 进行nms是否也去除不同类别之间的框 默认False</span><br>    <span class="hljs-comment"># max_det: 每张图片的最大目标个数 默认1000，超过1000就会过滤</span><br>    <span class="hljs-comment"># pred: [1,num_obj,6] = [1,5,6] 这里的预测信息pred还是相对于 img_size(640)。本身一开始18900变为了5个框，6为每个框的 x左右y左右 以及 置信度 类别值</span><br>    <span class="hljs-keyword">with</span> dt[<span class="hljs-number">2</span>]:<br>        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)<br>        <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;pred:<span class="hljs-subst">&#123;pred&#125;</span>&#x27;</span>) <span class="hljs-comment"># 张量，shape为(1, 1000, 6)，1000为预测框的数量，6为每个预测框的信息（x1,y1,x2,y2,confidence,class）</span><br><br><br></code></pre></td></tr></table></figure><p><code>Profile()</code>是ultralytics定义的一个类，是一个简单的上下文管理器（Context Manager）装饰器（Decorator），用于在代码中测量运行时间。内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Profile</span>(contextlib.ContextDecorator):<br>    <span class="hljs-comment"># YOLOv5 Profile class. Usage: @Profile() decorator or &#x27;with Profile():&#x27; context manager</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, t=<span class="hljs-number">0.0</span>, device: torch.device = <span class="hljs-literal">None</span></span>):<br>        self.t = t<br>        self.device = device<br>        self.cuda = <span class="hljs-built_in">bool</span>(device <span class="hljs-keyword">and</span> <span class="hljs-built_in">str</span>(device).startswith(<span class="hljs-string">&quot;cuda&quot;</span>))<br><br><span class="hljs-comment"># 被调用当进入 with 语句块时，它记录当前时间戳，并将其保存在 self.start 属性中</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__enter__</span>(<span class="hljs-params">self</span>):<br>        self.start = self.time()<br>        <span class="hljs-keyword">return</span> self<br><span class="hljs-comment"># 被调用当退出 with 语句块时，计算从进入到退出的时间差，保存在 self.dt 中，并将其累积到 self.t 中</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__exit__</span>(<span class="hljs-params">self, <span class="hljs-built_in">type</span>, value, traceback</span>):<br>        self.dt = self.time() - self.start  <span class="hljs-comment"># delta-time</span><br>        self.t += self.dt  <span class="hljs-comment"># accumulate dt</span><br>        <br><span class="hljs-comment"># 返回当前时间戳，如果 self.cuda 为 True（即运行在 CUDA 设备上），则在返回前调用了 torch.cuda.synchronize 以确保测量的时间准确</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">time</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">if</span> self.cuda:<br>            torch.cuda.synchronize(self.device)<br>        <span class="hljs-keyword">return</span> time.time()<br></code></pre></td></tr></table></figure><p>核心代码中，包含一个预热函数<code>warmup</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 通过运行一次推理来预热模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">warmup</span>(<span class="hljs-params">self, imgsz=(<span class="hljs-params"><span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">640</span>, <span class="hljs-number">640</span></span>)</span>):<br>    <span class="hljs-comment"># Warmup model by running inference once</span><br>    warmup_types = self.pt, self.jit, self.onnx, self.engine, self.saved_model, self.pb, self.triton<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(warmup_types) <span class="hljs-keyword">and</span> (self.device.<span class="hljs-built_in">type</span> != <span class="hljs-string">&#x27;cpu&#x27;</span> <span class="hljs-keyword">or</span> self.triton):<br>        im = torch.empty(*imgsz, dtype=torch.half <span class="hljs-keyword">if</span> self.fp16 <span class="hljs-keyword">else</span> torch.<span class="hljs-built_in">float</span>, device=self.device)  <span class="hljs-comment"># input</span><br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span> <span class="hljs-keyword">if</span> self.jit <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>):  <br>            self.forward(im)  <span class="hljs-comment"># warmup</span><br></code></pre></td></tr></table></figure><p>接下来是保存为csv文件的代码，只有当前面选择<code>save_csv</code>时才会执行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Define the path for the CSV file</span><br>csv_path = save_dir / <span class="hljs-string">&quot;predictions.csv&quot;</span><br><br><span class="hljs-comment"># Create or append to the CSV file</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">write_to_csv</span>(<span class="hljs-params">image_name, prediction, confidence</span>):<br>    data = &#123;<span class="hljs-string">&quot;Image Name&quot;</span>: image_name, <span class="hljs-string">&quot;Prediction&quot;</span>: prediction, <span class="hljs-string">&quot;Confidence&quot;</span>: confidence&#125;<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(csv_path, mode=<span class="hljs-string">&quot;a&quot;</span>, newline=<span class="hljs-string">&quot;&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        writer = csv.DictWriter(f, fieldnames=data.keys())<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> csv_path.is_file():<br>            writer.writeheader()<br>        writer.writerow(data)<br></code></pre></td></tr></table></figure><p>继续处理推理信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Process predictions</span><br><br><span class="hljs-comment"># 对每张图片进行处理，将pred(相对img_size 640)映射回原图img0 size</span><br><span class="hljs-comment"># 此处的det，表示5个检测框中的信息，i是每个batch的信息</span><br><span class="hljs-keyword">for</span> i, det <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pred): <br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;正在进入Pred迭代...&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;i:<span class="hljs-subst">&#123;i&#125;</span>,det:<span class="hljs-subst">&#123;det&#125;</span>&#x27;</span>) <span class="hljs-comment"># i:0</span><br>    <br><span class="hljs-comment"># 每处理一张图片，就会加1 </span><br>    seen += <span class="hljs-number">1</span><br>    <span class="hljs-comment"># 输入源是网页，对应取出dataset中的一张照片</span><br>    <span class="hljs-keyword">if</span> webcam:  <span class="hljs-comment"># batch_size &gt;= 1</span><br>        p, im0, frame = path[i], im0s[i].copy(), dataset.count<br>        s += <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;i&#125;</span>: &#x27;</span><br>    <span class="hljs-keyword">else</span>:<br>    <span class="hljs-comment"># p为当前图片或者视频绝对路径</span><br>    <span class="hljs-comment"># im0原始图片</span><br>    <span class="hljs-comment"># frame: 初始为0  可能是当前图片属于视频中的第几帧</span><br>        p, im0, frame = path, im0s.copy(), <span class="hljs-built_in">getattr</span>(dataset, <span class="hljs-string">&#x27;frame&#x27;</span>, <span class="hljs-number">0</span>)<br>        <br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;p:<span class="hljs-subst">&#123;p&#125;</span>,im0:<span class="hljs-subst">&#123;im0&#125;</span>,frame:<span class="hljs-subst">&#123;frame&#125;</span>&#x27;</span>) <span class="hljs-comment"># p data/images/bus.jpg im0 [[[[]]]] frame 0</span><br><br></code></pre></td></tr></table></figure><p>上面这段代码，实际上是在迭代<code>pred</code>这个对象。<code>pred</code>是什么呢？就是模型输出的一个batch里的预测数据，当bs为1，或者只有一张图片时，这个pred就只是由一个多维张量组成的列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python">   p = Path(p)  <span class="hljs-comment"># to Path</span><br>   <span class="hljs-comment"># 图片的保存路径</span><br>   save_path = <span class="hljs-built_in">str</span>(save_dir / p.name)  <span class="hljs-comment"># im.jpg</span><br>   <span class="hljs-comment"># txt 保存路径（保存预测框的坐标）</span><br>   txt_path = <span class="hljs-built_in">str</span>(save_dir / <span class="hljs-string">&#x27;labels&#x27;</span> / p.stem) + (<span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">if</span> dataset.mode == <span class="hljs-string">&#x27;image&#x27;</span> <span class="hljs-keyword">else</span> <span class="hljs-string">f&#x27;_<span class="hljs-subst">&#123;frame&#125;</span>&#x27;</span>)  <span class="hljs-comment"># im.txt</span><br><br><span class="hljs-comment"># 输出图片shape (w, h)</span><br>   s += <span class="hljs-string">&#x27;%gx%g &#x27;</span> % im.shape[<span class="hljs-number">2</span>:]  <span class="hljs-comment"># print string</span><br>   <span class="hljs-comment"># gn = [w, h, w, h]  用于后面的归一化</span><br>   gn = torch.tensor(im0.shape)[[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]]  <span class="hljs-comment"># normalization gain whwh</span><br>   <span class="hljs-comment"># imc: for save_crop 在save_crop中使用</span><br>   imc = im0.copy() <span class="hljs-keyword">if</span> save_crop <span class="hljs-keyword">else</span> im0  <span class="hljs-comment"># for save_crop</span><br><br><span class="hljs-comment"># 自定义的绘图工具，入参是图片，画图检测框的粗细，以及数字-标签对应的字典</span><br>   annotator = Annotator(im0, line_width=line_thickness, example=<span class="hljs-built_in">str</span>(names))<br>   <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(det):<br>       <br>       <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;正在进入scale_boxes...&#x27;</span>)<br>       <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;det:<span class="hljs-subst">&#123;det&#125;</span>&#x27;</span>) <span class="hljs-comment"># [[],[],[]] 张量，每个子列表为一个预测框的信息（x1,y1,x2,y2,confidence,class）</span><br><br>       <span class="hljs-comment"># Rescale boxes from img_size to im0 size</span><br>       <span class="hljs-comment"># 将预测信息（相对img_size 640）映射回原图 img0 size</span><br>       det[:, :<span class="hljs-number">4</span>] = scale_boxes(im.shape[<span class="hljs-number">2</span>:], det[:, :<span class="hljs-number">4</span>], im0.shape).<span class="hljs-built_in">round</span>()<br>       <br>       <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;已经完成了scale_boxes...&#x27;</span>)<br>       <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;det:<span class="hljs-subst">&#123;det&#125;</span>&#x27;</span>) <span class="hljs-comment"># [[],[],[]] 张量，每个子列表为一个预测框的信息（x1,y1,x2,y2,confidence,class）</span><br><br>       <span class="hljs-comment"># Print results</span><br>       <span class="hljs-comment"># 统计每个框的类别</span><br>       <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> det[:, <span class="hljs-number">5</span>].unique():<br>           n = (det[:, <span class="hljs-number">5</span>] == c).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># detections per class</span><br>           s += <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;n&#125;</span> <span class="hljs-subst">&#123;names[<span class="hljs-built_in">int</span>(c)]&#125;</span><span class="hljs-subst">&#123;<span class="hljs-string">&#x27;s&#x27;</span> * (n &gt; <span class="hljs-number">1</span>)&#125;</span>, &quot;</span>  <span class="hljs-comment"># add to string</span><br><br>       <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;s:<span class="hljs-subst">&#123;s&#125;</span>&#x27;</span>) <span class="hljs-comment"># s image 1/2 C:\Users\ZeroLoveSeA\Desktop\学习\CV\yolov5\data\images\bus.jpg: 640x480 4 persons, 1 bus</span><br></code></pre></td></tr></table></figure><h2 id="绘制预测图"><a href="#绘制预测图" class="headerlink" title="绘制预测图"></a>绘制预测图</h2><p>前面得到了预测的结果<code>det</code>，也就是一个多张量的列表，其中每个子列表为一个预测框的信息（x1,y1,x2,y2,confidence,class），接下来就需要遍历这个列表里面的每一个预测框，在一张图片上绘图。</p><p>这里用到了<code>reversed</code>这个方法，用来将一个张量里的所有元素都进行倒序排列。我理解这样可以进行后续的操作<code>for *xyxy, conf, cls in reversed(det)</code>，可以直接拿到最后两位作为置信度和分类标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python">        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;reversed(det):<span class="hljs-subst">&#123;<span class="hljs-built_in">reversed</span>(det)&#125;</span>&#x27;</span>) <span class="hljs-comment"># 反向张量，每个子列表为一个预测框的信息(class, confidence, y2,y1,x2,x1)</span><br><br>        <span class="hljs-comment"># 保存预测信息: txt、img0上画框、crop_img</span><br>        <span class="hljs-comment"># 迭代每个预测框，*xyxy是前四位，conf是第五位，cls是第六位</span><br>        <span class="hljs-keyword">for</span> *xyxy, conf, cls <span class="hljs-keyword">in</span> <span class="hljs-built_in">reversed</span>(det):<br>        <span class="hljs-comment"># 将每个图片的预测信息分别存入save_dir/labels下的xxx.txt中 每行: class_id+score+xywh</span><br>            <span class="hljs-keyword">if</span> save_txt:  <span class="hljs-comment"># Write to file</span><br>            <span class="hljs-comment"># 将xyxy(左上角 + 右下角)格式转换为xywh(中心的 + 宽高)格式 并除以gn(whwh)做归一化 转为list再保存</span><br>                xywh = (xyxy2xywh(torch.tensor(xyxy).view(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>)) / gn).view(-<span class="hljs-number">1</span>).tolist()  <span class="hljs-comment"># normalized xywh</span><br>                line = (cls, *xywh, conf) <span class="hljs-keyword">if</span> save_conf <span class="hljs-keyword">else</span> (cls, *xywh)  <span class="hljs-comment"># label format</span><br>                <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;txt_path&#125;</span>.txt&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                    f.write((<span class="hljs-string">&#x27;%g &#x27;</span> * <span class="hljs-built_in">len</span>(line)).rstrip() % line + <span class="hljs-string">&#x27;\n&#x27;</span>)<br><br><span class="hljs-comment"># 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下</span><br>            <span class="hljs-keyword">if</span> save_img <span class="hljs-keyword">or</span> save_crop <span class="hljs-keyword">or</span> view_img:  <span class="hljs-comment"># Add bbox to image</span><br>                c = <span class="hljs-built_in">int</span>(cls)  <span class="hljs-comment"># integer class</span><br>                label = <span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> hide_labels <span class="hljs-keyword">else</span> (names[c] <span class="hljs-keyword">if</span> hide_conf <span class="hljs-keyword">else</span> <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;names[c]&#125;</span> <span class="hljs-subst">&#123;conf:<span class="hljs-number">.2</span>f&#125;</span>&#x27;</span>)<br>                <br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;正在绘制框...&#x27;</span>)<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;xyxy:<span class="hljs-subst">&#123;xyxy&#125;</span>,label:<span class="hljs-subst">&#123;label&#125;</span>,color:<span class="hljs-subst">&#123;colors(c, <span class="hljs-literal">True</span>)&#125;</span>&#x27;</span>)<br>                <span class="hljs-comment"># xyxy:[tensor(0.), tensor(552.), tensor(68.), tensor(875.)],label:person 0.53,color:(56, 56, 255)</span><br> <br> <span class="hljs-comment"># 使用了自定义库中的box_label方法来进行绘图，color中的c参数是cls的个数</span><br>                annotator.box_label(xyxy, label, color=colors(c, <span class="hljs-literal">True</span>))<br>           <span class="hljs-comment"># 如果需要就将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下</span><br>            <span class="hljs-keyword">if</span> save_crop:<br>                save_one_box(xyxy, imc, file=save_dir / <span class="hljs-string">&#x27;crops&#x27;</span> / names[c] / <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;p.stem&#125;</span>.jpg&#x27;</span>, BGR=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># Stream results</span><br>    im0 = annotator.result()<br>    <span class="hljs-keyword">if</span> view_img:<br>        <span class="hljs-keyword">if</span> platform.system() == <span class="hljs-string">&#x27;Linux&#x27;</span> <span class="hljs-keyword">and</span> p <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> windows:<br>            windows.append(p)<br>            cv2.namedWindow(<span class="hljs-built_in">str</span>(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  <span class="hljs-comment"># allow window resize (Linux)</span><br>            cv2.resizeWindow(<span class="hljs-built_in">str</span>(p), im0.shape[<span class="hljs-number">1</span>], im0.shape[<span class="hljs-number">0</span>])<br>        <span class="hljs-comment"># 通过imshow显示出框</span><br>        cv2.imshow(<span class="hljs-built_in">str</span>(p), im0)<br>        cv2.waitKey(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 1 millisecond</span><br><br>    <span class="hljs-comment"># 是否需要保存图片或视频（检测后的图片/视频 里面已经被我们画好了框的） img0</span><br>    <span class="hljs-keyword">if</span> save_img:<br>        <span class="hljs-keyword">if</span> dataset.mode == <span class="hljs-string">&#x27;image&#x27;</span>:<br>            cv2.imwrite(save_path, im0)<br>        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># &#x27;video&#x27; or &#x27;stream&#x27;</span><br>            <span class="hljs-keyword">if</span> vid_path[i] != save_path:  <span class="hljs-comment"># new video</span><br>                vid_path[i] = save_path<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(vid_writer[i], cv2.VideoWriter):<br>                    vid_writer[i].release()  <span class="hljs-comment"># release previous video writer</span><br>                <span class="hljs-keyword">if</span> vid_cap:  <span class="hljs-comment"># video</span><br>                    fps = vid_cap.get(cv2.CAP_PROP_FPS)<br>                    w = <span class="hljs-built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))<br>                    h = <span class="hljs-built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))<br>                <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># stream</span><br>                    fps, w, h = <span class="hljs-number">30</span>, im0.shape[<span class="hljs-number">1</span>], im0.shape[<span class="hljs-number">0</span>]<br>                save_path = <span class="hljs-built_in">str</span>(Path(save_path).with_suffix(<span class="hljs-string">&#x27;.mp4&#x27;</span>))  <span class="hljs-comment"># force *.mp4 suffix on results videos</span><br>                vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*<span class="hljs-string">&#x27;mp4v&#x27;</span>), fps, (w, h))<br>            vid_writer[i].write(im0)<br><br><span class="hljs-comment"># Print time (inference-only)</span><br>LOGGER.info(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;s&#125;</span><span class="hljs-subst">&#123;<span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(det) <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;(no detections), &#x27;</span>&#125;</span><span class="hljs-subst">&#123;dt[<span class="hljs-number">1</span>].dt * <span class="hljs-number">1E3</span>:<span class="hljs-number">.1</span>f&#125;</span>ms&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="打印信息"><a href="#打印信息" class="headerlink" title="打印信息"></a>打印信息</h2><p>最后输出打印的信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># seen为预测图片总数，dt为耗时时间，求出平均时间</span><br>t = <span class="hljs-built_in">tuple</span>(x.t / seen * <span class="hljs-number">1E3</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> dt)  <span class="hljs-comment"># speeds per image</span><br>LOGGER.info(<span class="hljs-string">f&#x27;Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape <span class="hljs-subst">&#123;(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, *imgsz)&#125;</span>&#x27;</span> % t)<br><br><span class="hljs-comment"># 保存预测的label信息 xywh等   save_txt</span><br><span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">or</span> save_img:<br>    s = <span class="hljs-string">f&quot;\n<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(<span class="hljs-built_in">list</span>(save_dir.glob(<span class="hljs-string">&#x27;labels/*.txt&#x27;</span>)))&#125;</span> labels saved to <span class="hljs-subst">&#123;save_dir / <span class="hljs-string">&#x27;labels&#x27;</span>&#125;</span>&quot;</span> <span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;&#x27;</span><br>    LOGGER.info(<span class="hljs-string">f&quot;Results saved to <span class="hljs-subst">&#123;colorstr(<span class="hljs-string">&#x27;bold&#x27;</span>, save_dir)&#125;</span><span class="hljs-subst">&#123;s&#125;</span>&quot;</span>)<br><span class="hljs-keyword">if</span> update:<br><span class="hljs-comment"># strip_optimizer函数将optimizer从ckpt中删除  更新模型</span><br>    strip_optimizer(weights[<span class="hljs-number">0</span>])  <span class="hljs-comment"># update model (to fix SourceChangeWarning)</span><br></code></pre></td></tr></table></figure><h2 id="参数导入"><a href="#参数导入" class="headerlink" title="参数导入"></a>参数导入</h2><p>这里没啥好说的，单纯导入参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_opt</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;--weights&quot;</span>, nargs=<span class="hljs-string">&quot;+&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&quot;yolov5s.pt&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;model path or triton URL&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--source&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&quot;data/images&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;file/dir/URL/glob/screen/0(webcam)&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--data&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&quot;data/coco128.yaml&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;(optional) dataset.yaml path&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--imgsz&quot;</span>, <span class="hljs-string">&quot;--img&quot;</span>, <span class="hljs-string">&quot;--img-size&quot;</span>, nargs=<span class="hljs-string">&quot;+&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=[<span class="hljs-number">640</span>], <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;inference size h,w&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--conf-thres&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.25</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;confidence threshold&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--iou-thres&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.45</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;NMS IoU threshold&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--max-det&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1000</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;maximum detections per image&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--device&quot;</span>, default=<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;cuda device, i.e. 0 or 0,1,2,3 or cpu&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--view-img&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;show results&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--save-txt&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save results to *.txt&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--save-csv&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save results in CSV format&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--save-conf&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save confidences in --save-txt labels&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--save-crop&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save cropped prediction boxes&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--nosave&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;do not save images/videos&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--classes&quot;</span>, nargs=<span class="hljs-string">&quot;+&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;filter by class: --classes 0, or --classes 0 2 3&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--agnostic-nms&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;class-agnostic NMS&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--augment&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;augmented inference&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--visualize&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;visualize features&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--update&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;update all models&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--project&quot;</span>, default=ROOT / <span class="hljs-string">&quot;runs/detect&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save results to project/name&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--name&quot;</span>, default=<span class="hljs-string">&quot;exp&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;save results to project/name&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--exist-ok&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;existing project/name ok, do not increment&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--line-thickness&quot;</span>, default=<span class="hljs-number">3</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;bounding box thickness (pixels)&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--hide-labels&quot;</span>, default=<span class="hljs-literal">False</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;hide labels&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--hide-conf&quot;</span>, default=<span class="hljs-literal">False</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;hide confidences&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--half&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;use FP16 half-precision inference&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--dnn&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;use OpenCV DNN for ONNX inference&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--vid-stride&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;video frame-rate stride&quot;</span>)<br>    opt = parser.parse_args()<br>    opt.imgsz *= <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(opt.imgsz) == <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>  <span class="hljs-comment"># expand</span><br>    print_args(<span class="hljs-built_in">vars</span>(opt))<br>    <span class="hljs-keyword">return</span> opt<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">opt</span>):<br><span class="hljs-comment"># 检查是否安装依赖项</span><br>    check_requirements(ROOT / <span class="hljs-string">&quot;requirements.txt&quot;</span>, exclude=(<span class="hljs-string">&quot;tensorboard&quot;</span>, <span class="hljs-string">&quot;thop&quot;</span>)) <br>    run(**<span class="hljs-built_in">vars</span>(opt))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    opt = parse_opt()<br>    main(opt)<br></code></pre></td></tr></table></figure><p>整体看下来，代码逻辑是比较清晰易懂的。记得我第一次看这个代码的时候，被里面很多python的用法都吓到了，现在回过头看看，并不是很复杂，难点主要在怎么对张量进行变换。</p><p>2024&#x2F;1&#x2F;21 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>CV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CV</tag>
      
      <tag>工程实践</tag>
      
      <tag>Yolo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>工程实践：使用Docker打包自己的项目</title>
    <link href="/2024/01/19/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E4%BD%BF%E7%94%A8Docker%E6%89%93%E5%8C%85%E8%87%AA%E5%B7%B1%E7%9A%84%E9%A1%B9%E7%9B%AE/"/>
    <url>/2024/01/19/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9A%E4%BD%BF%E7%94%A8Docker%E6%89%93%E5%8C%85%E8%87%AA%E5%B7%B1%E7%9A%84%E9%A1%B9%E7%9B%AE/</url>
    
    <content type="html"><![CDATA[<p>Docker的重要性是老生常谈的话题了，无非就是那些工程部署上的好处。由于之前对Linux不熟悉，所以基本没有接触过它，最近工作中正好用到了，所以干脆研究一下。</p><h1 id="项目路径设置"><a href="#项目路径设置" class="headerlink" title="项目路径设置"></a>项目路径设置</h1><p>首先，我们要了解项目的路径结构是什么样的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">/project-root<br>│<br>├── Dockerfile <span class="hljs-comment"># 将要创建的Dockerfile</span><br>├── app.py <span class="hljs-comment"># 项目文件</span><br>├── requirements.txt <span class="hljs-comment"># 依赖项清单</span><br>└── downloaded-packages/ <span class="hljs-comment"># 无网环境下用于迁移环境的安装包</span><br><br></code></pre></td></tr></table></figure><h1 id="打包Docker容器"><a href="#打包Docker容器" class="headerlink" title="打包Docker容器"></a>打包Docker容器</h1><p>要将一个本地的项目打包成Docker容器，首先要创建一个<code>Dockerfile</code>。<code>Dockerfile</code>类似于一个脚本，用于准备环境，并通过路径下的项目文件构建成一个服务。</p><p>我们应在项目根路径下创建一个<code>Dockerfile</code>，以下是一个例子：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用官方的 Python 镜像作为基础</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.8</span><br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><br><span class="hljs-comment"># 复制项目文件到工作目录</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> . /app</span><br><br><span class="hljs-comment"># 安装项目依赖</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install --no-cache-dir -r requirements.txt</span><br><br><span class="hljs-comment"># 暴露应用运行的端口</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">8080</span><br><br><span class="hljs-comment"># 定义容器启动时运行的命令</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;python&quot;</span>, <span class="hljs-string">&quot;app.py&quot;</span>]</span><br></code></pre></td></tr></table></figure><h1 id="构建Docker容器"><a href="#构建Docker容器" class="headerlink" title="构建Docker容器"></a>构建Docker容器</h1><p>下一步是在项目根目录运行终端命令行，构建容器，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t your_image_name:tag .<br></code></pre></td></tr></table></figure><p>这段代码中，<code>your_image_name</code> 是你为容器指定的名称，<code>tag</code> 是容器的标签，<code>.</code> 表示使用当前目录中的 <code>Dockerfile</code>。</p><p>例如<code>docker build -t my_python_app:v1.0 .</code> 其中<code>my_python_app</code> 是容器的名称，<code>v1.0</code> 是版本标签，这有助于进行版本管理。</p><h1 id="运行Docker容器"><a href="#运行Docker容器" class="headerlink" title="运行Docker容器"></a>运行Docker容器</h1><p>在构建完成后，就可以运行容器了，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -p 8080:8080 your_image_name:tag<br></code></pre></td></tr></table></figure><p>以上代码将会将容器的8080端口映射到主机的8080端口，以供用户访问。其中的<code>tag</code>是容器的标签，可以是<code>latest</code>来运行最新的容器。</p><h1 id="向无网环境发送完整Docker"><a href="#向无网环境发送完整Docker" class="headerlink" title="向无网环境发送完整Docker"></a>向无网环境发送完整Docker</h1><p>有的时候，目标环境没有连接外网，这时候就需要进行环境迁移，相关内容可以看我的<a href="https://zerolovesea.github.io/2024/01/17/Linux-Python%E7%8E%AF%E5%A2%83%E8%BF%81%E7%A7%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E5%9C%A8%E6%97%A0%E7%BD%91%E7%8E%AF%E5%A2%83%E4%B8%AD%E8%BF%81%E7%A7%BBPython%E7%8E%AF%E5%A2%83%EF%BC%9F/">上一篇博客</a>，这里简单给出代码：</p><p>首先，在有网环境下载Python包：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip download -r requirements.txt --dest=/path/to/download/directory<br></code></pre></td></tr></table></figure><p>然后在目标环境安装一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install --no-index --find-links=/path/to/downloaded/packages -r requirements.txt<br></code></pre></td></tr></table></figure><p>假设用户将安装包放在根目录的<code>downloaded-packages</code>文件夹下，那么相应的，上面这些操作可以写在<code>Dockerfile</code>里，这样用户就不需要先手动构建环境了：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用官方的 Python 镜像作为基础</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.8</span><br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><br><span class="hljs-comment"># 复制项目文件到工作目录</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> . /app</span><br><br><span class="hljs-comment"># 将位于downloaded-packages的离线包拷贝到镜像的downloaded-packages中</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> downloaded-packages /app/downloaded-packages</span><br><br><span class="hljs-comment"># 安装项目依赖</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install --no-index --find-links=/app/downloaded-packages -r requirements.txt</span><br><br><span class="hljs-comment"># 暴露应用运行的端口</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">8080</span><br><br><span class="hljs-comment"># 定义容器启动时运行的命令</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;python&quot;</span>, <span class="hljs-string">&quot;app.py&quot;</span>]</span><br></code></pre></td></tr></table></figure><p>这样就可以和之前一样构建并运行Docker容器了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t your_image_name:tag .<br><br>docker run -p 8080:8080 your_image_name:tag<br></code></pre></td></tr></table></figure><h1 id="多文件夹项目的容器构建"><a href="#多文件夹项目的容器构建" class="headerlink" title="多文件夹项目的容器构建"></a>多文件夹项目的容器构建</h1><p>有时候，项目结构过于复杂，可以精确的将需要的文件夹移动到容器中，例如Dockerfile可以这么写：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用官方的 Python 镜像作为基础</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.8</span><br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><br><span class="hljs-comment"># 复制需要的项目文件到工作目录</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> src/ /app/src</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> data/ /app/data</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> requirements.txt /app/requirements.txt</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> app.py /app/app.py</span><br><br><span class="hljs-comment"># 将离线包拷贝到镜像中</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> downloaded-packages /app/downloaded-packages</span><br><br><span class="hljs-comment"># 安装项目依赖</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install --no-index --find-links=/app/downloaded-packages -r /app/requirements.txt</span><br><br><span class="hljs-comment"># 暴露应用运行的端口</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">8080</span><br><br><span class="hljs-comment"># 定义容器启动时运行的命令</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;python&quot;</span>, <span class="hljs-string">&quot;/app/app.py&quot;</span>]</span><br><br></code></pre></td></tr></table></figure><h1 id="在容器中修改Python源"><a href="#在容器中修改Python源" class="headerlink" title="在容器中修改Python源"></a>在容器中修改Python源</h1><p>回顾一下，怎么在Python环境修改安装源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip config <span class="hljs-built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple/<br></code></pre></td></tr></table></figure><p>同理，写在Dockerfile就可以了，代码如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用官方的 Python 镜像作为基础</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.8</span><br><br><span class="hljs-comment"># 设置 pip 的源为国内源（例如阿里云）</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip config <span class="hljs-built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple/</span><br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><br><span class="hljs-comment"># 复制项目文件到工作目录</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> . /app</span><br><br><span class="hljs-comment"># 将离线包拷贝到镜像中</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> downloaded-packages /app/downloaded-packages</span><br><br><span class="hljs-comment"># 安装项目依赖</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install --no-index --find-links=/app/downloaded-packages --no-binary=:all: -r requirements.txt</span><br><br><span class="hljs-comment"># 暴露应用运行的端口</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">8080</span><br><br><span class="hljs-comment"># 定义容器启动时运行的命令</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;python&quot;</span>, <span class="hljs-string">&quot;app.py&quot;</span>]</span><br></code></pre></td></tr></table></figure><p>你大概了解了，<code>RUN</code>指令实际上就是在运行命令行。</p><h1 id="实际项目中的Dockerfile"><a href="#实际项目中的Dockerfile" class="headerlink" title="实际项目中的Dockerfile"></a>实际项目中的Dockerfile</h1><p>这里给出一个实际项目中的Dockerfile，来看一下工程实践里是怎么写的：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># 使用官方 Python 3 镜像作为基础镜像</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.11</span>-bookworm<br><br><span class="hljs-comment"># 复制debian-sources.list文件到/etc/apt/sources.list</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./docker/debian-sources.list /etc/apt/sources.list</span><br><br><span class="hljs-comment"># 替换Debian软件包管理器的源，安装需要的镜像</span><br><span class="hljs-comment"># 修改Python安装源</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">rm</span> -rf /etc/apt/sources.list.d/debian.sources \</span><br><span class="language-bash">    &amp;&amp; apt-get update \</span><br><span class="language-bash">    &amp;&amp; apt-get install -y vim \</span><br><span class="language-bash">    &amp;&amp; apt-get install -y libgl1-mesa-glx \</span><br><span class="language-bash">    &amp;&amp; apt-get install -y redis-server \</span><br><span class="language-bash">    &amp;&amp; apt-get install -y nginx \</span><br><span class="language-bash">    \</span><br><span class="language-bash">    &amp;&amp; <span class="hljs-built_in">mkdir</span> -p /root/.pip \</span><br><span class="language-bash">    &amp;&amp; pip config <span class="hljs-built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple/ \ </span><br>    &amp;&amp; echo <span class="hljs-string">&quot;[install]&quot;</span> &gt;&gt; /root/.pip/pip.conf \<br>    &amp;&amp; echo <span class="hljs-string">&quot;trusted-host=mirrors.aliyun.com&quot;</span> &gt;&gt; /root/.pip/pip.conf <br><br><span class="hljs-comment"># 复制前端和Nginx配置文件</span><br><span class="hljs-keyword">COPY</span><span class="language-bash">  --from=behavior-detector-frontend:latest /behavior-detector-admin/dist/ /var/www/html</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./docker/nginx.default.conf /etc/nginx/sites-available/default</span><br><br><span class="hljs-comment"># 设置工作目录</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><span class="hljs-comment"># 复制当前目录下的所有文件到容器的 /app 目录</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./backend /app/</span><br><br><span class="hljs-comment"># 安装项目依赖</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install -r requirements.txt</span><br><br><span class="hljs-comment"># 暴露端口号</span><br><span class="hljs-comment"># 80 前端服务</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">80</span><br><span class="hljs-comment"># python 服务</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">7091</span><br><br><span class="hljs-comment"># 执行bash start.sh prod</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;bash&quot;</span>, <span class="hljs-string">&quot;start.sh&quot;</span>, <span class="hljs-string">&quot;prod&quot;</span>]</span><br></code></pre></td></tr></table></figure><p>2024&#x2F;1&#x2F;19 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>工程实践</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>环境迁移：如何在无网Linux环境中迁移Python环境？</title>
    <link href="/2024/01/17/Linux-Python%E7%8E%AF%E5%A2%83%E8%BF%81%E7%A7%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E5%9C%A8%E6%97%A0%E7%BD%91%E7%8E%AF%E5%A2%83%E4%B8%AD%E8%BF%81%E7%A7%BBPython%E7%8E%AF%E5%A2%83%EF%BC%9F/"/>
    <url>/2024/01/17/Linux-Python%E7%8E%AF%E5%A2%83%E8%BF%81%E7%A7%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E5%9C%A8%E6%97%A0%E7%BD%91%E7%8E%AF%E5%A2%83%E4%B8%AD%E8%BF%81%E7%A7%BBPython%E7%8E%AF%E5%A2%83%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<p>近期的项目中涉及到要在客户环境部署Python环境，通常来说创建虚拟环境，pip install一下依赖库就可以了，不过出于安全管理，客户现场的服务器并没有开启外网，这就带来了难题：如何迁移Python环境？</p><h1 id="克隆环境"><a href="#克隆环境" class="headerlink" title="克隆环境"></a>克隆环境</h1><p>本地虚拟环境迁移可以执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n <span class="hljs-string">&quot;new_env_name&quot;</span> --<span class="hljs-built_in">clone</span> <span class="hljs-string">&quot;old_env_name&quot;</span><br></code></pre></td></tr></table></figure><p>同样，还可以克隆同一网络下的不同机器下的环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n <span class="hljs-string">&quot;new_env_name&quot;</span> --<span class="hljs-built_in">clone</span> ~/path <br></code></pre></td></tr></table></figure><h1 id="导出本地项目依赖库清单"><a href="#导出本地项目依赖库清单" class="headerlink" title="导出本地项目依赖库清单"></a>导出本地项目依赖库清单</h1><p>首先，我们需要在本地的项目中构建一个<code>requirements.txt</code>，也就是依赖项。对于这个需求有两个办法可以实现：</p><ul><li>pip freeze</li><li>pipreqs</li></ul><h2 id="pip-freeze"><a href="#pip-freeze" class="headerlink" title="pip freeze"></a>pip freeze</h2><p>如果每个项目都有自己的虚拟环境，那么就可以在目标项目的根目录下，切换到项目的虚拟环境，并使用以下指令生成依赖库清单：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip freeze &gt; requirements.txt<br></code></pre></td></tr></table></figure><p>这个方法实际上是把这个虚拟环境里的所有包都导出了，所以会导出大量于项目无关的依赖。所以还可以使用另一个工具<code>pipreqs</code>库。</p><h2 id="pipreqs"><a href="#pipreqs" class="headerlink" title="pipreqs"></a>pipreqs</h2><p>首先需要安装<code>pipreqs</code>库。随后需要到项目根目录，执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pipreqs ./<br></code></pre></td></tr></table></figure><p>如果出现编码错误，就需要指定编码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pipreqs ./ --encoding=utf8<br>pipreqs ./ --encoding=<span class="hljs-string">&#x27;iso-8859-1&#x27;</span> <br></code></pre></td></tr></table></figure><h1 id="下载安装包到本地"><a href="#下载安装包到本地" class="headerlink" title="下载安装包到本地"></a>下载安装包到本地</h1><p>由于目标环境无法联网使用pip，因此需要先在本地下载安装包：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip download -r requirements.txt --dest=/path/to/download/directory<br></code></pre></td></tr></table></figure><blockquote><p>pip download -r requirements.txt -d packages&#x2F; -i <a href="https://mirrors.aliyun.com/pypi/simple/">https://mirrors.aliyun.com/pypi/simple/</a><br>上述指令会在packages目录下下载依赖项。</p></blockquote><p>上述指令会在目标路径下载python依赖包。</p><h1 id="在目标服务器配置环境"><a href="#在目标服务器配置环境" class="headerlink" title="在目标服务器配置环境"></a>在目标服务器配置环境</h1><p>接下来是重要的一步，将刚刚下载好的依赖包和<code>requirements.txt</code>复制到目标服务器的目标路径。我的路径设置如下：</p><p>&#x2F;path&#x2F;to&#x2F;your&#x2F;project&#x2F;<br>├── venv&#x2F;<br>├── requirements.txt # 依赖项清单<br>├── modules&#x2F; # 安装包文件夹<br>└── …</p><p>随后在项目根目录执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install --no-index --find-links=/path/to/your/project/modules -r requirements.txt<br></code></pre></td></tr></table></figure><ul><li><code>no-index</code>参数告诉 pip 不要使用默认的 Python Package Index (PyPI) 来查找包，而是仅使用后续提供的本地或者自定义的链接。</li><li><code>--find-links=/xxx/xxx/site-packages</code>: 这个选项指定了一个本地或自定义的包链接目录，告诉 pip 在这个目录中查找并安装包。</li><li><code>-r /xxx/xxx/site-packages/requirements.txt</code>: 这部分指明要安装的包的列表，这个列表通常保存在一个名为 <code>requirements.txt</code>的文件中，其中包含了需要安装的依赖包及其版本信息。</li></ul><div class="note note-warning">            <p>注意！两个环境的python安装包<strong>必须</strong>是同一版本下载的。如果目标环境是Python 3.8，下载安装包的环境是Python 3.10，那么包传过去之后是无法安装的（血泪史！）。</p>          </div><h1 id="检查安装是否成功"><a href="#检查安装是否成功" class="headerlink" title="检查安装是否成功"></a>检查安装是否成功</h1><p>安装完毕后，只需要使用<code>pip list</code>就可以查看是否安装成功。</p><h1 id="Linux压缩-解压"><a href="#Linux压缩-解压" class="headerlink" title="Linux压缩&#x2F;解压"></a>Linux压缩&#x2F;解压</h1><p>有时候下载的包比较多，直接传到目标系统就会很慢，这时候可以将文件夹压缩一下，发送过去再解压，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 压缩为zip文件</span><br>zip -r dirname.zip <span class="hljs-built_in">dirname</span><br><br><span class="hljs-comment"># 压缩为tar文件</span><br>tar -cvf dirname.tar <span class="hljs-built_in">dirname</span><br><br><span class="hljs-comment">#解压zip文件</span><br>unzip dirname.zip<br><br><span class="hljs-comment">#解压tar文件</span><br>tar -xf dirname.tar<br></code></pre></td></tr></table></figure><p>2024&#x2F;1&#x2F;17 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博弈论：混合策略</title>
    <link href="/2024/01/14/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E6%B7%B7%E5%90%88%E7%AD%96%E7%95%A5/"/>
    <url>/2024/01/14/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E6%B7%B7%E5%90%88%E7%AD%96%E7%95%A5/</url>
    
    <content type="html"><![CDATA[<div class="note note-info">            <p>纯策略：玩家在博弈中采用确定性的、不带有随机性的策略。简而言之，玩家通过选择一个特定的行动或策略来参与博弈，而且这个选择是确定的，没有随机性。</p><p>混合策略：玩家以一定的概率分布选择纯策略。在这种情况下，玩家不是坚持采用一个确定的策略，而是以一定的概率分布来随机选择不同的纯策略。混合策略可以用概率分布来表示，其中每个纯策略都有相应的概率。</p>          </div><p>上面给出了之前提到的纯策略和这次讲的混合策略的定义。我们可以用公式来表达这两者：</p><p>纯策略：$A_i &#x3D; {a_{i1}, a_{i2}, \dots, a_{i n_i}}$，其中纯策略$a_{i}\in A_{i}$。</p><p>混合策略：给每个纯策略一个概率分布。用$\Delta \left(\mathcal{A}_{i}\right)$表示$A_i$上的概率分布，即：</p><p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">Δ</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mrow><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo>&#x3D;</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mi>p</mi><mrow><mi>i</mi></mrow></msub><mo>&#x3D;</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><msub><mi>p</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>p</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>p</mi><mrow><mi>i</mi><msub><mi>n</mi><mrow><mi>i</mi></mrow></msub></mrow></msub><mo data-mjx-texclass="CLOSE">}</mo></mrow><mo>,</mo><msub><mi>p</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>≥</mo><mn>0</mn><mo>,</mo><munder><mo data-mjx-texclass="OP">∑</mo><mrow><mi>j</mi></mrow></munder><msub><mi>p</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>&#x3D;</mo><mn>1</mn><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></p><p>则混合策略$p_i \in \Delta A$。</p><p>期望收益：在随机策略中，要计算期望收益，那就需要纯策略的博弈结果的收益乘上这个结果出现的概率，对每个博弈结果进行求和，这个应该比较好理解。</p><p><strong>混合策略的目的：不论你使用哪一种行动，对方的收益都不变。</strong>这句话体现了混合策略的意义：</p><ul><li>增加不确定性和避免可预测性： 混合策略允许玩家以一定的概率分布随机选择不同的纯策略。通过引入随机性，混合策略使得其他玩家很难准确预测某个玩家将采取的确切行动，从而增加了对手的不确定性。并且玩家能够在一定程度上避免被对手轻松预测，因为他们无法确定下一步会选择哪个具体的纯策略。</li></ul><p>不过，这也为自身收益带来了不确定性：<strong>混合策略的本质是通过一定的概率分布随机选择纯策略，因此每次实施混合策略都可能导致不同的结果。</strong></p><p>尽管混合策略增加了不确定性，但混合策略纳什均衡的定义确保了玩家在采用混合策略时仍能够取得最优收益。在混合策略纳什均衡中，玩家的混合策略是其他玩家采用混合策略的最佳响应，因此玩家不能通过单方面改变自己的概率分布来提高自己的效用。</p><h1 id="求解混合策略纳什均衡"><a href="#求解混合策略纳什均衡" class="headerlink" title="求解混合策略纳什均衡"></a>求解混合策略纳什均衡</h1><p>根据纳什定理，<strong>有限的</strong>策略式博弈一定存在<strong>混合策略</strong>纳什均衡。因此，给定不同策略的期望的情况下，是可以求得纳什均衡的概率的。</p><p>例如：</p><p><img src="https://pic2.zhimg.com/80/v2-d8e93e71507dc22b259a320fe39e7601_720w.webp" alt="img"></p><p>上面的例子中，玩家1有$\pi_1$的概率选择$U$，玩家2有$\pi_2$的概率选择$L$。那么，我们只要令两者的期望收益相等，就可以求得这两个概率。</p><p>由玩家2选L的期望收益等于玩家2选R的期望收益，可以得到：</p><p>$2\pi_1+5(1-\pi_1)&#x3D;4\pi_1+2(1-\pi_1)$，解得$\pi_1&#x3D;0.6$。</p><p>由玩家1选U的期望收益等于玩家1选D的期望收益，可以得到：</p><p>$\pi_2&#x3D;3(1-\pi_2)$，解得$\pi_2&#x3D;0.75$。</p><p>因此纳什均衡是<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>p</mi><mo>&#x3D;</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mn>0.6</mn><mo>,</mo><mn>0.4</mn><mo data-mjx-texclass="CLOSE">}</mo></mrow><mo>,</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mn>0.75</mn><mo>,</mo><mn>0.25</mn><mo data-mjx-texclass="CLOSE">}</mo></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></p><p><strong>只要记住，当选择混合策略时，玩家的不同策略的期望收益应该相同，就可以轻松求得纳什均衡的概率。</strong></p><p>上面这句话可以这么理解，假如玩家的不同策略的期望收益不同，那么玩家就会选择高收益的策略，这就又回到了纯策略了。</p><blockquote><p>hexo写Latex太难写了，就这么短短几个字搞了快两小时都没好。</p></blockquote><p>2024&#x2F;1&#x2F;14 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>博弈论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博弈论</tag>
      
      <tag>混合策略</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>李开复争议之作：使用vllm上手YI-34B大模型</title>
    <link href="/2024/01/14/%E6%9D%8E%E5%BC%80%E5%A4%8D%E4%BA%89%E8%AE%AE%E4%B9%8B%E4%BD%9C%EF%BC%9A%E4%BD%BF%E7%94%A8vllm%E4%B8%8A%E6%89%8BYI-34B%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    <url>/2024/01/14/%E6%9D%8E%E5%BC%80%E5%A4%8D%E4%BA%89%E8%AE%AE%E4%B9%8B%E4%BD%9C%EF%BC%9A%E4%BD%BF%E7%94%A8vllm%E4%B8%8A%E6%89%8BYI-34B%E5%A4%A7%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="争议满满的Yi"><a href="#争议满满的Yi" class="headerlink" title="争议满满的Yi"></a>争议满满的Yi</h1><p>2023年11月6日，李开复创办的零一万物发布了首款开源中英双语大模型——Yi。有李开复博士坐镇，他的公司和模型的热度都很高。</p><p>模型发布后，它的测评得分刷新了一轮国产大模型的榜单。在中文能力上，Yi-34B在C-Eval中文能力排行榜上超越所有开源模型，同样开源的Yi-6B也超过了同规模所有开源模型。在上下文长度上，模型的窗口长度达到了200K，这是GPT-4的6倍。</p><p>不过，这个模型发布后也伴随着极大的争议。11月14日，阿里前技术副总裁贾扬清发布了一条之后在AI圈引起轩然大波的朋友圈。</p><p><img src="/images/pyq_yi.jpeg"></p><p>同样的，HuggingFace社区也有人提出这一点，Yi模型只在Llama上修改了几个变量。</p><p>不过这次我们不关心这个花边新闻，主要还是怎么部署模型。</p><h1 id="模型准备"><a href="#模型准备" class="headerlink" title="模型准备"></a>模型准备</h1><p>话不多说，直接上手。</p><p>我是在AutoDL上租的4090 24G显卡。因为HuggingFace在大陆连不上，所以连上服务器之后，首先需要pip install一下modelscope。</p><p>下载完之后，我们进<code>autodl-tmp</code>目录，下载一下模型文件。为了下载模型，首先我们需要进<code>IPython</code>，然后像juypter notebook一样执行python代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> modelscope.hub.snapshot_download <span class="hljs-keyword">import</span> snapshot_download<br><br>model_dir = snapshot_download(<br>    <span class="hljs-string">&#x27;01ai/Yi-34B-Chat-4bits&#x27;</span>, <br>    cache_dir=<span class="hljs-string">&#x27;autodl-tmp&#x27;</span>, <br>    revision=<span class="hljs-string">&#x27;master&#x27;</span>, <br>    ignore_file_pattern=<span class="hljs-string">&#x27;.bin&#x27;</span>)<br><br></code></pre></td></tr></table></figure><p>这里值得注意的是<code>ignore_file_pattern</code>参数，主要是忽视<code>bin</code>文件，因为只需要用<code>safetensor</code>的权重文件就够了。下载完之后，<code>Ctrl+Z</code>退出。</p><p>这是已经可以看到下载好的模型文件了。</p><p><img src="/images/153149.png"></p><p>接下来pip install一下<code>vllm</code>。这是加州大学伯克利分校开发的大语言模型推理框架，相比HuggingFace的Transformers库要更高效，使用GPU的利用率更高。</p><p>安装完一行就可以在命令行里先测试一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -m vllm.entrypoints.openai.api_server \<br>--model /root/autodl-tmp/autodl-tmp/01ai/Yi-34B-Chat-<br>4bits \<br>--served-model-name 01ai/Yi-34B-Chat-4bits \<br>--trust-remote-code \<br>--max-model-len 2048 \<br>-q awq<br></code></pre></td></tr></table></figure><p>以上这段代码来自<code>vllm</code>的官网。几个参数主要是模型文件的位置，输入长度和量化方式。<code>awq</code>是23年底推出的一种量化方式。先挖坑，以后研究。</p><p>上述代码会在本地的8000端口起一个服务，这样就可以使用crul指令发送请求了。</p><p>我们如下发送指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/completions \    <br>-H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>-d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">        &quot;model&quot;: &quot;01ai/Yi-34B-Chat-4bits&quot;,</span><br><span class="hljs-string">        &quot;prompt&quot;: &quot;请推荐一个苏州景点&quot;,</span><br><span class="hljs-string">        &quot;max_tokens&quot;: 2000,</span><br><span class="hljs-string">        &quot;temperature&quot;: 0</span><br><span class="hljs-string">&#125;&#x27;</span><br></code></pre></td></tr></table></figure><p>返回如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">&#123;<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;cmpl-ea645d5e785349a293f5fe618f482d7d&quot;</span>,<span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;text_completion&quot;</span>,<span class="hljs-string">&quot;created&quot;</span>:2921551,<span class="hljs-string">&quot;model&quot;</span>:<span class="hljs-string">&quot;01ai/Yi-34B-Chat-4bits&quot;</span>,<span class="hljs-string">&quot;choices&quot;</span>:[&#123;<span class="hljs-string">&quot;index&quot;</span>:0,<span class="hljs-string">&quot;text&quot;</span>:<span class="hljs-string">&quot;。\n苏州有许多著名的景点，每个都有其独特的魅力。以下是一些推荐的苏州景点：\n\n1. 拙政园：这是苏州最著名的古典园林之一，也是中国四大名园之一。拙政园以其精巧的布局、精湛的造园艺术和丰富的文化内涵而闻名。\n\n2. 留园：留园也是苏州四大名园之一，以建筑布置紧凑、奇石众多而著称。园中的“冠云峰”是太湖石中的绝品，值得一看。\n\n3. 苏州博物馆：由著名建筑师贝聿铭设计，不仅收藏了大量珍贵的文物，其本身就是一件艺术品。博物馆与拙政园相邻，建筑风格与周围环境相融合。\n\n4. 平江路历史街区：这是苏州保存最完好的古街之一，保留了大量的历史建筑和传统风貌，是体验苏州古城生活的好去处。\n\n5. 虎丘：虎丘山风景名胜区不仅有秀美的自然风光，还有丰富的历史文化遗产，如虎丘塔、剑池等。\n\n6. 周庄：虽然周庄不在苏州市区，但它是苏州附近最著名的水乡古镇，有着“中国第一水乡”的美誉。周庄的江南水乡风情和古建筑群吸引了众多游客。\n\n7. 同里古镇：同里也是苏州附近的一个著名古镇，保存有大量的明清古建筑，如退思园等，是感受江南古镇风情的好地方。\n\n8. 寒山寺：因唐代诗人张继的《枫桥夜泊》而闻名，寒山寺是苏州的佛教名刹，每年吸引大量游客前来参观。\n\n9. 金鸡湖景区：这是苏州现代化的一个标志，有美丽的湖景、现代化的建筑和丰富的娱乐设施，适合晚上游览。\n\n10. 苏州园林：除了拙政园和留园，苏州还有许多其他著名的园林，如网师园、狮子林等，每个园林都有其独特的特色。\n\n选择哪个景点取决于你的兴趣和偏好。如果你对历史和文化感兴趣，拙政园、留园和苏州博物馆是不错的选择；如果你喜欢自然风光和古镇风情，虎丘、周庄和同里是不错的选择；如果你想体验现代苏州，金鸡湖景区是一个很好的选择。\n\n请注意，由于疫情或其他原因，景点的开放情况和政策可能会有所变化，建议在出行前查看最新的信息。\n\n苏州园林：\n苏州园林是中国古典园林的杰出代表，被联合国教科文组织列为世界文化遗产。苏州园林以其精巧的布局、精湛的造园艺术和丰富的文化内涵而闻名。以下是一些著名的苏州园林：\n\n1. 拙政园：\n   - 位于苏州市区，是苏州最大的古典园林，也是中国四大名园之一。\n   - 拙政园始建于明代，后经多次扩建和修缮，形成了现在的规模。\n   - 园林布局巧妙，以水景为主，亭台楼阁、假山池沼布局得当，体现了江南园林的典型特色。\n\n2. 留园：\n   - 位于苏州市区，与拙政园、网师园并称为苏州三大名园。\n   - 留园以建筑布置紧凑、奇石众多而著称，其中“冠云峰”是太湖石中的绝品。\n   - 留园的造园艺术精湛，体现了古代造园家的高超技艺。\n\n3. 网师园：\n   - 位于苏州市区，是苏州古典园林中以小巧精致著称的代表。\n   - 网师园始建于南宋，历经多次修缮，保持了南宋时期的园林风格。\n   - 园林布局紧凑，建筑精美，是研究宋代园林的重要实例。\n\n4. 狮子林：\n   - 位于苏州市区，是苏州四大名园之一，以假山众多、奇石林立而闻名。\n   - 狮子林始建于元代，是江南地区著名的元代园林。\n   - 园林中的假山群被誉为“假山王国”，是中国古典园林中不可多得的艺术珍品。\n\n5. 沧浪亭：\n   - 位于苏州市区，是苏州现存历史最悠久的园林，始建于宋代。\n   - 沧浪亭以山石景观和亭台楼阁著称，是宋代园林艺术的代表作。\n   - 园林中的沧浪亭、翠玲珑等建筑是游客游览的重点。\n\n6. 艺圃：\n   - 位于苏州市区，是苏州古典园林中较为小巧的一座，但布局紧凑，景色幽静。\n   - 艺圃始建于明代，以水景为主，亭台楼阁、假山池沼布局得当。\n   - 园林中的乳鱼亭、醉翁亭等是游客喜爱的景点。\n\n这些苏州园林不仅是中国古典园林艺术的瑰宝，也是了解中国传统文化的重要窗口。游览这些园林，可以感受到古代文人的审美情趣和生活方式。\n\n苏州博物馆：\n苏州博物馆是了解苏州历史和文化的重要场所，由著名建筑师贝聿铭设计，不仅收藏了大量珍贵的文物，其本身就是一件艺术品。以下是关于苏州博物馆的一些信息：\n\n1. 建筑设计：\n   - 苏州博物馆新馆于2006年建成，由华裔建筑师贝聿铭设计。\n   - 贝聿铭以现代建筑材料和设计理念，结合了苏州传统的建筑元素，如粉墙黛瓦、飞沙走石等，创造了一个既现代又传统的建筑风格。\n\n2. 馆藏文物：\n   - 苏州博物馆收藏有大量珍贵的文物，包括历代字画、陶瓷器、玉器、青铜器等。\n   - 馆内的常设展览展示了苏州的历史文化，包括吴文化、苏州工艺、苏州园林等。\n\n3. 特色展览：\n   - 苏州博物馆不定期举办各种临时展览，包括国内外的艺术作品展、历史文物展等。\n   - 博物馆还与国内外其他博物馆合作，举办文化交流展览。\n\n4. 地理位置：\n   - 苏州博物馆位于苏州市区，紧邻著名的拙政园和狮子林。\n   - 博物馆所在的忠王府是太平天国时期的建筑，也是苏州博物馆的一部分。\n\n5. 参观信息：\n   - 苏州博物馆实行免费参观制度，但需要提前预约。\n   - 博物馆内设有专业的讲解员，提供中文和英文讲解服务。\n   - 博物馆内还设有书店、咖啡厅等设施，供游客休息和学习。\n\n参观苏州博物馆，不仅可以欣赏到精美的文物和现代化的建筑设计，还能了解到苏州乃至中国的历史和文化。由于其独特的建筑风格和丰富的馆藏，苏州博物馆已经成为苏州的一个重要旅游景点。\n\n苏州博物馆新馆由华裔建筑师贝聿铭设计，于2006年建成并对外开放。这座博物馆不仅是一个展示苏州历史文化的场所，也是一座融合了现代建筑理念和传统苏州建筑元素的艺术品。以下是苏州博物馆新馆的一些特点：\n\n1. 建筑设计：\n   - 贝聿铭的设计灵感来自于苏州传统的建筑形式，如粉墙黛瓦、飞沙走石等。\n   - 他使用了现代建筑材料，如玻璃、钢和石材，与传统元素相结合，创造出一个既现代又传统的建筑风格。\n   - 博物馆的屋顶采用了传统的歇山顶形式，但使用了现代的玻璃材料，形成了独特的“贝氏屋顶”。\n\n2. 空间布局：\n   - 博物馆内部空间布局巧妙，既有宽敞明亮的大厅，也有幽静雅致的小庭院。\n   - 博物馆分为三个主要部分：新馆、旧馆（忠王府）和现代艺术馆。\n\n3. 馆藏文物：\n   - 苏州博物馆收藏有大量珍贵的文物，包括历代字画、陶瓷器、玉器、青铜器等。\n   - 馆内的常设展览展示了苏州的历史文化，包括吴文化、苏州工艺、苏州园林等。\n\n4. 特色展览：\n   - 苏州博物馆不定期举办各种临时展览，包括国内外的艺术作品展、历史文物展等。\n   - 博物馆还与国内外其他博物馆合作，举办文化交流展览。\n\n5. 参观信息：\n   - 苏州博物馆实行免费参观制度，但需要提前预约。\n   - 博物馆内设有专业的讲解员，提供中文和英文讲解服务。\n   - 博物馆内还设有书店、咖啡厅等设施，供游客休息和学习。\n\n苏州博物馆新馆的设计不仅体现了贝聿铭对现代建筑的贡献，也是他对家乡苏州的深厚感情的体现。这座博物馆已经成为苏州的一个重要文化地标，吸引了来自世界各地的游客。\n\n苏州博物馆新馆由华裔建筑师贝聿铭设计，于2006年建成并对外开放。这座博物馆不仅是一个展示苏州历史文化的场所，也是一座融合了现代建筑理念和传统苏州建筑元素的艺术品。以下是苏州博物馆新馆的一些特点：\n\n1.&quot;</span>,<span class="hljs-string">&quot;logprobs&quot;</span>:null,<span class="hljs-string">&quot;finish_reason&quot;</span>:<span class="hljs-string">&quot;length&quot;</span>&#125;],<span class="hljs-string">&quot;usage&quot;</span>:&#123;<span class="hljs-string">&quot;prompt_tokens&quot;</span>:6,<span class="hljs-string">&quot;total_tokens&quot;</span>:2006,<span class="hljs-string">&quot;completion_tokens&quot;</span>:2000&#125;&#125;root@autodl-container-7906<br><br></code></pre></td></tr></table></figure><p>观察显卡的占用，大概在22&#x2F;24GB左右。在4Bit量化版本下，消费级显卡已经可以运行34B级别的大模型了。</p><h1 id="Gradio部署"><a href="#Gradio部署" class="headerlink" title="Gradio部署"></a>Gradio部署</h1><p>愿意的话，可以用Gradio部署一个服务，python脚本代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><br>openai_api_key = <span class="hljs-string">&#x27;EMPTY&#x27;</span><br>openai_api_base = <span class="hljs-string">&#x27;https://localhost:8000/v1&#x27;</span><br><br>client = OpenAI(<br>    api_key = openai_api_key,<br>    base_url = openai_api_base<br>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">msg, history</span>):<br>    history_openai_format = [&#123;<span class="hljs-string">&#x27;role&#x27;</span>:<span class="hljs-string">&#x27;system&#x27;</span>,<span class="hljs-string">&#x27;content&#x27;</span>:<span class="hljs-string">&#x27;你是周洋大帅哥创造的AI助手，请尽你所能回答用户提问的问题。&#x27;</span>&#125;]<br>    <span class="hljs-keyword">for</span> human, assistant <span class="hljs-keyword">in</span> history:<br>        history_openai_format.append(&#123;<span class="hljs-string">&#x27;role&#x27;</span>:<span class="hljs-string">&#x27;user&#x27;</span>,<span class="hljs-string">&#x27;content&#x27;</span>:human&#125;)<br>        history_openai_format.append(&#123;<span class="hljs-string">&#x27;role&#x27;</span>:<span class="hljs-string">&#x27;assistent&#x27;</span>,<span class="hljs-string">&#x27;content&#x27;</span>:assistant&#125;)<br>    history_openai_format.append(&#123;<span class="hljs-string">&#x27;role&#x27;</span>:<span class="hljs-string">&#x27;user&#x27;</span>,<span class="hljs-string">&#x27;content&#x27;</span>:msg&#125;)<br><br>    stream = client.chat.completions.create(<br>        model=<span class="hljs-string">&#x27;01ai/Yi-34B-Chat-4bits&#x27;</span>,<br>        messages=history_openai_format,<br>        temperature=<span class="hljs-number">0.8</span>,<br>        stream=<span class="hljs-literal">True</span>,<br>        extra_body=&#123;<span class="hljs-string">&#x27;repetition_penalty&#x27;</span>:<span class="hljs-number">1</span>,<span class="hljs-string">&#x27;stop_token_ids&#x27;</span>:[<span class="hljs-number">7</span>]&#125;<br>    )<br><br>    partial_message = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> stream:<br>        partial_message += (chunk.choices[<span class="hljs-number">0</span>].delta.content <span class="hljs-keyword">or</span> <span class="hljs-string">&#x27;&#x27;</span>)<br>        <span class="hljs-keyword">yield</span> partial_message<br><br><br>gr.ChatInterface(predict).queue().launch(share=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>这个脚本会在本地的8000端口起一个可视化服务，这时候你就可以随意和它对话了！</p><p>2024&#x2F;1&#x2F;14 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
      <tag>Yi-34B</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博弈论：如何理解帕累托最优？</title>
    <link href="/2024/01/13/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%B8%95%E7%B4%AF%E6%89%98%E6%9C%80%E4%BC%98%EF%BC%9F/"/>
    <url>/2024/01/13/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%B8%95%E7%B4%AF%E6%89%98%E6%9C%80%E4%BC%98%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<p>帕累托最优在斯坦福公开课中只占了很短的一部分，我原先只是粗看了一遍，后面发现这个概念的现实意义也很重要，因此单开一章学习一下。</p><h1 id="“非损人不利己”"><a href="#“非损人不利己”" class="headerlink" title="“非损人不利己”"></a>“非损人不利己”</h1><p>帕累托改进是指一种策略上的优化，使得没有人的收益在减少的情况下，至少有一个玩家的收益是提高的。在这种情况下，至少有一个玩家是喜欢这种策略的。</p><p>当不可能再出现更多帕累托改进的情况下，就达到了帕累托最优(Pareto Optimality)。此时只要任何尝试增加某个玩家的收益，都会导致另一个玩家的收益受损。</p><blockquote><p>帕累托最优：不可能再改善某些人的境况，而不使任何其他人受损。</p></blockquote><h1 id="经济学中的帕累托"><a href="#经济学中的帕累托" class="headerlink" title="经济学中的帕累托"></a>经济学中的帕累托</h1><p>在经济学中，达到帕累托最优，需要满足三个条件（来自Wikipedia）：</p><ul><li>交换的最优条件</li><li>生产的最优条件</li><li>交换和生产的最优条件</li></ul><p>只要不是帕累托最优，那么就有玩家可以在不损害其他人利益的情况下，让自己的收益变高。</p><p>如何理解这三个最优条件？</p><ul><li>交换最优：</li></ul><p>比如A、B两个消费者，A最爱吃苹果，认为一个苹果等于两个梨子，B最爱吃梨子，认为一个梨子等于两个苹果，如果A用一个梨子去交换B的一个苹果。那么对于A而言，A得到了一个苹果，相当于是两个梨子，边际替代率就是2。对于B而言，B得到了一个梨子，相当于是2个苹果，边际替代率也是2。</p><p>对A和B而言，若每一对商品的边际替代率相同，那么就是交换的最优条件，双方的利益都没受损。</p><ul><li>生产最优：</li></ul><p>比如用同量的投入，生产A可得收益100元，生产B仅得50元，这样企业就会改变策略，多生产A，少生产B。同样的，当竞标时，同样投入，A公司产出50，B公司产出100，那么资源就会流向B公司。</p><ul><li>混合最优：</li></ul><p>交换最优中，主要反映的是消费者偏好（边际替代率）。生产最优中，则反映的是生产效率（边际转换率）。</p><p>当两者相等，说明生产结构与需求结构完全吻合，生产的产品符合消费者需求，既不会短缺，也不会过剩。</p><blockquote><p>帕累托最优，体现的是效率和收益的均衡。</p></blockquote><p>严格意义上，这反应了自由市场的机制，在生产交换的不断调整下，最终会达到帕累托最优，也就是常说的“无形的手”。</p><p>例如，当改革农村，引入新科技的时候，农村的生产效率提高了，但城市没有利益受损，这时就产生了帕累托改进。</p><p>同样的，当国际合作中，双方交换资源时，也达到了帕累托改进。此时双方都获得了收益。</p><h1 id="经济学中的思维碰撞"><a href="#经济学中的思维碰撞" class="headerlink" title="经济学中的思维碰撞"></a>经济学中的思维碰撞</h1><p>博弈论的思维处处体现在经济学中，这带来了不少观点的冲突：</p><p>亚当斯密的自由市场理论认为，依靠自由市场中每个玩家的行动，就可以达到一个最优配置。事实证明，这只是一个纳什均衡点，而不是帕累托最优。</p><p>相反，马克思与凯恩斯认为市场需要中央政府的监管。认为政府充当了上帝的身份进行市场调配。</p><p>随着数学模型的应用，<strong>福利经济学第一定理和第二定理</strong>对他们的争论有了准确的描述：当以下三个前提条件成立时，市场竞争产生的均衡一定是帕累托最优的。这三个条件包括：（1）一个完全竞争的市场，（2）不存在外部性，（3）不存在信息不对称。这就说明亚当斯密和凯恩斯的理论都存在问题。</p><p>现实市场中，处处存在着不完全竞争与垄断，也处处包含着信息不对称。这导致亚当斯密的自由市场无法满足这三个条件。凯恩斯的理论则要求政府进行宏观调控。然而现实并不是理想的，政府并不是一个全知全能，没有私心的上帝，而是一个人性结合体，只是一个更可怕的博弈玩家。</p><h1 id="博弈论中的帕累托最优"><a href="#博弈论中的帕累托最优" class="headerlink" title="博弈论中的帕累托最优"></a>博弈论中的帕累托最优</h1><p>博弈论中用公式定义了帕累托最优：例如 $( \mathrm{\large O}(7,8) ) $和$ ( \mathrm{\large O}^{\prime}(4,5) )$，则 $(\mathrm{O}) Pareto-dominates (\mathrm{O}^{\prime}).$</p><p><img src="/images/130100.png"></p><p>在图示的例子中，$f1$是参与人1的收益，$f2$是参与人2的收益， 状态$C$不在帕累托前沿面(Pareto Frontier)，因为存在帕累托改进使它改进到$A$或者$B$点。</p><h1 id="帕累托最优是不是纳什均衡？"><a href="#帕累托最优是不是纳什均衡？" class="headerlink" title="帕累托最优是不是纳什均衡？"></a>帕累托最优是不是纳什均衡？</h1><p>复习一下：什么是纳什均衡？</p><blockquote><p>纳什均衡：全部参与者非合作博弈达到的期望效用最大化结果。</p><p>帕累托最优：所有人不再可以在在不损害他人利益的前提下获得更优资源的资源配置结果。</p></blockquote><p>首先要明确的是，帕累托最优并不是纳什均衡，因为它是从全局出发的。在囚徒困境中，纳什均衡是双方都采取合作策略，因为这是对于自身的支配性策略，而这个策略从全局来看是有不损害彼此的优化空间的。</p><blockquote><p>交流可以带来帕累托改进。</p></blockquote><table><thead><tr><th></th><th>3.5</th><th>5.5</th></tr></thead><tbody><tr><td>3.5</td><td>(8,8)</td><td>(3,2)</td></tr><tr><td>5.5</td><td>(2,3)</td><td>(6,6)</td></tr></tbody></table><p>囚徒困境中，双方沟通是可以达成帕累托改进的。这时，双方合作会带来各自的收益或是单方面的收益。</p><p>根据知乎上一些博主的分析，帕累托最优和纳什均衡无必然关系。大部分情况下，纳什均衡都不是帕累托最优，这是因为玩家是自私的。</p><p>此外还有一个很好的例子，同样来自知乎：</p><p>假设有一个上帝可以操纵所有人的行为，他会让大家选择帕累托最优的结果；但如果让市场来配置资源，所有人追求个人利益的最大化，那么结果是一个纳什均衡。举个例子，在生产过剩的时候，所有的奶农都把牛奶倒入河中，则牛奶供给减少，价格上升，这对大家都有好处，这是“帕累托最优”。</p><p>但是每个奶农总是希望别人家多倒一点牛奶，这样价格上升之后自家的牛奶就可以卖更多的钱。当每一个人都这么想的时候，就没人倒牛奶了，就走向了一个纳什均衡，然而并不是有效率的。</p><hr><p>为什么大家都知道当所有孩子都去补习了，大家水平都提高，则在应试考试中都获得不到好处，但却无法达成一个所有人都不补课的契约（因为当别人不补课时，你偷偷去补，就可以得到好处）。市场势力的存在使得每个人都必须考虑其他人的行为对自己的影响，最终相互作用，达到了一个对大家都不是最好的结果。</p><p>这也是为什么为什么不能放任自由市场调控，因为这样会走到一个纳什均衡，但并不是整体最佳的策略。</p><h1 id="理想与现实的碰撞"><a href="#理想与现实的碰撞" class="headerlink" title="理想与现实的碰撞"></a>理想与现实的碰撞</h1><p>现实中，一般不容易达到帕累托最优。在集体中，如果一部分受益，一部分受损，但只要受益的部分大于受损部分，那么集体的总收益也可以得到提升。此时受益者也可以给予受损者一定补偿以使其免遭损失。这个过程就是卡尔多-希克斯改进。</p><blockquote><p>先富者带动后富者。</p></blockquote><p>假设甲乙两人打算共同投资一个项目，当前有A和B两个项目。</p><p>对于A项目，甲能盈利100万，乙能盈利200万；对于B项目，甲能盈利200万，乙能盈利150万。如果按照帕累托改进的思想来挑项目，则A和B都选不上，因为帕累托要求任何一方的利益都不会受损，但是选A项目甲的利益会受损（甲少赚100万），选B项目乙的利益会受损（乙少赚50万）。</p><p>如果按照卡尔多-希克斯改进的思想来挑项目，那么应该选B项目。因为B相比A，甲能多赚100万，乙亏损50万，只要甲能拿出50万补贴乙，那么在乙不受损的情况下，甲还能多赚50万，整体的福利更高。</p><h2 id="问题来了"><a href="#问题来了" class="headerlink" title="问题来了"></a>问题来了</h2><p>牺牲部分人的利益，换来大部分人的收益，这样的价值观是否真的被社会认可吗？这就涉及到哲学问题了。</p><div class="note note-warning">            <p>当你选择将失控的火车碾向铁轨上的五个人时，你是要这么跟他们说吗？</p><p>你们的牺牲带来了帕累托改进，感谢你们！</p>          </div>]]></content>
    
    
    <categories>
      
      <category>博弈论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博弈论</tag>
      
      <tag>帕累托最优</tag>
      
      <tag>经济学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>代码实战：微调Mixtral8*7B</title>
    <link href="/2024/01/11/%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98%EF%BC%9A%E5%BE%AE%E8%B0%83Mixtral8-7B/"/>
    <url>/2024/01/11/%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98%EF%BC%9A%E5%BE%AE%E8%B0%83Mixtral8-7B/</url>
    
    <content type="html"><![CDATA[<p>这篇是Mixtral8x7B的微调代码实战，之前的博文中有写过，不过写的不是很好，这次单独再开一篇。</p><p>注意：微调需要A100的显卡。</p><h1 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h1><p>首先安装依赖包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">!pip install transformers trl accelerate torch bitsandbytes peft datasets -qU<br>!pip install flash-attn --no-build-isolation<br></code></pre></td></tr></table></figure><p>这里的flash attention是一个重要的东西，先挖个坑，之后研究一下。</p><h1 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h1><p>我们需要导入数据集，这里数据集来自Hugging Face。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>instruct_tune_dataset = load_dataset(<span class="hljs-string">&quot;mosaicml/instruct-v3&quot;</span>)<br>instruct_tune_dataset<br></code></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs css">DatasetDict(&#123;<br>    train: <span class="hljs-built_in">Dataset</span>(&#123;<br>        features: [<span class="hljs-string">&#x27;prompt&#x27;</span>, <span class="hljs-string">&#x27;response&#x27;</span>, <span class="hljs-string">&#x27;source&#x27;</span>],<br>        num_rows: <span class="hljs-number">56167</span><br>    &#125;)<br>    test: <span class="hljs-built_in">Dataset</span>(&#123;<br>        features: [<span class="hljs-string">&#x27;prompt&#x27;</span>, <span class="hljs-string">&#x27;response&#x27;</span>, <span class="hljs-string">&#x27;source&#x27;</span>],<br>        num_rows: <span class="hljs-number">6807</span><br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure><p>可以看到，数据集由三个部分组成：prompt，response，source。愿意的话可以打印一下看看：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):<br>  <span class="hljs-built_in">print</span>(instruct_tune_dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-string">&#x27;prompt&#x27;</span>][i])<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---&#x27;</span>*<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>对于Mixtral模型，数据集需要按照以下格式准备：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs verilog">&lt;s&gt;[INST] Use the provided <span class="hljs-keyword">input</span> to create an instruction that could have been used to <span class="hljs-keyword">generate</span> the response <span class="hljs-keyword">with</span> an LLM.<br><br>&#123;<span class="hljs-keyword">input</span>&#125; [/INST]<br><br>&#123;response&#125;&lt;/s&gt;<br></code></pre></td></tr></table></figure><p>而我们已有的数据集长这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">instruct_tune_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs delphi"><span class="hljs-comment">&#123;&#x27;prompt&#x27;: &#x27;Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction\nWhat are different types of grass?\n\n### Response\n&#x27;,</span><br><span class="hljs-comment"> &#x27;response&#x27;: &#x27;There are more than 12,000 species of grass. The most common is Kentucky Bluegrass, because it grows quickly, easily, and is soft to the touch. Rygrass is shiny and bright green colored. Fescues are dark green and shiny. Bermuda grass is harder but can grow in drier soil.&#x27;,</span><br><span class="hljs-comment"> &#x27;source&#x27;: &#x27;dolly_hhrlhf&#x27;&#125;</span><br></code></pre></td></tr></table></figure><p>定义一个处理的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_prompt</span>(<span class="hljs-params">sample</span>):<br>    bos_token = <span class="hljs-string">&quot;&lt;s&gt;&quot;</span><br>    original_system_message = <span class="hljs-string">&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.&quot;</span><br>    system_message = <span class="hljs-string">&quot;[INST]Use the provided input to create an instruction that could have been used to generate the response with an LLM.&quot;</span><br>    response = sample[<span class="hljs-string">&quot;prompt&quot;</span>].replace(original_system_message, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;\n\n### Instruction\n&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;\n### Response\n&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).strip()<br>    <span class="hljs-built_in">input</span> = sample[<span class="hljs-string">&quot;response&quot;</span>]<br>    eos_token = <span class="hljs-string">&quot;&lt;/s&gt;&quot;</span><br>    full_prompt = bos_token + system_message + <span class="hljs-string">&quot;\n&quot;</span> + <span class="hljs-built_in">input</span> + <span class="hljs-string">&quot;[/INST]&quot;</span> + response + eos_token<br><br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;full_prompt&quot;</span>: full_prompt&#125;<br></code></pre></td></tr></table></figure><p>拿之前的数据测试一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">create_prompt(instruct_tune_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vbnet"><span class="hljs-comment">&#x27;&lt;s&gt;[INST]Use the provided input to create an instruction that could have been used to generate the response with an LLM.\nThere are more than 12,000 species of grass. The most common is Kentucky Bluegrass, because it grows quickly, easily, and is soft to the touch. Rygrass is shiny and bright green colored. Fescues are dark green and shiny. Bermuda grass is harder but can grow in drier soil.[/INST]What are different types of grass?&lt;/s&gt;&#x27;</span><br></code></pre></td></tr></table></figure><p>最后对数据集做个映射：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mapped_data = instruct_tune_dataset.<span class="hljs-built_in">map</span>(create_prompt)<br></code></pre></td></tr></table></figure><h1 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">model_id = <span class="hljs-string">&quot;mistralai/Mixtral-8x7B-v0.1&quot;</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig<br><span class="hljs-keyword">import</span> torch<br><br>nf4_config = BitsAndBytesConfig(<br>   load_in_4bit=<span class="hljs-literal">True</span>,<br>   bnb_4bit_quant_type=<span class="hljs-string">&quot;nf4&quot;</span>,<br>   bnb_4bit_use_double_quant=<span class="hljs-literal">True</span>,<br>   bnb_4bit_compute_dtype=torch.bfloat16<br>) <span class="hljs-comment"># 量化参数</span><br><br>model = AutoModelForCausalLM.from_pretrained(<br>    model_id,<br>    device_map=<span class="hljs-string">&#x27;auto&#x27;</span>,<br>    quantization_config=nf4_config,<br>    use_cache=<span class="hljs-literal">False</span>,<br>    attn_implementation=<span class="hljs-string">&quot;flash_attention_2&quot;</span><br><br>) <br><br>tokenizer = AutoTokenizer.from_pretrained(model_id)<br><br>tokenizer.pad_token = tokenizer.eos_token<br>tokenizer.padding_side = <span class="hljs-string">&quot;right&quot;</span><br></code></pre></td></tr></table></figure><p>先写一个生成回复的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_response</span>(<span class="hljs-params">prompt, model</span>):<br>    encoded_input = tokenizer(prompt,  return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, add_special_tokens=<span class="hljs-literal">True</span>)<br>    model_inputs = encoded_input.to(<span class="hljs-string">&#x27;cuda&#x27;</span>)<br><br>    generated_ids = model.generate(<br>  **model_inputs,<br>  max_new_tokens=<span class="hljs-number">512</span>,<br>  do_sample=<span class="hljs-literal">True</span>, <br>  pad_token_id=tokenizer.eos_token_id)<br><br>    decoded_output = tokenizer.batch_decode(generated_ids)<br><br>    <span class="hljs-keyword">return</span> decoded_output[<span class="hljs-number">0</span>].replace(prompt, <span class="hljs-string">&quot;&quot;</span>)<br>  <br>  <br>prompt=<span class="hljs-string">&quot;&quot;&quot;[INST]Use the provided input to create an instruction that could have been used to generate the response with an LLM. \nThere are more than 12,000 species of grass. The most common is Kentucky Bluegrass, because it grows quickly, easily, and is soft to the touch. Rygrass is shiny and bright green colored. Fescues are dark green and shiny. Bermuda grass is harder but can grow in drier soil.[\INST]&quot;&quot;&quot;</span><br><br>generate_response(prompt, model)<br></code></pre></td></tr></table></figure><h1 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h1><p>下面需要对输入的训练数据集做分词：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_prompts</span>(<span class="hljs-params">prompt</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(prompt)<br><br>tokenized_train_dataset = mapped_data[<span class="hljs-string">&quot;train&quot;</span>].<span class="hljs-built_in">map</span>(tokenize_prompts)<br>tokenized_val_dataset = mapped_data[<span class="hljs-string">&quot;test&quot;</span>].<span class="hljs-built_in">map</span>(tokenize_prompts)<br></code></pre></td></tr></table></figure><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs routeros">MixtralForCausalLM(<br>  (model): MixtralModel(<br>    (embed_tokens): Embedding(32000, 4096)<br>    (layers): ModuleList(<br>      (0-31): 32 x MixtralDecoderLayer(<br>        (self_attn): MixtralFlashAttention2(<br>          (q_proj): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (k_proj): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (v_proj): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (o_proj): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (rotary_emb): MixtralRotaryEmbedding()<br>        )<br>        (block_sparse_moe): MixtralSparseMoeBlock(<br>          (gate): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=8, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (experts): ModuleList(<br>            (0-7): 8 x MixtralBLockSparseTop2MLP(<br>              (w1): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=14336, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>              (w2): Linear4bit(<span class="hljs-attribute">in_features</span>=14336, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>              (w3): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=14336, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>              (act_fn): SiLU()<br>            )<br>          )<br>        )<br>        (input_layernorm): MixtralRMSNorm()<br>        (post_attention_layernorm): MixtralRMSNorm()<br>      )<br>    )<br>    (norm): MixtralRMSNorm()<br>  )<br>  (lm_head): Linear(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=32000, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>)<br></code></pre></td></tr></table></figure><h1 id="设置训练参数"><a href="#设置训练参数" class="headerlink" title="设置训练参数"></a>设置训练参数</h1><p>需要设置一下训练必须的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraConfig, get_peft_model, prepare_model_for_kbit_training<br><br>peft_config = LoraConfig(<br>    lora_alpha=<span class="hljs-number">16</span>,<br>    lora_dropout=<span class="hljs-number">0.1</span>,<br>    r=<span class="hljs-number">64</span>,<br>    bias=<span class="hljs-string">&quot;none&quot;</span>,<br>    target_modules=[<br>        <span class="hljs-string">&quot;q_proj&quot;</span>,<br>        <span class="hljs-string">&quot;k_proj&quot;</span>,<br>        <span class="hljs-string">&quot;v_proj&quot;</span>,<br>        <span class="hljs-string">&quot;o_proj&quot;</span>,<br>        <span class="hljs-string">&quot;gate_proj&quot;</span>,<br>        <span class="hljs-string">&quot;up_proj&quot;</span>,<br>        <span class="hljs-string">&quot;down_proj&quot;</span>,<br>        <span class="hljs-string">&quot;lm_head&quot;</span>,<br>    ],<br>    task_type=<span class="hljs-string">&quot;CAUSAL_LM&quot;</span><br>)<br><br>model = prepare_model_for_kbit_training(model) <span class="hljs-comment"># 用来使得模型能够训练在4Bits精度</span><br>model = get_peft_model(model, peft_config)<br></code></pre></td></tr></table></figure><p>打印一下可训练参数数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_trainable_parameters</span>(<span class="hljs-params">model</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Prints the number of trainable parameters in the model.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    trainable_params = <span class="hljs-number">0</span><br>    all_param = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> _, param <span class="hljs-keyword">in</span> model.named_parameters():<br>        all_param += param.numel()<br>        <span class="hljs-keyword">if</span> param.requires_grad:<br>            trainable_params += param.numel()<br>    <span class="hljs-built_in">print</span>(<br>        <span class="hljs-string">f&quot;trainable params: <span class="hljs-subst">&#123;trainable_params&#125;</span> || all params: <span class="hljs-subst">&#123;all_param&#125;</span> || trainable%: <span class="hljs-subst">&#123;<span class="hljs-number">100</span> * trainable_params / all_param&#125;</span>&quot;</span><br>    )<br>    <br>print_trainable_parameters(model)<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">trainable</span> params: <span class="hljs-number">56836096</span> || <span class="hljs-literal">all</span> params: <span class="hljs-number">23539437568</span> || trainable%: <span class="hljs-number">0</span>.<span class="hljs-number">24145052674182907</span><br></code></pre></td></tr></table></figure><h1 id="设置训练超参数"><a href="#设置训练超参数" class="headerlink" title="设置训练超参数"></a>设置训练超参数</h1><p>还可以设置一些训练超参数：</p><p><code>num_train_epochs/max_steps</code>: 数据迭代次数，如果过高会造成过拟合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> torch.cuda.device_count() &gt; <span class="hljs-number">1</span>: <span class="hljs-comment"># If more than 1 GPU</span><br>    <span class="hljs-built_in">print</span>(torch.cuda.device_count())<br>    model.is_parallelizable = <span class="hljs-literal">True</span><br>    model.model_parallel = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments<br><br>args = TrainingArguments(<br>  output_dir = <span class="hljs-string">&quot;Mixtral_Alpace_v2&quot;</span>,<br>  <span class="hljs-comment">#num_train_epochs=5,</span><br>  max_steps = <span class="hljs-number">1000</span>, <span class="hljs-comment"># 可以选择num_train_epochs或者按steps进行训练</span><br>  per_device_train_batch_size = <span class="hljs-number">32</span>,<br>  warmup_steps = <span class="hljs-number">0.03</span>,<br>  logging_steps=<span class="hljs-number">10</span>,<br>  save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>  <span class="hljs-comment">#evaluation_strategy=&quot;epoch&quot;,</span><br>  evaluation_strategy=<span class="hljs-string">&quot;steps&quot;</span>,<br>  eval_steps=<span class="hljs-number">10</span>, <span class="hljs-comment"># 默认是每轮都会评估，也可以自定义设置</span><br>  learning_rate=<span class="hljs-number">2.5e-5</span>,<br>  bf16=<span class="hljs-literal">True</span>,<br>  <span class="hljs-comment"># lr_scheduler_type=&#x27;constant&#x27;,</span><br>)<br></code></pre></td></tr></table></figure><p>最后设置一下SFTTrainer。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> trl <span class="hljs-keyword">import</span> SFTTrainer<br><br>max_seq_length = <span class="hljs-number">1024</span><br><br>trainer = SFTTrainer(<br>  model=model,<br>  peft_config=peft_config,<br>  max_seq_length=max_seq_length,<br>  tokenizer=tokenizer,<br>  packing=<span class="hljs-literal">True</span>,<br>  formatting_func=create_prompt, <span class="hljs-comment"># 这个会自动对原始数据集做映射处理，也就是之前的操作可以省略</span><br>  args=args,<br>  train_dataset=instruct_tune_dataset[<span class="hljs-string">&quot;train&quot;</span>],<br>  eval_dataset=instruct_tune_dataset[<span class="hljs-string">&quot;test&quot;</span>]<br>)<br><br>trainer.train() <span class="hljs-comment"># 开始训练</span><br></code></pre></td></tr></table></figure><p>训练完毕后记得保存模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">trainer.save_model(<span class="hljs-string">&quot;Mixtral_V2&quot;</span>)<br></code></pre></td></tr></table></figure><h1 id="模型合并"><a href="#模型合并" class="headerlink" title="模型合并"></a>模型合并</h1><p>可以通过<code>merge_and_unload</code>方法进行合并。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">merged_model = model.merge_and_unload()<br></code></pre></td></tr></table></figure><p>最后可以再使用新模型推理一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">&quot;[INST]Use the provided input to create an instruction that could have been used to generate the response with an LLM.\nThere are more than 12,000 species of grass. The most common is Kentucky Bluegrass, because it grows quickly, easily, and is soft to the touch. Rygrass is shiny and bright green colored. Fescues are dark green and shiny. Bermuda grass is harder but can grow in drier soil.[/INST]&quot;</span><br><br>generate_response(prompt, merged_model)<br></code></pre></td></tr></table></figure><p>2024&#x2F;1&#x2F;11 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>代码实战</tag>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>提高Python可读性：Type Hints的应用</title>
    <link href="/2024/01/08/%E6%8F%90%E9%AB%98Python%E5%8F%AF%E8%AF%BB%E6%80%A7%EF%BC%9A%E7%B1%BB%E5%9E%8B%E6%8F%90%E7%A4%BA%E5%92%8CEnum/"/>
    <url>/2024/01/08/%E6%8F%90%E9%AB%98Python%E5%8F%AF%E8%AF%BB%E6%80%A7%EF%BC%9A%E7%B1%BB%E5%9E%8B%E6%8F%90%E7%A4%BA%E5%92%8CEnum/</url>
    
    <content type="html"><![CDATA[<p>Python的类型提示是从3.6版本引入的。什么是类型提示？就是在各个方法中提前预设好需要的变量类型是什么。尽管Python作为动态类型语言，只有在运行时才能获得数据，但是它也提供了数据类型提示，来使得开发时更少的出现报错。</p><p>Python中提供了两种方式：原生和Typing库。它们的作用有两个：</p><ol><li>让IDE识别，进行告警和提示。</li><li>帮助其他开发者理解代码。</li></ol><p>此处附上一个非常有用的<a href="https://zhuanlan.zhihu.com/p/424042902?hmsr=toutiao.io&utm_campaign=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io">参考链接</a>。</p><h1 id="Built-In-Type-Hints"><a href="#Built-In-Type-Hints" class="headerlink" title="Built-In Type Hints"></a>Built-In Type Hints</h1><p>例如我们可以定义函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_int</span>(<span class="hljs-params">a: <span class="hljs-built_in">int</span>, b: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">str</span>:  <br>    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;a&#125;</span>-<span class="hljs-subst">&#123;b&#125;</span>&quot;</span>  <br><br>r = add_int(<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;hello&#x27;</span>)  <br><span class="hljs-built_in">print</span>(r)<br></code></pre></td></tr></table></figure><p>可以看到，这个函数的两个参数被指定为<code>int</code>，输出则为<code>str</code>。因此当使用时，输入错误变量类型时就会报错。</p><p>Python原生类型包括了：</p><ol><li><strong>基本类型</strong>:<ul><li><code>int</code>: 整数</li><li><code>float</code>: 浮点数</li><li><code>bool</code>: 布尔值</li><li><code>str</code>: 字符串</li></ul></li><li><strong>特殊类型</strong>:<ul><li><code>None</code>: 表示没有值</li></ul></li><li><strong>集合类型</strong>:<ul><li><code>list</code>: 列表</li><li><code>tuple</code>: 元组</li><li><code>set</code>: 集合</li><li><code>dict</code>: 字典</li></ul></li></ol><p>其中值得主意的是<code>None</code>。当一个方法没有return任何东西时，它的返回就是<code>None</code>。</p><p>为了提供更全面的提示，还能够通过导入typing库来进行提示。</p><h2 id="容器类型"><a href="#容器类型" class="headerlink" title="容器类型"></a>容器类型</h2><p>有时候，需要标注输入的参数是一个列表，且列表中只能为int，可以这么写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_sum</span>(<span class="hljs-params">lst: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> lst:<br>        total += i <br>    <span class="hljs-keyword">return</span> total<br></code></pre></td></tr></table></figure><p>这就是一个很好的例子。同样的，还可以这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">l: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>] = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br><br>t: <span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">str</span>, ...] = (<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>)<br><br>d: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>] = &#123;<br>    <span class="hljs-string">&quot;a&quot;</span>: <span class="hljs-number">1</span>,<br>    <span class="hljs-string">&quot;b&quot;</span>: <span class="hljs-number">2</span>,<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="类型别名"><a href="#类型别名" class="headerlink" title="类型别名"></a>类型别名</h2><p>对于一些多重嵌套的类型，还可以自定义类型别名，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">Config = <span class="hljs-built_in">list</span>[<span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>], <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]]<br><br>config: Config = [<br>    (<span class="hljs-string">&quot;127.0.0.1&quot;</span>, <span class="hljs-number">8080</span>),<br>    &#123;<br>        <span class="hljs-string">&quot;MYSQL_DB&quot;</span>: <span class="hljs-string">&quot;db&quot;</span>,<br>        <span class="hljs-string">&quot;MYSQL_USER&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,<br>        <span class="hljs-string">&quot;MYSQL_PASS&quot;</span>: <span class="hljs-string">&quot;pass&quot;</span>,<br>        <span class="hljs-string">&quot;MYSQL_HOST&quot;</span>: <span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br>        <span class="hljs-string">&quot;MYSQL_PORT&quot;</span>: <span class="hljs-string">&quot;3306&quot;</span>,<br>    &#125;,<br>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">start_server</span>(<span class="hljs-params">config: Config</span>) -&gt; <span class="hljs-literal">None</span>:<br>    <span class="hljs-keyword">pass</span><br><br>start_server(config)<br></code></pre></td></tr></table></figure><h2 id="可变类型"><a href="#可变类型" class="headerlink" title="可变类型"></a>可变类型</h2><p>对于一些可变的参数，也可以添加类型标注：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_function</span>(<span class="hljs-params">*args: <span class="hljs-built_in">str</span>, **kwargs: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>    ...<br><br>my_function(<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>, <span class="hljs-number">1</span>, x=<span class="hljs-number">2</span>, y=<span class="hljs-string">&quot;c&quot;</span>)<br></code></pre></td></tr></table></figure><h1 id="Typing库"><a href="#Typing库" class="headerlink" title="Typing库"></a>Typing库</h1><p>在Python3.9以前，有一些类型需要通过<code>typing</code>库来提供支持：</p><p>例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># for Python 3.9+ </span><br>l1: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>] = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>t1: <span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>] = (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>d1: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>] = &#123;<span class="hljs-string">&quot;a&quot;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&quot;b&quot;</span>: <span class="hljs-number">4</span>&#125;<br><br><span class="hljs-comment"># for Python 3.8 and earlier</span><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Tuple</span>, <span class="hljs-type">Dict</span><br><br>x: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>] = [<span class="hljs-number">1</span>]<br>x: <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>, <span class="hljs-built_in">float</span>] = (<span class="hljs-number">3</span>, <span class="hljs-string">&quot;yes&quot;</span>, <span class="hljs-number">7.5</span>)<br>x: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">float</span>] = &#123;<span class="hljs-string">&#x27;field&#x27;</span>: <span class="hljs-number">2.0</span>&#125;<br></code></pre></td></tr></table></figure><p>以下提供了一些常用的类型解释：</p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td>int</td><td>整型</td></tr><tr><td>float</td><td>浮点数字</td></tr><tr><td>bool</td><td>布尔</td></tr><tr><td>str</td><td>字符串</td></tr><tr><td>bytes</td><td>8位字符</td></tr><tr><td>object</td><td>任意对象</td></tr><tr><td>List(str)</td><td>字符串组成的列表</td></tr><tr><td>Tuple[int, …]</td><td>任意数量的int对象的元组</td></tr><tr><td>Tuple[int, int]</td><td>两个int对象的元组</td></tr><tr><td>Dict[str, int]</td><td>键是 str 值是 int 的字典</td></tr><tr><td>Iterable[int]</td><td>包含 int 的可迭代对象</td></tr><tr><td>Sequence[bool]</td><td>布尔值序列（只读）</td></tr><tr><td>Mapping[str, int]</td><td>从 str 键到 int 值的映射（只读）</td></tr><tr><td>Any</td><td>具有任意类型的动态类型值</td></tr><tr><td>Union</td><td>联合类型</td></tr><tr><td>Optional</td><td>参数可以为空或已经声明的类型</td></tr><tr><td>Mapping</td><td>映射，是 collections.abc.Mapping 的泛型</td></tr><tr><td>MutableMapping</td><td>Mapping 对象的子类，可变</td></tr><tr><td>Generator</td><td>生成器类型, Generator[YieldType、SendType、ReturnType]</td></tr><tr><td>NoReturn</td><td>函数没有返回结果，等同None</td></tr><tr><td>Set</td><td>集合 set 的泛型, 推荐用于注解返回类型</td></tr><tr><td>AbstractSet</td><td>collections.abc.Set 的泛型，推荐用于注解参数</td></tr><tr><td>Sequence</td><td>ollections.abc.Sequence 的泛型，list、tuple 等的泛化类型</td></tr><tr><td>TypeVar</td><td>自定义兼容特定类型的变量</td></tr><tr><td>NewType</td><td>声明一些具有特殊含义的类型</td></tr><tr><td>Callable</td><td>可调用类型, Callable[[参数类型], 返回类型]</td></tr></tbody></table><p>有一些值得注意的类型：</p><p><code>Any</code>：表示能够返回任何类型，这也是python默认的返回类型。</p><p><code>TypeVar</code>：可以使用它来接收任意类型，例如：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs py">height = <span class="hljs-number">1.75</span><br>Height = TypeVar(<span class="hljs-string">&#x27;Height&#x27;</span>, <span class="hljs-built_in">int</span>, <span class="hljs-built_in">float</span>, <span class="hljs-literal">None</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_height</span>() -&gt; Height:<br>    <span class="hljs-keyword">return</span> height<br></code></pre></td></tr></table></figure><p><code>Union</code>：可以使用指定的类型，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Union</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">concat</span>(<span class="hljs-params">s1: <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">bytes</span>], s2: <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">bytes</span>]</span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">bytes</span>]:<br>    <span class="hljs-keyword">return</span> s1 + s2<br></code></pre></td></tr></table></figure><h2 id="TypeVar和Union的区别"><a href="#TypeVar和Union的区别" class="headerlink" title="TypeVar和Union的区别"></a>TypeVar和Union的区别</h2><p>TypeVar对多参数的要求更加严格，必须类型是一致的，而不能混着来，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> TypeVar<br><br>T = TypeVar(<span class="hljs-string">&quot;T&quot;</span>, <span class="hljs-built_in">str</span>, <span class="hljs-built_in">bytes</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">concat</span>(<span class="hljs-params">s1: T, s2: T</span>) -&gt; T:<br>    <span class="hljs-keyword">return</span> s1 + s2<br><br>concat(<span class="hljs-string">&quot;hello&quot;</span>, <span class="hljs-string">&quot;world&quot;</span>)<br>concat(<span class="hljs-string">b&quot;hello&quot;</span>, <span class="hljs-string">b&quot;world&quot;</span>)<br>concat(<span class="hljs-string">&quot;hello&quot;</span>, <span class="hljs-string">b&quot;world&quot;</span>) <span class="hljs-comment"># 报错，因为两个输入的类型不一致。</span><br></code></pre></td></tr></table></figure><p><code>Optional</code>：表示一个值可以是特定类型或 <code>None</code>。这在函数参数和返回类型中很有用，因为它允许你明确地表达某个值可能不存在的情况，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet</span>(<span class="hljs-params">name: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>]:<br>    <span class="hljs-keyword">if</span> name:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Hello, <span class="hljs-subst">&#123;name&#125;</span>&quot;</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br>result = greet(<span class="hljs-string">&quot;Alice&quot;</span>)<br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出: Hello, Alice</span><br><br>result = greet(<span class="hljs-literal">None</span>)<br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出: None</span><br></code></pre></td></tr></table></figure><p>上述函数中，输入和输出都可能是空值。</p><p>事实上，<code>Optional[str]</code> 与 <code>Union[str, None]</code> 是等价的。</p><p><code>NewType</code>：可以声明一些具有特殊含义的类型：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs py">Person = NewType(<span class="hljs-string">&#x27;Person&#x27;</span>, <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>, <span class="hljs-built_in">float</span>])<br>person = Person((<span class="hljs-string">&#x27;Mike&#x27;</span>, <span class="hljs-number">22</span>, <span class="hljs-number">1.75</span>))<br></code></pre></td></tr></table></figure><h1 id="Type-Hints实践"><a href="#Type-Hints实践" class="headerlink" title="Type Hints实践"></a>Type Hints实践</h1><h2 id="Dataclass"><a href="#Dataclass" class="headerlink" title="Dataclass"></a>Dataclass</h2><p>在实际开发中，有很多可以用到类型提示的方法，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass, field<br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-built_in">id</span>: <span class="hljs-built_in">int</span><br>    name: <span class="hljs-built_in">str</span><br>    friends: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>] = field(default_factory=<span class="hljs-built_in">list</span>)<br><br>data = &#123;<br>    <span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-number">123</span>,<br>    <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Tim&quot;</span>,<br>&#125;<br><br>user = User(**data)<br><span class="hljs-built_in">print</span>(user.<span class="hljs-built_in">id</span>, user.name, user.friends)<br></code></pre></td></tr></table></figure><p>上面的例子中，我们给User的属性规定了类型。</p><h2 id="Pydantic"><a href="#Pydantic" class="headerlink" title="Pydantic"></a>Pydantic</h2><p>Pydantic也基于Type Hints，用来对数据类型进行检查：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span><br><br><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    <span class="hljs-built_in">id</span>: <span class="hljs-built_in">int</span><br>    name = <span class="hljs-string">&#x27;John Doe&#x27;</span><br>    signup_ts: <span class="hljs-type">Optional</span>[datetime] = <span class="hljs-literal">None</span><br>    friends: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>] = []<br><br>external_data = &#123;<br>    <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-string">&#x27;123&#x27;</span>,<br>    <span class="hljs-string">&#x27;signup_ts&#x27;</span>: <span class="hljs-string">&#x27;2021-09-02 17:00&#x27;</span>,<br>    <span class="hljs-string">&#x27;friends&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;3&#x27;</span>],<br>&#125;<br>user = User(**external_data)<br></code></pre></td></tr></table></figure><p>2024&#x2F;1&#x2F;8 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>类型提示</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论QA问答系统发展史：从Text2Vec到LLM</title>
    <link href="/2024/01/07/%E8%AE%BAQA%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E5%8F%91%E5%B1%95%E5%8F%B2%EF%BC%9A%E4%BB%8EText2Vec%E5%88%B0LLM/"/>
    <url>/2024/01/07/%E8%AE%BAQA%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E5%8F%91%E5%B1%95%E5%8F%B2%EF%BC%9A%E4%BB%8EText2Vec%E5%88%B0LLM/</url>
    
    <content type="html"><![CDATA[<p>周末在家刚好没事，看了一下问答系统的发展历史，在这里实现一下不同时期的QA系统。</p><h1 id="文本嵌入-文本相似度"><a href="#文本嵌入-文本相似度" class="headerlink" title="文本嵌入+文本相似度"></a>文本嵌入+文本相似度</h1><p>我们排开早期的按照规则实现的问答系统，最早被我们了解到的QA系统应该是通过文本嵌入+文本相似度实现的。</p><p>首先文本嵌入有多种实现方式，这里大致介绍一下：</p><p>文本嵌入是将文本转换为数值向量的过程，使得可以在这些向量之间进行相似性计算。以下是一些经典的文本嵌入模型：</p><ol><li>TF-IDF（Term Frequency-Inverse Document Frequency）：<ul><li>TF-IDF 是一种统计方法，用于评估一个词对于一个文档集或一个单独的文档的重要性。它基于词频（TF）和逆文档频率（IDF）的乘积来为每个词赋予权重。</li></ul></li><li>Word2Vec：<ul><li>Word2Vec 是一种基于神经网络的模型，用于学习词向量。它可以生成具有语义意义的密集向量，捕捉到词之间的上下文关系。</li></ul></li><li>GloVe（Global Vectors for Word Representation）：<ul><li>GloVe 是一个基于统计的模型，用于学习词向量。它结合了词共现矩阵的全局统计信息来生成词嵌入。</li></ul></li><li>FastText：<ul><li>FastText 是由 Facebook Research 开发的一个模型，它不仅可以生成词向量，还可以处理子词信息。这使得 FastText 在处理稀有词或者未见词时表现得更好。</li></ul></li><li>BERT（Bidirectional Encoder Representations from Transformers）：<ul><li>BERT 是一个基于 Transformer 架构的预训练模型，用于生成上下文感知的词嵌入。BERT 考虑了句子的双向信息，使得生成的嵌入可以捕获更丰富的语义信息。</li></ul></li><li>ELMo（Embeddings from Language Models）：<ul><li>ELMo 是另一个基于深度双向 LSTM 的模型，用于生成上下文感知的词嵌入。与传统的静态词嵌入不同，ELMo 为每个词生成多个嵌入向量，这些向量捕获了不同的上下文信息。</li></ul></li></ol><p>总之，这些模型的核心思想是通过各自算法将每个字符嵌入成高维向量，这样就可以计算不同文本之间的相似程度。</p><p>我们可以使用<code>sklearn</code>中的<code>TfidfVectorizer</code>实现一个简单的问答系统：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer<br><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> cosine_similarity<br><br><span class="hljs-comment"># 示例的问题和答案数据</span><br>questions = [<br>    <span class="hljs-string">&quot;什么是Python?&quot;</span>,<br>    <span class="hljs-string">&quot;Python有哪些优点?&quot;</span>,<br>    <span class="hljs-string">&quot;如何定义函数?&quot;</span>,<br>    <span class="hljs-string">&quot;Python的应用场景是什么?&quot;</span><br>]<br><br>answers = [<br>    <span class="hljs-string">&quot;Python是一种高级编程语言。&quot;</span>,<br>    <span class="hljs-string">&quot;Python有简单易读的语法、丰富的库和广泛的应用场景。&quot;</span>,<br>    <span class="hljs-string">&quot;在Python中，函数可以使用def关键字进行定义。&quot;</span>,<br>    <span class="hljs-string">&quot;Python在Web开发、数据分析、人工智能等多个领域有广泛的应用。&quot;</span><br>]<br></code></pre></td></tr></table></figure><p>我们有一些问题，以及一些对应的回答，将它们放在一个列表里。随后，我们使用<code>TfidfVectorizer</code>将这些问答向量化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用TF-IDF向量化文本数据</span><br>vectorizer = TfidfVectorizer()<br>tfidf_matrix = vectorizer.fit_transform(questions + answers)<br><br>tfidf_matrix<br><br>&gt;&gt; &lt;8x12 sparse matrix of <span class="hljs-built_in">type</span> <span class="hljs-string">&#x27;&lt;class &#x27;</span>numpy.float64<span class="hljs-string">&#x27;&gt;&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-number">12</span> stored elements <span class="hljs-keyword">in</span> Compressed Sparse Row <span class="hljs-built_in">format</span>&gt;<br></code></pre></td></tr></table></figure><p>将问答对嵌入后，可以看到变成了一个8*12的稀疏矩阵。这代表这8句话被嵌入到12维向量。</p><p>现在我们准备一个问题，并转化为向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">user_question = <span class="hljs-string">&quot;Python有哪些应用场景?&quot;</span><br>user_question_vec = vectorizer.transform([user_question])<br><br>user_question_vec<br><br>&gt;&gt; &lt;1x12 sparse matrix of <span class="hljs-built_in">type</span> <span class="hljs-string">&#x27;&lt;class &#x27;</span>numpy.float64<span class="hljs-string">&#x27;&gt;&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-number">0</span> stored elements <span class="hljs-keyword">in</span> Compressed Sparse Row <span class="hljs-built_in">format</span>&gt;<br></code></pre></td></tr></table></figure><p>可以看到问题被转化为了向量，这时候就可以进行相似度搜索了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">similarities = cosine_similarity(user_question_vec, tfidf_matrix)[<span class="hljs-number">0</span>]<br>most_similar_idx = np.argmax(similarities)<br><br>answers[most_similar_idx]<br><br>&gt;&gt; <span class="hljs-string">&#x27;Python是一种高级编程语言。&#x27;</span><br></code></pre></td></tr></table></figure><p>我们可以简单写成函数来实现这个问答：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_most_similar_question</span>(<span class="hljs-params">user_question,tfidf_matrix</span>):<br>    <span class="hljs-comment"># 首先将输入问题向量化</span><br>    user_question_vec = vectorizer.transform([user_question])<br>    <span class="hljs-comment"># 计算相似度</span><br>    similarities = cosine_similarity(user_question_vec,tfidf_matrix)[<span class="hljs-number">0</span>]<br>    <span class="hljs-built_in">print</span>(similarities)<br>    most_similar_idx = np.argmax(similarities)<br>    <span class="hljs-keyword">return</span> answers[most_similar_idx]<br><br><span class="hljs-comment"># 用户输入问题</span><br>user_input = <span class="hljs-string">&quot;什么是Python?&quot;</span><br><br><span class="hljs-comment"># 获取最相似的问题和答案</span><br>most_similar_question = get_most_similar_question(user_input, questions, tfidf_matrix)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;对应的答案是：<span class="hljs-subst">&#123;corresponding_answer&#125;</span>&quot;</span>)<br><br>&gt;&gt; [<span class="hljs-number">1.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span> <span class="hljs-number">0.</span>]<br>&gt;&gt; 对应的答案是：Python是一种高级编程语言。<br></code></pre></td></tr></table></figure><p>由于question&#x2F;answer和TF-IDF矩阵都是一开始就准备好的，这个函数里只需要输入问题和准备好的稀疏矩阵就可以了。可以看到，他从矩阵中找到相似度最高的问题，对应回答中相同的index即是期望看到的回答。</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>这是最早的QA系统实现手段之一。实现简单易懂，原理也并不复杂。然而它有很多不足，首先，它需要提前准备大量的问答对，以适应不同领域的各个问题，其次对于不同的提问形式，它很难给出精准准确的回答。</p><p>本质上，作为基于统计的方法，它本质上并没有理解问题的语义，只是找了一个最像的问答对作为回答。</p><h1 id="语言模型嵌入"><a href="#语言模型嵌入" class="headerlink" title="语言模型嵌入"></a>语言模型嵌入</h1><p>TF-IDF使用了基于统计的文本嵌入方式，后续随着NLP的发展，又出现了语言模型。这时候已经能通过语言模型将文本嵌入为更高维的输入了，一定程度上也能够理解语义。</p><p>使用Text2Vec进行了实现，它核心使用了transformers库的text2vec-base-chinese嵌入模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> text2vec <span class="hljs-keyword">import</span> SentenceModel, cos_sim, semantic_search<br><br><span class="hljs-comment"># 使用了transformers库的text2vec-base-chinese嵌入模型</span><br>embedder = SentenceModel()<br><br><span class="hljs-comment"># 语料样本库</span><br>corpus = [<br>    <span class="hljs-string">&#x27;花呗更改绑定银行卡&#x27;</span>,<br>    <span class="hljs-string">&#x27;我什么时候开通了花呗&#x27;</span>,<br>    <span class="hljs-string">&#x27;A man is eating food.&#x27;</span>,<br>    <span class="hljs-string">&#x27;A man is eating a piece of bread.&#x27;</span>,<br>    <span class="hljs-string">&#x27;The girl is carrying a baby.&#x27;</span>,<br>    <span class="hljs-string">&#x27;A man is riding a horse.&#x27;</span>,<br>    <span class="hljs-string">&#x27;A woman is playing violin.&#x27;</span>,<br>    <span class="hljs-string">&#x27;Two men pushed carts through the woods.&#x27;</span>,<br>    <span class="hljs-string">&#x27;A man is riding a white horse on an enclosed ground.&#x27;</span>,<br>    <span class="hljs-string">&#x27;A monkey is playing drums.&#x27;</span>,<br>    <span class="hljs-string">&#x27;A cheetah is running behind its prey.&#x27;</span><br>]<br><br><span class="hljs-comment"># 将语料进行嵌入</span><br>corpus_embeddings = embedder.encode(corpus)<br>corpus_embeddings<br></code></pre></td></tr></table></figure><p>得到的嵌入数据如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">array([[ <span class="hljs-number">6.53620958e-01</span>, -<span class="hljs-number">7.66664222e-02</span>,  <span class="hljs-number">9.59622979e-01</span>, ...,<br>        -<span class="hljs-number">6.01225317e-01</span>, -<span class="hljs-number">1.67934457e-03</span>,  <span class="hljs-number">2.14576736e-01</span>],<br>       [ <span class="hljs-number">6.70483976e-04</span>, -<span class="hljs-number">4.66219693e-01</span>,  <span class="hljs-number">8.83835256e-01</span>, ...,<br>        -<span class="hljs-number">6.52768135e-01</span>, -<span class="hljs-number">2.59505898e-01</span>, -<span class="hljs-number">4.05015022e-01</span>],<br>       [-<span class="hljs-number">6.99393526e-02</span>, -<span class="hljs-number">4.93847728e-01</span>,  <span class="hljs-number">3.72701913e-01</span>, ...,<br>         <span class="hljs-number">2.30209693e-01</span>, -<span class="hljs-number">6.62487626e-01</span>, -<span class="hljs-number">1.37236178e-01</span>],<br>       ...,<br>       [ <span class="hljs-number">4.95887578e-01</span>, -<span class="hljs-number">1.03028201e-01</span>,  <span class="hljs-number">1.88396394e-01</span>, ...,<br>         <span class="hljs-number">1.14771016e-01</span>, -<span class="hljs-number">1.29482400e+00</span>,  <span class="hljs-number">9.49718833e-01</span>],<br>       [ <span class="hljs-number">5.01094282e-01</span>, -<span class="hljs-number">4.13963169e-01</span>, -<span class="hljs-number">1.61480501e-01</span>, ...,<br>         <span class="hljs-number">3.57740372e-03</span>, -<span class="hljs-number">1.32486129e+00</span>,  <span class="hljs-number">3.83615524e-01</span>],<br>       [-<span class="hljs-number">1.52376592e-02</span>,  <span class="hljs-number">2.37213261e-02</span>,  <span class="hljs-number">4.10200447e-01</span>, ...,<br>        -<span class="hljs-number">2.21184328e-01</span>, -<span class="hljs-number">9.90046620e-01</span>, -<span class="hljs-number">3.17562759e-01</span>]], dtype=float32)<br></code></pre></td></tr></table></figure><p>在嵌入之后，得到了一个高维矩阵。我们再准备一些问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">queries = [<br>    <span class="hljs-string">&#x27;如何更换花呗绑定银行卡&#x27;</span>,<br>    <span class="hljs-string">&#x27;A man is eating pasta.&#x27;</span>,<br>    <span class="hljs-string">&#x27;Someone in a gorilla costume is playing a set of drums.&#x27;</span>,<br>    <span class="hljs-string">&#x27;A cheetah chases prey on across a field.&#x27;</span>]<br></code></pre></td></tr></table></figure><p>随后我们对其进行遍历以得到回答：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> query <span class="hljs-keyword">in</span> queries:<br>    query_embedding = embedder.encode(query)<br>    hits = semantic_search(query_embedding, corpus_embeddings, top_k=<span class="hljs-number">3</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n\n======================\n\n&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Query:&quot;</span>, query)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n语料中最相似的三个回答：&quot;</span>)<br>    hits = hits[<span class="hljs-number">0</span>]  <br>    <span class="hljs-keyword">for</span> hit <span class="hljs-keyword">in</span> hits:<br>        <span class="hljs-built_in">print</span>(corpus[hit[<span class="hljs-string">&#x27;corpus_id&#x27;</span>]], <span class="hljs-string">&quot;(Score: &#123;:.4f&#125;)&quot;</span>.<span class="hljs-built_in">format</span>(hit[<span class="hljs-string">&#x27;score&#x27;</span>]))<br></code></pre></td></tr></table></figure><p>回答如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python">======================<br>Query: 如何更换花呗绑定银行卡<br><br>语料中最相似的三个回答：<br>花呗更改绑定银行卡 (Score: <span class="hljs-number">0.8551</span>)<br>我什么时候开通了花呗 (Score: <span class="hljs-number">0.7212</span>)<br>A man <span class="hljs-keyword">is</span> eating food. (Score: <span class="hljs-number">0.3118</span>)<br>======================<br>Query: A man <span class="hljs-keyword">is</span> eating pasta.<br><br>语料中最相似的三个回答：<br>A man <span class="hljs-keyword">is</span> eating food. (Score: <span class="hljs-number">0.7840</span>)<br>A man <span class="hljs-keyword">is</span> riding a white horse on an enclosed ground. (Score: <span class="hljs-number">0.6906</span>)<br>A man <span class="hljs-keyword">is</span> eating a piece of bread. (Score: <span class="hljs-number">0.6831</span>)<br>======================<br>Query: Someone <span class="hljs-keyword">in</span> a gorilla costume <span class="hljs-keyword">is</span> playing a <span class="hljs-built_in">set</span> of drums.<br><br>语料中最相似的三个回答：<br>A monkey <span class="hljs-keyword">is</span> playing drums. (Score: <span class="hljs-number">0.6758</span>)<br>A man <span class="hljs-keyword">is</span> riding a white horse on an enclosed ground. (Score: <span class="hljs-number">0.6351</span>)<br>The girl <span class="hljs-keyword">is</span> carrying a baby. (Score: <span class="hljs-number">0.5438</span>)<br>======================<br>Query: A cheetah chases prey on across a field.<br><br>语料中最相似的三个回答：<br>A cheetah <span class="hljs-keyword">is</span> running behind its prey. (Score: <span class="hljs-number">0.6736</span>)<br>A man <span class="hljs-keyword">is</span> riding a white horse on an enclosed ground. (Score: <span class="hljs-number">0.5731</span>)<br>A monkey <span class="hljs-keyword">is</span> playing drums. (Score: <span class="hljs-number">0.4977</span>)<br></code></pre></td></tr></table></figure><p>同样的，Bert语言模型在一定程度上是这个模型的进一步扩展，这里先按下不表。</p><h2 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h2><p>在一定程度上，这种语言模型只是对传统基于统计的嵌入方式进行了改良，本质检索上并没有脱离相似度的桎梏。当然，后续Bert等语言模型能够进行文本分类，文本续写等任务，但是在问答任务上仍然不是一个很好的解决方案。</p><h1 id="大语言模型"><a href="#大语言模型" class="headerlink" title="大语言模型"></a>大语言模型</h1><p>在大语言模型问世后，基于文本相似度的问答系统一时间被打入冷宫。通过在大量问题语料上进行训练，语言模型能够在输入一个问题时，输出最符合训练语料和语义的回答。这对于之前是一个巨大的跨越。</p><p>通过AzureOpenAI进行了简单的调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> AzureChatOpenAI<br><br>llm = AzureChatOpenAI(<br>                        azure_endpoint=XXXXX,<br>                        openai_api_version=XXXXX,<br>                        deployment_name=XXXXX,<br>                        temperature=XXXXX,<br>                        openai_api_key=XXXXX,<br>                        openai_api_type=XXXXX,<br>                        streaming=XXXXX)<br><br>llm.predict(<span class="hljs-string">&#x27;Python是什么？&#x27;</span>)<br><br>&gt;&gt; <span class="hljs-string">&#x27;Python是一种高级编程语言，由Guido van Rossum于1989年开发。它具有简洁、易读、易学的特点，被广泛应用于软件开发、数据分析、人工智能等领域。Python具有丰富的标准库和第三方库，可以用于开发各种类型的应用程序。它支持面向对象编程、函数式编程和过程式编程等多种编程范式。Python的语法简洁明了，代码可读性强，因此被称为“优雅的编程语言”。&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h2><p>大语言模型经过了上亿问答语料的学习，它能够通过学到过的内容，找到最符合人类逻辑的下一个输出。由于问题是对Python的询问，它从上文中找到了最有可能出现的回答，并以人类能够理解的方式进行输出。</p><p>然而，由于生成语言模型以生成符合语义的句子为目的，因此它无法判断输出的内容是否准确，这也是它目前备受诟病的缺陷之一。</p><h1 id="基于RAG的大语言模型QA系统"><a href="#基于RAG的大语言模型QA系统" class="headerlink" title="基于RAG的大语言模型QA系统"></a>基于RAG的大语言模型QA系统</h1><p>前面提到基于统计的检索方法并不能以符合语义的方式输出回答，而是调用原文。那么现在我们有了会说人话的大语言模型，能不能将它们结合在一起呢？</p><p>基于这个思想，出现了RAG（检索增强生成）。通过结合输入问题和检索到的相关内容，大语言模型将得到的内容进行包装，使得其能够输出合理的，符合语义的回答。</p><p>通过Langchain和ChromaDB进行了简单的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> SentenceTransformerEmbeddings<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> CharacterTextSplitter<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> TextLoader<br><br><span class="hljs-comment"># 从本地导入语料</span><br>loader = TextLoader(<span class="hljs-string">&#x27;state_of_the_union.txt&#x27;</span>)<br>documents = loader.load()<br><br><span class="hljs-comment"># 将文本进行切块</span><br>text_splitter = CharacterTextSplitter(chunk_size=<span class="hljs-number">1000</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>docs = text_splitter.split_documents(documents)<br><br><span class="hljs-comment"># 将语料嵌入后存入向量数据库</span><br>embeddings = SentenceTransformerEmbeddings()<br>db = Chroma.from_documents(docs, embeddings)<br> <br></code></pre></td></tr></table></figure><p>首先，我们可以看一下简单的相似度搜索会得到什么样的回答：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">query = <span class="hljs-string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span><br>docs = db.similarity_search(query)<br><span class="hljs-built_in">print</span>(docs[<span class="hljs-number">0</span>].page_content)<br><br>&gt;&gt; Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And <span class="hljs-keyword">while</span> you’re at it, <span class="hljs-keyword">pass</span> the Disclose Act so Americans can know who <span class="hljs-keyword">is</span> funding our elections. <br></code></pre></td></tr></table></figure><p>可以看到，基于相似度搜索只返回了原文中相似的部分。</p><p>同样也可以看一下得分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">docs = db.similarity_search_with_score(query)<br>docs[<span class="hljs-number">0</span>]<br><br>&gt;&gt; (Document(page_content=<span class="hljs-string">&#x27;Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.&#x27;</span>, metadata=&#123;<span class="hljs-string">&#x27;source&#x27;</span>: <span class="hljs-string">&#x27;state_of_the_union.txt&#x27;</span>&#125;),<br> <span class="hljs-number">1.2032095193862915</span>)<br></code></pre></td></tr></table></figure><p>现在，我们引入大语言模型，让它理解问题和原文内容，并包装出合理的回答。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate<br><br>template = <span class="hljs-string">&quot;&quot;&quot;You are an assistant for question-answering tasks.</span><br><span class="hljs-string">Use the following pieces of retrieved context to answer the question.</span><br><span class="hljs-string">If you don&#x27;t know the answer, just say that you don&#x27;t know.</span><br><span class="hljs-string">Use three sentences maximum and keep the answer concise.</span><br><span class="hljs-string">Question: &#123;question&#125;</span><br><span class="hljs-string">Context: &#123;context&#125;</span><br><span class="hljs-string">Answer:</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>prompt = ChatPromptTemplate.from_template(template)<br></code></pre></td></tr></table></figure><p>在设定好输入提示词模板后，我们可以构建一个思维链。在这个链之中，内容是一个检索器，问题是一个可执行的输入，这两个东西被填入提示词模板后，交给大语言模型，并规定输出的格式是字符串：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain.schema.runnable <span class="hljs-keyword">import</span> RunnablePassthrough<br><span class="hljs-keyword">from</span> langchain.schema.output_parser <span class="hljs-keyword">import</span> StrOutputParser<br><br>rag_chain = (<br>    &#123;<span class="hljs-string">&quot;context&quot;</span>: retriever,  <span class="hljs-string">&quot;question&quot;</span>: RunnablePassthrough()&#125;<br>    | prompt<br>    | llm<br>    | StrOutputParser()<br>)<br><br>query = <span class="hljs-string">&quot;What did the president say about Justice Breyer&quot;</span><br>rag_chain.invoke(query)<br><br>&gt;&gt; The president thanked Justice Stephen Breyer <span class="hljs-keyword">for</span> his service <span class="hljs-keyword">and</span> acknowledged his dedication to serving the country.\n<br></code></pre></td></tr></table></figure><p>可以看到，输出的回答更符合人类的理解。</p><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>最后，我们可以将输入的文本向量持久化在数据库中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">vectordb = Chroma.from_documents(documents=documents, embedding=embeddings, persist_directory=<span class="hljs-string">&#x27;db&#x27;</span>)<br>vectordb.persist()<br>vectordb = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><p>在调用时如下操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">vectordb = Chroma(persist_directory=<span class="hljs-string">&#x27;db&#x27;</span>, embedding_function=embeddings)<br>retriever = db.as_retriever(search_type=<span class="hljs-string">&quot;mmr&quot;</span>)<br>retriever.get_relevant_documents(query)[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><p>2024&#x2F;1&#x2F;7 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
      <tag>问答系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何完成皆大欢喜的项目：近期工作所感</title>
    <link href="/2024/01/06/%E5%A6%82%E4%BD%95%E5%AE%8C%E6%88%90%E7%9A%86%E5%A4%A7%E6%AC%A2%E5%96%9C%E7%9A%84%E9%A1%B9%E7%9B%AE%EF%BC%9A%E8%BF%91%E6%9C%9F%E5%B7%A5%E4%BD%9C%E6%89%80%E6%84%9F/"/>
    <url>/2024/01/06/%E5%A6%82%E4%BD%95%E5%AE%8C%E6%88%90%E7%9A%86%E5%A4%A7%E6%AC%A2%E5%96%9C%E7%9A%84%E9%A1%B9%E7%9B%AE%EF%BC%9A%E8%BF%91%E6%9C%9F%E5%B7%A5%E4%BD%9C%E6%89%80%E6%84%9F/</url>
    
    <content type="html"><![CDATA[<p>最近的工作有些跌宕起伏，原先在做知识图谱的应用开发，后面又被抽调到另一个项目做新功能的开发，上周又被紧急要求推掉手头的工作，赶另外一个项目。</p><p>这个项目的问题已有一段时间，沟通不顺，技术困扰。有的时候乙方认为的完美方案在甲方这边可能并不能达到要求，相反是另一个方案更能合甲方心意。作为项目管理者在开发人员和甲方之中斡旋，是一个非常重要的议题。</p><h1 id="如何做一个合格的开发者"><a href="#如何做一个合格的开发者" class="headerlink" title="如何做一个合格的开发者"></a>如何做一个合格的开发者</h1><ul><li><p>明确的时间表：</p><p>甲方公司很少会时刻关注开发者的每日开发进程，因此开发团队一定需要有一个开发周期表，类似于项目里程碑，这个玩意主要是让甲方图个心安，知道开发者心里有数。</p></li><li><p>软工作占40%：</p><p>有句老话：程序员最讨厌不写文档的人和要他写文档的人。据说曾经有个程序员因为没写好文档被同事捅了数刀:&#x2F;。</p><p>说实话，我自己在开发的时候也不大爱写文档。从开发者的角度来看，自己亲手写的代码，总觉得外人一看代码，就应该很好理解怎么用。然而事实上实际项目中可能只有60%的时间在开发上，剩下得有20%的时间都在写部署手册和指标。</p><p><strong>评估指标</strong>：这个东西是实际项目中对开发团队非常有利的东西，你要是不写，甲方就会觉得开发者没做什么实事。相反要是写的特别详细，哪怕指标只提升了百分之零点几，甲方都觉得你尽力了。这个和发论文很像，哪怕你没做多少工作，评估指标换一换，文章写的好一点都可以发刊。</p><p><strong>部署手册</strong>：写这个玩意就是给啥也不会的小白看的。说白了，就是手把手让一个白痴会操作系统。这个确实从不同角度来看体验很不一样，对于不会Linux操作系统和vim的用户来说，对文档里的<strong>改名</strong>，<strong>复制</strong>一系列操作一脸懵逼。</p><blockquote><p> 这是我工作里感受最深的点，甲方往往对开发者的代码量，工作时长没有那么重视，却对一些汇报，文档之类的软工作要求非常严格，这是双方最大的冲突来源。</p><p>80分的硬工作，95分的软工作。</p></blockquote></li></ul><h1 id="如何做一个合格的项目管理者"><a href="#如何做一个合格的项目管理者" class="headerlink" title="如何做一个合格的项目管理者"></a>如何做一个合格的项目管理者</h1><ul><li><p>高频率的沟通：</p><p>同样的，在甲方里也存在不同的管理等级，作为项目管理者也需要时刻向顶头上司汇报。尽管自身没有开发的压力，但是有汇报的压力。因此就需要时刻与开发者保持沟通，从这个角度来看，项目管理者只是另一个乙方。</p></li><li><p>专业的提问：</p><p>同样，作为项目管理者，需要了解项目以及开发者的技术栈，以防止被开发者带偏。合理的提出专业的问题，而不是提一些愚蠢的基础问题，这一点非常重要。</p></li></ul><h1 id="运用博弈论来分析"><a href="#运用博弈论来分析" class="headerlink" title="运用博弈论来分析"></a>运用博弈论来分析</h1><p>在博弈论中，项目管理者和开发者构成了一个非零和不完全信息博弈，事实上，双方的收益矩阵可以表示如下：</p><table><thead><tr><th>开发者&#x2F;项目管理者</th><th>不积极沟通</th><th>积极沟通</th></tr></thead><tbody><tr><td>不积极沟通</td><td>（0，0）</td><td>（0，1.5）</td></tr><tr><td>积极沟通</td><td>（1，0）</td><td>（3，3）</td></tr></tbody></table><p>如果双方都不积极沟通，项目容易跑偏，最后大家都不落好。如果开发者单方面积极沟通，那么甲方高层无法从项目管理者获取到及时的积极信息。相反，管理者单方面积极，则容易出现双方冲突的情况。只有在双方都积极时才能让彼此都获得最高的收益：管理者的努力让高层看到，开发者的项目完成符合甲方需求。</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
      <tag>项目管理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python常用装饰器汇总</title>
    <link href="/2024/01/05/Python%E5%B8%B8%E7%94%A8%E8%A3%85%E9%A5%B0%E5%99%A8%E6%B1%87%E6%80%BB/"/>
    <url>/2024/01/05/Python%E5%B8%B8%E7%94%A8%E8%A3%85%E9%A5%B0%E5%99%A8%E6%B1%87%E6%80%BB/</url>
    
    <content type="html"><![CDATA[<p>前面提到了装饰器的一些原理和使用方法，这一篇博客专门讲一下有哪些常用的装饰器。</p><h1 id="property"><a href="#property" class="headerlink" title="@property"></a>@property</h1><p>在开发中，经常会需要构建类。构建类的时候是需要为类分配属性的。往往的属性会被写在<code>__init__</code>方法下，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Predict</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,arg1,arg2</span>):<br>        self.arg1 = arg1<br>        self.arg2 = arg2<br></code></pre></td></tr></table></figure><p>这种方式构建的类实例，可以被轻松赋值更改，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">predict_instance = Predict(arg1=<span class="hljs-number">1</span>,arg2=<span class="hljs-number">2</span>)<br>predict_instance.arg1 = <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>这样就会使得使用时安全性大大降低。为了解决这个问题，需要引入私有属性。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Predict</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,arg1,arg2</span>):<br>        self.__arg1 = arg1<br>        self.__arg2 = arg2<br></code></pre></td></tr></table></figure><p>这时候就无法访问<code>arg1</code>这个私有属性了，要怎么访问呢？那就需要定义一个方法去删除：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Predict</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,arg1,arg2</span>):<br>        self.__arg1 = arg1<br>        self.__arg2 = arg2<br>    <br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">arg1</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.__age<br>    <br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">arg2</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.__age<br></code></pre></td></tr></table></figure><p>通过定义了两个方法，就可以访问到这两个私有变量了。那么这里<code>@property</code>这个装饰器起到的作用就是把这两个方法变成可以直接调用的属性，这样调用时就不需要像普通方法一样写成<code>arg1()</code>了。</p><p>如果还想修改和删除这些私有变量，就需要再构建新的方法，并使用原方法组装成装饰器，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@arg1.setter</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">arg1</span>(<span class="hljs-params">self, arg1</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(arg1, <span class="hljs-built_in">int</span>):<br>        self.__arg1 = arg1<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError<br><br><span class="hljs-meta">@arg1.deleter</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">age1</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;删除年龄数据！&quot;</span>)<br>    <br>predict_instance.arg1 = <span class="hljs-number">3</span><br><span class="hljs-keyword">del</span> predict_instance.arg1<br></code></pre></td></tr></table></figure><p>通过设置了这两个方法，就可以和之前一样对私有变量进行修改 。</p><h1 id="abstractmethod"><a href="#abstractmethod" class="headerlink" title="@abstractmethod"></a>@abstractmethod</h1><p><code>@abstractmethod</code>是一个实现抽象方法的装饰器。所谓抽象方法，就是一个模板，后续继承自该类的类都需要满足<code>abstractmethod</code>的方法。这是为了模块化功能，使得项目代码更清晰。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> abstractmethod<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LLM_Base</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br><span class="hljs-keyword">pass</span><br>    <br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><p>在基类不需要实现具体的方法，但需要在子类中实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">OpenAI</span>(<span class="hljs-title class_ inherited__">LLM_Base</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,model</span>):<br>        self.model = model<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,message</span>):<br>        <span class="hljs-keyword">return</span> (model.predict(message))<br></code></pre></td></tr></table></figure><p>可以看到OpenAI类继承自LLM_Base，并实现了predict的方法。如果没有实现就会报错。</p><h1 id="classmethod"><a href="#classmethod" class="headerlink" title="@classmethod"></a>@classmethod</h1><p><code>@classmethod</code>和后面提到的<code>@staticmethod</code>有点像，它的作用是让类里的方法可以直接调用类的参数，并且不需要实例化类。也就是说，这个方法不需要<code>self</code>参数，但是第一个参数需要是<code>cls</code>，这代表类本身：从原理上来说，这个方法在内部先实例化了类，因此不需要外部显式的实例化。</p><p>举一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> datetime<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, birthdate</span>):<br>        self.name = name<br>        self.birthdate = birthdate<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_age</span>(<span class="hljs-params">self</span>):<br>        today = datetime.date.today()<br>        age = today.year - self.birthdate.year - ((today.month, today.day) &lt; (self.birthdate.month, self.birthdate.day))<br>        <span class="hljs-keyword">return</span> age<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">display</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;self.name&#125;</span> is <span class="hljs-subst">&#123;self.calculate_age()&#125;</span> years old.&quot;</span><br><br><span class="hljs-meta">    @classmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">from_birthyear</span>(<span class="hljs-params">cls, name, birthyear</span>):<br>        <span class="hljs-string">&quot;&quot;</span>通过输入名字和日期生成一个实例。<span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        return cls(name, datetime.date(birthyear, 1, 1))</span><br><span class="hljs-string"></span><br></code></pre></td></tr></table></figure><p>上面实现了一个类，这个类要求初始化时输入姓名和出生日期。同时也支持通过类方法<code>from_birthyear</code>创建实例，其中的<code>cls</code>不需要显式传递。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs pytho"># 使用普通的 __init__ 方法创建实例<br>person1 = Person(&quot;Alice&quot;, datetime.date(1990, 10, 15))<br>print(person1.display())  # 输出：Alice is 34 years old.<br><br># 使用 @classmethod 创建实例<br>person2 = Person.from_birthyear(&quot;Bob&quot;, 1995)<br>print(person2.display())  # 输出：Bob is 29 years old.<br></code></pre></td></tr></table></figure><blockquote><p>网上翻阅了一些相关内容，发现这个classmethod的好处主要是在可以直接调用类的参数。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Pizza</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, radius, height</span>):<br>        self.radius = radius<br>        self.height = height<br> <br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_area</span>(<span class="hljs-params">radius</span>):<br>        <span class="hljs-keyword">return</span> math.pi * (radius ** <span class="hljs-number">2</span>)<br> <br><span class="hljs-meta">    @classmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_volume</span>(<span class="hljs-params">cls, height, radius</span>):<br>        <span class="hljs-keyword">return</span> height * cls.compute_area(radius)    <span class="hljs-comment">#调用@staticmethod方法</span><br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_volume</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.compute_volume(self.height, self.radius)   <br>    <br><span class="hljs-built_in">print</span>(Pizza.compute_volume(<span class="hljs-number">12</span>, <span class="hljs-number">2</span>))<br><br>&gt;&gt; <span class="hljs-number">150.79644737231007</span><br></code></pre></td></tr></table></figure><p>可以看到它可以直接调用类里的静态方法。</p></blockquote><h1 id="staticmethod"><a href="#staticmethod" class="headerlink" title="@staticmethod"></a>@staticmethod</h1><p>静态方法就很好理解了，相比<code>classmethod</code>，它不需要实例化类，也不用类里的参数，只是一个单独可以调用的方法。之所以引入它，是为了区分这个函数属于某一类。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MathUtility</span>:<br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add_numbers</span>(<span class="hljs-params">num1, num2</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Static method to add two numbers.&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> num1 + num2<br>    <br><span class="hljs-built_in">sum</span> = MathUtility.add_numbers(num1=<span class="hljs-number">4</span>,num2=<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure><h1 id="dataclass"><a href="#dataclass" class="headerlink" title="@dataclass"></a>@dataclass</h1><p><code>@dataclass</code>在python3.7被引入。它的主要作用就是省略了<code>__init__</code>这个过程传统写类的时候，需要给类写一个初始化方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name: <span class="hljs-built_in">str</span>, unit_price: <span class="hljs-built_in">float</span>, quantity_on_hand: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span></span>):<br>    self.name = name<br>    self.unit_price = unit_price<br>    self.quantity_on_hand = quantity_on_hand<br></code></pre></td></tr></table></figure><p>而使用了<code>@dataclass</code>后，只需要这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass<br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">InventoryItem</span>:<br>    name: <span class="hljs-built_in">str</span><br>    unit_price: <span class="hljs-built_in">float</span><br>    quantity_on_hand: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">total_cost</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">float</span>:<br>        <span class="hljs-keyword">return</span> self.unit_price * self.quantity_on_hand<br></code></pre></td></tr></table></figure><p>此外，这个装饰器实际上不止实现了<code>__init__</code>方法，还实现了其他数据相关的魔术方法，例如：<code>__eq__</code>，<code>__repr__</code>等等。</p><p>我们还可以设置其中的<code>forzen</code>参数，将类参数设置为只读对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass<br><br><span class="hljs-meta">@dataclass(<span class="hljs-params">frozen=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>:<br>    name: <span class="hljs-built_in">str</span><br>    age: <span class="hljs-built_in">int</span><br>    iq: <span class="hljs-built_in">int</span> = <span class="hljs-number">100</span><br></code></pre></td></tr></table></figure><h1 id="overload"><a href="#overload" class="headerlink" title="@overload"></a>@overload</h1><p><code>overload</code>主要解决的是重载的概念。正常情况下，当Python同时定义两个同名方法时，后者才是真正调用时会被用到的方法，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">quack</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Quack: &quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">quack</span>(<span class="hljs-params">mark</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Quack: <span class="hljs-subst">&#123;mark&#125;</span>&quot;</span>)<br>    <br>quack <span class="hljs-comment"># 报错</span><br>quack(<span class="hljs-string">&#x27;Hello&#x27;</span>) <span class="hljs-comment"># Quack: Hello</span><br></code></pre></td></tr></table></figure><p>如果调用<code>overload</code>，就可以实现覆盖的效果。最后一个没有<code>overload</code>装饰器的同名方法将会涵盖之前的方法，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> overload<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Duck</span>:<br><br><span class="hljs-meta">    @overload</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">quack</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>: <br>        ...<br><br><span class="hljs-meta">    @overload</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">quack</span>(<span class="hljs-params">self, mark: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-literal">None</span>: <br>        ...<br><br>    <span class="hljs-comment"># 以上两个方法最终会被这个方法覆盖掉</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">quack</span>(<span class="hljs-params">self, arg=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-keyword">if</span> arg:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;GaGaGa: <span class="hljs-subst">&#123;arg&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;GaGaGa!&quot;</span>)<br><br>d = Duck()<br>d.quack()                <span class="hljs-comment"># Output: GaGaGa!</span><br>d.quack(<span class="hljs-string">&quot;I am a duck~&quot;</span>)  <span class="hljs-comment"># Output: GaGaGa: I am a duck~</span><br></code></pre></td></tr></table></figure><p><code>overload</code>实际上是一个类型检查的工具。它会为同名的所有方法，分配不同入参时的输出结果的类型。</p><blockquote><p>有的时候，一个方法可能有多种入参的组合，输出的结果类型不一样，这个时候就可以用overload实现。</p></blockquote><p>类似的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> overload<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>:<br><span class="hljs-meta">    @overload</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_method</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">pass</span><br>    <br><span class="hljs-meta">    @overload</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_method</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">pass</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_method</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(x, <span class="hljs-built_in">int</span>):<br>            <span class="hljs-keyword">return</span> x * <span class="hljs-number">2</span><br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(x, <span class="hljs-built_in">str</span>):<br>            <span class="hljs-keyword">return</span> x.upper()<br><br>obj = MyClass()<br><br><span class="hljs-comment"># 测试方法重载</span><br><span class="hljs-built_in">print</span>(obj.my_method(<span class="hljs-number">10</span>))     <span class="hljs-comment"># 输出: 20</span><br><span class="hljs-built_in">print</span>(obj.my_method(<span class="hljs-string">&#x27;hello&#x27;</span>))  <span class="hljs-comment"># 输出: HELLO</span><br></code></pre></td></tr></table></figure><p>理解了一下，用<code>overload</code>装饰的方法，只需要写它的入参类型和出参类型，具体实现是交给最后的方法实现。这个主要还是让IDE去理解，辅助类型提示。</p><h1 id="singleton"><a href="#singleton" class="headerlink" title="@singleton"></a>@singleton</h1><p><code>singleton</code>是一种设计思路，意为<strong>单例模式</strong>，也就是一个类只能有一个实例。基于这个思路可以手动实现<code>singleton</code>装饰器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">singleton</span>(<span class="hljs-params">cls</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;装饰器实现的 Singleton 模式&quot;&quot;&quot;</span><br>    instances = &#123;&#125;  <span class="hljs-comment"># 存储类实例的字典</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_instance</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        <span class="hljs-keyword">if</span> cls <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> instances:<br>            instances[cls] = cls(*args, **kwargs)<br>        <span class="hljs-keyword">return</span> instances[cls]<br><br>    <span class="hljs-keyword">return</span> get_instance<br><br><span class="hljs-meta">@singleton</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, value</span>):<br>        self.value = value<br><br><span class="hljs-comment"># 创建实例</span><br>obj1 = MyClass(<span class="hljs-number">1</span>)<br>obj2 = MyClass(<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 检查两个对象是否相同</span><br><span class="hljs-built_in">print</span>(obj1 <span class="hljs-keyword">is</span> obj2)  <span class="hljs-comment"># 输出: True</span><br><span class="hljs-built_in">print</span>(obj1.value)    <span class="hljs-comment"># 输出: 1</span><br><span class="hljs-built_in">print</span>(obj2.value)    <span class="hljs-comment"># 输出: 1</span><br></code></pre></td></tr></table></figure><h1 id="lru-cache"><a href="#lru-cache" class="headerlink" title="@lru_cache"></a>@lru_cache</h1><p><code>@lru_cache</code>是Python 标准库中 <code>functools</code> 模块提供的一个装饰器，用于实现函数的缓存功能。<code>LRU</code> 代表 “Least Recently Used”（最近最少使用），这意味着当缓存达到其最大大小时，最早缓存的项会被删除以为新的项腾出空间。</p><p>使用 <code>@lru_cache</code> 装饰器可以优化那些计算密集型、且参数相同的函数，因为它会缓存函数的结果，避免对相同输入进行重复计算。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> lru_cache<br><br><span class="hljs-meta">@lru_cache(<span class="hljs-params">maxsize=<span class="hljs-number">3</span></span>)  </span><span class="hljs-comment"># 设置最大缓存大小为 3</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fibonacci</span>(<span class="hljs-params">n</span>):<br>    <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">return</span> n<br>    <span class="hljs-keyword">return</span> fibonacci(n-<span class="hljs-number">1</span>) + fibonacci(n-<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 计算斐波那契数列的值</span><br><span class="hljs-built_in">print</span>(fibonacci(<span class="hljs-number">10</span>))  <span class="hljs-comment"># 第 10 个斐波那契数是 55</span><br><br><span class="hljs-comment"># 由于使用了缓存，再次调用 fibonacci(10) 时，结果会立即返回，而不需要再次计算</span><br><span class="hljs-built_in">print</span>(fibonacci(<span class="hljs-number">10</span>))  <span class="hljs-comment"># 仍然输出 55，但不会执行递归计算</span><br></code></pre></td></tr></table></figure><h1 id="log-results"><a href="#log-results" class="headerlink" title="@log_results"></a>@log_results</h1><p>在运行复杂的函数调用时，跟踪每个函数的输出变得至关重要。因此可以手动实现<code>@log_results</code>装饰器，来帮助我们记录函数的结果，以便于调试和监控:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">log_results</span>(<span class="hljs-params">func</span>):<br>     <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>(<span class="hljs-params">*args, **kwargs</span>):<br>         result = func(*args, **kwargs)<br>         <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;results.log&quot;</span>, <span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-keyword">as</span> log_file:<br>             log_file.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;func.__name__&#125;</span> - Result: <span class="hljs-subst">&#123;result&#125;</span>\n&quot;</span>)<br>            <span class="hljs-keyword">return</span> result<br> <br><span class="hljs-keyword">return</span> wrapper<br><br><span class="hljs-meta">@log_results</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_metrics</span>(<span class="hljs-params">data</span>):<br>     <span class="hljs-comment"># Your metric calculation code here</span><br></code></pre></td></tr></table></figure><p>2024&#x2F;1&#x2F;6 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>装饰器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python开发：装饰器如何理解和使用？</title>
    <link href="/2024/01/04/Python%E5%BC%80%E5%8F%91%EF%BC%9A%E8%A3%85%E9%A5%B0%E5%99%A8%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8%EF%BC%9F/"/>
    <url>/2024/01/04/Python%E5%BC%80%E5%8F%91%EF%BC%9A%E8%A3%85%E9%A5%B0%E5%99%A8%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h1><p>看社区代码的时候经常会看到装饰器的出现，我原先大概知道它的概念，也就是使用一个函数作为另一个函数的输入。今天上班路上刚好刷到码农高天的讲解视频，感觉对它的理解更深了一点，因此写篇博客记录一下。</p><p>首先提到了闭包的概念。</p><blockquote><p>闭包：在函数中嵌套一个函数，并引用了外部函数的变量。</p></blockquote><p>例如以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">outer</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner</span>(<span class="hljs-params">y</span>):<br>        <span class="hljs-keyword">return</span> x + y<br>    <span class="hljs-keyword">return</span> inner<br><br><span class="hljs-built_in">print</span>(outer(<span class="hljs-number">9</span>)(<span class="hljs-number">5</span>))<br><span class="hljs-comment"># 14</span><br></code></pre></td></tr></table></figure><p>上面的例子中，整个函数运行时，先运行<code>outer</code>函数，将<code>x</code>传入，随后运行<code>inner</code>函数的时候，又用到了<code>outer</code>函数的参数，最终输出结果。</p><p>Python中的装饰器就是一个语法糖，实现了闭包的作用，这样你可以利用重复调用外部函数，构建不同的函数。</p><blockquote><p>语法糖：由英国计算机科学家彼得·兰丁发明的一个术语，指计算机语言中添加的某种语法，这种语法对语言的功能没有影响，但是更方便程序员使用。</p></blockquote><p>一个经典的例子，用于统计内部函数的运算时间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">time_calc</span>(<span class="hljs-params">function</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>(<span class="hljs-params">*args, **kargs</span>):        <br>        start_time = time.time() <span class="hljs-comment"># 起始时间        </span><br>        f = function(*args,**kargs) <span class="hljs-comment"># 函数调用       </span><br>        exec_time = time.time() - start_time <span class="hljs-comment"># 统计结束时间        </span><br>        <span class="hljs-keyword">return</span> f    <br>    <span class="hljs-keyword">return</span> wrapper   <span class="hljs-comment"># 最后返回内部函数</span><br>    <br><span class="hljs-comment"># 使用装饰器</span><br><span class="hljs-meta">@time_calc    </span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-keyword">return</span> a + b<br>    <br><span class="hljs-meta">@time_calc</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sub</span>(<span class="hljs-params">a, b</span>):    <br>    <span class="hljs-keyword">return</span> a - b<br></code></pre></td></tr></table></figure><p>我们可以对比以下不用装饰器应该怎么写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义一个新的add函数，但是没用装饰器</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">no_decorator</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-keyword">return</span> a + b<br><br>f = time_calc(add)(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br><br>&gt;&gt; <span class="hljs-number">3</span><br>&gt;&gt; 函数 no_decorator() 执行时间为: <span class="hljs-number">0.000000</span> 秒    <br></code></pre></td></tr></table></figure><p>而使用装饰器时，可以看到代码更清晰了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">add(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br><br>&gt;&gt; <span class="hljs-number">3</span><br>&gt;&gt; 函数 add() 执行时间为: <span class="hljs-number">0.000000</span> 秒<br></code></pre></td></tr></table></figure><h1 id="同时使用多个装饰器"><a href="#同时使用多个装饰器" class="headerlink" title="同时使用多个装饰器"></a>同时使用多个装饰器</h1><p>当一个函数同时使用多个装饰器时，将依次调用。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">decorator_a</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner_a</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        <span class="hljs-built_in">print</span> <span class="hljs-string">&#x27;Get in inner_a&#x27;</span><br>        <span class="hljs-keyword">return</span> func(*args, **kwargs)<br>    <span class="hljs-keyword">return</span> inner_a<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">decorator_b</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner_b</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        <span class="hljs-built_in">print</span> <span class="hljs-string">&#x27;Get in inner_b&#x27;</span><br>        <span class="hljs-keyword">return</span> func(*args, **kwargs)<br>    <span class="hljs-keyword">return</span> inner_b<br><br><span class="hljs-meta">@decorator_b</span><br><span class="hljs-meta">@decorator_a</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-built_in">print</span> <span class="hljs-string">&#x27;Get in f&#x27;</span><br>    <span class="hljs-keyword">return</span> x * <span class="hljs-number">2</span><br>f(<span class="hljs-number">1</span>)<br><br>&gt;&gt; Get <span class="hljs-keyword">in</span> inner_b<br>&gt;&gt; Get <span class="hljs-keyword">in</span> inner_a<br>&gt;&gt; Get <span class="hljs-keyword">in</span> f<br></code></pre></td></tr></table></figure><p>也就是运行时，先运行了decorator_b，再运行了decorator_a，最后运行的被装饰的内部函数f(x)。</p><h1 id="闭包函数和装饰器的return"><a href="#闭包函数和装饰器的return" class="headerlink" title="闭包函数和装饰器的return"></a>闭包函数和装饰器的return</h1><p>前面我们看到，在一个装饰器中，有两个return，分别是闭包函数的return和装饰器的return。如何理解他们呢？</p><p>例如如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_decorator</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>():<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;执行装饰器逻辑&quot;</span>)<br>        func()  <span class="hljs-comment"># 调用原始函数</span><br>    <span class="hljs-keyword">return</span> wrapper  <span class="hljs-comment"># 返回闭包函数</span><br><br><span class="hljs-meta">@my_decorator</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">say_hello</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello!&quot;</span>)<br><br>say_hello()  <span class="hljs-comment"># 输出 &quot;执行装饰器逻辑&quot; 和 &quot;Hello!&quot;</span><br></code></pre></td></tr></table></figure><p>首先，闭包函数没有return，但是可以接收到装饰器函数的变量。装饰器函数有return。运行时返回的是<code>wrapper</code>这个函数。当使用<code> @my_decorator</code> 装饰 say_hello 函数时，say_hello 被重新赋值为<code>wrapper</code>函数。</p><p>当装饰器函数和闭包函数都有返回值时，函数的最终返回值是最内层执行的函数的返回值。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_decorator</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>():<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这是装饰器的内部函数&quot;</span>)<br>        <span class="hljs-keyword">return</span> func()  <span class="hljs-comment"># 调用原始函数并返回其结果</span><br>    <span class="hljs-keyword">return</span> wrapper  <span class="hljs-comment"># 返回装饰器的内部函数</span><br><br><span class="hljs-meta">@my_decorator</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_function</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这是原始函数&quot;</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;返回值来自原始函数&quot;</span><br><br>result = my_function()<br><span class="hljs-built_in">print</span>(result)  <br><br>&gt;&gt; 这是装饰器的内部函数<br>&gt;&gt; 这是原始函数<br>&gt;&gt; 返回值来自原始函数<br></code></pre></td></tr></table></figure><p>这个例子中闭包函数的返回值是<code>“返回值来自原始函数”</code>，而装饰器则返回装饰过后的函数。</p><p>result是闭包函数的返回值，也就是最后return的<code>“返回值来自原始函数”</code>。在这过程中，装饰器函数先被调用，返回一个修改过后的闭包函数，而闭包函数产生传入函数的结果。</p><h1 id="实际用例"><a href="#实际用例" class="headerlink" title="实际用例"></a>实际用例</h1><p>从网上看了一个例子：</p><p>进入视图函数前，需要增加自定义验证（比如判断是否为空，是否包含危险字符等），涉及两个装饰器：@login_required和@custom_login_required</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">login_required</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner</span>():<br>        <span class="hljs-comment">#一般这里是验证逻辑</span><br>        ...<br>        func()<br>    <span class="hljs-keyword">return</span> inner<br> <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">custom_login_required</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner</span>():<br>        <span class="hljs-comment">#这里添加自定义验证逻辑</span><br>        ...<br>        func()<br>    <span class="hljs-keyword">return</span> inner<br> <br> <br><span class="hljs-meta">@custom_login_required</span><br><span class="hljs-meta">@login_required</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">index</span>(<span class="hljs-params">request</span>):<br>...<br></code></pre></td></tr></table></figure><p>上面这个函数等价于<code>index = custom_login_required(login_required(index))</code></p><blockquote><p>使用python装饰器的好处就是在不用更改原函数的代码前提下给函数增加新的功能。从这句话来看，也可以知道装饰器的作用是在原函数的基础上外挂一些额外的功能。因此。装饰器函数的返回是调用传入函数函数的一个函数 。</p></blockquote><h1 id="使用类作为装饰器"><a href="#使用类作为装饰器" class="headerlink" title="使用类作为装饰器"></a>使用类作为装饰器</h1><p>类同样可以作为装饰器，接收一个对象进行初始化，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">myDecorator</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, f</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;inside myDecorator.__init__()&quot;</span>)<br>        f() <span class="hljs-comment"># Prove that function definition has completed</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;inside myDecorator.__call__()&quot;</span>)<br><br><span class="hljs-meta">@myDecorator</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">aFunction</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;inside aFunction()&quot;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished decorating aFunction()&quot;</span>)<br>aFunction()<br><br><br>&gt;&gt; inside myDecorator.__init__()<br>&gt;&gt; inside aFunction()<br>&gt;&gt; Finished decorating aFunction()<br>&gt;&gt; inside myDecorator.__call__()<br></code></pre></td></tr></table></figure><p>上面这个例子中，<code>aFunction</code>使用了<code>myDecorator</code>这个类作为装饰器，这个装饰器的作用是接收一个函数，在初始化时运行它。</p><p>当为<code>aFunction</code>定义<code>@myDecorator</code>这个装饰器的同时，装饰器函数被实例化了。在实例的同时，执行了一次闭包函数<code>aFunction</code>。因此，先打印的句子是<code>inside myDecorator.__init__()</code> 和<code>inside aFunction()</code>。</p><p>随后打印了<code>Finished decorating aFunction()</code>。最后打印了<code>inside myDecorator.__call__()</code>，这是因为是装饰器的返回内容。换句话说，最后我们运行了被装饰过后的<code>aFunction</code>，而不是它的原函数。因此它执行的是<code>myDecorator</code>这个类的执行函数，也就是魔法函数<code>__call__</code>。</p><blockquote><p>被装饰后的函数<code>aFunction()</code>实际上已经是类<code>myDecorator</code>的对象。当再调用<code>aFunction()</code>函数时，实际上就是调用类<code>myDecorator</code>的对象，因此会调用到类<code>myDecorator</code>的<code>__call__()</code>方法。</p></blockquote><h1 id="多参数对象作为装饰器"><a href="#多参数对象作为装饰器" class="headerlink" title="多参数对象作为装饰器"></a>多参数对象作为装饰器</h1><p>前面是把类作为装饰器，同样可以把类实例化成对象后作为装饰器调用。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decorator</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, arg1, arg2</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;执行类Decorator的__init__()方法&#x27;</span>)<br>        self.arg1 = arg1<br>        self.arg2 = arg2<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, f</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;执行类Decorator的__call__()方法&#x27;</span>)<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrap</span>(<span class="hljs-params">*args</span>):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;执行wrap()&#x27;</span>)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;装饰器参数：&#x27;</span>, self.arg1, self.arg2)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;执行&#x27;</span> + f.__name__ + <span class="hljs-string">&#x27;()&#x27;</span>)<br>            f(*args)<br>            <span class="hljs-built_in">print</span>(f.__name__ + <span class="hljs-string">&#x27;()执行完毕&#x27;</span>)<br>        <span class="hljs-keyword">return</span> wrap<br>    <br><span class="hljs-meta">@Decorator(<span class="hljs-params"><span class="hljs-string">&#x27;Hello&#x27;</span>, <span class="hljs-string">&#x27;World&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">example</span>(<span class="hljs-params">a1, a2, a3</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;传入example()的参数：&#x27;</span>, a1, a2, a3)<br>    <br>&gt;&gt; 执行类Decorator的__init__()方法<br>&gt;&gt; 执行类Decorator的__call__()方法<br></code></pre></td></tr></table></figure><p>以上代码中，装饰器是一个类，在实际调用中，往装饰器传参使其变成一个实例对象。哪怕没有运行传入的函数，在调用装饰器的同时已经开始了实例化并执行<code>__call__</code>方法，因此可以看到已经产生了结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">example(<span class="hljs-string">&#x27;Wish&#x27;</span>, <span class="hljs-string">&#x27;Happy&#x27;</span>, <span class="hljs-string">&#x27;EveryDay&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;测试代码执行完毕&#x27;</span>)<br><br>&gt;&gt; 执行wrap()<br>&gt;&gt; 装饰器参数： Hello World<br>&gt;&gt; 执行example()<br>&gt;&gt; 传入example()的参数： Wish Happy EveryDay<br>&gt;&gt; example()执行完毕<br>&gt;&gt; 测试代码执行完毕<br></code></pre></td></tr></table></figure><p>在实例化之后，直接运行这个被装饰后的函数。可以看到，它直接从<code>__call__</code>方法中的<code>wrap</code>函数开始执行。</p><h1 id="自定义的实例"><a href="#自定义的实例" class="headerlink" title="自定义的实例"></a>自定义的实例</h1><p>我又写了一个测试实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">test_dec</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,arg1,arg2</span>):<br>        self.arg1 = arg1<br>        self.arg2 = arg2<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self,f</span>):<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrap</span>(<span class="hljs-params">*args</span>):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;装饰器参数：&#x27;</span>,self.arg1,self.arg2)<br>            <span class="hljs-keyword">return</span> f(*args)<br>        <span class="hljs-keyword">return</span> wrap<br>    <br><span class="hljs-meta">@test_dec(<span class="hljs-params"><span class="hljs-string">&#x27;hello&#x27;</span>,<span class="hljs-string">&#x27;world&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">example</span>(<span class="hljs-params">a1,a2,a3</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;传入example()的参数：&#x27;</span>,a1,a2,a3)<br>    <span class="hljs-keyword">return</span>(<span class="hljs-string">&#x27;a,b,c&#x27;</span>)<br><br>b = example(<span class="hljs-string">&#x27;Wish&#x27;</span>, <span class="hljs-string">&#x27;Happy&#x27;</span>, <span class="hljs-string">&#x27;EveryDay&#x27;</span>)<br>b<br><br>&gt;&gt; 装饰器参数： hello world<br>&gt;&gt; 传入example()的参数： Wish Happy EveryDay<br><br>&gt;&gt; <span class="hljs-string">&#x27;a,b,c&#x27;</span><br></code></pre></td></tr></table></figure><p>在应用时，装饰器被实例化，它会对闭包函数进行装饰，加上了一个print语句。同时返回装饰后的闭包函数。外部函数则print一个语句，并返回a, b, c。</p><p>当执行<code>b = example(&#39;Wish&#39;, &#39;Happy&#39;, &#39;EveryDay&#39;)</code>时，依次执行了装饰器和函数本身，最后的结果：闭包函数的结果被赋值给了b。</p><p>2024&#x2F;1&#x2F;4 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
      <tag>装饰器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Loguru：目前最方便的Python日志方案</title>
    <link href="/2024/01/03/Loguru%EF%BC%9A%E7%9B%AE%E5%89%8D%E6%9C%80%E6%96%B9%E4%BE%BF%E7%9A%84Python%E6%97%A5%E5%BF%97%E6%96%B9%E6%A1%88/"/>
    <url>/2024/01/03/Loguru%EF%BC%9A%E7%9B%AE%E5%89%8D%E6%9C%80%E6%96%B9%E4%BE%BF%E7%9A%84Python%E6%97%A5%E5%BF%97%E6%96%B9%E6%A1%88/</url>
    
    <content type="html"><![CDATA[<p>最近在做公司的Machine Learning和Knowledge Graph的项目，这之中都需要日志模块。之前写的时候用的是基于python自带的logging模块的自定义类，相信很多python开发者都了解过。</p><p>logging库本身用起来倒也不是很难，就是需要单独实例化<code>StreamHandler</code>和<code>FileHandler</code>才可以同时生成持久化日志和流式日志，还是有点复杂。对于想<del>偷懒</del>保持代码简洁的我，还是需要一个更方便的解决方案。</p><p>刚好有一天刷知乎看到有人推荐了Loguru，看了一下确实很符合代码简洁的需求。网上对这个库的评价都是“优雅”，“简单”。Github页面甚至用了“Python logging made (stupidly) simple”来形容它的易用性。</p><h1 id="Loguru"><a href="#Loguru" class="headerlink" title="Loguru"></a>Loguru</h1><p>Loguru中包含了一个logger类，可以直接调用。之后所有的日志处理都基于这个实例化的logger类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> loguru <span class="hljs-keyword">import</span> logger<br></code></pre></td></tr></table></figure><p>由于logger本身已经实例化，可以把它像print一样调用，日志信息会直接显示在控制台：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">logger.debug(<span class="hljs-string">&#x27;this is a debug message&#x27;</span>)<br>logger.info(<span class="hljs-string">&#x27;this is info message&#x27;</span>)<br>logger.warning(<span class="hljs-string">&#x27;this is warning message&#x27;</span>)<br>logger.error(<span class="hljs-string">&#x27;this is error message&#x27;</span>)<br>logger.info(<span class="hljs-string">&#x27;this is info message&#x27;</span>)<br>logger.success(<span class="hljs-string">&#x27;this is success message!&#x27;</span>)<br>logger.critical(<span class="hljs-string">&#x27;this is critical message!&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h1><p>如果需要把它持久化在本地，也可以使用logger的add方法，添加到日志文件中。这时在调用logger时，就会同步在日志文件中更新日志。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br>log_dir = <span class="hljs-string">&#x27;/logfile&#x27;</span><br>logfile_dir = os.path.join(log_dir,<span class="hljs-string">&#x27;model_evl.log&#x27;</span>)<br><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(log_dir):<br>    os.mkdir(log_dir)<br><br>logger.add(logfile_dir)<br>logger.debug(<span class="hljs-string">&#x27;this is a debug message&#x27;</span>)<br>logger.info(<span class="hljs-string">&#x27;this is info message&#x27;</span>)<br>logger.warning(<span class="hljs-string">&#x27;this is warning message&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h1><p>logger的基础配置如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> loguru <span class="hljs-keyword">import</span> logger<br><br>logger.add(<br>    sink=<span class="hljs-string">&#x27;./logs/train.log&#x27;</span>,  <br>    level=<span class="hljs-string">&#x27;INFO&#x27;</span>,<br>    rotation=<span class="hljs-string">&#x27;00:00&#x27;</span>, <span class="hljs-comment"># &#x27;5 seconds&#x27; 也可以是Int，当Int时代表日志的容量限制。      </span><br>    retention=<span class="hljs-string">&#x27;7 days&#x27;</span>,  <span class="hljs-comment"># &#x27;4 weeks&#x27;/&#x27;1 minutes&#x27;:删除超过4星期/1分钟的日志 3: 仅保留三个最新文件</span><br>    compression=<span class="hljs-string">&#x27;zip&#x27;</span>,        <br>    encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>,  <br>    backtrace=<span class="hljs-literal">True</span>, <span class="hljs-comment"># 设置为True时会将报错信息完整记录在日志</span><br>    enqueue=<span class="hljs-literal">True</span>,<br>    <span class="hljs-built_in">format</span>=<span class="hljs-string">&quot;&#123;time:YYYY-MM-DD HH:mm:ss&#125; | &#123;level&#125; | &#123;message&#125;&quot;</span><br>)<br></code></pre></td></tr></table></figure><p>以下是参数的解释：</p><ul><li><code>sink</code>:  创建日志文件的路径。</li><li><code>level</code>: 记录日志的等级，低于这个等级的日志不会被记录。等级顺序为 debug &lt; info &lt; warning &lt; error。设置 INFO 会让 logger.debug 的输出信息不被写入磁盘。这个和logging库是一样的。</li><li><code>rotation</code>: 轮换策略，此处代表每天凌晨创建新的日志文件进行日志 IO；也可以通过设置 “2 MB” 来指定 日志文件达到 2 MB 时进行轮换。</li><li><code>retention</code>: 只保留 7 天。</li><li><code>compression</code>: 日志文件较大时会采用 zip 进行压缩。</li><li><code>encoding</code>: 日志的编码方式。</li><li><code>format</code>: 定义日志字符串的样式。</li><li><code>filter</code>：用于过滤记录。 </li><li><code>colorize</code>: 采用布尔值并确定是否应启用终端着色。 </li><li><code>serialize</code>：如果设置为 True，日志记录会保存成 JSON。 </li><li><code>backtrace</code>：确定异常跟踪是否应该延伸到捕获错误的点之外，以便于调试。 诊断：确定变量值是否应显示在异常跟踪中。您应该在生产环境中将其设置为 False 以避免泄露敏感信息。 </li><li><code>diagnose</code>: 确定变量值是否应在异常跟踪中显示。在生产环境中应将其设置为 False，以避免泄露敏感信息。</li><li><code>enqueue</code>：启用此选项会将日志记录放入队列中，以避免多个进程记录到同一目的地时发生冲突。 </li><li><code>catch</code>：如果在记录到指定的接收器时发生意外错误，您可以通过将此选项设置为 True 来捕获该错误。错误将打印到标准错误。</li></ul><p>这样看也比较清晰：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">logger.add(<span class="hljs-string">&quot;test.log&quot;</span>, rotation=<span class="hljs-string">&quot;10 MB&quot;</span>)     <span class="hljs-comment"># 文件大于10M会重新生成一个文件</span><br>logger.add(<span class="hljs-string">&quot;test.log&quot;</span>, rotation=<span class="hljs-string">&quot;00:00&quot;</span>)     <span class="hljs-comment"># 每天0点创建新文件</span><br>logger.add(<span class="hljs-string">&quot;test.log&quot;</span>, rotation=<span class="hljs-string">&quot;1 week&quot;</span>)    <span class="hljs-comment"># 每过一周就会创建新文件</span><br>logger.add(<span class="hljs-string">&quot;test.log&quot;</span>, retention=<span class="hljs-string">&quot;5 days&quot;</span>)   <span class="hljs-comment"># 只保留最近五天的日志文件</span><br>logger.add(<span class="hljs-string">&quot;test.log&quot;</span>, compression=<span class="hljs-string">&quot;zip&quot;</span>)    <span class="hljs-comment"># 以zip格式对日志进行保存</span><br>logger.add(<span class="hljs-string">&#x27;log-&#123;time&#125;.log&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>)  <span class="hljs-comment">#会给日志文件名自动增加时间信息以区分，比如log-2021-03-15_23-36-51_241786.log，encoding参数设置保存为UTF-8编码</span><br></code></pre></td></tr></table></figure><h1 id="过滤日志"><a href="#过滤日志" class="headerlink" title="过滤日志"></a>过滤日志</h1><p>可以使用filter来过滤日志。例如我们可以创建一个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">from</span> loguru <span class="hljs-keyword">import</span> logger<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">level_filter</span>(<span class="hljs-params">level</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">is_level</span>(<span class="hljs-params">record</span>):<br>        <span class="hljs-keyword">return</span> record[<span class="hljs-string">&quot;level&quot;</span>].name == level<br>    <span class="hljs-keyword">return</span> is_level<br><br>logger.remove(<span class="hljs-number">0</span>)<br>logger.add(<span class="hljs-string">&quot;./logs/app.log&quot;</span>, <span class="hljs-built_in">filter</span>=level_filter(level=<span class="hljs-string">&quot;WARNING&quot;</span>))<br></code></pre></td></tr></table></figure><p>在<code>filter</code>中添加过滤函数，可以限制最终日志文件的信息。当然也可以用lambda函数：<code>filter=lambda record: record[&quot;level&quot;].name == &quot;CRITICAL&quot;</code>。</p><h1 id="使用装饰器捕捉异常"><a href="#使用装饰器捕捉异常" class="headerlink" title="使用装饰器捕捉异常"></a>使用装饰器捕捉异常</h1><p>loguru提供了一个装饰器来捕捉函数的异常报错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> loguru <span class="hljs-keyword">import</span> logger<br><br><span class="hljs-meta">@logger.catch()</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>/<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>这时运行以下代码，日志文件会捕捉报错信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">logger.add(<span class="hljs-string">&quot;test.log&quot;</span>, retention=<span class="hljs-string">&quot;5 days&quot;</span>)<br>test()<br></code></pre></td></tr></table></figure><p>不过使用装饰器会导致函数无法并行运行，这时就需要在函数面前单独加上一个<code>logger.add(&#39;log/running_logs.log&#39;)</code>才能让它正常记录日志。</p><p>2024&#x2F;1&#x2F;3 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>Loguru</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于子词的分词方法：BPE算法</title>
    <link href="/2024/01/01/%E5%9F%BA%E4%BA%8E%E5%AD%97%E8%AF%8D%E7%9A%84%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95%EF%BC%9ABPE%E7%AE%97%E6%B3%95/"/>
    <url>/2024/01/01/%E5%9F%BA%E4%BA%8E%E5%AD%97%E8%AF%8D%E7%9A%84%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95%EF%BC%9ABPE%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>了解NLP或LLM的同学应该都对文本嵌入不陌生，例如Word2Vec，GloVe等。这些嵌入方法的第一步都是对文本进行分词，随后以各种各样的方式将分词Token转化为编码。</p><p>在这过程中，分词这一步经常会被忽视。如果以字母单位进行分词，就会导致词表过大，推理时速度非常冗长，如果单词单位进行分词，就会无法处理未知的词汇。尤其是词库过大时，在上万个单词中计算概率分布，计算量非常大。今天就介绍一下BPE(Byte Pair Encoding)分词算法。这个算法被各大模型广泛使用，用以构建词表。</p><h1 id="完整分词流程"><a href="#完整分词流程" class="headerlink" title="完整分词流程"></a>完整分词流程</h1><p>一个完整的分词流程是这样的：输入句子为：<code>&quot;I went to New York last week.&quot;</code></p><p>分词器会将这话分为：<code>[&#39;i&#39;, &#39;went&#39;, &#39;to&#39;, &#39;New&#39;, &#39;York&#39;, &#39;last&#39;, &#39;week&#39;]</code> 这就是最普通的分词。然而它无法泛化变位的词关系。例如，当模型学习了<code>old, older, oldest</code>，这三个词是不同形态下的一个词。它不知道<code>smart, smarter, smartest</code>这是和类似的变位关系。</p><p>此外，<code>old, older, oldest</code>本身也会被当作三个独立的词进行学习，这等于丢失了很多语言信息。为了解决这个问题，出现了基于子词的分词方法。</p><h1 id="基于子词的分词方法"><a href="#基于子词的分词方法" class="headerlink" title="基于子词的分词方法"></a>基于子词的分词方法</h1><p>基于子词(subword)的分词方法很符合逻辑，英语中有词根的定义，相同的词根在语义上类似。因此，人们尝试提取词根来进行分词。再进一步，又将词根进一步细化，把词根又切分成更小的子词。例如<br><code>unfortunately</code>可以被拆分为：<code>un</code> + <code>for</code> + <code>tun</code> + <code>ate</code> + <code>ly</code>。&#96;</p><p>总结一下，与传统分词对比，基于子词的分词方法的优势在于：</p><ul><li>可以更好的处理未知或罕见的词汇。</li><li>可以学习到词缀之间的关系。</li><li>分词比单词的词根分词更细。</li></ul><h1 id="BPE算法"><a href="#BPE算法" class="headerlink" title="BPE算法"></a>BPE算法</h1><p>BPE算法本身的名字有点不符合分词这个任务类型：Bytes Pair Encoding。其实它来自于一种数据压缩算法。</p><blockquote><p>BPE算法的核心思想：每一步都将最常见的一对相邻数据单位替换为该数据中没有出现过的一个新单位，反复迭代直到满足停止条件。</p></blockquote><p>假设有需要编码（压缩）的数据<code>aaabdaaabac</code>。可以注意到相邻字节对<code>aa</code>最常出现，因此我们将用一个新字节 <code>Z</code> 替换它。</p><ol><li>现在有了 <code>ZabdZabac</code>，其中 <code>Z</code> &#x3D;<code>aa</code>。下一个常见的字节对是 <code>ab</code>，用<code>Y</code>替换它。</li><li>现在有 <code>ZYdZYac</code>，其中<code>Z</code> &#x3D; <code>aa</code> ，<code>Y</code> &#x3D; <code>ab</code>。剩下的唯一字节对是<code>ac</code>，它只有一个，所以我们不对它进行编码。</li><li>我们可以递归地使用字节对编码将 <code>ZY</code> 编码为 <code>X</code>。</li><li>我们的数据现在已转换为 <code>XdXac</code>，其中 <code>X</code> &#x3D; <code>ZY</code>，<code>Y</code> &#x3D; <code>ab</code>，<code>Z</code> &#x3D; <code>aa</code>。它不能被进一步压缩，因为没有出现多次的字节对。</li><li>该算法不断重复此过程，直到不能进一步压缩 ，比如说没有更多高频 byte 对，或是没有没用过的 byte 来进行替换表示了。最后算法会在写出压缩数据前，写出替换 byte 对的替换表。</li></ol><p>这个算法在NLP长时间的发展中被引入。在LLM中，脱离了Bytes的层面，而转移到字符层面。在具实现上，采用了以下的步骤：</p><ol><li>计算每对相邻字符&#x2F;子词的频率</li><li>找到出现频率最高的相邻字符或子词，并将它们合并成一个新的符号</li><li>在词汇表中添加这个新的符号</li><li>更新输入文本中的所有相邻字符或子词，用新的符号替换它们</li><li>重新计算各对相邻字符或子词的频率，回到步骤2</li></ol><p>更具体的流程如下：</p><ol><li>把每个文档 $d$ 变成一个个单词，比如你可以简单用空格分词就好</li><li>统计每个单词 $w$ 在所有文档中的出现频率，并得到初始的字符集 <code>alphabet</code> 作为一开始的 Vocab（包括后面的<code>&lt;/w&gt;</code>）</li><li>先将每个单词划分为一个个 utf-8 char，称为一个划分，比如 <code>highest -&gt; h, i, g, h, e, s, t</code></li><li>然后，在每个单词的划分最后面加上 <code>&lt;/w&gt;</code>，那么现在 <code>highest -&gt; h, i, g, h, e, s, t, &lt;/w&gt;</code></li><li>重复下面步骤直到满足两个条件中的任意一个：1）Vocab 达到上限。2）达到最大迭代次数</li></ol><ul><li>找到最经常一起出现的 pair，并记录这个合并规则放在 merge table 里面，同时把合并之后的结果放到 Vocab 里面</li><li>更新所有单词的划分，假设我们发现<code> (h, i)</code> 最经常一起出现，那么 <code>highest -&gt; hi, g, h, e, s, t, &lt;/w&gt;</code></li></ul><blockquote><p>加入<code>&lt;/w&gt;</code>是为了标记单词之间的边界。</p></blockquote><h2 id="使用BPE编码"><a href="#使用BPE编码" class="headerlink" title="使用BPE编码"></a>使用BPE编码</h2><p>完成训练后，将得到一个merge table和一个词表Vocab。当我们需要对一段文本进行处理时，就需要先把文本拆成一个个单词，每个单词拆分成字符。随后遍历merge table，根据规则更新字符的合并策略。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>假设我们对一段文本统计词频，得到不同单词的频数，随后把每个单词变成一个个 utf-8 字符然后加上<code>&lt;/w&gt;</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;l o w &lt;/w&gt;&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;l o w e r &lt;/w&gt;&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n e w e s t &lt;/w&gt;&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;w i d e s t &lt;/w&gt;&#x27;</span>: <span class="hljs-number">3</span>&#125;<br></code></pre></td></tr></table></figure><p>出现最频繁的字节对是<code>e</code>和<code>s</code>，共出现了6+3&#x3D;9次，因此将它们合并：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;l o w &lt;/w&gt;&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;l o w e r &lt;/w&gt;&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n e w es t &lt;/w&gt;&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;w i d es t &lt;/w&gt;&#x27;</span>: <span class="hljs-number">3</span>&#125;<br></code></pre></td></tr></table></figure><p> 现在出现最频繁的字节对是<code>es</code>和<code>t</code>，共出现了6+3&#x3D;9次，因此将它们合并：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;l o w &lt;/w&gt;&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;l o w e r &lt;/w&gt;&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n e w est &lt;/w&gt;&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;w i d est &lt;/w&gt;&#x27;</span>: <span class="hljs-number">3</span>&#125;<br></code></pre></td></tr></table></figure><p>现在出现最频繁的字节对是<code>est</code>和<code>&lt;/w&gt;</code>，共出现了6+3&#x3D;9次，因此将它们合并：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;l o w &lt;/w&gt;&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;l o w e r &lt;/w&gt;&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n e w est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;w i d est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">3</span>&#125;<br></code></pre></td></tr></table></figure><p>出现最频繁的字节对是<code>l</code>和<code>o</code>，共出现了5+2&#x3D;7次，因此将它们合并：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;lo w &lt;/w&gt;&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;lo w e r &lt;/w&gt;&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n e w est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;w i d est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">3</span>&#125;<br></code></pre></td></tr></table></figure><p>出现最频繁的字节对是<code>lo</code>和<code>w</code>，共出现了5+2&#x3D;7次，因此将它们合并：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;low &lt;/w&gt;&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;low e r &lt;/w&gt;&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n e w est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;w i d est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">3</span>&#125;<br></code></pre></td></tr></table></figure><p>我们一直迭代到预设的字词词表大小或最高频的字节对的频数都为1，就得到了合适的词表。</p><h2 id="中文分词思路"><a href="#中文分词思路" class="headerlink" title="中文分词思路"></a>中文分词思路</h2><p>中文的分词思路也是类似的。我们在编码后，可能会得到这么一句话：”W1在W2W3W4里，W5的W6W7W8W9高。”</p><p>它对对应的哈希表是：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">W1</span> <span class="hljs-operator">=</span> [无论]<br><span class="hljs-attribute">W2</span> <span class="hljs-operator">=</span> [英文]<br><span class="hljs-attribute">W3</span> <span class="hljs-operator">=</span> [还是]<br><span class="hljs-attribute">W4</span> <span class="hljs-operator">=</span> [中文]<br><span class="hljs-attribute">W5</span> <span class="hljs-operator">=</span> [词汇]<br><span class="hljs-attribute">W6</span> <span class="hljs-operator">=</span> [特点]<br><span class="hljs-attribute">W7</span> <span class="hljs-operator">=</span> [就是]<br><span class="hljs-attribute">W8</span> <span class="hljs-operator">=</span> [出现]<br><span class="hljs-attribute">W9</span> <span class="hljs-operator">=</span> [频率]<br></code></pre></td></tr></table></figure><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>看了一下网上的源码，比较清晰。代码分成了两个部分，一个是统计词频，一个是合并词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> re, collections<br><br>text = <span class="hljs-string">&quot;The aims for this subject is for students to develop an understanding of the main algorithms used in naturallanguage processing, for use in a diverse range of applications including text classification, machine translation, and question answering. Topics to be covered include part-of-speech tagging, n-gram language modelling, syntactic parsing and deep learning. The programming language used is Python, see for more information on its use in the workshops, assignments and installation at home.&quot;</span><br><span class="hljs-comment"># text = &#x27;low &#x27;*5 +&#x27;lower &#x27;*2+&#x27;newest &#x27;*6 +&#x27;widest &#x27;*3</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_vocab</span>(<span class="hljs-params">text</span>):<br><span class="hljs-comment"># 初始化为0</span><br>vocab = collections.defaultdict(<span class="hljs-built_in">int</span>)<br>    <span class="hljs-comment"># 去头去尾再根据空格split</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> text.strip().split():<br>        <span class="hljs-comment"># 给list中每个元素增加空格，并在最后增加结束符号，同时统计单词出现次数</span><br>        vocab[<span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-built_in">list</span>(word)) + <span class="hljs-string">&#x27; &lt;/w&gt;&#x27;</span>] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> vocab<br><span class="hljs-built_in">print</span>(get_vocab(text))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_stats</span>(<span class="hljs-params">vocab</span>):<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">这个函数遍历词汇表中的所有单词，并计算彼此相邻的一对标记。</span><br><span class="hljs-string"></span><br><span class="hljs-string">EXAMPLE:</span><br><span class="hljs-string">    word = &#x27;T h e &lt;\w&gt;&#x27;</span><br><span class="hljs-string">    这个单词可以两两组合成： [(&#x27;T&#x27;, &#x27;h&#x27;), (&#x27;h&#x27;, &#x27;e&#x27;), (&#x27;e&#x27;, &#x27;&lt;\w&gt;&#x27;)]</span><br><span class="hljs-string">    </span><br><span class="hljs-string">输入:</span><br><span class="hljs-string">    vocab: Dict[str, int]  # vocab统计了词语出现的词频</span><br><span class="hljs-string">    </span><br><span class="hljs-string">输出:</span><br><span class="hljs-string">    pairs: Dict[Tuple[str, str], int] # 字母对，pairs统计了单词对出现的频率</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>    pairs = collections.defaultdict(<span class="hljs-built_in">int</span>)<br>    <br>    <span class="hljs-keyword">for</span> word,freq <span class="hljs-keyword">in</span> vocab.items():<br>        <br>        <span class="hljs-comment"># 遍历每一个word里面的symbol，去凑所有的相邻两个内容</span><br>        symbols = word.split()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(symbols)-<span class="hljs-number">1</span>):<br>            pairs[(symbols[i],symbols[i+<span class="hljs-number">1</span>])] += freq<br><br>    <span class="hljs-keyword">return</span> pairs<br></code></pre></td></tr></table></figure><p>合并高频字符对：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">merge_vocab</span>(<span class="hljs-params">pair, v_in</span>):<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    EXAMPLE:</span><br><span class="hljs-string">        word = &#x27;T h e &lt;\w&gt;&#x27;</span><br><span class="hljs-string">        pair = (&#x27;e&#x27;, &#x27;&lt;\w&gt;&#x27;)</span><br><span class="hljs-string">        word_after_merge = &#x27;T h e&lt;\w&gt;&#x27;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    输入:</span><br><span class="hljs-string">        pair: Tuple[str, str] # 需要合并的字符对</span><br><span class="hljs-string">        v_in: Dict[str, int]  # 合并前的vocab</span><br><span class="hljs-string"></span><br><span class="hljs-string">    输出:</span><br><span class="hljs-string">        v_out: Dict[str, int] # 合并后的vocab</span><br><span class="hljs-string"></span><br><span class="hljs-string">    注意:</span><br><span class="hljs-string">        当合并word &#x27;Th e&lt;\w&gt;&#x27;中的字符对 (&#x27;h&#x27;, &#x27;e&#x27;)时，&#x27;Th&#x27;和&#x27;e&lt;\w&gt;&#x27;字符对不能被合并。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    v_out = &#123;&#125;<br>    <span class="hljs-comment"># 把pair拆开，然后用空格合并起来，然后用\把空格转义</span><br>    bigram = re.escape(<span class="hljs-string">&#x27; &#x27;</span>.join(pair))<br>    <span class="hljs-comment"># 自定义一个正则规则, (?&lt;!\S)h\ e(?!\S) 只有前面、后面不是非空白字符(\S)(意思前后得是没东西的)，才匹配h\ e，这样就可以把Th\ e&lt;\w&gt;排除在外</span><br>    p = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r&#x27;(?&lt;!\S)&#x27;</span> + bigram + <span class="hljs-string">r&#x27;(?!\S)&#x27;</span>)<br>    <br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> v_in:<br>        <span class="hljs-comment"># 遍历当前的vocabulary，找到匹配正则的v时，才用合并的pair去替换变成新的pair new，如果没有匹配上，那就保持原来的。</span><br>        <span class="hljs-comment"># 比如pair当前是&#x27;h&#x27;和&#x27;e&#x27;，然后遍历vocabulary，找到符合前后都没有东西只有&#x27;h\ e&#x27;的时候就把他们并在一起变成&#x27;he&#x27;</span><br>        new = p.sub(<span class="hljs-string">&#x27;&#x27;</span>.join(pair),v)<br>        <span class="hljs-comment"># 然后新的合并的数量就是当前vocabulary里面pair对应的数量</span><br>        v_out[new] = v_in[v]<br>    <span class="hljs-keyword">return</span> v_out<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_tokens</span>(<span class="hljs-params">vocab</span>):<br>    tokens = collections.defaultdict(<span class="hljs-built_in">int</span>)<br>    <span class="hljs-keyword">for</span> word, freq <span class="hljs-keyword">in</span> vocab.items():<br>        word_tokens = word.split()<br>        <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> word_tokens:<br>            tokens[token] += freq<br>    <span class="hljs-keyword">return</span> tokens<br><br><br><span class="hljs-comment"># Get free book from Gutenberg</span><br><span class="hljs-comment"># wget http://www.gutenberg.org/cache/epub/16457/pg16457.txt</span><br><span class="hljs-comment"># vocab = get_vocab(&#x27;pg16457.txt&#x27;)</span><br><br>vocab = get_vocab(text)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Vocab =&quot;</span>, vocab)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;==========&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Tokens Before BPE&#x27;</span>)<br>tokens = get_tokens(vocab)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Tokens: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(tokens))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Number of tokens: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">len</span>(tokens)))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;==========&#x27;</span>)<br><br><span class="hljs-comment">#about 100 merges we start to see common words</span><br>num_merges = <span class="hljs-number">100</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_merges):<br>    pairs = get_stats(vocab)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> pairs:<br>        <span class="hljs-keyword">break</span><br>    <br>    <span class="hljs-comment"># vocabulary里面pair出现次数最高的作为最先合并的pair</span><br>    best = <span class="hljs-built_in">max</span>(pairs, key=pairs.get)<br>    <br>    <span class="hljs-comment"># 先给他合并了再说，当然这里不操作也没什么，到merge_vocab里面都一样</span><br>    new_token = <span class="hljs-string">&#x27;&#x27;</span>.join(best)<br>    vocab = merge_vocab(best, vocab)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Iter: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Best pair: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(best))<br>    <span class="hljs-comment"># add new token to the vocab</span><br>    tokens[new_token] = pairs[best]<br>    <span class="hljs-comment"># deduct frequency for tokens have been merged</span><br>    tokens[best[<span class="hljs-number">0</span>]] -= pairs[best]<br>    tokens[best[<span class="hljs-number">1</span>]] -= pairs[best]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Tokens: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(tokens))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Number of tokens: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">len</span>(tokens)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;==========&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;vocab, &#x27;</span>, vocab)<br></code></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python">==========<br>Tokens Before BPE<br>Tokens: defaultdict(&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;int&#x27;</span>&gt;, &#123;<span class="hljs-string">&#x27;l&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;o&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;w&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;&lt;/w&gt;&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;e&#x27;</span>: <span class="hljs-number">17</span>, <span class="hljs-string">&#x27;r&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;s&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;t&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;i&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;d&#x27;</span>: <span class="hljs-number">3</span>&#125;)<br>Number of tokens: <span class="hljs-number">11</span><br>==========<br>Iter: <span class="hljs-number">0</span><br>Best pair: (<span class="hljs-string">&#x27;e&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>)<br>Tokens: defaultdict(&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;int&#x27;</span>&gt;, &#123;<span class="hljs-string">&#x27;l&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;o&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;w&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;&lt;/w&gt;&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;e&#x27;</span>: <span class="hljs-number">8</span>, <span class="hljs-string">&#x27;r&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;es&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;t&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;i&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;d&#x27;</span>: <span class="hljs-number">3</span>&#125;)<br>Number of tokens: <span class="hljs-number">11</span><br>==========<br>Iter: <span class="hljs-number">1</span><br>Best pair: (<span class="hljs-string">&#x27;es&#x27;</span>, <span class="hljs-string">&#x27;t&#x27;</span>)<br>Tokens: defaultdict(&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;int&#x27;</span>&gt;, &#123;<span class="hljs-string">&#x27;l&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;o&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;w&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;&lt;/w&gt;&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;e&#x27;</span>: <span class="hljs-number">8</span>, <span class="hljs-string">&#x27;r&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;est&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;i&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;d&#x27;</span>: <span class="hljs-number">3</span>&#125;)<br>Number of tokens: <span class="hljs-number">10</span><br>==========<br>Iter: <span class="hljs-number">2</span><br>Best pair: (<span class="hljs-string">&#x27;est&#x27;</span>, <span class="hljs-string">&#x27;&lt;/w&gt;&#x27;</span>)<br>Tokens: defaultdict(&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;int&#x27;</span>&gt;, &#123;<span class="hljs-string">&#x27;l&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;o&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;w&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;&lt;/w&gt;&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;e&#x27;</span>: <span class="hljs-number">8</span>, <span class="hljs-string">&#x27;r&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;i&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;d&#x27;</span>: <span class="hljs-number">3</span>&#125;)<br>Number of tokens: <span class="hljs-number">10</span><br>==========<br>Iter: <span class="hljs-number">3</span><br>Best pair: (<span class="hljs-string">&#x27;l&#x27;</span>, <span class="hljs-string">&#x27;o&#x27;</span>)<br>Tokens: defaultdict(&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;int&#x27;</span>&gt;, &#123;<span class="hljs-string">&#x27;lo&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;w&#x27;</span>: <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;&lt;/w&gt;&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;e&#x27;</span>: <span class="hljs-number">8</span>, <span class="hljs-string">&#x27;r&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;i&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;d&#x27;</span>: <span class="hljs-number">3</span>&#125;)<br>Number of tokens: <span class="hljs-number">9</span><br>==========<br>Iter: <span class="hljs-number">4</span><br>Best pair: (<span class="hljs-string">&#x27;lo&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>)<br>Tokens: defaultdict(&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;int&#x27;</span>&gt;, &#123;<span class="hljs-string">&#x27;low&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;&lt;/w&gt;&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;e&#x27;</span>: <span class="hljs-number">8</span>, <span class="hljs-string">&#x27;r&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;n&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;w&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;est&lt;/w&gt;&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;i&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;d&#x27;</span>: <span class="hljs-number">3</span>&#125;)<br>Number of tokens: <span class="hljs-number">9</span><br>==========<br></code></pre></td></tr></table></figure><p>至此，我们通过输入文本，得到了一个分词的词表。下面就需要对文本进行编码和解码。</p><h1 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h1><p>对于编码，需要对文本中每个单词进行拆分，并遍历词表，寻找是否有token是当前单词的子字符串。从最长的 token 迭代到最短的 token，尝试将每个单词中的子字符串替换为 token。 最终，我们将迭代所有 token，并将所有子字符串替换为 token。 如果仍然有子字符串没被替换但所有 token 都已迭代完毕，则将剩余的子词替换为特殊 token，如 <unk></p><p>例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">[<span class="hljs-string">&quot;the&lt;/w&gt;&quot;</span>, <span class="hljs-string">&quot;highest&lt;/w&gt;&quot;</span>, <span class="hljs-string">&quot;mountain&lt;/w&gt;&quot;</span>]<br><br><span class="hljs-comment"># 排好序的subword表</span><br><span class="hljs-comment"># 长度 6         5           4        4         4       4          2</span><br>[<span class="hljs-string">&quot;errrr&lt;/w&gt;&quot;</span>, <span class="hljs-string">&quot;tain&lt;/w&gt;&quot;</span>, <span class="hljs-string">&quot;moun&quot;</span>, <span class="hljs-string">&quot;est&lt;/w&gt;&quot;</span>, <span class="hljs-string">&quot;high&quot;</span>, <span class="hljs-string">&quot;the&lt;/w&gt;&quot;</span>, <span class="hljs-string">&quot;a&lt;/w&gt;&quot;</span>]<br><br><span class="hljs-comment"># 迭代结果</span><br><span class="hljs-string">&quot;the&lt;/w&gt;&quot;</span> -&gt; [<span class="hljs-string">&quot;the&lt;/w&gt;&quot;</span>]<br><span class="hljs-string">&quot;highest&lt;/w&gt;&quot;</span> -&gt; [<span class="hljs-string">&quot;high&quot;</span>, <span class="hljs-string">&quot;est&lt;/w&gt;&quot;</span>]<br><span class="hljs-string">&quot;mountain&lt;/w&gt;&quot;</span> -&gt; [<span class="hljs-string">&quot;moun&quot;</span>, <span class="hljs-string">&quot;tain&lt;/w&gt;&quot;</span>]<br></code></pre></td></tr></table></figure><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_tokens_from_vocab</span>(<span class="hljs-params">vocab</span>):<br>    tokens_frequencies = collections.defaultdict(<span class="hljs-built_in">int</span>)<br>    vocab_tokenization = &#123;&#125;<br>    <span class="hljs-keyword">for</span> word, freq <span class="hljs-keyword">in</span> vocab.items():<br>        <span class="hljs-comment"># 看vocabulary里面的token频率，相当于上面的code中的tokens去除freq为0的</span><br>        word_tokens = word.split()<br>        <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> word_tokens:<br>            tokens_frequencies[token] += freq<br>        <span class="hljs-comment"># vocab和其对应的tokens</span><br>        vocab_tokenization[<span class="hljs-string">&#x27;&#x27;</span>.join(word_tokens)] = word_tokens<br>    <span class="hljs-keyword">return</span> tokens_frequencies, vocab_tokenization<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">measure_token_length</span>(<span class="hljs-params">token</span>):<br>    <br>    <span class="hljs-comment"># 如果token最后四个元素是 &lt; / w &gt;</span><br>    <span class="hljs-keyword">if</span> token[-<span class="hljs-number">4</span>:] == <span class="hljs-string">&#x27;&lt;/w&gt;&#x27;</span>:<br>        <span class="hljs-comment"># 那就返回除了最后四个之外的长度再加上1(结尾)</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(token[:-<span class="hljs-number">4</span>]) + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 如果这个token里面没有结尾就直接返回当前长度</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(token)<br>    <br><span class="hljs-comment"># 如果vocabulary里面找不到要拆分的词，就根据已经有的token现拆</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_word</span>(<span class="hljs-params">string, sorted_tokens, unknown_token=<span class="hljs-string">&#x27;&lt;/u&gt;&#x27;</span></span>):<br>    <br>    <span class="hljs-comment"># base case，没词进来了，那拆的结果就是空的</span><br>    <span class="hljs-keyword">if</span> string == <span class="hljs-string">&#x27;&#x27;</span>:<br>        <span class="hljs-keyword">return</span> []<br>    <span class="hljs-comment"># 已有的sorted tokens没有了，那就真的没这个词了</span><br>    <span class="hljs-keyword">if</span> sorted_tokens == []:<br>        <span class="hljs-keyword">return</span> [unknown_token] * <span class="hljs-built_in">len</span>(string)<br><br>    <span class="hljs-comment"># 记录拆分结果</span><br>    string_tokens = []<br>    <br>    <span class="hljs-comment"># iterate over all tokens to find match</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sorted_tokens)):<br>        token = sorted_tokens[i]<br>        <br>        <span class="hljs-comment"># 自定义一个正则，然后要把token里面包含句号的变成[.]</span><br>        token_reg = re.escape(token.replace(<span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[.]&#x27;</span>))<br>        <br>        <span class="hljs-comment"># 在当前string里面遍历，找到每一个match token的开始和结束位置，比如string=good，然后token是o，输出[(2,2),(3,3)]?</span><br>        matched_positions = [(m.start(<span class="hljs-number">0</span>), m.end(<span class="hljs-number">0</span>)) <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> re.finditer(token_reg, string)]<br>        <span class="hljs-comment"># if no match found in the string, go to next token</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(matched_positions) == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">continue</span><br>        <span class="hljs-comment"># 因为要拆分这个词，匹配上的token把这个word拆开了，那就要拿到除了match部分之外的substring，所以这里要拿match的start</span><br>        substring_end_positions = [matched_position[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> matched_position <span class="hljs-keyword">in</span> matched_positions]<br>        substring_start_position = <span class="hljs-number">0</span><br>        <br>        <br>        <span class="hljs-comment"># 如果有匹配成功的话，就会进入这个循环</span><br>        <span class="hljs-keyword">for</span> substring_end_position <span class="hljs-keyword">in</span> substring_end_positions:<br>            <span class="hljs-comment"># slice for sub-word</span><br>            substring = string[substring_start_position:substring_end_position]<br>            <span class="hljs-comment"># tokenize this sub-word with tokens remaining 接着用substring匹配剩余的sorted token，因为刚就匹配了一个</span><br>            string_tokens += tokenize_word(string=substring, sorted_tokens=sorted_tokens[i+<span class="hljs-number">1</span>:], unknown_token=unknown_token)<br>            <span class="hljs-comment"># 先把sorted token里面匹配上的记下来</span><br>            string_tokens += [token]<br>            substring_start_position = substring_end_position + <span class="hljs-built_in">len</span>(token)<br>        <span class="hljs-comment"># tokenize the remaining string 去除前头的substring，去除已经匹配上的，后面还剩下substring_start_pos到结束的一段substring没看</span><br>        remaining_substring = string[substring_start_position:]<br>        <span class="hljs-comment"># 接着匹配</span><br>        string_tokens += tokenize_word(string=remaining_substring, sorted_tokens=sorted_tokens[i+<span class="hljs-number">1</span>:], unknown_token=unknown_token)<br>        <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># return list of unknown token if no match is found for the string</span><br>        string_tokens = [unknown_token] * <span class="hljs-built_in">len</span>(string)<br>        <br>    <span class="hljs-keyword">return</span> string_tokens<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">该函数生成一个所有标记的列表，按其长度（第一键）和频率（第二键）排序。</span><br><span class="hljs-string"></span><br><span class="hljs-string">EXAMPLE:</span><br><span class="hljs-string">    token frequency dictionary before sorting: &#123;&#x27;natural&#x27;: 3, &#x27;language&#x27;:2, &#x27;processing&#x27;: 4, &#x27;lecture&#x27;: 4&#125;</span><br><span class="hljs-string">    sorted tokens: [&#x27;processing&#x27;, &#x27;language&#x27;, &#x27;lecture&#x27;, &#x27;natural&#x27;]</span><br><span class="hljs-string">    </span><br><span class="hljs-string">INPUT:</span><br><span class="hljs-string">    token_frequencies: Dict[str, int] # Counter for token frequency</span><br><span class="hljs-string">    </span><br><span class="hljs-string">OUTPUT:</span><br><span class="hljs-string">    sorted_token: List[str] # Tokens sorted by length and frequency</span><br><span class="hljs-string"></span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sort_tokens</span>(<span class="hljs-params">tokens_frequencies</span>):<br>    <span class="hljs-comment"># 对 token_frequencies里面的东西，先进行长度排序，再进行频次，sorted是从低到高所以要reverse</span><br>    sorted_tokens_tuple = <span class="hljs-built_in">sorted</span>(tokens_frequencies.items(), key=<span class="hljs-keyword">lambda</span> item:(measure_token_length(item[<span class="hljs-number">0</span>]),item[<span class="hljs-number">1</span>]), reverse=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment"># 然后只要tokens不要频次</span><br>    sorted_tokens = [token <span class="hljs-keyword">for</span> (token, freq) <span class="hljs-keyword">in</span> sorted_tokens_tuple]<br><br>    <span class="hljs-keyword">return</span> sorted_tokens<br><br><span class="hljs-comment">#display the vocab</span><br>tokens_frequencies, vocab_tokenization = get_tokens_from_vocab(vocab)<br><br><span class="hljs-comment">#sort tokens by length and frequency</span><br>sorted_tokens = sort_tokens(tokens_frequencies)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Tokens =&quot;</span>, sorted_tokens, <span class="hljs-string">&quot;\n&quot;</span>)<br><br><span class="hljs-comment">#print(&quot;vocab tokenization: &quot;, vocab_tokenization)</span><br><br>sentence_1 = <span class="hljs-string">&#x27;I like natural language processing!&#x27;</span><br>sentence_2 = <span class="hljs-string">&#x27;I like natural languaaage processing!&#x27;</span><br>sentence_list = [sentence_1, sentence_2]<br><br><span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentence_list:<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;==========&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Sentence =&quot;</span>, sentence)<br>    <br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentence.split():<br>        word = word + <span class="hljs-string">&quot;&lt;/w&gt;&quot;</span><br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Tokenizing word: &#123;&#125;...&#x27;</span>.<span class="hljs-built_in">format</span>(word))<br>        <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> vocab_tokenization:<br>            <span class="hljs-built_in">print</span>(vocab_tokenization[word])<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(tokenize_word(string=word, sorted_tokens=sorted_tokens, unknown_token=<span class="hljs-string">&#x27;&lt;/u&gt;&#x27;</span>))<br></code></pre></td></tr></table></figure><h1 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h1><p>解码则是将所有Token进行合并：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 编码序列</span><br>[<span class="hljs-string">&quot;the&lt;/w&gt;&quot;</span>, <span class="hljs-string">&quot;high&quot;</span>, <span class="hljs-string">&quot;est&lt;/w&gt;&quot;</span>, <span class="hljs-string">&quot;moun&quot;</span>, <span class="hljs-string">&quot;tain&lt;/w&gt;&quot;</span>]<br><br><span class="hljs-comment"># 解码序列</span><br><span class="hljs-string">&quot;the&lt;/w&gt; highest&lt;/w&gt; mountain&lt;/w&gt;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="HuggingFace实现"><a href="#HuggingFace实现" class="headerlink" title="HuggingFace实现"></a>HuggingFace实现</h1><p>HF提供了比较快捷的调用接口。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tokenizers <span class="hljs-keyword">import</span> CharBPETokenizer<br><br><span class="hljs-comment"># Instantiate tokenizer</span><br>tokenizer = CharBPETokenizer()<br><br>tokenizer.train_from_iterator(<br>    corpus,<br>    vocab_size=<span class="hljs-number">17</span>,<br>    min_frequency=<span class="hljs-number">2</span>,<br>)<br></code></pre></td></tr></table></figure><h1 id="优点和缺点"><a href="#优点和缺点" class="headerlink" title="优点和缺点"></a>优点和缺点</h1><p>优点：</p><p>BPE的优点前面已经提到，它比单词级别的分词表更细颗粒度，并一定程度保持了语义关系。并且也适用于一些未知的单词。</p><p>缺点：</p><p>BPE是基于统计的算法，如果语料规模小，效果不一定好。</p><p>2024&#x2F;1&#x2F;2 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
      <tag>BPE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LlaMA的工程代码实现</title>
    <link href="/2024/01/01/LlaMA%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <url>/2024/01/01/LlaMA%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>前面讲了一下LlaMA1的架构，现在看一下官方是如何实现它的。</p><p><img src="/images/182444.png" alt="transformers库中实现的LlaMA架构"></p><p>观察模型架构，可以看到模型由几个比较关键的层组成：是LlaMA自己的Decoder层，一共有40层，每一层包含了自注意力层，旋转位置编码和一个MLP层。MLP层中包含了SiLU激活层，一个前置和一个后置的RMS均方归一化层。在最后输出时又加了一个RMS归一层。</p><h1 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h1><p>分词器的实现主要使用了sentencepiece这个库，具体的实现方式是BPE算法。</p><blockquote><p>BPE(Byte Pair Encoding)：目的是使用一些子词来编码数据，在LlaMA1中，将数字也分成了最小的单个数字。BPE的三个核心流程是<code>词表构建</code>，<code>语料编码</code>，<code>语料解码</code>。</p></blockquote><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> logging <span class="hljs-keyword">import</span> getLogger<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><br><span class="hljs-keyword">from</span> sentencepiece <span class="hljs-keyword">import</span> SentencePieceProcessor<br><br>logger = getLogger()<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tokenizer</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;tokenizing and encoding/decoding text using SentencePiece.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_path: <span class="hljs-built_in">str</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">使用SentencePiece模型初始化分词器。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            model_path (str): SentencePiece模型路径。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># reload tokenizer</span><br>        self.sp_model = SentencePieceProcessor(model_file=model_path)<br>        logger.info(<span class="hljs-string">f&quot;Reloaded SentencePiece model from <span class="hljs-subst">&#123;model_path&#125;</span>&quot;</span>)<br><br>        <span class="hljs-comment"># BOS / EOS token IDs</span><br>        self.n_words: <span class="hljs-built_in">int</span> = self.sp_model.vocab_size()<br>        self.bos_id: <span class="hljs-built_in">int</span> = self.sp_model.bos_id()<br>        self.eos_id: <span class="hljs-built_in">int</span> = self.sp_model.eos_id()<br>        self.pad_id: <span class="hljs-built_in">int</span> = self.sp_model.pad_id()<br>        logger.info(<br>            <span class="hljs-string">f&quot;#words: <span class="hljs-subst">&#123;self.n_words&#125;</span> - BOS ID: <span class="hljs-subst">&#123;self.bos_id&#125;</span> - EOS ID: <span class="hljs-subst">&#123;self.eos_id&#125;</span>&quot;</span><br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, bos: <span class="hljs-built_in">bool</span>, eos: <span class="hljs-built_in">bool</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">将一个字符串编码成Token ID的列表</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            s (str): 被编码的输入字符串。</span><br><span class="hljs-string">            bos (bool): 是否在序列的开头添加起始标记。</span><br><span class="hljs-string">            eos (bool): 是否附加结束序列标记。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            List[int]: 一个Token ID的列表</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        t = self.sp_model.encode(s)<br>        <span class="hljs-keyword">if</span> bos:<br>            t = [self.bos_id] + t<br>        <span class="hljs-keyword">if</span> eos:<br>            t = t + [self.eos_id]<br>        <span class="hljs-keyword">return</span> t<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, t: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        将一个Token ID的列表解码为字符串。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            t (List[int]): 被解码的Token ID列表。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            str: 解码后的字符串。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> self.sp_model.decode(t)<br></code></pre></td></tr></table></figure><h1 id="模型设置"><a href="#模型设置" class="headerlink" title="模型设置"></a>模型设置</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>, <span class="hljs-type">Tuple</span><br><br><span class="hljs-keyword">import</span> fairscale.nn.model_parallel.initialize <span class="hljs-keyword">as</span> fs_init<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> fairscale.nn.model_parallel.layers <span class="hljs-keyword">import</span> (<br>    ColumnParallelLinear,<br>    ParallelEmbedding,<br>    RowParallelLinear,<br>)<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ModelArgs</span>:<br>    dim: <span class="hljs-built_in">int</span> = <span class="hljs-number">4096</span><br>    n_layers: <span class="hljs-built_in">int</span> = <span class="hljs-number">32</span><br>    n_heads: <span class="hljs-built_in">int</span> = <span class="hljs-number">32</span><br>    n_kv_heads: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span><br>    vocab_size: <span class="hljs-built_in">int</span> = -<span class="hljs-number">1</span>  <span class="hljs-comment"># defined later by tokenizer</span><br>    multiple_of: <span class="hljs-built_in">int</span> = <span class="hljs-number">256</span>  <span class="hljs-comment"># make SwiGLU hidden layer size multiple of large power of 2</span><br>    ffn_dim_multiplier: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">float</span>] = <span class="hljs-literal">None</span><br>    norm_eps: <span class="hljs-built_in">float</span> = <span class="hljs-number">1e-5</span><br><br>    max_batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">32</span><br>    max_seq_len: <span class="hljs-built_in">int</span> = <span class="hljs-number">2048</span><br>    <br></code></pre></td></tr></table></figure><h1 id="RMS-Norm"><a href="#RMS-Norm" class="headerlink" title="RMS Norm"></a>RMS Norm</h1><p>LLaMa中的另一个创新点是使用了 RMSNorm 归一化函数。我们可以对比一下简单的层归一化：</p><p>$\text{LayerNorm}(x) &#x3D; \gamma \frac{x - \mu}{\sigma} + \beta$</p><p>其中：</p><ul><li>$( x )$ 是输入向量或矩阵。</li><li>$( \mu )$ 表示 $( x )$ 的均值。</li><li>$( \sigma )$ 是 $( x )$ 的标准差。</li><li>$( \gamma )$ 用于缩放归一化结果的参数。</li><li>$( \beta )$ 用于偏移归一化结果的参数。</li></ul><p>LayerNorm是一种标准化方法，它计算一个样本的均值和方差，然后使用这些来对样本进行归一化。这种方法是独立于批量大小的，使得模型更加稳定。在训练时可以理解为对每一句的输入进行归一化。</p><p>RMSNorm则是对LayerNorm的一个改进，但移除了其中的均值项，也就是移除了中间的re-center的步骤，可以看作LayerNorm在均值为0时的一个特例。论文通过实验证明，re-center操作不重要。RMSNorm与 LayerNorm不同，它不是使用整个样本的均值和方差，而是使用平方根的均值来归一化，这样做可以降低噪声的影响。</p><p>$\text{RMSNorm}(x) &#x3D; \frac{x}{\sqrt{\text{E}[x^2] + \epsilon}}$</p><p>其中：</p><ul><li>$(x )$ 是输入向量或矩阵。</li><li>$( \text{E}[x^2] )$ 表示 $( x )$ 的平方的期望值。</li><li>$( \epsilon )$ 是一个小的正常数，用于防止分母为零。</li></ul><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RMSNorm</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim: <span class="hljs-built_in">int</span>, eps: <span class="hljs-built_in">float</span> = <span class="hljs-number">1e-6</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化RMSNorm归一化层。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            dim (int): 输入张量的维度。</span><br><span class="hljs-string">            eps (float, optional): 为了数值稳定性（出现0），添加到分母的小值。默认值为1e-6。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Attributes:</span><br><span class="hljs-string">            eps (float): 为了数值稳定性，添加到分母的小值。</span><br><span class="hljs-string">            weight (nn.Parameter): 可学习的缩放参数。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.eps = eps<br>        self.weight = nn.Parameter(torch.ones(dim))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_norm</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        对输入张量应用RMSNorm归一化。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x (torch.Tensor): 输入张量。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            torch.Tensor: 归一化后的张量。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> x * torch.rsqrt(x.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).mean(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) + self.eps)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">       通过RMSNorm层进行前向传播。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x (torch.Tensor): 输入张量。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            torch.Tensor: 应用RMSNorm后的输出张量。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        output = self._norm(x.<span class="hljs-built_in">float</span>()).type_as(x)<br>        <span class="hljs-keyword">return</span> output * self.weight<br></code></pre></td></tr></table></figure><h1 id="SwiGLU激活函数"><a href="#SwiGLU激活函数" class="headerlink" title="SwiGLU激活函数"></a>SwiGLU激活函数</h1><p>LLaMA采用SwiGLU替换了原有的ReLU。这是Swish激活组合和GLU激活函数的组合。</p><p>Swish的公式是：$Swish&#x3D;x\cdot sigmoid(\beta x)$ 也是对输入$(x )$乘以一个系数，对$(x )$进行限制。</p><p>GLU的公式是：$GLU(x)&#x3D;\sigma(W x+b)\otimes(V x+c)$</p><p>两者组合后的SwiGLU公式为：$SwiGLU(x,W,V,b,c,\beta)&#x3D;Swish_{\beta}(x W+b)\otimes(x V+c)$</p><h1 id="Transformer构建"><a href="#Transformer构建" class="headerlink" title="Transformer构建"></a>Transformer构建</h1><p>LlaMA中，每个Transformer块由自注意力层和FFN层组成，随后进行堆叠。</p><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention:"></a>Attention:</h2><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, args: ModelArgs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化注意力模块。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            args (ModelArgs): 模型配置参数。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Attributes:</span><br><span class="hljs-string">            n_kv_heads (int): Key/Value头的个数。</span><br><span class="hljs-string">            n_local_heads (int): 本地查询头的数量。主要用在分布式场景。</span><br><span class="hljs-string">            n_local_kv_heads (int): 本地Key/Value头的数量。主要用在分布式场景。</span><br><span class="hljs-string">            n_rep (int): 本地头的重复次数。</span><br><span class="hljs-string">            head_dim (int): 每个注意力头的维度大小。</span><br><span class="hljs-string">            wq (ColumnParallelLinear): Queries的线性变换。</span><br><span class="hljs-string">            wk (ColumnParallelLinear): Keys的线性变换。</span><br><span class="hljs-string">            wv (ColumnParallelLinear): Values的线性变换。</span><br><span class="hljs-string">            wo (RowParallelLinear): 输出的线性变换。</span><br><span class="hljs-string">            cache_k (torch.Tensor): 注意力的Cached keys。</span><br><span class="hljs-string">            cache_v (torch.Tensor): 注意力的Cached values。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.n_local_heads = args.n_heads // fs_init.get_model_parallel_world_size()<br>        self.head_dim = args.dim // args.n_heads <span class="hljs-comment"># 4096//32 = 128</span><br><br>        self.wq = ColumnParallelLinear(<br>            args.dim,<br>            args.n_heads * self.head_dim,<br>            bias=<span class="hljs-literal">False</span>,<br>            gather_output=<span class="hljs-literal">False</span>,<br>            init_method=<span class="hljs-keyword">lambda</span> x: x,<br>        ) <span class="hljs-comment"># (4096,4096)</span><br>        self.wk = ColumnParallelLinear(<br>            args.dim,<br>            args.n_heads * self.head_dim,<br>            bias=<span class="hljs-literal">False</span>,<br>            gather_output=<span class="hljs-literal">False</span>,<br>            init_method=<span class="hljs-keyword">lambda</span> x: x,<br>        ) <span class="hljs-comment"># (4096,4096)</span><br>        self.wv = ColumnParallelLinear(<br>            args.dim,<br>            args.n_heads * self.head_dim,<br>            bias=<span class="hljs-literal">False</span>,<br>            gather_output=<span class="hljs-literal">False</span>,<br>            init_method=<span class="hljs-keyword">lambda</span> x: x,<br>        ) <span class="hljs-comment"># (4096,4096)</span><br>        self.wo = RowParallelLinear(<br>            args.n_heads * self.head_dim,<br>            args.dim,<br>            bias=<span class="hljs-literal">False</span>,<br>            input_is_parallel=<span class="hljs-literal">True</span>,<br>            init_method=<span class="hljs-keyword">lambda</span> x: x,<br>        ) <span class="hljs-comment"># (4096,4096)</span><br><br>        self.cache_k = torch.zeros(<br>            (args.max_batch_size, args.max_seq_len, self.n_local_heads, self.head_dim)<br>        ).cuda() <span class="hljs-comment"># (32,2048,n_local_heads,128)</span><br>        self.cache_v = torch.zeros(<br>            (args.max_batch_size, args.max_seq_len, self.n_local_heads, self.head_dim)<br>        ).cuda() <span class="hljs-comment"># (32,2048,n_local_heads,128)</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor, start_pos: <span class="hljs-built_in">int</span>, freqs_cis: torch.Tensor, mask: <span class="hljs-type">Optional</span>[torch.Tensor]</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        注意力模块的前向传播。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x (torch.Tensor):输入张量。</span><br><span class="hljs-string">            start_pos (int): 缓存的起始位置。</span><br><span class="hljs-string">            freqs_cis (torch.Tensor): 预计算的频率张量。</span><br><span class="hljs-string">            mask (torch.Tensor, optional): 注意力掩码张量。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            torch.Tensor: 注意力后的输出张量。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        bsz, seqlen, _ = x.shape<br>        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)<br><br>        <span class="hljs-comment"># Resize (4096,4096) ==&gt; (batch_size, seq_len, n_local_heads, 128)</span><br>        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)<br>        xk = xk.view(bsz, seqlen, self.n_local_heads, self.head_dim)<br>        xv = xv.view(bsz, seqlen, self.n_local_heads, self.head_dim)<br><br>        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)<br><br>        self.cache_k = self.cache_k.to(xq)<br>        self.cache_v = self.cache_v.to(xq)<br><br>        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk<br>        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv<br><br>        keys = self.cache_k[:bsz, : start_pos + seqlen]<br>        values = self.cache_v[:bsz, : start_pos + seqlen]<br><br>        <span class="hljs-comment"># 转置</span><br>        xq = xq.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <br>        keys = keys.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        values = values.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        scores = torch.matmul(xq, keys.transpose(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)) / math.sqrt(self.head_dim)<br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            scores = scores + mask  <span class="hljs-comment"># (batch_size, n_local_heads, seq_len, cache_len + seq_len)</span><br>        scores = F.softmax(scores.<span class="hljs-built_in">float</span>(), dim=-<span class="hljs-number">1</span>).type_as(xq)<br>        output = torch.matmul(scores, values)  <span class="hljs-comment"># (batch_size, n_local_heads, seq_len, head_dim)</span><br>        output = output.transpose(<br>            <span class="hljs-number">1</span>, <span class="hljs-number">2</span><br>        ).contiguous().view(bsz, seqlen, -<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">return</span> self.wo(output)<br></code></pre></td></tr></table></figure><h2 id="FFN层"><a href="#FFN层" class="headerlink" title="FFN层"></a>FFN层</h2><p>FFN层就是简单的前向传播，其中激活函数的选择和位置都进行了改变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeedForward</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        dim: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        hidden_dim: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        multiple_of: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化FeedForward模块。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            dim (int): 输入维度。</span><br><span class="hljs-string">            hidden_dim (int): 前馈层的隐藏维度。</span><br><span class="hljs-string">            multiple_of (int): 确保隐藏维度是此值的倍数。</span><br><span class="hljs-string">            ffn_dim_multiplier (float, optional): 隐藏维度的自定义乘数。默认为None。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Attributes:</span><br><span class="hljs-string">            w1 (ColumnParallelLinear): 第一层的线性变换。</span><br><span class="hljs-string">            w2 (RowParallelLinear): 第二层的线性变换。</span><br><span class="hljs-string">            w3 (ColumnParallelLinear): 第三层的线性变换。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        hidden_dim = <span class="hljs-built_in">int</span>(<span class="hljs-number">2</span> * hidden_dim / <span class="hljs-number">3</span>)<br>        hidden_dim = multiple_of * ((hidden_dim + multiple_of - <span class="hljs-number">1</span>) // multiple_of)<br><br>        self.w1 = ColumnParallelLinear(<br>            dim, hidden_dim, bias=<span class="hljs-literal">False</span>, gather_output=<span class="hljs-literal">False</span>, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )<br>        self.w2 = RowParallelLinear(<br>            hidden_dim, dim, bias=<span class="hljs-literal">False</span>, input_is_parallel=<span class="hljs-literal">True</span>, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )<br>        self.w3 = ColumnParallelLinear(<br>            dim, hidden_dim, bias=<span class="hljs-literal">False</span>, gather_output=<span class="hljs-literal">False</span>, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.w2(F.silu(self.w1(x)) * self.w3(x))<br></code></pre></td></tr></table></figure><h2 id="Transformer-Block"><a href="#Transformer-Block" class="headerlink" title="Transformer Block"></a>Transformer Block</h2><p>注意力层和FFN层合并后就是一个单独的Transformer块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TransformerBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, layer_id: <span class="hljs-built_in">int</span>, args: ModelArgs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化TransformerBlock。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            layer_id (int): 层的标识符。</span><br><span class="hljs-string">            args (ModelArgs): 模型配置参数。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Attributes:</span><br><span class="hljs-string">            n_heads (int): 注意力头的数量。</span><br><span class="hljs-string">            dim (int): 模型的维度大小。</span><br><span class="hljs-string">            head_dim (int): 每个注意力头的维度大小。</span><br><span class="hljs-string">            attention (Attention): 注意力模块。</span><br><span class="hljs-string">            feed_forward (FeedForward): 前馈模块。</span><br><span class="hljs-string">            layer_id (int): 层的标识符。</span><br><span class="hljs-string">            attention_norm (RMSNorm): 注意力输出的层归一化。</span><br><span class="hljs-string">            ffn_norm (RMSNorm): 前馈输出的层归一化。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.n_heads = args.n_heads <span class="hljs-comment"># 32</span><br>        self.dim = args.dim <span class="hljs-comment"># 4096</span><br>        self.head_dim = args.dim // args.n_heads <span class="hljs-comment"># 4096//32 = 128</span><br>        self.attention = Attention(args)<br>        self.feed_forward = FeedForward(<br>            dim=args.dim, hidden_dim=<span class="hljs-number">4</span> * args.dim, multiple_of=args.multiple_of<br>        )<br>        self.layer_id = layer_id<br>        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)<br>        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor, start_pos: <span class="hljs-built_in">int</span>, freqs_cis: torch.Tensor, mask: <span class="hljs-type">Optional</span>[torch.Tensor]</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        执行TransformerBlock的前向传播。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x (torch.Tensor): 输入张量。</span><br><span class="hljs-string">            start_pos (int): 注意力缓存的起始位置。</span><br><span class="hljs-string">            freqs_cis (torch.Tensor): 预计算的余弦和正弦频率。</span><br><span class="hljs-string">            mask (torch.Tensor, optional): 注意力的掩码张量。默认为None。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            torch.Tensor: 应用注意力和前馈层后的输出张量。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)<br>        out = h + self.feed_forward.forward(self.ffn_norm(h))<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>最后把transformer块合并一下，加上Embedding层，就是一个完整的Transformer结构了。</p><p>Forward部分，先对输入的token做token embedding，然后添加位置信息。对于decoder模型，为了防止标签泄漏，需要掩码，所以做了一个上三角的掩码矩阵。接下来就是逐层的计算transformer。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Transformer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, params: ModelArgs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化Transformer模型。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            params (ModelArgs): 模型配置参数。</span><br><span class="hljs-string">            </span><br><span class="hljs-string">        Attributes:</span><br><span class="hljs-string">            params (ModelArgs): 模型配置参数。</span><br><span class="hljs-string">            vocab_size (int): 词汇表大小。</span><br><span class="hljs-string">            n_layers (int): 模型中的层数。</span><br><span class="hljs-string">            tok_embeddings (ParallelEmbedding): Token嵌入。</span><br><span class="hljs-string">            layers (torch.nn.ModuleList): Transformer块的列表。</span><br><span class="hljs-string">            norm (RMSNorm): 模型输出的层归一化。</span><br><span class="hljs-string">            output (ColumnParallelLinear): 最终输出的线性层。</span><br><span class="hljs-string">            freqs_cis (torch.Tensor): 预计算的余弦和正弦频率。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.params = params<br>        self.vocab_size = params.vocab_size <span class="hljs-comment"># -1</span><br>        self.n_layers = params.n_layers <span class="hljs-comment"># 32</span><br><br>        self.tok_embeddings = ParallelEmbedding(<br>            params.vocab_size, params.dim, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        )  <span class="hljs-comment"># (-1,4096)</span><br><br>        self.layers = torch.nn.ModuleList()<br>        <br>        <span class="hljs-comment"># 逐层添加</span><br>        <span class="hljs-keyword">for</span> layer_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(params.n_layers):<br>            self.layers.append(TransformerBlock(layer_id, params))<br><br>        self.norm = RMSNorm(params.dim, eps=params.norm_eps)<br>        self.output = ColumnParallelLinear(<br>            params.dim, params.vocab_size, bias=<span class="hljs-literal">False</span>, init_method=<span class="hljs-keyword">lambda</span> x: x<br>        ) <span class="hljs-comment"># (4096,-1)</span><br><br>        self.freqs_cis = precompute_freqs_cis(<br>            self.params.dim // self.params.n_heads, self.params.max_seq_len * <span class="hljs-number">2</span><br>        )<br><br><span class="hljs-meta">    @torch.inference_mode()</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, tokens: torch.Tensor, start_pos: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        执行Transformer模型的前向传播。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            tokens (torch.Tensor): 输入的token索引。</span><br><span class="hljs-string">            start_pos (int): 注意力缓存的起始位置。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            torch.Tensor: 应用Transformer模型后的输出logits。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        _bsz, seqlen = tokens.shape<br>        h = self.tok_embeddings(tokens)<br>        self.freqs_cis = self.freqs_cis.to(h.device)<br>        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]<br><br>        mask = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> seqlen &gt; <span class="hljs-number">1</span>:<br>            mask = torch.full((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, seqlen, seqlen), <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;-inf&quot;</span>), device=tokens.device)<br>            mask = torch.triu(mask, diagonal=start_pos + <span class="hljs-number">1</span>).type_as(h)<br><br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>            h = layer(h, start_pos, freqs_cis, mask)<br>        h = self.norm(h)<br>        output = self.output(h[:, -<span class="hljs-number">1</span>, :])  <span class="hljs-comment"># only compute last logits</span><br>        <span class="hljs-keyword">return</span> output.<span class="hljs-built_in">float</span>()<br></code></pre></td></tr></table></figure><h1 id="Generation"><a href="#Generation" class="headerlink" title="Generation"></a>Generation</h1><p>代码的最后一部分是模型的生成部分：</p><p>第一部分是代码的依赖库以及输出的格式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Literal</span>, <span class="hljs-type">Optional</span>, <span class="hljs-type">Tuple</span>, TypedDict<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> fairscale.nn.model_parallel.initialize <span class="hljs-keyword">import</span> (<br>    get_model_parallel_rank,<br>    initialize_model_parallel,<br>    model_parallel_is_initialized,<br>)<br><br><span class="hljs-keyword">from</span> llama.model <span class="hljs-keyword">import</span> ModelArgs, Transformer<br><span class="hljs-keyword">from</span> llama.tokenizer <span class="hljs-keyword">import</span> Tokenizer<br><br>Role = <span class="hljs-type">Literal</span>[<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;assistant&quot;</span>]<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Message</span>(<span class="hljs-title class_ inherited__">TypedDict</span>):<br>    role: Role<br>    content: <span class="hljs-built_in">str</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CompletionPrediction</span>(TypedDict, total=<span class="hljs-literal">False</span>):<br>    generation: <span class="hljs-built_in">str</span><br>    tokens: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]  <span class="hljs-comment"># not required</span><br>    logprobs: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]  <span class="hljs-comment"># not required</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ChatPrediction</span>(TypedDict, total=<span class="hljs-literal">False</span>):<br>    generation: Message<br>    tokens: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]  <span class="hljs-comment"># not required</span><br>    logprobs: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]  <span class="hljs-comment"># not required</span><br><br><br>Dialog = <span class="hljs-type">List</span>[Message]<br><br>B_INST, E_INST = <span class="hljs-string">&quot;[INST]&quot;</span>, <span class="hljs-string">&quot;[/INST]&quot;</span><br>B_SYS, E_SYS = <span class="hljs-string">&quot;&lt;&lt;SYS&gt;&gt;\n&quot;</span>, <span class="hljs-string">&quot;\n&lt;&lt;/SYS&gt;&gt;\n\n&quot;</span><br><br>SPECIAL_TAGS = [B_INST, E_INST, <span class="hljs-string">&quot;&lt;&lt;SYS&gt;&gt;&quot;</span>, <span class="hljs-string">&quot;&lt;&lt;/SYS&gt;&gt;&quot;</span>]<br>UNSAFE_ERROR = <span class="hljs-string">&quot;Error: special tags are not allowed as part of the prompt.&quot;</span><br></code></pre></td></tr></table></figure><p>第二部分是模型实例类，其中包含了构建模型，生成推理结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Llama</span>:<br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">build</span>(<span class="hljs-params"></span><br><span class="hljs-params">        ckpt_dir: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">        tokenizer_path: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">        max_seq_len: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        max_batch_size: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        model_parallel_size: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        seed: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-string">&quot;Llama&quot;</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        构建一个Llama实例，通过初始化和加载预训练模型。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            ckpt_dir (str): 包含检查点文件的目录路径。</span><br><span class="hljs-string">            tokenizer_path (str): tokenizer文件的路径。</span><br><span class="hljs-string">            max_seq_len (int): 输入文本的最大序列长度。</span><br><span class="hljs-string">            max_batch_size (int): 推理的最大批量大小。</span><br><span class="hljs-string">            model_parallel_size (Optional[int], optional): 模型并行进程的数量。</span><br><span class="hljs-string">如果未提供，将从环境中确定。默认为None。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            Llama: 带有加载的模型和分词器的Llama类的实例。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Raises:</span><br><span class="hljs-string">            AssertionError: 如果指定目录中没有检查点文件，或者模型并行大小与检查点文件的数量不匹配。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Note:</span><br><span class="hljs-string">            此方法会初始化分布式进程组，将设备设置为CUDA，并加载预训练模型和分词器。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> torch.distributed.is_initialized():<br>            torch.distributed.init_process_group(<span class="hljs-string">&quot;nccl&quot;</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> model_parallel_is_initialized():<br>            <span class="hljs-keyword">if</span> model_parallel_size <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                model_parallel_size = <span class="hljs-built_in">int</span>(os.environ.get(<span class="hljs-string">&quot;WORLD_SIZE&quot;</span>, <span class="hljs-number">1</span>))<br>            initialize_model_parallel(model_parallel_size)<br><br>        local_rank = <span class="hljs-built_in">int</span>(os.environ.get(<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>, <span class="hljs-number">0</span>))<br>        torch.cuda.set_device(local_rank)<br><br>        <span class="hljs-comment"># seed must be the same in all processes</span><br>        torch.manual_seed(seed)<br><br>        <span class="hljs-keyword">if</span> local_rank &gt; <span class="hljs-number">0</span>:<br>            sys.stdout = <span class="hljs-built_in">open</span>(os.devnull, <span class="hljs-string">&quot;w&quot;</span>)<br><br>        start_time = time.time()<br>        checkpoints = <span class="hljs-built_in">sorted</span>(Path(ckpt_dir).glob(<span class="hljs-string">&quot;*.pth&quot;</span>))<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(checkpoints) &gt; <span class="hljs-number">0</span>, <span class="hljs-string">f&quot;no checkpoint files found in <span class="hljs-subst">&#123;ckpt_dir&#125;</span>&quot;</span><br>        <span class="hljs-keyword">assert</span> model_parallel_size == <span class="hljs-built_in">len</span>(<br>            checkpoints<br>        ), <span class="hljs-string">f&quot;Loading a checkpoint for MP=<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(checkpoints)&#125;</span> but world size is <span class="hljs-subst">&#123;model_parallel_size&#125;</span>&quot;</span><br>        ckpt_path = checkpoints[get_model_parallel_rank()]<br>        checkpoint = torch.load(ckpt_path, map_location=<span class="hljs-string">&quot;cpu&quot;</span>)<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(Path(ckpt_dir) / <span class="hljs-string">&quot;params.json&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            params = json.loads(f.read())<br><br>        model_args: ModelArgs = ModelArgs(<br>            max_seq_len=max_seq_len,<br>            max_batch_size=max_batch_size,<br>            **params,<br>        )<br>        tokenizer = Tokenizer(model_path=tokenizer_path)<br>        model_args.vocab_size = tokenizer.n_words<br>        torch.set_default_tensor_type(torch.cuda.HalfTensor)<br>        model = Transformer(model_args)<br>        model.load_state_dict(checkpoint, strict=<span class="hljs-literal">False</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Loaded in <span class="hljs-subst">&#123;time.time() - start_time:<span class="hljs-number">.2</span>f&#125;</span> seconds&quot;</span>)<br><br>        <span class="hljs-keyword">return</span> Llama(model, tokenizer)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model: Transformer, tokenizer: Tokenizer</span>):<br>        self.model = model<br>        self.tokenizer = tokenizer<br><br><span class="hljs-meta">    @torch.inference_mode()</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generate</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        prompt_tokens: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]],</span><br><span class="hljs-params">        max_gen_len: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.6</span>,</span><br><span class="hljs-params">        top_p: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.9</span>,</span><br><span class="hljs-params">        logprobs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        echo: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]], <span class="hljs-type">Optional</span>[<span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]]]]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        基于提供的提示使用语言生成模型生成文本序列。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            prompt_tokens (List[List[int]]): Tokenized prompts的列表, 其中每个提示表示为整数列表。</span><br><span class="hljs-string">            max_gen_len (int): 生成文本序列的最大长度。</span><br><span class="hljs-string">            temperature (float, optional): 控制采样中随机性的温度值。默认为0.6。</span><br><span class="hljs-string">            top_p (float, optional): 核心采样的top-p概率阈值。默认为0.9。</span><br><span class="hljs-string">            logprobs (bool, optional): 指示是否计算Token对数概率的标志。默认为False。</span><br><span class="hljs-string">            echo (bool, optional): 指示是否在生成的输出中包括提示Token的标志。默认为False。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            Tuple[List[List[int]], Optional[List[List[float]]]]: 包含生成的Token序列的元组，如果logprobs为True，则包含相应的Token对数概率。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Note:</span><br><span class="hljs-string">            此方法使用提供的提示作为生成文本的基础。它使用核心采样（nucleus sampling）来产生具有控制随机性的文本。</span><br><span class="hljs-string">如果logprobs为True，则为每个生成的Token计算Token对数概率。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        params = self.model.params<br>        bsz = <span class="hljs-built_in">len</span>(prompt_tokens)<br>        <span class="hljs-keyword">assert</span> bsz &lt;= params.max_batch_size, (bsz, params.max_batch_size)<br><br>        min_prompt_len = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">len</span>(t) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> prompt_tokens)<br>        max_prompt_len = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">len</span>(t) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> prompt_tokens)<br>        <span class="hljs-keyword">assert</span> max_prompt_len &lt;= params.max_seq_len<br>        total_len = <span class="hljs-built_in">min</span>(params.max_seq_len, max_gen_len + max_prompt_len)<br><br>        pad_id = self.tokenizer.pad_id<br>        tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=<span class="hljs-string">&quot;cuda&quot;</span>)<br>        <span class="hljs-keyword">for</span> k, t <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(prompt_tokens):<br>            tokens[k, : <span class="hljs-built_in">len</span>(t)] = torch.tensor(t, dtype=torch.long, device=<span class="hljs-string">&quot;cuda&quot;</span>)<br>        <span class="hljs-keyword">if</span> logprobs:<br>            token_logprobs = torch.zeros_like(tokens, dtype=torch.<span class="hljs-built_in">float</span>)<br><br>        prev_pos = <span class="hljs-number">0</span><br>        eos_reached = torch.tensor([<span class="hljs-literal">False</span>] * bsz, device=<span class="hljs-string">&quot;cuda&quot;</span>)<br>        input_text_mask = tokens != pad_id<br>        <span class="hljs-keyword">if</span> min_prompt_len == total_len:<br>            logits = self.model.forward(tokens, prev_pos)<br>            token_logprobs = -F.cross_entropy(<br>                <span class="hljs-built_in">input</span>=logits.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>                target=tokens,<br>                reduction=<span class="hljs-string">&quot;none&quot;</span>,<br>                ignore_index=pad_id,<br>            )<br><br>        <span class="hljs-keyword">for</span> cur_pos <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(min_prompt_len, total_len):<br>            logits = self.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)<br>            <span class="hljs-keyword">if</span> temperature &gt; <span class="hljs-number">0</span>:<br>                probs = torch.softmax(logits[:, -<span class="hljs-number">1</span>] / temperature, dim=-<span class="hljs-number">1</span>)<br>                next_token = sample_top_p(probs, top_p)<br>            <span class="hljs-keyword">else</span>:<br>                next_token = torch.argmax(logits[:, -<span class="hljs-number">1</span>], dim=-<span class="hljs-number">1</span>)<br><br>            next_token = next_token.reshape(-<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># only replace token if prompt has already been generated</span><br>            next_token = torch.where(<br>                input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token<br>            )<br>            tokens[:, cur_pos] = next_token<br>            <span class="hljs-keyword">if</span> logprobs:<br>                token_logprobs[:, prev_pos + <span class="hljs-number">1</span> : cur_pos + <span class="hljs-number">1</span>] = -F.cross_entropy(<br>                    <span class="hljs-built_in">input</span>=logits.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>                    target=tokens[:, prev_pos + <span class="hljs-number">1</span> : cur_pos + <span class="hljs-number">1</span>],<br>                    reduction=<span class="hljs-string">&quot;none&quot;</span>,<br>                    ignore_index=pad_id,<br>                )<br>            eos_reached |= (~input_text_mask[:, cur_pos]) &amp; (<br>                next_token == self.tokenizer.eos_id<br>            )<br>            prev_pos = cur_pos<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">all</span>(eos_reached):<br>                <span class="hljs-keyword">break</span><br><br>        <span class="hljs-keyword">if</span> logprobs:<br>            token_logprobs = token_logprobs.tolist()<br>        out_tokens, out_logprobs = [], []<br>        <span class="hljs-keyword">for</span> i, toks <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tokens.tolist()):<br>            <span class="hljs-comment"># cut to max gen len</span><br>            start = <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> echo <span class="hljs-keyword">else</span> <span class="hljs-built_in">len</span>(prompt_tokens[i])<br>            toks = toks[start : <span class="hljs-built_in">len</span>(prompt_tokens[i]) + max_gen_len]<br>            probs = <span class="hljs-literal">None</span><br>            <span class="hljs-keyword">if</span> logprobs:<br>                probs = token_logprobs[i][start : <span class="hljs-built_in">len</span>(prompt_tokens[i]) + max_gen_len]<br>            <span class="hljs-comment"># cut to eos tok if any</span><br>            <span class="hljs-keyword">if</span> self.tokenizer.eos_id <span class="hljs-keyword">in</span> toks:<br>                eos_idx = toks.index(self.tokenizer.eos_id)<br>                toks = toks[:eos_idx]<br>                probs = probs[:eos_idx] <span class="hljs-keyword">if</span> logprobs <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>            out_tokens.append(toks)<br>            out_logprobs.append(probs)<br>        <span class="hljs-keyword">return</span> (out_tokens, out_logprobs <span class="hljs-keyword">if</span> logprobs <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">text_completion</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        prompts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>],</span><br><span class="hljs-params">        temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.6</span>,</span><br><span class="hljs-params">        top_p: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.9</span>,</span><br><span class="hljs-params">        max_gen_len: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        logprobs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        echo: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[CompletionPrediction]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        对一组提示词使用语言生成模型进行文本补完。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            prompts (List[str]): 需要补完的文本提示词列表。</span><br><span class="hljs-string">            temperature (float, optional): 控制采样中随机性的温度值。默认为0.6。</span><br><span class="hljs-string">            top_p (float, optional): 核心采样的top-p概率阈值。默认为0.9。</span><br><span class="hljs-string">            max_gen_len (Optional[int], optional): 生成完成序列的最大长度。</span><br><span class="hljs-string">如果未提供，将设置为模型的最大序列长度减1。</span><br><span class="hljs-string">            logprobs (bool, optional): 指示是否计算Token对数概率的标志。默认为False。</span><br><span class="hljs-string">            echo (bool, optional): 指示是否在生成的输出中包括提示Token的标志。默认为False。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            List[CompletionPrediction]: 完成预测的列表，每个预测包含生成的文本完成。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Note:</span><br><span class="hljs-string">            此方法为提供的提示词生成文本补完，并使用核心采样引入控制随机性。</span><br><span class="hljs-string">            如果logprobs被设置为True，则为每个生成的Token计算对数概率。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> max_gen_len <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            max_gen_len = self.model.params.max_seq_len - <span class="hljs-number">1</span><br>        prompt_tokens = [self.tokenizer.encode(x, bos=<span class="hljs-literal">True</span>, eos=<span class="hljs-literal">False</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> prompts]<br>        generation_tokens, generation_logprobs = self.generate(<br>            prompt_tokens=prompt_tokens,<br>            max_gen_len=max_gen_len,<br>            temperature=temperature,<br>            top_p=top_p,<br>            logprobs=logprobs,<br>            echo=echo,<br>        )<br>        <span class="hljs-keyword">if</span> logprobs:<br>            <span class="hljs-keyword">return</span> [<br>                &#123;<br>                    <span class="hljs-string">&quot;generation&quot;</span>: self.tokenizer.decode(t),<br>                    <span class="hljs-string">&quot;tokens&quot;</span>: [self.tokenizer.decode(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> t],<br>                    <span class="hljs-string">&quot;logprobs&quot;</span>: logprobs_i,<br>                &#125;<br>                <span class="hljs-keyword">for</span> t, logprobs_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(generation_tokens, generation_logprobs)<br>            ]<br>        <span class="hljs-keyword">return</span> [&#123;<span class="hljs-string">&quot;generation&quot;</span>: self.tokenizer.decode(t)&#125; <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> generation_tokens]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completion</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        dialogs: <span class="hljs-type">List</span>[Dialog],</span><br><span class="hljs-params">        temperature: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.6</span>,</span><br><span class="hljs-params">        top_p: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.9</span>,</span><br><span class="hljs-params">        max_gen_len: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        logprobs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[ChatPrediction]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">      </span><br><span class="hljs-string">        使用语言生成模型，对一个交谈对话的列表生成assistant回复。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            dialogs (List[Dialog]): 会话对话的列表，其中每个对话都是消息列表。</span><br><span class="hljs-string">            temperature (float, optional): 控制采样中随机性的温度值。默认为0.6。</span><br><span class="hljs-string">            top_p (float, optional): 核心采样的top-p概率阈值。默认为0.9。</span><br><span class="hljs-string">            max_gen_len (Optional[int], optional): 生成响应序列的最大长度。如果未提供，将设置为模型的最大序列长度减1。</span><br><span class="hljs-string">            logprobs (bool, optional): 指示是否计算Token对数概率的标志。默认为False。</span><br><span class="hljs-string">            </span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            List[ChatPrediction]: 聊天预测列表，每个预测包含assistant生成的响应。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Raises:</span><br><span class="hljs-string">            AssertionError: 如果对话中的最后一条消息不是来自用户。</span><br><span class="hljs-string">            AssertionError: 如果对话角色不按照所需的&#x27;user&#x27;、&#x27;assistant&#x27;和可选的&#x27;system&#x27;顺序。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Note:</span><br><span class="hljs-string">            此方法为提供的会话对话生成assistant的响应。</span><br><span class="hljs-string">            它使用核心采样引入文本生成中的控制随机性。</span><br><span class="hljs-string">            如果logprobs设置为True，则将为每个生成的Token计算对数概率。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> max_gen_len <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            max_gen_len = self.model.params.max_seq_len - <span class="hljs-number">1</span><br>        prompt_tokens = []<br>        unsafe_requests = []<br>        <span class="hljs-keyword">for</span> dialog <span class="hljs-keyword">in</span> dialogs:<br>            unsafe_requests.append(<br>                <span class="hljs-built_in">any</span>([tag <span class="hljs-keyword">in</span> msg[<span class="hljs-string">&quot;content&quot;</span>] <span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> SPECIAL_TAGS <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> dialog])<br>            )<br>            <span class="hljs-keyword">if</span> dialog[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;role&quot;</span>] == <span class="hljs-string">&quot;system&quot;</span>:<br>                dialog = [<br>                    &#123;<br>                        <span class="hljs-string">&quot;role&quot;</span>: dialog[<span class="hljs-number">1</span>][<span class="hljs-string">&quot;role&quot;</span>],<br>                        <span class="hljs-string">&quot;content&quot;</span>: B_SYS<br>                        + dialog[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;content&quot;</span>]<br>                        + E_SYS<br>                        + dialog[<span class="hljs-number">1</span>][<span class="hljs-string">&quot;content&quot;</span>],<br>                    &#125;<br>                ] + dialog[<span class="hljs-number">2</span>:]<br>            <span class="hljs-keyword">assert</span> <span class="hljs-built_in">all</span>([msg[<span class="hljs-string">&quot;role&quot;</span>] == <span class="hljs-string">&quot;user&quot;</span> <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> dialog[::<span class="hljs-number">2</span>]]) <span class="hljs-keyword">and</span> <span class="hljs-built_in">all</span>(<br>                [msg[<span class="hljs-string">&quot;role&quot;</span>] == <span class="hljs-string">&quot;assistant&quot;</span> <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> dialog[<span class="hljs-number">1</span>::<span class="hljs-number">2</span>]]<br>            ), (<br>                <span class="hljs-string">&quot;model only supports &#x27;system&#x27;, &#x27;user&#x27; and &#x27;assistant&#x27; roles, &quot;</span><br>                <span class="hljs-string">&quot;starting with &#x27;system&#x27;, then &#x27;user&#x27; and alternating (u/a/u/a/u...)&quot;</span><br>            )<br>            dialog_tokens: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-built_in">sum</span>(<br>                [<br>                    self.tokenizer.encode(<br>                        <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;B_INST&#125;</span> <span class="hljs-subst">&#123;(prompt[<span class="hljs-string">&#x27;content&#x27;</span>]).strip()&#125;</span> <span class="hljs-subst">&#123;E_INST&#125;</span> <span class="hljs-subst">&#123;(answer[<span class="hljs-string">&#x27;content&#x27;</span>]).strip()&#125;</span> &quot;</span>,<br>                        bos=<span class="hljs-literal">True</span>,<br>                        eos=<span class="hljs-literal">True</span>,<br>                    )<br>                    <span class="hljs-keyword">for</span> prompt, answer <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<br>                        dialog[::<span class="hljs-number">2</span>],<br>                        dialog[<span class="hljs-number">1</span>::<span class="hljs-number">2</span>],<br>                    )<br>                ],<br>                [],<br>            )<br>            <span class="hljs-keyword">assert</span> (<br>                dialog[-<span class="hljs-number">1</span>][<span class="hljs-string">&quot;role&quot;</span>] == <span class="hljs-string">&quot;user&quot;</span><br>            ), <span class="hljs-string">f&quot;Last message must be from user, got <span class="hljs-subst">&#123;dialog[-<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;role&#x27;</span>]&#125;</span>&quot;</span><br>            dialog_tokens += self.tokenizer.encode(<br>                <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;B_INST&#125;</span> <span class="hljs-subst">&#123;(dialog[-<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;content&#x27;</span>]).strip()&#125;</span> <span class="hljs-subst">&#123;E_INST&#125;</span>&quot;</span>,<br>                bos=<span class="hljs-literal">True</span>,<br>                eos=<span class="hljs-literal">False</span>,<br>            )<br>            prompt_tokens.append(dialog_tokens)<br><br>        generation_tokens, generation_logprobs = self.generate(<br>            prompt_tokens=prompt_tokens,<br>            max_gen_len=max_gen_len,<br>            temperature=temperature,<br>            top_p=top_p,<br>            logprobs=logprobs,<br>        )<br>        <span class="hljs-keyword">if</span> logprobs:<br>            <span class="hljs-keyword">return</span> [<br>                &#123;<br>                    <span class="hljs-string">&quot;generation&quot;</span>: &#123;<br>                        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>,<br>                        <span class="hljs-string">&quot;content&quot;</span>: self.tokenizer.decode(t)<br>                        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> unsafe<br>                        <span class="hljs-keyword">else</span> UNSAFE_ERROR,<br>                    &#125;,<br>                    <span class="hljs-string">&quot;tokens&quot;</span>: [self.tokenizer.decode(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> t],<br>                    <span class="hljs-string">&quot;logprobs&quot;</span>: logprobs_i,<br>                &#125;<br>                <span class="hljs-keyword">for</span> t, logprobs_i, unsafe <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<br>                    generation_tokens, generation_logprobs, unsafe_requests<br>                )<br>            ]<br>        <span class="hljs-keyword">return</span> [<br>            &#123;<br>                <span class="hljs-string">&quot;generation&quot;</span>: &#123;<br>                    <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>,<br>                    <span class="hljs-string">&quot;content&quot;</span>: self.tokenizer.decode(t) <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> unsafe <span class="hljs-keyword">else</span> UNSAFE_ERROR,<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">for</span> t, unsafe <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(generation_tokens, unsafe_requests)<br>        ]<br></code></pre></td></tr></table></figure><p>最后一部分是top-p采样的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sample_top_p</span>(<span class="hljs-params">probs, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    在概率分布上执行top-p（核心）采样。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        probs (torch.Tensor): 概率分布张量。</span><br><span class="hljs-string">        p (float): 用于top-p采样的概率阈值。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        torch.Tensor: 采样的Token索引。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Note:</span><br><span class="hljs-string">        Top-p抽样选择了最小的一组Token，其累积概率超过阈值p，并根据选择的Token对分布进行重新归一化。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    probs_sort, probs_idx = torch.sort(probs, dim=-<span class="hljs-number">1</span>, descending=<span class="hljs-literal">True</span>)<br>    probs_sum = torch.cumsum(probs_sort, dim=-<span class="hljs-number">1</span>)<br>    mask = probs_sum - probs_sort &gt; p<br>    probs_sort[mask] = <span class="hljs-number">0.0</span><br>    probs_sort.div_(probs_sort.<span class="hljs-built_in">sum</span>(dim=-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>))<br>    next_token = torch.multinomial(probs_sort, num_samples=<span class="hljs-number">1</span>)<br>    next_token = torch.gather(probs_idx, -<span class="hljs-number">1</span>, next_token)<br>    <span class="hljs-keyword">return</span> next_token<br></code></pre></td></tr></table></figure><p>2024&#x2F;1&#x2F;1 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
      <tag>LlaMA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解读LlaMA Paper: 开放且高效的基础语言模型集</title>
    <link href="/2024/01/01/%E8%A7%A3%E8%AF%BBLlaMA-Paper-%E5%BC%80%E6%94%BE%E4%B8%94%E9%AB%98%E6%95%88%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%9B%86/"/>
    <url>/2024/01/01/%E8%A7%A3%E8%AF%BBLlaMA-Paper-%E5%BC%80%E6%94%BE%E4%B8%94%E9%AB%98%E6%95%88%E7%9A%84%E5%9F%BA%E7%A1%80%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<p>大名鼎鼎的开源语言模型LLaMA由Meta公司发布于2023年2月27日。这在研究社区中引起了广泛的热议，它的架构也被后续各大开源模型争相模仿。</p><p>发布的模型参数数量及文件大小：</p><ul><li>7B：12.55 GB。</li><li>13B：24.24 GB。</li><li>33B：60.6 GB。</li><li>65B：121.6 GB。</li></ul><p>数据集总大小则是4828GB，占比如下：</p><ul><li>English CommonCrawl [67%]</li><li>C4 [15%]</li><li>GitHub [4.5%]</li><li>Wikipedia [4.5%]</li><li>Gutenberg and Books3 [4.5%]</li><li>ArXiv [2.5%]</li><li>Stack Exchange [2%]</li></ul><h1 id="LLaMA模型架构"><a href="#LLaMA模型架构" class="headerlink" title="LLaMA模型架构"></a>LLaMA模型架构</h1><p><img src="/images/llama_stru.png" alt="LLaMA模型架构"><br>LLaMA1的架构已经有很多分析了，总结一共有以下几点：</p><ul><li><p>前置归一化(Pre-normalizatio)：受到GPT3的启发，LLaMa 对每个 Transformer 子层的输入进行归一化，而不是对输出进行归一化。这是为了训练的稳定性。</p></li><li><p>归一化函数使用的是RMSNorm(均方层归一化)。公式：<br><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mrow><mover><mi>x</mi><mo stretchy="false">¯</mo></mover></mrow><mrow><mi>i</mi></mrow></msub><mo>&#x3D;</mo><mfrac><msub><mi>a</mi><mrow><mi>i</mi></mrow></msub><mrow><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">M</mi><mi mathvariant="normal">S</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="bold">x</mi></mrow><mo stretchy="false">)</mo></mrow></mfrac><msub><mi>g</mi><mrow><mi>i</mi></mrow></msub><mo>,</mo><mstyle scriptlevel="0"><mspace width="1em"></mspace></mstyle><mrow><mi mathvariant="normal">w</mi><mi mathvariant="normal">h</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mtext>&nbsp;</mtext><mi mathvariant="normal">R</mi><mi mathvariant="normal">M</mi><mi mathvariant="normal">S</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="bold">x</mi></mrow><mo stretchy="false">)</mo><mo>&#x3D;</mo><msqrt><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo data-mjx-texclass="OP">∑</mo><mrow><mi>i</mi><mo>&#x3D;</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><msubsup><mi>x</mi><mrow><mi>i</mi></mrow><mrow><mn>2</mn></mrow></msubsup></msqrt></math></p></li><li><p>受PaLM启发，使用了SwiGLU激活函数，公式：$\mathrm{SwiGLU}(x,W,W,W,b,c,\beta)&#x3D;\mathrm{Swish}_{\beta}(x W+b)\otimes(x V+c)$</p></li><li><p>受GPTNeo启发，采用了旋转位置编码Rotary Embeddings(RoPE)。</p></li></ul><h1 id="LLaMA论文中的关键信息"><a href="#LLaMA论文中的关键信息" class="headerlink" title="LLaMA论文中的关键信息"></a>LLaMA论文中的关键信息</h1><ol><li>LLaMA 只使用公开可用数据集进行训练，模型已开源；<ul><li>基于 <strong>transformer</strong> 架构；</li><li>训练数据集大小：<strong>1.4T 个 tokens</strong>；</li><li>参数范围 <strong>7B~65B</strong>；</li></ul></li><li>使用更多的 token 进行训练，而不是一味的扩大参数，一样能取得不错的性能。<ul><li><strong>LLaMA-13B</strong> 在大多数基准测试中<strong>优于 GPT-3（175B）</strong>；</li></ul></li><li>用户更想要的可能是一个<strong>推理速度最快</strong>而不是<strong>训练速度最快</strong>的模型；此时模型大小就非常重要：<ul><li>LLaMA 可以在单个 GPU 上运行；</li><li><strong>LLaMA-13B 可以在单个 V100 上运行</strong>；</li></ul></li><li>训练成本<ul><li><strong>2048 个 A100</strong> 80GB GPU 上，开发和训练约 5 个月；</li><li>训练 65B 模型时，在 <strong>2048 个 A100</strong> 80GB GPU 上能处理约 <strong>380 tokens&#x2F;秒&#x2F;GPU</strong>，因此 1.4T token 的数据集训练一次大约需要 <strong>21 天</strong>；</li><li>耗能约 2638 MWh，折算排放 1015 吨 CO2。</li></ul></li></ol><h1 id="原文翻译"><a href="#原文翻译" class="headerlink" title="原文翻译"></a>原文翻译</h1><h2 id="译-论文-LLaMA：开放和高效的基础语言模型集（Meta-Facebook，2022）"><a href="#译-论文-LLaMA：开放和高效的基础语言模型集（Meta-Facebook，2022）" class="headerlink" title="[译][论文] LLaMA：开放和高效的基础语言模型集（Meta&#x2F;Facebook，2022）"></a>[译][论文] LLaMA：开放和高效的基础语言模型集（Meta&#x2F;Facebook，2022）</h2><p>本文翻译自 2022 年 Meta的大模型论文： <a href="https://arxiv.org/abs/2302.13971">LLaMA: Open and Efficient Foundation Language Models</a>。</p><p>作者：Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文介绍了 LLaMA，一个包含 <strong>7B~65B</strong>（70~650 亿） 参数的基础语言模型集（a collection of foundation language models）。 我们使用了数万亿个（trillions of） token训练这些模型，证明了使用公开数据集就能训练出最先进的模型， 而并非必须使用专有和私有数据集。尤其是，<strong>LLaMA-13B 在大多数基准测试中均优于 GPT-3（175B）</strong> ，而 LLaMA-65B 则与最佳模型 Chinchilla-70B 和 PaLM-540B 相当。 我们已经将所有模型<a href="https://github.com/facebookresearch/llama">开源</a>，以供社区研究。</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>在大规模文本语料库（massive corpora of texts）上训练的大型语言模型（Large Languages Models, LLM），已经有能力根据给定的文本指令（textual instructions） 或示例（a few examples）执行新的任务。</p><p>这种 <strong>few-shot</strong> 的属性首先出现在<strong>将模型扩展到足够大的规模时</strong>。 在此之后，出现了很多进一步扩展这些模型的工作， 它们都遵循了这样一个假设：<strong>更多的参数将产生更好的性能</strong>。 然而，Hoffmann 等（2022）的最新工作表明，对于给定的计算预算（compute budget）， 最佳性能并非来自那些最大的模型，而是来自那些<strong>在更多数据上训练出来的较小模型</strong>。</p><blockquote><p>“few-shot” 指一个模型有能力根据给定的少量示例去执行其他的类似任务的能力。</p></blockquote><h3 id="1-1-大模型训练：更多的参数-vs-更大的数据集"><a href="#1-1-大模型训练：更多的参数-vs-更大的数据集" class="headerlink" title="1.1 大模型训练：更多的参数 vs 更大的数据集"></a>1.1 大模型训练：更多的参数 vs 更大的数据集</h3><p>Hoffmann 等（2022）提出了 scaling laws，目标是针对给定的训练计算预算（compute budget），如何最佳地扩展（scale）数据集和模型大小。 但是，</p><ul><li>这个模型没有考虑推理（inference）预算，而在提供大规模推理时，这一点尤其重要： 在这种情况下，给定一个性能目标，我们更想要的是一个推理速度最快而非训练速度最快的模型。</li><li>对于一个给定的性能要求，训练一个大模型可能是一种更便宜的方式； 但对于最终的推理来说，<strong>较小的模型+更长的训练时间</strong>（a smaller one trained longer）反而更实惠。 例如，Hoffmann 等（2022）建议用 200B tokens 来训练 10B 模型，但我们发现即使在 1T 个 token 之后，7B 模型的性能仍在随着 token 的增多而提高。</li></ul><h3 id="1-2-LLaMA：减少参数，增大数据集"><a href="#1-2-LLaMA：减少参数，增大数据集" class="headerlink" title="1.2 LLaMA：减少参数，增大数据集"></a>1.2 LLaMA：减少参数，增大数据集</h3><p>本文的重点是：对于给定的不同推理预算（inference budgets）， 通过<strong>使用更多 token 进行训练</strong>的方式（超过业内常用的 token 规模） 来获得最佳的性能（the best possible performance）。我们将得到的模型称为 <strong>LLaMA</strong>。 LLaMA 的参数范围在 <strong>7B ~ 65B</strong>，性能与目前业界最佳的一些大语言模型相当。 例如，</p><ul><li><strong>LLaMA-13B</strong> 在大多数基准测试中<strong>优于 GPT-3</strong>， 尽管参数连后者的 <strong>10%</strong> 都不到；</li><li><strong>LLaMA 可以在单个 GPU 上运行</strong>， 这使得大模型的获取和研究更容易，而不再只是少数几个大厂的专利；</li><li>在高端系列上，<strong>LLaMA-65B</strong> 也与最佳的大语言模型（如 Chinchilla 或 PaLM-540B）性能相当。</li></ul><p>与 Chinchilla、PaLM、GPT-3 不同，我们只使用了公开数据（publicly available data）， 因此我们的工作是开源兼容的；</p><ul><li>相比之下，大多数现有模型依赖于不公开或没有文档的数据，例如 “Books–2TB” 和 “Social media conversations”；</li><li>也存在一些例外，例如 OPT（Zhang 等，2022）、GPT-NeoX（Black 等，2022）、BLOOM（Scao 等，2022）和 GLM（Zeng 等，2022）， 但它们的性能都无法与 PaLM-62B 或 Chinchilla 相比。</li></ul><h3 id="1-3-内容组织"><a href="#1-3-内容组织" class="headerlink" title="1.3 内容组织"></a>1.3 内容组织</h3><p>本文接下来的内容如下：</p><ul><li>描述我们对 Transformer 架构所做的改动，以及我们的训练方法:</li><li>给出 LLaMA 的性能，基于标准基准测试与其他 LLM 进行比较；</li><li>使用 responsible AI 社区的最新基准测试，揭示 LLaMA 模型中存在的一些偏见和毒性（biases and toxicity）。</li></ul><h2 id="2-方法（Approach）"><a href="#2-方法（Approach）" class="headerlink" title="2 方法（Approach）"></a>2 方法（Approach）</h2><p>我们的训练方法与前人的一些工作（Brown 等，2020；Chowdhery 等，2022）类似， 并受到 Chinchilla scaling laws（Hoffmann 等，2022）的启发。 我们使用一个标准的优化器(optimizer) 在大量文本数据上训练大型的Transformers模型。</p><h3 id="2-1-预训练数据（Pre-training-Data）"><a href="#2-1-预训练数据（Pre-training-Data）" class="headerlink" title="2.1 预训练数据（Pre-training Data）"></a>2.1 预训练数据（Pre-training Data）</h3><h4 id="2-1-1-数据集"><a href="#2-1-1-数据集" class="headerlink" title="2.1.1 数据集"></a>2.1.1 数据集</h4><p>训练数据集有几种不同来源，涵盖了多个领域，如表 1 所示。</p><table><thead><tr><th>数据集</th><th>占比</th><th>迭代次数（Epochs）</th><th>数据集大小（Disk size）</th></tr></thead><tbody><tr><td>CommonCrawl</td><td>67.0%</td><td>1.10</td><td>3.3 TB</td></tr><tr><td>C4</td><td>15.0%</td><td>1.06</td><td>783 GB</td></tr><tr><td>Github</td><td>4.5%</td><td>0.64</td><td>328 GB</td></tr><tr><td>Wikipedia</td><td>4.5%</td><td>2.45</td><td>83 GB</td></tr><tr><td>Books</td><td>4.5%</td><td>2.23</td><td>85 GB</td></tr><tr><td>ArXiv</td><td>2.5%</td><td>1.06</td><td>92 GB</td></tr><tr><td>StackExchange</td><td>2.0%</td><td>1.03</td><td>78 GB</td></tr></tbody></table><p>表 1：预训练数据。<br>其中 epochs 是用 1.4T tokens 预训练时的迭代次数。用 1T tokens 预训练时也是用的这个数据集比例。</p><p>这里的数据集大部分都是其他 LLM 训练用过的， 但我们只用其中公开可得（publicly available）的部分，并且要保持开源兼容（compatible with open sourcing）。</p><p><strong>English CommonCrawl [67%]</strong></p><p>我们使用 CCNet pipeline（Wenzek 等，2020）对 2017~2020 的五个 CommonCrawl dumps 进行预处理。</p><ul><li>在行级别（line level）上对数据去重，</li><li>使用 fastText 线性分类器进行语言识别，去掉非英文网页，</li><li>使用 ngram 语言模型过滤掉一些低质量内容。</li></ul><p>此外，我们还训练了一个线性模型，将页面分为两类：</p><ol><li>被 Wikipedia 引用过的网页；</li><li>没有被 Wikipedia 引用过的（随机采样网页）。这一类将被丢弃。</li></ol><p><strong>C4 [15%]</strong></p><p>在前期探索性实验中，我们观察到使用多样化的预处理 CommonCrawl 数据集可以提高性能。 因此，我们将公开可用的 C4 数据集（Raffel 等，2020）也包含到了训练数据中。</p><p>对 C4 的预处理也是<strong>去重和语言识别</strong>：与 CCNet 的主要区别在于质量过滤（quality filtering）， 主要依赖于启发式方法（heuristics），例如是否存在标点符号或网页中单词和句子的数量。</p><p><strong>Github [4.5%]</strong></p><p>使用了 Google BigQuery 上公开可用的 GitHub 数据集，但仅保留其中用 Apache、BSD 和 MIT license 的项目。 此外，</p><ul><li>基于行长度（line length），字母或数字字符（alphanumeric characters）比例等，用启发式方法过滤掉低质量文件；</li><li>使用正则表达式删除一些模板段落（boilerplate），例如 headers；</li><li>在文件级别上使用精确匹配对得到的数据集进行去重。</li></ul><p><strong>Wikipedia [4.5%]</strong></p><ul><li><p>使用了 2022 年 6 月至 8 月的一部分 Wikipedia dumps， 覆盖 20 种语言（use either the Latin or Cyrillic scripts）：bg、ca、cs、da、de、en、es、fr、hr、hu、it、nl、pl、pt、ro、ru、sl、sr、sv、uk。</p></li><li><p>删掉了其中的超链接、注释和其他 formatting boilerplate。</p></li></ul><p><strong>Gutenberg and Books3 [4.5%]</strong></p><p>训练数据集中包含两个书籍语料库：</p><ol><li>Gutenberg Project：<strong>公版书</strong>（public domain books）；</li><li>Books3 section of ThePile（Gao 等，2020）：一个用于训练大语言模型的<strong>公开可用</strong>数据集。</li></ol><p>在书级别（book level）去重，内容超过 90% 重复的书会被剔除出去。</p><p><strong>ArXiv [2.5%]</strong></p><p>为了让训练数据集包含一定的科学数据（scientific data），我们对一些 arXiv Latex 文件做处理之后加到训练数据集。</p><ul><li>按照 Lewkowycz 等（2022）的方法，删除了the first section 之前的所有内容以及参考文献，</li><li>从 .tex 文件中删除了注释，</li><li>对作者编写的定义和宏（definitions and macros written by users）做了内联展开（inline-expand），使得论文更加一致（increase consistency across papers）。</li></ul><p><strong>Stack Exchange [2%]</strong></p><p>Stack Exchange 是一个高质量的问答网站，涵盖了从计算机科学到化学等各种领域。 我们的训练数据集包括了一个 Stack Exchange dump：</p><ul><li>保留其中最大的 28 个网站的数据，</li><li>从文本中删除了 HTML tags ，</li><li>按分数（从高到低）对答案进行了排序。</li></ul><h4 id="2-1-2-Tokenizer（分词器）"><a href="#2-1-2-Tokenizer（分词器）" class="headerlink" title="2.1.2 Tokenizer（分词器）"></a>2.1.2 Tokenizer（分词器）</h4><p>我们使用 bytepair encoding（BPE）算法（Sennrich 等，2015）对数据进行 tokenization，算法实现采用的是 Sentence-Piece（Kudo 和 Richardson，2018）。需要说明的是，为了分解未知的 UTF-8字符，我们将所有数字拆分为单个 digits，再 fallback到 bytes。</p><p>最终，我们的整个训练数据集在 tokenization 后包含大约 <strong>1.4T 个 token</strong>。</p><ul><li>对于大多数训练数据，每个 token 在训练期间仅使用一次；</li><li>维基百科和书籍是个例外，会被使用两次（two epochs）。</li></ul><h3 id="2-2-架构（Architecture）"><a href="#2-2-架构（Architecture）" class="headerlink" title="2.2 架构（Architecture）"></a>2.2 架构（Architecture）</h3><p>与最近大语言模型的研究趋势一致，我们的模型网络也基于 Transformer 架构（Vaswani 等，2017），但做了很多改进，也借鉴了其他模型（例如 PaLM）中的一些技巧。</p><h4 id="2-2-1-改进"><a href="#2-2-1-改进" class="headerlink" title="2.2.1 改进"></a>2.2.1 改进</h4><p>以下是与原始架构的主要差异，</p><h5 id="前置归一化（Pre-normalization）：受-GPT3-启发"><a href="#前置归一化（Pre-normalization）：受-GPT3-启发" class="headerlink" title="前置归一化（Pre-normalization）：受 GPT3 启发"></a>前置归一化（Pre-normalization）：受 GPT3 启发</h5><p>为了提高训练稳定性，我们对每个 Transformer子层的输入进行归一化，而不是对输出进行归一化。 这里使用了由 Zhang 和 Sennrich（2019）提出的 RMSNorm 归一化函数。</p><h5 id="SwiGLU-激活函数：受-PaLM-启发"><a href="#SwiGLU-激活函数：受-PaLM-启发" class="headerlink" title="SwiGLU 激活函数：受 PaLM 启发"></a>SwiGLU 激活函数：受 PaLM 启发</h5><p>用 SwiGLU 激活函数替换 ReLU 非线性，该函数由 Shazeer（2020）提出，目的是提升性能。 但我们使用的维度是 <code>2/3 * 4d</code>，而不是 PaLM 中的 <code>4d</code>。</p><h5 id="旋转嵌入（Rotary-Embeddings）：受-GPTNeo-启发"><a href="#旋转嵌入（Rotary-Embeddings）：受-GPTNeo-启发" class="headerlink" title="旋转嵌入（Rotary Embeddings）：受 GPTNeo 启发"></a>旋转嵌入（Rotary Embeddings）：受 GPTNeo 启发</h5><p>去掉了绝对位置嵌入（absolute positional embeddings），并在每个网络层中添加旋转位置嵌入（rotary positional embeddings，RoPE）。 RoPE 由 Su 等（2021）提出。</p><h4 id="2-2-2-不同-LLaMA-模型的超参数"><a href="#2-2-2-不同-LLaMA-模型的超参数" class="headerlink" title="2.2.2 不同 LLaMA 模型的超参数"></a>2.2.2 不同 LLaMA 模型的超参数</h4><p>不同模型的超参数详细信息见表 2。</p><table><thead><tr><th align="left">params</th><th align="left">dimension</th><th align="left">n heads</th><th align="left">n layers</th><th align="left">learning rate</th><th align="left">batch size</th><th align="left">n tokens</th></tr></thead><tbody><tr><td align="left">6.7B</td><td align="left">4096</td><td align="left">32</td><td align="left">32</td><td align="left">3.0e-4</td><td align="left">4M</td><td align="left">1.0T</td></tr><tr><td align="left">13.0B</td><td align="left">5120</td><td align="left">40</td><td align="left">40</td><td align="left">3.0e-4</td><td align="left">4M</td><td align="left">1.0T</td></tr><tr><td align="left">32.5B</td><td align="left">6656</td><td align="left">52</td><td align="left">60</td><td align="left">1.5e-4</td><td align="left">4M</td><td align="left">1.4T</td></tr><tr><td align="left">65.2B</td><td align="left">8192</td><td align="left">64</td><td align="left">80</td><td align="left">1.5e-4</td><td align="left">4M</td><td align="left">1.4T</td></tr></tbody></table><p>表 2： Model sizes, architectures, and optimization hyper-parameters.</p><h3 id="2-3-优化器（Optimizer）"><a href="#2-3-优化器（Optimizer）" class="headerlink" title="2.3 优化器（Optimizer）"></a>2.3 优化器（Optimizer）</h3><ul><li>使用了 AdamW 优化器（Loshchilov 和 Hutter，2017）对模型进行训练，具体超参数：β1&#x3D;0.9,β2&#x3D;0.95；</li><li>使用了一个 cosine learning rate schedule，最终的学习率达到了最大学习率的 10％；</li><li>使用了 0.1 的权重衰减（weight decay）和 1.0 的梯度裁剪（gradient clipping）；</li><li>使用了 2,000 个 warmup steps，并根据模型大小来调整 learning rate 和 batch size。</li></ul><h3 id="2-4-高效实现（Efficient-implementation）：提高训练速度"><a href="#2-4-高效实现（Efficient-implementation）：提高训练速度" class="headerlink" title="2.4 高效实现（Efficient implementation）：提高训练速度"></a>2.4 高效实现（Efficient implementation）：提高训练速度</h3><p>我们进行了几项优化来提高模型的训练速度。</p><p>首先，我们使用 <strong>causal multi-head attention</strong> 的一个高效实现来<strong>减少内存占用和运行时</strong>。 这种实现是受 Rabe 和 Staats（2021）的启发，并使用了 Dao 等（2022）的反向传播，现在 <a href="https://github.com/facebookresearch/xformers">xformers 库</a> 中已经提供了。 优化原理：由于语言建模任务存在因果特性，因此可以不存储注意力权重（attention weights），不计算那些已经被掩码（masked）的 key&#x2F;query 得分。</p><p>为进一步提高训练效率，我们通过 <strong>checkpoint</strong> 技术， 减少了在反向传播期间需要重新计算的激活数量。更具体地说：</p><ul><li>我们保存了计算成本高昂的激活，例如线性层的输出。实现方式是<strong>手动实现 Transformer 层的反向函数</strong>，而不用 PyTorch autograd。</li><li>如 Korthikanti 等（2022）中提到的， 为了充分受益于这种优化，我们需要通过模型和序列并行（model and sequence parallelism）来<strong>减少模型的内存使用</strong>。</li><li>此外，我们还尽可能地 overlap 激活计算和 GPU 之间的网络通信（由于 all_reduce 操作）。</li></ul><p>训练 65B 参数的模型时，我们的代码在 <strong>2048 个 A100 80GB GPU</strong> 上能处理约 <strong>380 tokens&#x2F;秒&#x2F;GPU</strong>。这意味着 1.4T token 的数据集上训练大约需要 <strong>21 天</strong>。</p><h2 id="3-主要结果（Main-results）"><a href="#3-主要结果（Main-results）" class="headerlink" title="3 主要结果（Main results）"></a>3 主要结果（Main results）</h2><p>参考前人工作（Brown 等，2020），我们测试了<strong>零样本（zero-shot）和少样本（few-shot）</strong>两种任务， 进行总共 20 个基准测试：</p><ul><li>零样本：提供任务的文本描述和一个测试示例。模型可以使用开放式生成（open-ended generation）提供答案，或对提议的答案进行排名。</li><li>少样本：提供一些（1~64 个）任务示例和一个测试示例。模型将此文本作为输入并生成答案，或对不同选项进行排名。</li></ul><p>我们将 LLaMA 与其他基础模型进行比较，包括</p><ul><li>未开源模型：GPT-3（Brown 等，2020）、Gopher（Rae 等，2021）、Chinchilla（Hoffmann 等，2022）和 PaLM（Chowdhery 等，2022），</li><li>开源模型：OPT 模型（Zhang 等，2022）、GPT-J（Wang 和 Komatsuzaki，2021）和 GPTNeo（Black 等，2022）。</li><li>在第 4 节中，我们还将简要比较 LLaMA 与 instruction-tuned 模型，如 OPT-IML（Iyer 等，2022）和 Flan-PaLM（Chung 等，2022）。</li></ul><p>我们在自由形式生成任务（free-form generation）和多项选择（multiple choice）任务上评估 LLaMA。 多项选择任务的目标是在提供的上下文基础上，从一组给定选项中选择最合适的。我们使用的最合适标准就是可性能最高（highest likelihood）。</p><ul><li>对于大部分数据集，我们遵循 Gao 等（2021）的方法，使用由完成字符数归一化的可能性（likelihood normalized by the number of characters），</li><li>对于少量数据集（OpenBookQA，BoolQ），我们遵循 Brown 等（2020）的方法，根据在“Answer:”上下文中给定的完成可能性（likelihood of the completion given “Answer:” as context），用公式表示就是 <strong>P(completion|context) &#x2F; P(completion|”Answer:”)</strong>.</li></ul><h3 id="3-1-常识推理（Common-Sense-Reasoning）"><a href="#3-1-常识推理（Common-Sense-Reasoning）" class="headerlink" title="3.1 常识推理（Common Sense Reasoning）"></a>3.1 常识推理（Common Sense Reasoning）</h3><p>使用下面八个标准的常识推理基准测试：</p><ol><li>BoolQ（Clark 等，2019）</li><li>PIQA（Bisk 等，2020）</li><li>SIQA（Sap 等，2019）</li><li>HellaSwag（Zellers 等，2019）</li><li>WinoGrande（Sakaguchi 等，2021）</li><li>OpenBookQA（Mihaylov 等，2018）</li><li>&amp; 8. ARC easy 和 challenge（Clark 等，2018）</li></ol><p>这些数据集包括 Cloze 和 Winograd 风格的任务，以及多项选择题。与语言建模社区类似，我们使用零样本设置进行评估。在表 3 中，我们与各种规模的现有模型进行比较。</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-3.png" alt="表 3：Zero-shot performance on Common Sense Reasoning tasks"></p><p>几点说明：</p><ul><li>除了 BoolQ，LLaMA-65B 在其他所有基准测试都优于 Chinchilla-70B。</li><li>同样，该模型在除了 BoolQ 和 WinoGrande 之外的所有地方都超过了 PaLM-540B。</li><li>LLaMA-13B 模型尽管比 GPT-3 小了 90％ 多，但在大多数基准测试中表现比 GPT-3 还好。</li></ul><h3 id="3-2-闭卷问答（Closed-book-Question-Answering）"><a href="#3-2-闭卷问答（Closed-book-Question-Answering）" class="headerlink" title="3.2 闭卷问答（Closed-book Question Answering）"></a>3.2 闭卷问答（Closed-book Question Answering）</h3><p>我们将 LLaMA 与现有的大语言模型进行比较，在两个闭卷问答基准测试：</p><ol><li>自然问题（Kwiatkowski 等，2019）</li><li>TriviaQA（Joshi 等，2017）。</li></ol><p>对于这两个基准测试，在相同设置下（例如，模型不能访问那些有助于回答问题的文档）， 取得了完全相同的性能。 表 4 和表 5 分别是在这两个 benchmark 上的结果：</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-4.png" alt="表 4：NaturalQuestions. Exact match performance"></p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-5.png" alt="表 5：TriviaQA. Zero-shot and few-shot exact match performance on the filtered dev set"></p><p>在这两个基准测试中，LLaMA-65B 在零样本和少样本设置中都实现了 state-of-the-arts 的性能。 更重要的是，LLaMA-13B 在这些基准测试中与 GPT-3 和 Chinchilla 相比也具有竞争力，尽管参数只有后者的 10%~20％（5-10 smaller）。 在推理场景，<strong>LLaMA-13B 能在单个 V100 GPU</strong> 上运行。</p><h3 id="3-3-阅读理解（Reading-Comprehension）"><a href="#3-3-阅读理解（Reading-Comprehension）" class="headerlink" title="3.3 阅读理解（Reading Comprehension）"></a>3.3 阅读理解（Reading Comprehension）</h3><p>阅读理解能力测试基于 “RACE 阅读理解基准测试”（Lai 等，2017）。 这个数据集是从<strong>为中国初中和高中生设计的英文阅读理解考试</strong>中收集的。 一些设置遵循 Brown 等（2020），测试结果见表 6，</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-6.png" alt="表 6：阅读理解能力测试。Zero-shot accuracy"></p><p>在这些基准测试中，LLaMA-65B 与 PaLM-540B 相当，而 LLaMA-13B 比 GPT-3 好几个百分点。</p><h3 id="3-4-数学推理（Mathematical-reasoning）"><a href="#3-4-数学推理（Mathematical-reasoning）" class="headerlink" title="3.4 数学推理（Mathematical reasoning）"></a>3.4 数学推理（Mathematical reasoning）</h3><p>在两个数学推理基准测试上评估模型：</p><ol><li>MATH（Hendrycks 等，2021）：一个包含 12K 个初中和高中数学问题的数据集，LaTeX 格式；</li><li>GSM8k（Cobbe 等，2021）：一个初中数学问题集。</li></ol><p>表 7 比较了 PaLM 和 Minerva（Lewkowycz 等，2022）进行比较。</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-7.png" alt="表 7：量化推理数据集（quantitative reasoning datasets）上的模型性能"></p><ul><li>Minerva 是一系列在 ArXiv 和 Math Web Pages 中提取的 38.5B token 上 finetune 而成的 PaLM 模型。</li><li>PaLM 和 LLaMA 都没有在数学数据上进行 finetune 。</li></ul><p>PaLM 和 Minerva 的性能数字取自 Lewkowycz 等（2022），我们分别用和不用 maj1@k 进行了比较。 maj1@k 表示我们为每个问题生成 k 个样本，并进行多数投票（Wang 等，2022）。</p><p>在 GSM8k 上，可以看到 LLaMA-65B 优于 Minerva-62B，尽管它没有在数学数据上进行微调。</p><h3 id="3-5-代码生成（Code-generation）"><a href="#3-5-代码生成（Code-generation）" class="headerlink" title="3.5 代码生成（Code generation）"></a>3.5 代码生成（Code generation）</h3><p>评估模型从给出的自然语言描述来生成代码的能力，使用了两个基准测试：</p><ol><li>HumanEval（Chen 等，2021）</li><li>MBPP（Austin 等，2021）</li></ol><p>这两个测试，都是给模型几句关于程序的描述，以及一些输入输出示例。</p><p>在表 8 中，我们将 LLaMA 的 pass@1 得分与未在代码上进行微调的现有语言模型进行了比较，即 PaLM 和 LaMDA（Thoppilan 等，2022）。 PaLM 和 LLaMA 是在包含相似数量的代码 token 的数据集上训练的。</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-8.png" alt="表8：代码生成的模型表现"></p><p>如表 8 所示：</p><ul><li>对于类似数量的参数，LLaMA 优于其他一般模型，如 LaMDA 和 PaLM，它们没有专门针对代码进行训练或微调。</li><li>LLaMA 具有 13B 参数及以上，在 HumanEval 和 MBPP 上均优于 LaMDA 137B。</li><li>LLaMA 65B 也优于 PaLM 62B，即使它的训练时间更长。</li></ul><blockquote><p>本表中 pass@1 结果是通过 temperature&#x3D;0.1 采样得到的。 pass@100 和 pass@80 指标是通过 temperature&#x3D;0.8 获得的。 我们使用与 Chen 等（2021）相同的方法来获得 pass@k 的无偏估计。</p></blockquote><p>通过在代码特定 token 上进行微调，可以提高生成代码的性能。例如，</p><ul><li>PaLM-Coder（Chowdhery 等，2022）将 PaLM 在 HumanEval 上的 pass@1 分数从 PaLM 的 26.2％提高到 36％。</li><li>其他专门针对代码进行训练的模型在这些任务上也表现比通用模型更好（Chen 等，2021; Nijkamp 等，2022; Fried 等，2022）。</li></ul><p>在代码 token 上进行微调超出了本文的范围。</p><h3 id="3-6-大规模多任务语言理解（Massive-Multitask-Language-Understanding）"><a href="#3-6-大规模多任务语言理解（Massive-Multitask-Language-Understanding）" class="headerlink" title="3.6 大规模多任务语言理解（Massive Multitask Language Understanding）"></a>3.6 大规模多任务语言理解（Massive Multitask Language Understanding）</h3><p>大规模多任务语言理解基准测试（MMLU）由 Hendrycks 等（2020）提出， 包括涵盖人文、STEM 和社会科学等各种知识领域的多项选择题。 我们在 5-shot 设置下使用基准测试提供的示例来评估我们的模型，结果如表 9 所示，</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-9.png" alt="表9：Massive Multitask Language Understanding (MMLU). Five-shot accuracy"></p><p>可以看到，LLaMA-65B 落后于 Chinchilla-70B 和 PaLM-540B 几个百分点，并且在大部分领域都是如此。 一个可能的解释是我们在预训练数据中使用了有限数量的书籍和学术论文，即 ArXiv、Gutenberg 和 Books3，总共只有 <strong>177GB</strong>， 而后两个模型是在多达 <strong>2TB</strong> 的书籍上进行训练的。 Gopher、Chinchilla 和 PaLM 使用的大量书籍可能也解释了为什么 Gopher 在这个基准测试中表现优于 GPT-3，而在其他基准测试中表现只是差不多。</p><h3 id="3-7-训练过程中性能的变化"><a href="#3-7-训练过程中性能的变化" class="headerlink" title="3.7 训练过程中性能的变化"></a>3.7 训练过程中性能的变化</h3><p>在训练过程中，我们跟踪了 LLaMA 在一些问题回答和常识基准测试上的性能，如图 2，</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/figure-2.png" alt="图 2：Evolution of performance on question answering and common sense reasoning during training"></p><p>在大多数基准测试中，性能随着 token 数量稳步提高，并与模型的训练困惑度(training perplexity)相关（见图 1）。</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/figure-1.png" alt="图 1：Training loss over train tokens for the 7B, 13B, 33B, and 65 models. LLaMA-33B and LLaMA- 65B were trained on 1.4T tokens. The smaller models were trained on 1.0T tokens. All models are trained with a batch size of 4M tokens"></p><p>SIQA 和 WinoGrande 是例外。</p><ul><li>特别是在 SIQA 上，我们观察到性能变化很大，这可能表明这个基准测试不可靠；</li><li>在 WinoGrande 上，性能与训练困惑度的相关性不太好：LLaMA-33B 和 LLaMA-65B 在训练期间的性能相似。</li></ul><h2 id="4-指令微调（Instruction-Finetuning）"><a href="#4-指令微调（Instruction-Finetuning）" class="headerlink" title="4 指令微调（Instruction Finetuning）"></a>4 指令微调（Instruction Finetuning）</h2><p>在本节中，我们将说明简单地在指令数据上进行微调，就会迅速提高在 MMLU 上的性能。</p><p>尽管 LLaMA-65B 的未微调版本已经能够 follow 基本指令，但我们观察到进行一点微调可以提高在 MMLU 上的性能， 并能进一步提高模型 follow 指令的能力。 由于这不是本文的重点，我们只进行了一次实验，遵循 Chung 等（2022）的相同协议来训练一个指令模型 LLaMA-I。 LLaMA-I 在 MMLU 上的结果见表 10，与当前中等规模的指令微调模型 OPT-IML（Iyer 等，2022）和 Flan-PaLM 系列（Chung 等，2022）进行了比较：</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-10.png" alt="表 10：Instruction finetuning – MMLU (5-shot). Comparison of models of moderate size with and without instruction finetuning on MMLU"></p><p>尽管这里使用的指令微调方法很简单，但我们在 MMLU 上达到了 68.9％。 LLaMA-I（65B）在 MMLU 上优于现有的中等规模指令微调模型，但仍远远落后于最先进的 GPT code-davinci-002 在 MMLU 上的 77.4（数字来自 Iyer 等（2022））。</p><h2 id="5-偏差，毒性和错误信息"><a href="#5-偏差，毒性和错误信息" class="headerlink" title="5 偏差，毒性和错误信息"></a>5 偏差，毒性和错误信息</h2><p>大型语言模型已被证明能够复制和放大训练数据中存在的偏见（Sheng等，2019年；Kurita等，2019年），并生成有毒或冒犯性的内容（Gehman等，2020年）。由于我们的训练数据集包含大量来自网络的数据，我们认为确定我们的模型生成此类内容的潜力至关重要。为了了解LLaMA-65B的潜在危害，我们在测量有毒内容产生和刻板印象检测的不同基准上进行评估。虽然我们选择了一些语言模型社区用于指示这些模型存在问题的标准基准，但这些评估并不足以完全理解与这些模型相关的风险。</p><h3 id="5-1-真实的有毒提示-RealToxicityPrompts包含约100k个提示"><a href="#5-1-真实的有毒提示-RealToxicityPrompts包含约100k个提示" class="headerlink" title="5.1 真实的有毒提示(RealToxicityPrompts包含约100k个提示)"></a>5.1 真实的有毒提示(RealToxicityPrompts包含约100k个提示)</h3><p>语言模型可以生成有毒的语言(toxic language)，例如侮辱、仇恨言论或威胁。模型可以生成的有毒内容范围非常广泛，使得进行全面评估具有挑战性。近期的几项研究（Zhang等，2022；Hoffmann等，2022）已将RealToxicityPrompts基准（Gehman等，2020）视为其模型有多毒的指标。</p><p>RealToxicityPrompts包含约100k个提示，模型必须完成这些提示；然后通过向PerspectiveAPI 3发送请求自动评估其毒性得分。我们无法控制第三方PerspectiveAPI使用的流程，这使得与先前模型进行比较变得困难。</p><p>对于这100k个提示中的每一个，我们使用我们的模型贪婪地生成结果，并测量其毒性得分。每个提示的得分范围从0（非有毒）到1（有毒）。在表11中，我们报告了我们在RealToxicityPrompts的基础和尊重提示类别上的平均得分。这些得分与我们在文献中观察到的是“可比较的”（例如，Chinchilla为0.087），但这些工作和我们的方法（在采样策略、提示数量和API时间方面）存在差异。</p><p><img src="/images/134725.png" alt="表11：RealToxicityPrompts"></p><p>我们观察到，随着模型大小的增加，哪怕是对于要求尊重的提示，毒性也会增加。这也在之前的研究中观察到（Zhang等，2022），但Hoffmann等人（2022）是一个显著的例外，他们并未观察到Chinchilla和Gopher之间有任何差异，尽管大小不同。这可能是由于更大的模型Gopher的性能比Chinchilla差，表明毒性与模型大小之间的关系可能只适用于同一模型系列内。</p><h3 id="5-2-CrowS-Pairs"><a href="#5-2-CrowS-Pairs" class="headerlink" title="5.2 CrowS-Pairs"></a>5.2 CrowS-Pairs</h3><p>我们在CrowS-Pairs（Nangia等，2020）上评估我们模型的偏见。这个数据集允许在9个类别中测量偏见：性别、宗教、种族&#x2F;肤色、性取向、年龄、国籍、残疾、外貌和社会经济地位。每个示例由一个刻板印象和一个反刻板印象组成，我们使用zero-shot设置中两个句子的困惑度来测量模型对刻板句子的偏好。因此，较高的分数表示较高的偏见。</p><p>我们在表12中与GPT-3和OPT-175B进行比较。平均而言，LLaMA与这两个模型相比略有优势。我们的模型在宗教类别中尤其偏见明显（与OPT-175B相比增加了+10%），其次是年龄和性别。我们预计这些偏见来自CommonCrawl，尽管经过了多个过滤步骤。</p><p><img src="/images/134901.png" alt="表12：CrowS-Pairs。我们将LLaMA-65B、OPT-175B和GPT-3-175B中包含的偏见水平进行了比较。得分越高表示偏见越大。"></p><h3 id="5-3-WinoGender"><a href="#5-3-WinoGender" class="headerlink" title="5.3 WinoGender"></a>5.3 WinoGender</h3><p>为了进一步研究我们模型在性别类别上的偏见，我们查看了WinoGender基准测试（Rudinger等，2018），这是一个共指解析数据集。WinoGender由Winograd模式组成，通过确定模型的共指解析性能是否受到代词性别的影响来评估偏见。</p><blockquote><p>人们为了避免重复，习惯用代词、称谓和缩略语来指代前面提到的实体全称。 例如，在文章开始处会写“哈尔滨工业大学”，后面可能会说“哈工大”、“工大”等，还会提到“这所大学”、“她”等。 这种现象称为共指现象。共指解析的目的就在于自动识别表示同一个实体的名词短语或代词，并将他们归类。</p></blockquote><p>更具体地说，每个句子都有三个提及：一个“职业”、“参与者”和一个“代词”，其中代词要么指代职业，要么指代参与者。我们提示模型确定共指关系，并根据句子的上下文测量它是否正确地这样做。目标是揭示模型是否捕捉到了与职业相关的社会偏见。</p><p>例如，WinoGender数据集中的一个句子是：“护士通知病人，他的班次将在一个小时后结束。”，接着是指的是“His”。然后，我们比较护士和病人与模型进行共指解析的续集的困惑度。我们使用3个代词评估性能：“her&#x2F;her&#x2F;she”、“his&#x2F;him&#x2F;he”和“their&#x2F;them&#x2F;someone”（不同的选择对应于代词的语法功能）。</p><p>在表13中，我们报告了数据集中包含的三种不同代词的共指得分。我们观察到，我们的模型在为“their&#x2F;them&#x2F;someone”代词执行共指解析时明显优于“her&#x2F;her&#x2F;she”和“his&#x2F;him&#x2F;he”代词。之前的工作（Rae等，2021年；Hoffmann等，2022）也有类似的观察，并可能表明存在性别偏见。</p><p>确实，在“her&#x2F;her&#x2F;she”和“his&#x2F;him&#x2F;he”代词的情况下，模型可能使用职业的大多数性别进行共指解析，而不是使用句子的证据。为了进一步研究这一假设，我们查看了WinoGender数据集中“her&#x2F;her&#x2F;she”和“his&#x2F;him&#x2F;he”代词的“gotcha”案例集。这些案例对应于代词不匹配职业的大多数性别的句子，而职业是正确答案。</p><p>在表13中，我们观察到我们的模型LLaMA-65B在“gotcha”示例上的错误更多，明确显示它捕捉到了与性别和职业相关的社会偏见。无论性别如何，我们的模型在“her&#x2F;her&#x2F;she”和“his&#x2F;him&#x2F;he”代词上的性能下降，这表明存在偏见。</p><p><img src="/images/135040.png" alt="表13：WinoGender"></p><p>在表14中，我们报告了我们模型在两个问题上的性能，以测量真实模型和真实性和信息性的交集。与GPT-3相比，我们的模型在两个类别中得分更高，但正确答案的比率仍然很低，显示我们的模型可能会产生错误答案。</p><p><img src="/images/135147.png" alt="表14：Truthful QA"></p><h3 id="5-4-TruthfulQA"><a href="#5-4-TruthfulQA" class="headerlink" title="5.4 TruthfulQA"></a>5.4 TruthfulQA</h3><p>TruthfulQA（Lin等，2021）旨在衡量模型的真实性，即其识别某个声明是否真实的能力。Lin等人（2021）考虑了“真实”在“实际世界的字面真实”意义上的定义，而不是只在信仰系统或传统背景下为真的声明。这个基准测试可以评估模型生成错误信息或错误声明的风险。这些问题以多种风格编写，涵盖了38个类别，并且旨在具有对抗性。</p><h2 id="6-碳足迹（Carbon-footprint）"><a href="#6-碳足迹（Carbon-footprint）" class="headerlink" title="6 碳足迹（Carbon footprint）"></a>6 碳足迹（Carbon footprint）</h2><p>训练 LLaMA 消耗了大量能源，排放了很多二氧化碳。我们遵循最近的文献，将总能耗和产生的碳足迹分解在表 15 中：</p><p><img src="https://arthurchiao.art/assets/img/llama-paper/table-15.png" alt="表15：同一数据中心训练不同模型的碳足迹"></p><p>我们采用 Wu 等(2022)的公式来估算训练模型所需的瓦时数（Watt-hour, Wh）和碳排放量（carbon emissions）。对于瓦时数，我们使用以下公式：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">Wh</span> <span class="hljs-operator">=</span> GPU-h * (GPU power consumption) * PUE<br></code></pre></td></tr></table></figure><p>其中，我们的功率使用效率（PUE）为 1.1。 产生的碳排放量取决于用于训练所在的数据中心的位置。例如，</p><ul><li>BLOOM 使用排放 0.057kg CO2eq&#x2F;KWh 的电网，产生 27吨CO2eq 的排放量，</li><li>OPT 使用排放 0.231kg CO2eq&#x2F;KWh 的电网，导致 82吨CO2eq 的排放量。</li></ul><p>在本研究中，我们感兴趣的是在同一个数据中心的情况下，不同模型训练的碳排放成本。 因此，我们不考虑数据中心的位置，并使用美国国家平均碳强度系数（carbon intensity factor） 0.385kg CO2eq&#x2F;KWh。 那么此时就有：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tCO2eq</span> = MWh * <span class="hljs-number">0</span>:<span class="hljs-number">385</span><br></code></pre></td></tr></table></figure><p>我们对 OPT 和 BLOOM 采用相同的公式进行公平比较。</p><ul><li>对于 OPT，我们假设训练需要在 992 个 A100-80GB 上进行 34 天。</li><li>我们在 <strong>2048 个 A100 80GB 上，用了约 5 个月</strong>时间来开发 LLaMA。 根据前面的公式，计算得到 LLaMA 的训练成本约为 2638 MWh，总排放量为 1015吨的CO2eq。</li></ul><p>我们希望 LLaMA 的发布有助于减少未来的碳排放，因为它训练已经完成（很多情况下大家直接用或者进行微调就行了）: 而且其中一些小参数模型可以在单个 GPU 上运行。</p><h2 id="7-相关工作（Related-work）"><a href="#7-相关工作（Related-work）" class="headerlink" title="7 相关工作（Related work）"></a>7 相关工作（Related work）</h2><p><strong>语言模型</strong>是单词、 token 或字符组成的序列的概率分布（probability distributions over sequences of words, tokens or characters）(Shannon, 1948, 1951)。</p><p>这个任务通常被描述为<strong>对下一个 token 的预测</strong>，在自然语言处理（Bahl 等，1983；Brown 等，1990）中很早就是一个核心问题了。 Turing（1950）提出通过<strong>“模仿游戏”</strong>（imitation game），使用语言来衡量机器智能， 因此<strong>语言建模</strong>（language modeling）成为了衡量人工智能进展的基准（Mahoney，1999）。</p><h3 id="7-1-架构"><a href="#7-1-架构" class="headerlink" title="7.1 架构"></a>7.1 架构</h3><p>传统上，语言模型基于n-gram计数统计（Bahl等，1983），并提出了各种平滑技术来改善对稀有事件的估计（Katz，1987；Kneser和Ney，1995）。在过去的两十年中，神经网络已成功应用于语言建模任务，从前馈模型（Bengio等，2000）、循环神经网络（Elman，1990；Mikolov等，2010）到长短时记忆网络（LSTMs）（Hochreiter和Schmidhuber，1997；Graves，2013）。最近，基于自注意力的Transformer网络带来了重大的改进，尤其是对于捕获长距离依赖关系（Vaswani等，2017；Radford等，2018；Dai等，2019）。</p><h3 id="7-2-规模化"><a href="#7-2-规模化" class="headerlink" title="7.2 规模化"></a>7.2 规模化</h3><p>对于语言模型的规模化，无论是模型还是数据集的大小，都有着悠久的历史。Brants等（2007）展示了使用训练有2万亿(2 trillion)Token后得到的3000亿n-gram的语言模型对机器翻译质量的好处。</p><p>虽然这项工作依赖于一个简单的平滑技术，称为Stupid Backoff，但Heafield等（2013）后来展示了如何将Kneser-Ney平滑技术扩展到Web规模的数据。这使得可以从CommonCrawl的9750亿Token中训练一个5-gram模型，从而得到一个有5000亿n-gram的模型（Buck等，2014）。Chelba等（2013）引入了一个名为One Billion Word的基准测试，这是一个大规模的训练数据集，用于衡量语言模型的进展。</p><p>在神经语言模型的背景下，Jozefowicz等（2016）通过将LSTMs扩展到10亿参数，在Billion Word基准测试上获得了最新的结果。随后，基于Transformers的扩展模型在许多NLP任务上都有所改进。值得注意的模型包括BERT（Devlin等，2018）、GPT-2（Radford，2019）、Megatron-LM（Shoeybi等，2019）和T5（Raffel等，2020）。</p><p>GPT-3（Brown等，2020）是一个有1750亿参数的模型，这是一个重大突破。这导致了一系列大型语言模型的出现，例如Jurassic-1（Lieber等，2021）、Megatron-Turing NLG（Smith等，2022）、Gopher（Rae等，2021）、Chinchilla（Hoffmann等，2022）、PaLM（Chowdhery等，2022）、OPT（Zhang等，2022）和GLM（Zeng等，2022）。</p><p>Hestness等（2017）和Rosenfeld等（2019）研究了规模化对深度学习模型性能的影响，显示了模型和数据集大小与系统性能之间存在的幂律关系。Kaplan等（2020）专门为基于Transformer的语言模型导出了幂律，这些幂律后来由Hoffmann等（2022）通过在扩展数据集时调整学习率表进行了进一步的细化。最后，Wei等（2022）研究了规模化对大型语言模型能力的影响。</p><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8 总结"></a>8 总结</h2><p>在本文中，我们介绍了一系列公开发布的语言模型，并与最先进的基础模型竞争。尤其值得注意的是，LLaMA-13B的性能超过了GPT-3，而其大小只有GPT-3的十分之一多。而LLaMA-65B与Chinchilla-70B和PaLM-540B处于竞争地位。</p><p>与之前的研究不同，我们展示了仅使用公开可用的数据进行训练即可实现最先进的性能，而无需求助于专有数据集。我们希望将这些模型发布给研究社区，这将加速大型语言模型的发展，并帮助改进其稳健性以及缓解已知问题，如毒性和偏见。</p><p>此外，我们观察到，与Chung等人（2022年）类似，对这些模型进行指令微调会带来有希望的结果，我们计划在未来的工作中进一步研究这一点。最后，鉴于我们在规模化过程中不断提高性能，我们计划在未来发布使用更大的预训练语料库训练的更大型的模型。</p><p>2024&#x2F;1&#x2F;1 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
      <tag>LlaMA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博弈论：纳什均衡</title>
    <link href="/2023/12/31/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1/"/>
    <url>/2023/12/31/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1/</url>
    
    <content type="html"><![CDATA[<p>著名的纳什均衡(Nash equilibrium)由美国数学家John Forbes Nash Jr.于1950年发表。在一个博弈过程中，无论对方的策略选择如何，当事人一方都会选择某个确定的策略，则该策略被称作支配性策略。</p><p>如果两个博弈的当事人的策略组合分别构成各自的支配性策略，那么这个组合就被定义为纳什均衡。一个策略组合被称为纳什均衡，当每个博弈者的均衡策略都是为了达到自己期望收益的最大值，与此同时，其他所有博弈者也遵循这样的策略。</p><p>用一个大白话来说，就是在一场博弈中，每个玩家都不愿意主动更改自己的策略。</p><h1 id="纳什均衡实验：猜数字游戏"><a href="#纳什均衡实验：猜数字游戏" class="headerlink" title="纳什均衡实验：猜数字游戏"></a>纳什均衡实验：猜数字游戏</h1><p>斯坦福的公开课上举了一个例子来说明纳什均衡。猜数字游戏要求每个人从1-100中选择一个整数，最后从最接近平均值三分之二的人中随机选一个获得奖励，假设参加这项游戏的人数足够多。</p><p>在这种情况下，纳什均衡会是多少呢？由于获胜者要求是接近平均值的三分之二，如果我们假设大家的选择都是均匀分布，那均值应该是$50$，最终最可能获胜的数字应该是$50\times \frac{2}{3} &#x3D;33$</p><p>而如果获胜数字最有可能是$33$，那最有可能获胜的数字应该是$30\times \frac{2}{3} &#x3D;22$</p><p>再往下，最有可能获胜的数字应该是$22\times \frac{2}{3} &#x3D;11$</p><p>……</p><p>到了最后，假设大家都是理智的，纳什均衡的解将是0。这时候最终获奖者将随机从0中选出。</p><p>这是一个美国的真实实验，最终结果中，2%的实验者选择了$66$、5 %选择了$50$、10 %选择了$33$、6 %选择了$22$、12 %选择了$0$或者$1$。但最后的获胜数字为$19$。这也说明了<strong>实际博弈中，不是所有玩家都是理性的</strong>。</p><h1 id="纳什均衡"><a href="#纳什均衡" class="headerlink" title="纳什均衡"></a>纳什均衡</h1><p>在之前提到的囚徒困境中，纳什均衡点将是双方都招供，因为在未知对方选择的情况下，招供是己方的支配性策略(Strongly dominates)。所谓支配型策略，就是指一个策略在任何时刻的效用都最大。</p><p>相对的，如果一个策略在任何状态下的效用都不小于另一个策略，则被称为弱支配策略(Weakly dominates)。</p><p>如果一个决策支配其他所有决策，那么称之为占优策略。如果该决策严格压制每一个其他决策，那么称之为<strong>严格占优策略</strong>，并且该策略唯一。由占优策略组成的策略组合一定是纳什均衡点，全部由严格占优策略组成的策略组合一定是唯一的纳什均衡点。</p><h1 id="硬币正反游戏"><a href="#硬币正反游戏" class="headerlink" title="硬币正反游戏"></a>硬币正反游戏</h1><p>百度百科的纳什均衡条目下给出了一个游戏：</p><p>两个人玩一个硬币正反的游戏，规则是：双方各自亮出硬币的一面，或正或反。如果我们都是正面，则玩家A给玩家B$3$元，如果都是反面，玩家A给玩家B$1$元，剩下的情况玩家B给玩家A$2$元。现在问题是，这个游戏对A公平吗？</p><p>每一种游戏依具其规则的不同会存在两种纳什均衡，一种是纯策略纳什均衡，也就是说玩家都能够采取固定的策略(比如一直出正面或者一直出反面)，使得每人都赚得最多或亏得最少；或者是混合策略纳什均衡，而在这个游戏中，便应该采用混合策略纳什均衡。</p><p>可以构建一个收益矩阵：</p><table><thead><tr><th>玩家B&#x2F;玩家A</th><th>正面</th><th>反面</th></tr></thead><tbody><tr><td>正面</td><td>(3, -3)</td><td>(-2, 2)</td></tr><tr><td>反面</td><td>(2, -2)</td><td>(1, -1)</td></tr></tbody></table><p>假如A出正面的概率是X，反面概率是1-X，B出正面的概率是Y，反面是1-Y。为了利益最大化，应该使得B无论什么决策时的收益都相等（因为对手一旦改变决策的策略就会使得A的收益下降）。</p><p>A的期望收益可以列出方程如下：</p><p>$3y+(-2)\times (1-y)&#x3D;(-2)\times y+1\times (1-y)$</p><p>$y&#x3D;\frac{3}{8}$</p><p>B的期望收益则为：</p><p>$-3x+(-2)\times (1-x)&#x3D;(-2)\times x+(-1)\times (1-x)$</p><p>$x&#x3D;\frac{3}{8}$</p><p>对于B，每次博弈的期望收益是$2(1-x)-3x&#x3D;\frac{1}{8}$元。这意味着，双方每次都采取最优策略时，平均每次B的收益都是$\frac{1}{8}$元。那么，只要B采取$\frac{3}{8}$，$\frac{5}{8}$的混合策略，就会立于不败之地。</p><p>如果A全出正面，那么每次的期望收益是$\frac{3+3+3-2-2-2-2-2}{8}&#x3D;-\frac{1}{8}$元。</p><p>如果A全出反面，每次的期望收益也是$\frac{-2-2-2+1+1+1+1+1}{8}&#x3D;-\frac{1}{8}$元。</p><p>如果A用完全随机$(\frac{1}{2}，\frac{1}{2})$策略，收益是$\frac{1}{2}(\frac{3}{8} * 3 + \frac{5}{8} * (-20)) + \frac{1}{2}(\frac{3}{8}* (-2) + \frac{5}{8} * 1) &#x3D; -\frac{1}{8}$元。</p><hr><p>这个问题还有另一种思考方式：只要A的期望不为$0$，这个游戏就对他不公平。而他的期望收益可以列为：</p><p>$E(A)&#x3D;3p-2p-2(1-p)&#x3D;p+2p-2&#x3D;3p-2$</p><p>如果$E(A)&#x3D;0$，那么这是公平的。此时求得$p$为$\frac{2}{3}$，即如果A按照$\frac{2}{3}$的概率选择正面，那么游戏就对他公平。</p><p>而这个游戏的纳什均衡是A选择正面，B选择正面，或A选择反面，B也选择反面。</p><h1 id="如何挑选纳什均衡点？"><a href="#如何挑选纳什均衡点？" class="headerlink" title="如何挑选纳什均衡点？"></a>如何挑选纳什均衡点？</h1><p>从定义上来看，纳什均衡就是给定其他决策者的决策，每个决策者都没有单独改变决策的动机。（也就是当前决策是最优决策）</p><p>假设一共有A、B、C三个决策者，知A、B决策下C做出最优决策<code>C*</code>，已知A、C决策下B做出最优决策<code>B*</code>，已知B、C决策下A做出最优决策<code>C*</code>，则<code>(A*,B*,C*)</code>是一个纳什均衡点。</p><h2 id="如何从决策矩阵中挑选纳什均衡点？"><a href="#如何从决策矩阵中挑选纳什均衡点？" class="headerlink" title="如何从决策矩阵中挑选纳什均衡点？"></a>如何从决策矩阵中挑选纳什均衡点？</h2><p>看该单元格，是否左侧的值是该列左侧值的最大值，右侧的值是否是该行右侧值的最大值。</p><table><thead><tr><th>1&#x2F;2</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>C</td><td>-1,-1</td><td>-4,0</td></tr><tr><td>D</td><td>0,-4</td><td>-3,-3 &lt;–NE点</td></tr></tbody></table><table><thead><tr><th>1&#x2F;2</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>C</td><td>1，1 &lt;–NE点</td><td>0,0</td></tr><tr><td>D</td><td>0,0</td><td>1，1 &lt;–NE点</td></tr></tbody></table><table><thead><tr><th>1&#x2F;2</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>C</td><td>2，1 &lt;–NE点</td><td>0，0</td></tr><tr><td>D</td><td>0，0</td><td>2，1 &lt;–NE点</td></tr></tbody></table><p>也存在无纯策略纳什均衡的情况，例如：</p><table><thead><tr><th>1&#x2F;2</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>C</td><td>1,-1</td><td>-1,1</td></tr><tr><td>D</td><td>-1,1</td><td>1,-1</td></tr></tbody></table><p>注意：</p><ul><li>纳什均衡不一定是全局最优。比如囚徒困境。</li><li>纳什均衡也不是自发实现的，需要有一定的沟通协商规定，总之就是直接间接获取他人的决策信息。</li></ul><h1 id="帕累托最优"><a href="#帕累托最优" class="headerlink" title="帕累托最优"></a>帕累托最优</h1><p>前面提到的纳什均衡是个体寻找自身的最佳策略，而在整个博弈中，要找到一个对大家都最优的策略，这就是帕累托最优(Pareto Optimality)。</p><p>帕累托最优的核心思想是，给定一组多目标或多标准的评价指标，如果没有办法在不损害任何一个目标的前提下改善其他目标，那么我们就说该解决方案是帕累托最优的。它要解决的问题就是多目标优化问题。</p><p>简单来说，如果一个解决方案或策略在满足所有给定标准或目标的同时，无法进一步改进或优化，那么它就被认为是帕累托最优的。</p><p>也就是说，我们从全局出发，只要有一个全局的策略组合对于所有玩家的效用都高，那么它就是帕累托最优，同时它对于其他策略组合产生了帕累托支配的关系。例如，如果有 $( \mathrm{\large O}(7,8) ) $和$ ( \mathrm{\large O}^{\prime}(4,5) )$，则 $(\mathrm{O}) Pareto-dominates (\mathrm{O}^{\prime}).$</p><p>注意：</p><ul><li>一场游戏中可能有多个帕累托最优决策组合。</li><li>一场游戏中最少含有一个帕累托最优决策组合。</li></ul><p>2023&#x2F;12&#x2F;31 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>博弈论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博弈论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博弈论：利己主义者的游戏</title>
    <link href="/2023/12/31/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E5%88%A9%E5%B7%B1%E4%B8%BB%E4%B9%89%E8%80%85%E7%9A%84%E6%B8%B8%E6%88%8F/"/>
    <url>/2023/12/31/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E5%88%A9%E5%B7%B1%E4%B8%BB%E4%B9%89%E8%80%85%E7%9A%84%E6%B8%B8%E6%88%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="利己代理"><a href="#利己代理" class="headerlink" title="利己代理"></a>利己代理</h1><p>博弈论中有一个名词：Self-Interested Agents。字面意思就是利己代理。换句话说，博弈中的玩家的目的并非是只考虑自己，或者是伤害别人。Self-Interested更多意义是指决策者根据自己所得到的信息，依照自己的判断做出决策。</p><p>因此，为了量化这个性质，引出了效用理论(Utility Theory)，这个理论认为每个玩家都有自己的一个效用函数，这个函数决定了玩家的决策。而决策者的每个行为都为了最大化效用期望。</p><h1 id="经典造反问题"><a href="#经典造反问题" class="headerlink" title="经典造反问题"></a>经典造反问题</h1><p>之前提到可以用收益矩阵来衡量博弈论的问题，但是有些问题比较复杂，不好写成矩阵。例如造反问题：</p><p>共有$10000000$个人，每个人都可以选择是否造反，只有达到$2000000$个人才算造反成功。如果造反达到人数要求，无论决策者选择什么收益都是$1$；如果造反没有达到人数要求，则决策者选择造反的收益是$-1$；如果造反没有达到人数要求，则决策者选择不造反的收益是$0$。</p><p>这种情况下，可以如此定义：</p><p>玩家：$\text{Players:} : N &#x3D; {1,…,10,000,000} $</p><p>每个玩家i的决策集：$\text{Actions Set for player i:} : A_i &#x3D; { \text{Revolt, Not} } $</p><p>每个玩家的效用函数：<br>(1) $u_i(a_i) &#x3D; 1 : \text{if} : j : a_j &#x3D; \text{Revolt} \geqslant 2,000,000 $<br>(2) $u_i(a_i) &#x3D; -1 : \text{if} : j : a_j &#x3D; \text{Revolt} &lt; 2,000,000 : \text{and} : a_i &#x3D; \text{Revolt} $<br>(3) $u_i(a_i) &#x3D; -0 : \text{if} : j : a_j &#x3D; \text{Revolt} &lt; 2,000,000 : \text{and} : a_i &#x3D; \text{Not}$</p><h1 id="零和博弈"><a href="#零和博弈" class="headerlink" title="零和博弈"></a>零和博弈</h1><p>什么是零和博弈？两个人对局，必有一个人赢，一个人输。如果我们把获胜看作$1$分，失败看作$-1$，那么每一局的总分永远为$0$。换句话说，零和博弈中，不存在共赢的现象，总有一方是绝对赢家，另一方是输家。</p><div class="note note-success">            <p>定义：零和博弈（zero-sum game），又称零和游戏，与非零和博弈相对，是博弈论的一个概念，属<a href="https://baike.baidu.com/item/%E9%9D%9E%E5%90%88%E4%BD%9C%E5%8D%9A%E5%BC%88/4277540?fromModule=lemma_inlink">非合作博弈</a>。它是指参与<a href="https://baike.baidu.com/item/%E5%8D%9A%E5%BC%88/4669968?fromModule=lemma_inlink">博弈</a>的各方，在严格竞争下，一方的收益必然意味着另一方的<a href="https://baike.baidu.com/item/%E6%8D%9F%E5%A4%B1/10932540?fromModule=lemma_inlink">损失</a>，博弈各方的收益和损失相加总和永远为“零”，故双方不存在合作的可能。</p>          </div><p>一个零和博弈的例子：玩家1和2都有三个策略供选择，并且每种决策组合的总得分都是0。</p><table><thead><tr><th></th><th>A</th><th>B</th><th>C</th></tr></thead><tbody><tr><td>1</td><td>(30,-30)</td><td>(-10,10)</td><td>(20,-20)</td></tr><tr><td>2</td><td>(10,-10)</td><td>(20,-20)</td><td>(-20,20)</td></tr></tbody></table><p>现实生活中并不是所有博弈都是要拼个你死我活的，也就是说，共同的收益不是始终为0。囚徒困境就是一个典型的非零和博弈。</p><h1 id="囚徒困境"><a href="#囚徒困境" class="headerlink" title="囚徒困境"></a>囚徒困境</h1><p>著名的囚徒困境描述了一个非零和博弈的场景：</p><p>两个罪犯被关入监狱，不能互相沟通情况。</p><ol><li>如果两个人都不揭发对方，每个人都坐牢一年；</li><li>若一人揭发，而另一人沉默，则揭发者立即获释，沉默者则因不合作而入狱十年；</li><li>若互相揭发，则因证据确凿，二者都判刑八年。</li></ol><p>我们可以把这个场景画成一个收益矩阵：</p><table><thead><tr><th>罪犯2&#x2F;罪犯1</th><th>不合作</th><th>合作</th></tr></thead><tbody><tr><td>不合作</td><td>(1,1)</td><td>(-2,2)</td></tr><tr><td>合作</td><td>(2,-2)</td><td>(-1,-1)</td></tr></tbody></table><p>从全局来看，双方都不合作的收益最大。然而每个人的个人最优策略都是合作，因此他们会倾向于互相揭发，而不是同守沉默。</p><p>我们可以看一下为什么每个人的最佳策略都是合作。以罪犯1为例，当他选择合作时，不管罪犯2选择什么策略，合作带来的收益都要高于不合作（$2&gt;1$, $-1&gt;-2$），这样的选择被称为<strong>绝对占优策略</strong>。后面我们会知道，绝对占优策略并不是全局最佳策略，但是玩家往往会选择这种策略。</p><div class="note note-success">            <p>一个法国网红小哥根据这个题材拍了个[视频](<a href="https://www.youtube.com/watch?v=bXH4ldYHvCg&list=LL&index=279">如果您殺了人….哪一種朋友會幫你保守秘密到最後？ - YouTube</a>)，有兴趣的人可以去看一下。</p>          </div><div class="note note-danger">            <p>重要的前提：博弈论中的理论都基于玩家是理性的。这意味着他们会根据自己的效用函数进行决策。脱离这个前提就无法进行合理的推理。</p>          </div><h2 id="单次博弈和多次博弈"><a href="#单次博弈和多次博弈" class="headerlink" title="单次博弈和多次博弈"></a>单次博弈和多次博弈</h2><p>单次博弈和多次博弈的结果是不一样的。在囚徒困境案例中，由于是单次博弈，失败的玩家并没有重来的机会。而多次博弈中，玩家将有机会惩罚另一个玩家在上一回合的结果。这也是需要考虑的点。</p><h1 id="Robert-Axelrod的博弈论模拟实验"><a href="#Robert-Axelrod的博弈论模拟实验" class="headerlink" title="Robert Axelrod的博弈论模拟实验"></a>Robert Axelrod的博弈论模拟实验</h1><p>1980年，时任密歇根大学政治学教授Robert Axelrod举办了一场针对囚徒困境的计算机程序模拟大赛。他邀请了多个博弈论家设计一个计算机程序，然后让不同程序彼此多次的两两进行博弈。每个程序都会根据自己的策略和对手之前的行为来决定是否选择合作还是背叛。</p><p>提交的一些战略有以下几种：</p><ol><li>总是背叛：程序每回合都选择背叛，也是最安全的策略，但失去了合作的机会。</li><li>总是合作：该策略遇到合作的程序时，效果非常好，然而遇到背叛时，这个策略会带来糟糕的结果。</li><li>随机：程序以50%的概率合作。</li></ol><p>最终获胜的程序是一报还一报(TIT FOR TAT)，由多伦多大学的数学教授Anatol Rapoport提交。这个策略是在第一次选择合作，随后根据之前的对局选择是否合作。如果上一局对方选择背叛，下一局程序也选择背叛作为惩罚，反之则合作。</p><h2 id="第二次实验：静态群体"><a href="#第二次实验：静态群体" class="headerlink" title="第二次实验：静态群体"></a>第二次实验：静态群体</h2><p>这个实验之后又举办了第二次。第二次有63个程序参加了实验，最终前15名中，只有1个程序是<strong>不善良</strong>的，其余的程序都具备<strong>善良</strong>，<strong>被激怒性</strong>，<strong>宽容性</strong>。冠军策略是之前TIT FOR TAT策略的一种变体，程序在遇到对手背叛时会连续两次背叛进行惩罚。而当遇到合作的程序时，它将一直保持合作。 </p><ul><li>善良性：从来不主动背叛对手。</li><li>被激怒性：对于对手的背叛会加以惩罚。</li><li>宽容性：对于一次背叛，不会无休止的惩罚。</li></ul><h2 id="第三次实验：动态群体"><a href="#第三次实验：动态群体" class="headerlink" title="第三次实验：动态群体"></a>第三次实验：动态群体</h2><p>第二次实验后，又进行了第三次实验，这次加入了进化的规则，程序会逐渐学习并进化。每一轮实验中，得分最高的程序会在第二轮实验中拥有更高的占比。</p><p>实验结果中，TIT FOR TAT策略的程序的占比从最开始的$\frac{1}{63}$，进化1000代后，占比上升到总体的24%。前15的程序中，唯一不善良的程序的策略是，先合作，如果对手一直合作，就突然背叛一次。等对手开始报复时，它又开始合作。等对手继续合作时，再一次背叛。</p><div class="note note-success">            <p>总得分最高不一定需要每次博弈都要最高分。</p>          </div><p>2023&#x2F;12&#x2F;31 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>博弈论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博弈论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>写在2023的最后一天</title>
    <link href="/2023/12/31/%E5%86%99%E5%9C%A82023%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%A4%A9/"/>
    <url>/2023/12/31/%E5%86%99%E5%9C%A82023%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%A4%A9/</url>
    
    <content type="html"><![CDATA[<p>今天是2023年的最后一天，也可以称得上是我过去十年里最重要，足以改变我人生轨迹的一年。因此回顾一下过去，展望一下未来。</p><p>22年的一整年，我都处于非常糟糕的状态。焦虑，茫然，还有对未来的恐惧，这些情绪时常笼罩着我。22年的2月18日，我完成了第一个硕士的答辩，尽管出了一些小状况，但是算是顺利毕业。</p><p>毕业后的那个暑假，我开始四处找事情做。毕业之前，我在朋友的剧本杀店里兼职当DM，主要带一些恐怖和推理的本子。这个兼职让我认识了不少新来的留学生和华裔，不过很大程度上这只是一个排解压力的工作。</p><p><img src="/images/20231231104633.jpg" alt="短暂的DM生涯"></p><p>毕业之后，我进了一家西班牙华人圈比较有名的一个外卖平台当运营实习生。这份工作的薪水可以说是相当微薄，并且日常工作并没有什么特别有价值的东西。但是好在在里面认识了两个同事朋友，这算得上是这份工作最大的收获。</p><p><img src="/images/20231231104840.jpg"></p><p>和我同住多年的就读于UCM社会学的室友也于2月和我一起毕业，他选择了回国就业。彼时由于疫情复发，机票价格又回升到非常离谱的价格，因此我再三考虑，还是决定留下。三月，我和另外两个室友搬出了共住数年的大公寓，移步至附近一个特别狭小的房子。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/20231231104750.jpg" alt="2月的搬家"></div><div class="group-image-wrap"><img src="/images/20231231104856.jpg" alt="告别室友"></div></div></div><p>在一硕毕业时，我已经从各方面了解我当时这个专业的就业情况，由于信息学和图情专业在国内就业情况非常不尽如人意，我决定向数据分析师发展。那个暑假里，我在UCM的暑期班里完成Python数据分析课，这算是走上数据之路的第一个脚步。</p><p>当时我的一个室友也是刚刚从一硕毕业，他的专业是计算机科学，并且决定再申请一个Data Science的二硕。在他的影响下，我没事也会看一下DS相关的背景知识。</p><p>22年4月的时候，我和认识很久，但彼时不是很熟的朋友芳芳一起结伴去爬了马德里周边的雪山。同月，我们完成了朝圣之路。这是我多年来第一次融入西班牙文化的徒步。我在青年旅馆里听着其他朝圣者高声唱歌，在床板上留下了纪念：一路顺风。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/20231231105008.jpg" alt="朝圣之路"></div><div class="group-image-wrap"><img src="/images/20231231105107.jpg" alt="随手涂鸦要批评！"></div></div></div><p>这场旅途中，我和芳芳相互都有好感，因此朝圣结束后我们很快就确定了关系，这对我的影响非常大。回来以后，我开始考虑继续留下来的可能。正好室友在申请二硕，于是我也开始申请第二个硕士。</p><p><img src="/images/20231231105130.jpg" alt="哈哈哈哈哈"></p><p>我最开始的选择专业是金融和商业分析方向，数据挖掘和数据科学并不是我的首选。不过随着慢慢了解，尤其是金融行业对于各方面背景的限制，我最终还是放弃了金融系的offer，选择了大数据与数据科学硕士。</p><p>在申请上了硕士之后，距离开学还有近半年，我于是跟着室友一起，陆陆续续刷了一些网课。这之中，我刷完了宋浩老师的高数&#x2F;概率论&#x2F;线性代数，Coursera的机器学习&#x2F;深度学习，IBM的数据工程。虽然学的比较浅薄，但是也算是补了基础知识。</p><p>在这过程中，我从外卖平台离职，全职入职了一家电商公司做数据分析和市场营销，还和芳芳一起去了巴塞罗那，加那利群岛。工作几个月以后，我于9月开始就读第二个硕士。这个硕士里，我有几门课的分数都不错，比如数据库可视化，机器学习，深度学习都拿到了sobresaliente.</p><p>过去的数年本硕生涯里，我都和当地同学交流不多，仅限于打招呼和一些课堂上的沟通。不过这次硕士，我换了个心态，开始努力和他们沟通，并且常常在whatsapp群里分享一些编程知识，这让我受益匪浅。我认识很多朋友，比如Santiago Montiel, Maria Camberos, Alfredo Sepulveda, Ignacio Michavila等等。</p><p>2022年的10月，我在网上搜到一个美国印第安纳大学的大学生机器学习竞赛。抱着试一试的心态，我报名参加了。这个竞赛要求使用机器学习模型对文本进行检测，判断其中是否有违禁信息的存在。这个比赛在2023年的2月正式开始，我的三个队友都来自美国，除了一个女生以外，其他两个都有机器学习背景。</p><p>此前我没有任何的竞赛经历，对于怎么做也是完全一窍不通，好在我的队友非常给力，一个印度裔的女生承担了主要的Coding部分，另一个男生承担了建模的部分，而我写了一些处理文本的函数。在他们的贡献下，我们的最终提交得到了First prize(一件纪念衬衫和价值120美元的Amazon代金券)。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/20231231105217.png" alt="分享狂魔"></div><div class="group-image-wrap"><img src="/images/20231231105328.png" alt="一些交流的存档"></div></div></div><p><img src="/images/20231231105647.jpg" alt="最终的奖状"></p><p>这对我产生了非常大的激励，4月份，我和关系比较好的几个同学以及室友，组了一支队伍参加宜家在西班牙举办的DataFest Spain 2023。我作为队长，给队伍取名为Team Turing。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/20231231105759_1.jpg" alt="Team Turing"></div><div class="group-image-wrap"><img src="/images/20231231105759.jpg" alt="自由的工作环境"></div></div></div><p>比赛的场地在宜家本地的办公楼，这是我第一次近距离接触到国际大企业，他们的工作环境非常让我向往。比赛三天里，我们可以像员工一样，在任何地方写代码，咖啡，水果和零食都可以随意拿。</p><p>这次比赛又是很幸运，我们在第一天参加比赛的时候，主办方问我们是否愿意再加一个找不到队伍的成员。后来，这位就读于马德里理工大学数学与计算机双学位的同学Francisco Javier扛起了队伍的大梁，他的编程功底和逻辑思维能力非常强，在一晚上就能迭代了几十个模型。</p><p>这次的课题是时序分析，我和我的同学尝试了Arima模型，我的室友尝试了RNN网络，而Javier则始终在尝试XGBoost。他手工构建了十几个特征，最终在排行榜上名列前茅。</p><p>比赛持续了三天，主办方在第三天揭晓各个奖项的得主。当主持人说到：Best Prediciton Team的时候，我忽然有种奇怪的预感。当他发出T这个音的时候，我已经站起来了。最终，Team Turing拿到了最佳预测团队的奖项，这也是我们认为最有价值的奖项。</p><p>现场的氛围非常好，大家都是全西班牙各地的STEM大学生。在三天的比赛里，各种参赛者建立非常好的关系，不同组之间也会分享各自的分析见解。从台下走到台上的路上，我见到的所有人都在笑着对我们说Enhorabuena。他们之中的很多人，后来都陆陆续续成为了Linkedin上的点赞之交。</p><p><img src="/images/20231231105758.jpg" alt="比赛最后一日的合照"></p><p>由于这场比赛在Kaggle平台提交代码，比赛之后，我开始接触Kaggle。这是一个有名的数据科学社区，里面会定期举行竞赛。很多行业大牛都在这里拿到了Grandmaster，这是Kaggle中最高的头衔。</p><p>我在里面提交的第一篇Notebook就获得了几个点赞和评论。尽管其中不少都是求互赞的评论，但我视作是对我的认可，之后就开始坚持在上面传代码。后来回过头看，才发现当时写的代码实在是非常糟糕，不规范且毫无章法。</p><p>Kaggle社区每两周都会举行一个Playground比赛，主要是一些机器学习任务，包括时序分析，分类，回归任务。我从6月开始就没有拉下一场比赛，基本都能拿到前10%的成绩。Kaggle社区有很多非常友好的成员，其中很多人工作已久，代码更加规范，思路更加清晰，并且热衷于分享自己的想法。此外，他们对新人非常友好，时常会给予鼓励。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/20231231112938.png" alt="一些点赞"></div><div class="group-image-wrap"><img src="/images/20231231110244.jpg" alt="短暂的一个金牌，只享受了一天"></div></div></div><p>这之中，我最印象深刻的是两个人：一个是Oscar Augilar，他是Grand View University的分析学助教，目前在Notebook排名38&#x2F;320,091。另一个是Ravi Ramakrishan，他在阿联酋迪拜国际银行担任数据科学经理，目前Notebook排名7&#x2F;320,091，Discussion排名2&#x2F;377,099。</p><p>Oscar的代码可读性非常强，并且由于他的分析学背景，对于数据的分析非常合理且全面。Ravi则更喜欢把代码封装成函数，每次都看的我非常费劲。不过他非常乐于回答问题，每天都能在每个评论区碰到他。我从他们身上学到了非常多的东西。后来我于2023年12月拿到了Notebook的Master头衔，他们两个也都向我表达了祝贺。</p><p>6月份，我完成了硕士答辩，由于各种家事，我开始准备回国的事宜。在这过程中，我又去参加了几次活动，一次是马德里Innovation Lab举办的人工智能夏令营，一次是开发Yolo V5&#x2F;V8的Ultralystic公司在马德里举办的分享会，以及还有一次深圳政府举办的创新创业大赛。这几次活动我都认识了许多新的朋友。</p><p><img src="/images/20231231105757.jpg" alt="夏令营认识的新朋友"></p><p>回国前，我也和芳芳度过了最后一段充实的时光。我们去听了演唱会，去爬了山（尽管差点在山上回不来），还去游了泳。9月29 号，我告别了过去9年认识的朋友，坐上了回国的飞机。</p><p>回国以后，出于对就业的焦虑，我没有花很多时间投简历。国庆刚结束，我就很快入职了一家工业软件公司，担当算法开发工程师。实际工作中，很多东西都是临时需要用，才开始接触。比如Langchain和Autogen，在工作前我都没有系统接触过。当然这也是好事，重新接触这些代码，让我对项目代码产生了更深的理解，原先编程中不理解的点，都在实际应用中得到了解答。</p><p>2023年的12月27日，我写下了第一篇博客，打算记录自己的学习，工作和生活。回顾过去两年，当时的我非常迷茫，而二硕的选择彻彻底底改变了我的人生轨迹。</p><p>2023年的12月31日，是这忙忙碌碌一年的最后一天，我依旧迷茫。但是迷茫并不是坏事，迷茫而不自知才是。我想这是我过去一年的最大收获。</p><p>2023&#x2F;12&#x2F;31 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博弈论：基本概念</title>
    <link href="/2023/12/30/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    <url>/2023/12/30/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<p>博弈论是我从22年底就在断断续续看的东西，这个部分的内容是我根据斯坦福博弈论公开课，冯诺依曼的博弈论以及一些网络资源的理解得到的结论，因此理解上可能有所偏差。</p><hr><p>今天早上打2v2斗地主的时候，碰到对面两个人均70万豆的土豪（原谅我们没见过世面，账户上的豆从来没超过十万:P），刚好这一局我们炸弹不少，等到最后双方只有几十张牌的时候，倍数已经叠到好几万了。这时候，记牌器显示对面还有8张10，而我们一个人手上有一个6张的2的炸弹，另一个人手上有2张2。</p><p>这时我们面临一个选择，这8张10是在一个人手上，还是每个人各4张？如果是前者，那我们如果选择炸掉，那输的时候，倍数就会翻倍，而如果是后者，那我们就稳赢了。基于他们是大土豪，他们是不是有很大的概率前面一直不出炸弹，而是留到最后？从他们的角度，我们俩个加起来才1万6的豆子，即使输，收益也不会输很多，因此会不会想着放我们走？</p><p>最后我们飞快打出炸弹，赢下了这一局，爽吃1万6的豆。这个过程无疑与博弈论息息相关。</p><p><img src="https://img.gmz88.com:4433/uploadimg/image/20190305/15517632955c7e075fa8d193.45589369.gif"></p><h1 id="博弈的定义"><a href="#博弈的定义" class="headerlink" title="博弈的定义"></a>博弈的定义</h1><p>根据定义，博弈是在一定的规则下，各个参与者根据掌握的信息，决定自己的行动策略，以实现利益最大化或是风险最小化。</p><p>博弈论起源于运筹学和经济学，更像是数学和社会科学的结合体，因此社会&#x2F;经济中的很多现象都可以用博弈论进行解释。此外生物学中也会用博弈论来预测生物的进化。</p><h2 id="博弈四要素"><a href="#博弈四要素" class="headerlink" title="博弈四要素"></a>博弈四要素</h2><p>参与者&#x2F;玩家(Player)：博弈中的每个参与者被称为玩家，每个玩家都有自己的目标和策略。</p><p>策略(Strategies)：策略即玩家可以采取的行动。<br>支付(Payoffs)：支付是玩家在策略组合中的收益和损失。<br>信息(Infomation)：信息是玩家进行决策时获得的信息。</p><h2 id="博弈的分类"><a href="#博弈的分类" class="headerlink" title="博弈的分类"></a>博弈的分类</h2><p><img src="/images/game_theory.jpg" alt="博弈的基本分类"></p><p>博弈的分类主要可以从三个维度来看，分别是是否合作，行动顺序，玩家的信息水平：</p><ul><li>合作博弈：玩家之间是否有一个具有约束力的协议&#x2F;规则。</li><li>行动顺序：玩家的决策是否有时间顺序。</li><li>信息水平：玩家对于其他玩家的了解程度。</li></ul><table><thead><tr><th>信息&#x2F;行动顺序</th><th>静态（玩家同时行动&#x2F;彼此不知道行动）</th><th>动态（玩家行动由先后顺序）</th></tr></thead><tbody><tr><td>完全信息</td><td>完全信息静态博弈（纳什均衡）</td><td>完全信息动态博弈（子博弈完美纳什均衡）</td></tr><tr><td>不完全信息</td><td>不完全信息静态博弈（贝叶斯纳什均衡）</td><td>不完全信息动态博弈（完美贝叶斯纳什均衡）</td></tr></tbody></table><h1 id="博弈的数学定义"><a href="#博弈的数学定义" class="headerlink" title="博弈的数学定义"></a>博弈的数学定义</h1><p>博弈可以被抽象为范式，比较典型的有以下几个：</p><ol><li><p>博弈的玩家集可以表示为 $N&#x3D;{1,2,…,n}$</p></li><li><p>每个玩家的策略集表示为 $S_{i},\forall i\in N$</p></li><li><p>每个玩家的支付集表示为 $R_{i},\forall i\in N$</p></li></ol><p>因此，一个静态博弈可以表示为 $\left.v&#x3D;\langle N,{S_{i}},{R_{i}}\right\rangle$</p><p>此外，还有一种定义：<br>设定${N}$是玩家的集合，每个玩家$i\in\mathbb{N};$都有一个策略集合：<br>$\pi : \prod_{i \in \mathbb{N}} i \to \mathbb{R}^{\mathbb{N}}$</p><p>也就是说，只要知道玩家的策略集合，就可以找到一个对应的实数。</p><h1 id="TCP-Backoff游戏和收益矩阵"><a href="#TCP-Backoff游戏和收益矩阵" class="headerlink" title="TCP Backoff游戏和收益矩阵"></a>TCP Backoff游戏和收益矩阵</h1><p>斯坦福大学的博弈论课程中以一个TCP backoff机制作为引子介绍了博弈论。</p><p>这是计算机网络中的退避协议，用来处理网络拥堵时的流量分配。两台电脑之间想要实现通信，可以选择建立回退机制以及不建立回退机制。如果AB双方均建立回退机制，则双方延迟都是1。如果A、B一方建立回退机制，另一方不建立，那么建立的一方延迟是4，不建立的一方延迟是0。如果双方都不建立回退机制，则双方延迟都是3。</p><p>根据这种规则，可以构建一个矩阵如下：</p><table><thead><tr><th>B &#x2F; A</th><th>Y</th><th>N</th></tr></thead><tbody><tr><td>Y</td><td>(-1,-1)</td><td>(-4,0)</td></tr><tr><td>N</td><td>(0,-4)</td><td>(-3,3)</td></tr></tbody></table><p>上面这个矩阵被称为收益矩阵，在博弈论中起到了重要的作用。A&#x2F;B的不同选择带来的收益，将由一个实数进行表示。</p><hr><p>今天先写到这，下次再继续写。</p><p>2023&#x2F;12&#x2F;30 于苏州</p>]]></content>
    
    
    <categories>
      
      <category>博弈论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博弈论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python开发：Argparse/配置环境变量</title>
    <link href="/2023/12/30/Python%E5%BC%80%E5%8F%91%EF%BC%9AArgparse-%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"/>
    <url>/2023/12/30/Python%E5%BC%80%E5%8F%91%EF%BC%9AArgparse-%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url>
    
    <content type="html"><![CDATA[<p>在训练模型&#x2F;项目开发的时候，经常会遇到需要为程序赋值参数的场景。Python中的Argparse库就提供了这个功能。</p><h1 id="Argparse用法"><a href="#Argparse用法" class="headerlink" title="Argparse用法"></a>Argparse用法</h1><p>我们先定义一个类，它包含一个run函数，需要在运行时输入一些参数，因此需要去这些参数进行解析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse<br><br><span class="hljs-comment"># 定义一个类和对应的函数，这里我简单写一下</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PredictService</span>:<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br><span class="hljs-keyword">pass</span><br><span class="hljs-meta">@staticmethod</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">question: <span class="hljs-built_in">str</span>,clear_data: <span class="hljs-built_in">bool</span>,load_from_db: <span class="hljs-built_in">bool</span></span>):<br><span class="hljs-keyword">if</span> clear_data <span class="hljs-keyword">and</span> load_from_db:<br>some_function(question)<br><span class="hljs-keyword">return</span> <br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><span class="hljs-comment"># 实例化参数解析器</span><br>    parser = argparse.ArgumentParser(description=<span class="hljs-string">&#x27;Predict using the PredictService&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--question&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;The question for prediction&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--load_from_db&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Load data from the database&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--clear_data&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Clear data&#x27;</span>)<br><br>args = parser.parse_args()<br><br><span class="hljs-comment"># 使用解析得到的参数</span><br>predict_service_instance = PredictService()<br><br><span class="hljs-comment"># 解析后，args会成为一个字典</span><br>sample_question = args.question <br><br>predict_service_instance.run(<br>    question=args.question,<br>    load_from_db=args.load_from_db,<br>    clear_data=args.clear_data,<br>)<br></code></pre></td></tr></table></figure><p>实际运行时，需要在命令行运行代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python your_script.py --question <span class="hljs-string">&quot;What is the relationship between transformer models and computer vision?&quot;</span> --load_from_db --clear_data <br></code></pre></td></tr></table></figure><p>这样就大功告成了！</p><h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><p>有时候，出于安全，通常会将密钥&#x2F;API存放在本地的环境变量文件里，这样在推送代码时，不会将隐私信息推送上去。同时，在运行代码时，需要对环境变量进行解析。</p><h2 id="通过-env文件加载环境变量："><a href="#通过-env文件加载环境变量：" class="headerlink" title="通过.env文件加载环境变量："></a>通过.env文件加载环境变量：</h2><p>通过运行以下命令，能够获取本地的.env文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> load_dotenv<br>load_dotenv()<br></code></pre></td></tr></table></figure><h2 id="编写-env文件"><a href="#编写-env文件" class="headerlink" title="编写.env文件"></a>编写.env文件</h2><p>编写环境变量文件也不复杂，直接在文件里赋值即可：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">QUESTION</span>=What is the relationship between transformer models and computer vision?<br><span class="hljs-attr">LOAD_FROM_DB</span>=<span class="hljs-literal">True</span><br><span class="hljs-attr">CLEAR_DATA</span>=<span class="hljs-literal">True</span><br><span class="hljs-attr">API</span>=XXXXXXXXX<br></code></pre></td></tr></table></figure><h2 id="使用-os-environ-获取环境变量"><a href="#使用-os-environ-获取环境变量" class="headerlink" title="使用 os.environ 获取环境变量"></a>使用 os.environ 获取环境变量</h2><p>加载环境变量后，就需要去获取变量。这时候可以把变量看作一个字典，使用get就可以提取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 优先使用命令行参数，如果没有则使用环境变量</span><br>question = os.environ.get(<span class="hljs-string">&#x27;QUESTION&#x27;</span>, args.question)  <br>load_from_db = os.environ.get(<span class="hljs-string">&#x27;LOAD_FROM_DB&#x27;</span>, <span class="hljs-string">&#x27;False&#x27;</span>).lower() == <span class="hljs-string">&#x27;true&#x27;</span><br>clear_data = os.environ.get(<span class="hljs-string">&#x27;CLEAR_DATA&#x27;</span>, <span class="hljs-string">&#x27;False&#x27;</span>).lower() == <span class="hljs-string">&#x27;true&#x27;</span><br>txt = os.environ.get(<span class="hljs-string">&#x27;TXT&#x27;</span>, args.txt)<br></code></pre></td></tr></table></figure><p>这样就可以直接使用刚刚获取的环境变量值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">predict_service_instance = PredictService()<br><br>predict_service_instance.run(<br>    question=question,<br>    load_from_db=load_from_db,<br>    clear_data=clear_data,<br>    txt=sample_text<br>)<br></code></pre></td></tr></table></figure><p>这时候在命令行运行脚本时，就不需要输入信息了，因为它直接解析了本地的环境文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python your_script.py <br></code></pre></td></tr></table></figure><h2 id="在命令行使用export导入环境变量："><a href="#在命令行使用export导入环境变量：" class="headerlink" title="在命令行使用export导入环境变量："></a>在命令行使用export导入环境变量：</h2><p>除了解析环境文件，还可以直接在命令行手动导入环境变量，缺点是关了以后就需要重新输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> QUESTION=<span class="hljs-string">&quot;What is the relationship between transformer models and computer vision?&quot;</span><br><span class="hljs-built_in">export</span> LOAD_FROM_DB=True<br><span class="hljs-built_in">export</span> CLEAR_DATA=True<br><br>python your_script.py<br></code></pre></td></tr></table></figure><p>2023&#x2F;12&#x2F;30 于昆山</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>详解Mixtral 8*7B: 高质量的专家组合模型</title>
    <link href="/2023/12/30/%E8%AF%A6%E8%A7%A3Mixtral-8-7B-%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84%E4%B8%93%E5%AE%B6%E7%BB%84%E5%90%88%E6%A8%A1%E5%9E%8B/"/>
    <url>/2023/12/30/%E8%AF%A6%E8%A7%A3Mixtral-8-7B-%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84%E4%B8%93%E5%AE%B6%E7%BB%84%E5%90%88%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p>2023年12月8日，来自欧洲的团队Mistral AI团队发布了他们的新开源模型：Mixtral 8x7B。他们发布的方式也是别具一格，直接甩出一条87G文件的磁力链接。<br><img src="/images/8f8012cfb2c44e55aa4e0e1cc0894864.png"></p><p>值得一提的是，这家位于巴黎的公司上一次发布的Mistral 7B模型，也是直接发的磁力链接，并且把LLama2 13B作为基准碾压了一遍。</p><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><p>Mixtral采用了SMoE(稀疏混合专家模型)架构，把原来的前馈层改成了一个路由网络，用来给8个并行的子层进行分配Token。这里的子层就被称为专家。由于运行时不是所有参数都会进行推理，因此这个架构被称为稀疏架构，这也是名字中S(Sparse)的由来。</p><p><img src="/images/image2_17.png"></p><p>Mixtral共拥有8个专家，每个专家参数为7B。由于存在共享参数，模型的总参数为47B而非56B。</p><div class="note note-success">            <p>其实由上你也可以看出来，这个架构解决的主要还是推理速度，而非显存占用，因为47B参数在运行时依旧需要先加载进入显存。</p>          </div><p><img src="/images/123326.png" alt="模型具体架构"></p><h1 id="原文翻译"><a href="#原文翻译" class="headerlink" title="原文翻译"></a>原文翻译</h1><p>由于Mixtral 8x7B目前还没有发布论文，我们可以解读一下团队发布的博客。</p><hr><p>Mistral AI 继续履行着它创立以来的使命，为开发者社区提供最佳的开源模型。人工智能的发展需要采取新的技术转向，而不是重复使用众所周知的架构和训练范式。最重要的是，它应该让社区能从原始模型中受益，以促进新的发明和使用。</p><p>今天，我们自豪地发布了 Mixtral 8x7B，这是一个高质量稀疏专家混合模型 （SMoE），且权重已经开源 。该模型的许可证是Apache 2.0 。Mixtral 在大多数基准测试中的表现优于 Llama 2 70B，且<strong>推理速度提高了 6 倍</strong>。它是目前的最强开源模型，也是成本&#x2F;性能权衡方面整体上的最佳模型。重点是，它在大多数标准基准测试上都与 GPT3.5 相当或优于 GPT3.5。</p><p>Mixtral 具有以下特性：</p><ul><li>它能够处理 32k Token的上下文。</li><li>它能够处理英语、法语、意大利语、德语和西班牙语。</li><li>它在代码生成方面性能强大。</li><li>通过对它进行微调，转换为指令遵循(instruaction-following)模型，在 MT-Bench 上能达到 8.3 分。</li></ul><h2 id="走在推广稀疏架构的开源模型的前沿"><a href="#走在推广稀疏架构的开源模型的前沿" class="headerlink" title="走在推广稀疏架构的开源模型的前沿"></a>走在推广稀疏架构的开源模型的前沿</h2><p>Mixtral 是一个稀疏的专家混合网络(sMoE, sparse mixture-of-experts)。这是一种仅解码器(decoder-only)模型，其中前馈模块(Feed Forward，即全连接层)从一组 8 组不同的参数中进行选择。在每一层，对于每个Token，有一个路由(Router)网络都会选择其中8组参数中的两个组（也就是“专家”）来处理Token并将其的输出进行累加组合。</p><p>这种技术在增加了参数数量的情况下，控制了成本和延迟，因为模型只需要使用每个Token参数集中总数的一小部分。具体来说，Mixtral 有 46.7B 的总参数，但每个Token只使用 12.9B 参数。因此它的推理速度应当与 12.9B 模型相同。</p><p>Mixtral 使用从开放网络中提取的数据进行预训练——这一过程中将同时训练“专家”和“路由”。</p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>我们将 Mixtral 与 Llama 2 系列和 GPT3.5 基本型号进行了比较。在大多数基准测试中，Mixtral 都达到或优于 Llama 2 70B 和 GPT3.5。<br><img src="/images/110331.png"></p><p>在下图中，我们衡量了模型质量与推理预算的权衡。与 Llama 7 型号相比，Mistral 8B 和 Mixtral 8x7B 属于更高效的模型。</p><p><img src="/images/110418.png"></p><p>下表给出了上图的详细结果。</p><p><img src="/images/110546.png"></p><h2 id="模型幻觉和偏见"><a href="#模型幻觉和偏见" class="headerlink" title="模型幻觉和偏见"></a>模型幻觉和偏见</h2><p>为了识别可能通过微调&#x2F;偏好建模来纠正的缺陷，我们在BBQ&#x2F;BOLD上评估了基本模型的性能。</p><p><img src="/images/110639.png"></p><p>与 Llama 2 相比，Mixtral 在 BBQ 基准测试上的偏差较小。总体而言，Mixtral 在 BOLD 上表现出比 Llama 2 更积极的情绪，且每个维度的差异都较一致，不存在偏科的情况。</p><h2 id="语言"><a href="#语言" class="headerlink" title="语言"></a>语言</h2><p>Mixtral 8x7B 精通法语、德语、西班牙语、意大利语和英语。</p><p><img src="/images/110748.png"></p><h2 id="指导模型"><a href="#指导模型" class="headerlink" title="指导模型"></a>指导模型</h2><p>我们发布了 Mixtral 8x7B Instruct 和 Mixtral 8x7B。它们通过监督微调和直接偏好优化 （DPO） 进行了优化，以便仔细遵循人类给出的指令。在 MT-Bench 上，它的得分达到了 8.30，使其成为当前最好的开源模型，性能可与 GPT3.5 相媲美。</p><h2 id="使用开源部署堆栈部署-Mixtral"><a href="#使用开源部署堆栈部署-Mixtral" class="headerlink" title="使用开源部署堆栈部署 Mixtral"></a>使用开源部署堆栈部署 Mixtral</h2><p>为了使社区能够使用完全开源的堆栈运行 Mixtral，我们提交了对 vLLM 项目的更改，该项目集成了 Megablocks CUDA 内核以实现高效推理。</p><h1 id="关于Mistral-AI"><a href="#关于Mistral-AI" class="headerlink" title="关于Mistral AI"></a>关于Mistral AI</h1><p><img src="https://siliconcanals.com/wp-content/uploads/2023/12/Mistral-1140x570.jpg"><br>写博客的时候搜了一下这家公司。Mistral AI来自巴黎，团队成员大多来自于Google，Meta，HuggingFace。他们中的大部分都是从事AI行业多年的大佬。Mistral AI的上一个7B模型就已经获得了社区非常好的反响，基准测试中超过了LLama2 34B。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/images/120729.png"></div><div class="group-image-wrap"><img src="/images/120812.png"></div><div class="group-image-wrap"><img src="/images/120902.png"></div></div></div><p>在人工智能成为风口的当下，这家公司在六个月内就筹集了1.12亿美元的融资，且A轮融资已经筹集了3.85亿欧元，这也让Mistral AI的估值达到约20亿美元，自6月份首次亮相以来，其估值已增长超过七倍，成为欧洲最成功的大模型公司。</p><p>公司的核心创始人是Arthur Mensch(CEO), Timothée Lacroix(CTO)和Guillaume Lample（Chief Scientist)，CEO来自于Google DeepMind，后两者都来自于MetaAI，且均在LLama模型中做出了重大贡献。</p><h1 id="使用QLoRA对Mixtral模型微调"><a href="#使用QLoRA对Mixtral模型微调" class="headerlink" title="使用QLoRA对Mixtral模型微调"></a>使用QLoRA对Mixtral模型微调</h1><p>参考了一些示例代码，写了下微调的示例代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入库</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraConfig, PeftModel, prepare_model_for_kbit_training<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> (<br>    AutoModelForCausalLM,<br>    AutoTokenizer,<br>    BitsAndBytesConfig,<br>    AutoTokenizer,<br>    TrainingArguments<br>)<br><span class="hljs-keyword">from</span> trl <span class="hljs-keyword">import</span> SFTTrainer<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">model_name = <span class="hljs-string">&quot;mistralai/Mixtral-8x7B-v0.1&quot;</span><br><br><span class="hljs-comment"># 设置Tokenizer</span><br>tokenizer = AutoTokenizer.from_pretrained(model_name, add_eos_token=<span class="hljs-literal">True</span>, use_fast=<span class="hljs-literal">True</span>)<br>tokenizer.pad_token = tokenizer.unk_token<br>tokenizer.pad_token_id =  tokenizer.unk_token_id<br>tokenizer.padding_side = <span class="hljs-string">&#x27;left&#x27;</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 设置数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_ultrachat</span>(<span class="hljs-params">ds</span>):<br>  text = []<br>  <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> ds:<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(row[<span class="hljs-string">&#x27;messages&#x27;</span>]) &gt; <span class="hljs-number">2</span>:<br>      text.append(<span class="hljs-string">&quot;### Human: &quot;</span>+row[<span class="hljs-string">&#x27;messages&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;content&#x27;</span>]+<span class="hljs-string">&quot;### Assistant: &quot;</span>+row[<span class="hljs-string">&#x27;messages&#x27;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;content&#x27;</span>]+<span class="hljs-string">&quot;### Human: &quot;</span>+row[<span class="hljs-string">&#x27;messages&#x27;</span>][<span class="hljs-number">2</span>][<span class="hljs-string">&#x27;content&#x27;</span>]+<span class="hljs-string">&quot;### Assistant: &quot;</span>+row[<span class="hljs-string">&#x27;messages&#x27;</span>][<span class="hljs-number">3</span>][<span class="hljs-string">&#x27;content&#x27;</span>])<br>    <span class="hljs-keyword">else</span>: <span class="hljs-comment">#not all tialogues have more than one turn</span><br>      text.append(<span class="hljs-string">&quot;### Human: &quot;</span>+row[<span class="hljs-string">&#x27;messages&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;content&#x27;</span>]+<span class="hljs-string">&quot;### Assistant: &quot;</span>+row[<span class="hljs-string">&#x27;messages&#x27;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;content&#x27;</span>])<br>  ds = ds.add_column(name=<span class="hljs-string">&quot;text&quot;</span>, column=text)<br>  <span class="hljs-keyword">return</span> ds<br>dataset_train_sft = load_dataset(<span class="hljs-string">&quot;HuggingFaceH4/ultrachat_200k&quot;</span>, split=<span class="hljs-string">&quot;train_sft&quot;</span>)<br>dataset_test_sft = load_dataset(<span class="hljs-string">&quot;HuggingFaceH4/ultrachat_200k&quot;</span>, split=<span class="hljs-string">&quot;test_sft[:5%]&quot;</span>)<br><br>dataset_test_sft = format_ultrachat(dataset_test_sft)<br>dataset_train_sft = format_ultrachat(dataset_train_sft)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入模型和量化参数</span><br>compute_dtype = <span class="hljs-built_in">getattr</span>(torch, <span class="hljs-string">&quot;float16&quot;</span>)<br>bnb_config = BitsAndBytesConfig(<br>        load_in_4bit=<span class="hljs-literal">True</span>,<br>        bnb_4bit_quant_type=<span class="hljs-string">&quot;nf4&quot;</span>,<br>        bnb_4bit_compute_dtype=compute_dtype,<br>        bnb_4bit_use_double_quant=<span class="hljs-literal">True</span>,<br>)<br>model = AutoModelForCausalLM.from_pretrained(<br>          model_name, quantization_config=bnb_config, device_map=&#123;<span class="hljs-string">&quot;&quot;</span>: <span class="hljs-number">0</span>&#125;<br>)<br>model = prepare_model_for_kbit_training(model)<br><br><span class="hljs-comment">#Configure the pad token in the model</span><br>model.config.pad_token_id = tokenizer.pad_token_id<br>model.config.use_cache = <span class="hljs-literal">False</span> <span class="hljs-comment"># Gradient checkpointing is used by default but not compatible with caching</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">peft_config = LoraConfig(<br>        lora_alpha=<span class="hljs-number">64</span>,<br>        lora_dropout=<span class="hljs-number">0.1</span>,<br>        r=<span class="hljs-number">16</span>,<br>        bias=<span class="hljs-string">&quot;none&quot;</span>,<br>        task_type=<span class="hljs-string">&quot;CAUSAL_LM&quot;</span>,<br>        target_modules= [<span class="hljs-string">&#x27;k_proj&#x27;</span>, <span class="hljs-string">&#x27;q_proj&#x27;</span>, <span class="hljs-string">&#x27;v_proj&#x27;</span>, <span class="hljs-string">&#x27;o_proj&#x27;</span>]<br>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 设置训练参数</span><br>training_arguments = TrainingArguments(<br>        output_dir=<span class="hljs-string">&quot;./results_mixtral_sft/&quot;</span>,<br>        evaluation_strategy=<span class="hljs-string">&quot;steps&quot;</span>,<br>        do_eval=<span class="hljs-literal">True</span>,<br>        optim=<span class="hljs-string">&quot;paged_adamw_8bit&quot;</span>,<br>        per_device_train_batch_size=<span class="hljs-number">8</span>,<br>        gradient_accumulation_steps=<span class="hljs-number">2</span>,<br>        per_device_eval_batch_size=<span class="hljs-number">8</span>,<br>        log_level=<span class="hljs-string">&quot;debug&quot;</span>,<br>        save_steps=<span class="hljs-number">50</span>,<br>        logging_steps=<span class="hljs-number">50</span>,<br>        learning_rate=<span class="hljs-number">2e-5</span>,<br>        eval_steps=<span class="hljs-number">50</span>,<br>        max_steps=<span class="hljs-number">300</span>,<br>        warmup_steps=<span class="hljs-number">30</span>,<br>        lr_scheduler_type=<span class="hljs-string">&quot;linear&quot;</span>,<br>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 开始训练</span><br>trainer = SFTTrainer(<br>        model=model,<br>        train_dataset=dataset_train_sft,<br>        eval_dataset=dataset_test_sft,<br>        peft_config=peft_config,<br>        dataset_text_field=<span class="hljs-string">&quot;text&quot;</span>,<br>        max_seq_length=<span class="hljs-number">512</span>,<br>        tokenizer=tokenizer,<br>        args=training_arguments,<br>)<br><br>trainer.train()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型测试</span><br>text = <span class="hljs-string">&quot;Hello my name is&quot;</span><br>inputs = tokenizer(text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br><br>outputs = model.generate(**inputs, max_new_tokens=<span class="hljs-number">20</span>)<br><span class="hljs-built_in">print</span>(tokenizer.decode(outputs[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))<br><br><span class="hljs-comment"># 模型保存</span><br>new_model = <span class="hljs-string">&#x27;yang_zhou/mixtral&#x27;</span><br>trainer.model.save_pretrained(new_model)<br><br><span class="hljs-keyword">del</span> model, trainer<br>torch.cuda.empty_cache()<br><br><span class="hljs-comment"># 重新加载模型</span><br>model_reload = AutoModelForCausalLM.from_pretrained(<br>          model_name, quantization_config=bnb_config, device_map=&#123;<span class="hljs-string">&quot;&quot;</span>: <span class="hljs-number">0</span>&#125;<br>)<br>model = PeftModel.from_pretrained(model_reload, new_model)<br><br><span class="hljs-comment"># 合并模型</span><br>output_path = <span class="hljs-string">&#x27;yang_zhou/mixtral/ft_model&#x27;</span><br>model = model.merge_and_unload()<br>model.save_pretrained(output_path)<br></code></pre></td></tr></table></figure><p>2023&#x2F;12&#x2F;30 于昆山</p>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python开发：换源/更新Python包/虚拟环境</title>
    <link href="/2023/12/29/Python%E5%BC%80%E5%8F%91%EF%BC%9A%E6%8D%A2%E6%BA%90-%E6%9B%B4%E6%96%B0Python%E5%8C%85-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/"/>
    <url>/2023/12/29/Python%E5%BC%80%E5%8F%91%EF%BC%9A%E6%8D%A2%E6%BA%90-%E6%9B%B4%E6%96%B0Python%E5%8C%85-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/</url>
    
    <content type="html"><![CDATA[<h1 id="Python换源"><a href="#Python换源" class="headerlink" title="Python换源"></a>Python换源</h1><p>因为一些众所周知的原因，我回国以后打开VSCode的第一件事，就是火速更换Python的默认pip源。</p><ol><li><p>临时更换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install pandas -i http://pypi.douban.com/simple/<br></code></pre></td></tr></table></figure></li><li><p>永久更换：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip config <span class="hljs-built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple/<br></code></pre></td></tr></table></figure></li><li><p>目前在国内已经有一些比较稳定，且能够及时更新的镜像源，可选的地址有：</p></li></ol><ul><li>豆瓣：<a href="http://pypi.douban.com/simple/">http://pypi.douban.com/simple/</a></li><li>中科大：<a href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.mirrors.ustc.edu.cn/simple/</a></li><li>清华：<a href="https://pypi.tuna.tsinghua.edu.cn/simple/">https://pypi.tuna.tsinghua.edu.cn/simple/</a></li><li>阿里云：<a href="https://mirrors.aliyun.com/pypi/simple/">https://mirrors.aliyun.com/pypi/simple/</a></li></ul><p>通常阿里云和清华用的会多一点，不过清华源有时候会出现更新不及时的情况。</p><h1 id="更新Python包"><a href="#更新Python包" class="headerlink" title="更新Python包"></a>更新Python包</h1><p>想要更新本地已安装的Python包，可以使用以下命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 更新单个包</span><br>pip install --upgrade package_name<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 更新多个包</span><br>pip install --upgrade package1 package2 package3<br></code></pre></td></tr></table></figure><h1 id="虚拟环境"><a href="#虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境</h1><p>虚拟环境对于项目更迭速度极快的开发者来说应该不陌生。在读书的时候，老师经常向我们安利虚拟环境的重要性，当时我比较不以为然：都装在Base环境下，用的时候不用麻烦一直切换了，这不比切换虚拟环境来的方便吗？</p><p>不过，后来在GitHub上看了一些项目，有些老的项目依赖库也很老，更新到新版本反而会导致项目不可用。这时就体现虚拟环境的重要性了，每个项目一个环境，相互不冲突，这样无论是结构清晰度还是环境整洁度都要高很多。</p><p>构建Python虚拟环境的方式有不少，比如<code>Pipenv</code>,<code>Virtualenv</code>和 <code>Conda</code>。我自己用Conda多一些。</p><h2 id="使用Virtualenv构建虚拟环境"><a href="#使用Virtualenv构建虚拟环境" class="headerlink" title="使用Virtualenv构建虚拟环境"></a>使用Virtualenv构建虚拟环境</h2><ol><li><p>安装Virtualenv</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install virtualenv<br></code></pre></td></tr></table></figure></li><li><p>进入你的项目文件夹</p></li><li><p>输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python&lt;version&gt; -m venv &lt;virtual-environment-name&gt;<br></code></pre></td></tr></table></figure><p>例如想要生成一个python版本为3.12的虚拟环境，名字叫LLM_ENV</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -3.12 -m venv LLM_ENV<br></code></pre></td></tr></table></figure></li><li><p>激活虚拟环境：<br>要激活虚拟环境，你需要执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">.\LLM_ENV\Scripts\activate<br></code></pre></td></tr></table></figure><p>在Windows环境下，则需要在CMD中执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">.\LLM_ENV\Scripts\activate.bat<br></code></pre></td></tr></table></figure></li><li><p>停止环境:<br>要退出虚拟环境，直接执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">deactivate <br></code></pre></td></tr></table></figure></li></ol><h2 id="使用Conda构建虚拟环境"><a href="#使用Conda构建虚拟环境" class="headerlink" title="使用Conda构建虚拟环境"></a>使用Conda构建虚拟环境</h2><p>Conda是一个广泛被使用的跨平台包&#x2F;环境管理器，也是我最常用的工具。用它能够创建管理任何类型的包和依赖。简单来说，它是一个编程语言的Windows商店。比较有名的Anaconda和miniconda就在它的基础上构建。</p><p>要使用Conda构建虚拟环境，可以参照以下步骤：</p><ol><li><p>找到Anaconda Prompt&#x2F;Anaconda PowerShell Prompt</p></li><li><p>在命令行中输入以下指令，这会帮助你生成一个名为<code>env name</code>，python版本为3.12的虚拟环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create --name &lt;<span class="hljs-built_in">env</span> name&gt; python=3.12<br></code></pre></td></tr></table></figure></li><li><p>想要激活虚拟环境，则只需要在命令行中输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda activate &lt;<span class="hljs-built_in">env</span> name&gt;<br></code></pre></td></tr></table></figure></li><li><p>想要停止虚拟环境，则需要在命令行中输入：deactivate</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">deactivate<br></code></pre></td></tr></table></figure></li><li><p>删除虚拟环境，命令则如下：</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda remove -n &lt;env name&gt; --<span class="hljs-built_in">all</span><br></code></pre></td></tr></table></figure><p>2023&#x2F;12&#x2F;29 于公司</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>项目协同开发-Git基础操作</title>
    <link href="/2023/12/29/%E9%A1%B9%E7%9B%AE%E5%8D%8F%E5%90%8C%E5%BC%80%E5%8F%91-Git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"/>
    <url>/2023/12/29/%E9%A1%B9%E7%9B%AE%E5%8D%8F%E5%90%8C%E5%BC%80%E5%8F%91-Git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是Git"><a href="#什么是Git" class="headerlink" title="什么是Git"></a>什么是Git</h1><p>项目开发里必不可少的就是版本控制系统了，相信每个已经工作的码农都经常接触这个玩意。什么？你说你们都用百度网盘共享代码？你小子来买瓜的是吧。</p><p><img src="/images/003MWcpMly8gvklr96zbsg60hd0hdn2q02.gif"></p><p>Git是当今世界上使用最广泛的现代版本控制系统，由Linux之父-暴躁老哥Linus Torvalds 于 2005 年开发。作为一个分布式版本控制系统，开发者保存在本地的代码，本身就是一个完整的版本控制存储库。开发人员会在本地提交其工作，然后再将存储库的副本与服务器上的副本进行同步。</p><p>Git的起源也和Linux系统的发展息息相关。早在1991年，Linus开发出开源系统Linux后，全世界的开发者都向他发送了自己贡献的代码，Linus会对这些代码检查测试，在达到他的要求后将代码合并。在这种高频的代码版本更迭中，需要一个合适的版本控制工具。</p><p>最开始Lin叔使用了一个商业版本控制系统BitKeeper，但是由于一些纠纷，Lin叔没有继续使用它，而是花了十天的时间自己开发出了未来风靡世界的Git。<br><img src="/images/v2-7cb1639ab23aaf21dcdc5a8beda23296_ipico.jpg"></p><p>下面我们先来说一些Git的常用操作代码。</p><h1 id="Git用法："><a href="#Git用法：" class="headerlink" title="Git用法："></a>Git用法：</h1><h2 id="本地仓库管理"><a href="#本地仓库管理" class="headerlink" title="本地仓库管理"></a>本地仓库管理</h2><p>新手上门三板斧：<code>init</code>&#x2F;<code>add</code>&#x2F;<code>commit</code>自不用多说。</p><p><strong>本地初始化一个仓库，你将能够在本地进行版本控制操作，包括提交，分支，回退等：</strong><br><code>git init</code></p><p><strong>在修改了本地文件后，你可以将修改的内容添加到本地的暂存区：</strong><br><code>git add .</code><br><strong>确定了暂存区后，可以本地提交代码：</strong><br><code>git commit</code><br><code>git commit -m &#39;This is a commit message&#39; #附加提交信息</code></p><p><strong>本地切换已经建立好的分支，分支可以管理单个项目中不同的开发方向：</strong><br><code>git switch &lt;branch-name&gt;</code><br><strong>也可以通过加上<code>-c</code>，直接在本地建立新分支，并自动切换到该分支：</strong><br><code>git switch -c &lt;new-branch-name&gt;</code></p><p><strong>通过<code>-M</code> 可以为本地当前分支改名：</strong><br><code>git branch -M main</code></p><h2 id="远程仓库管理"><a href="#远程仓库管理" class="headerlink" title="远程仓库管理"></a>远程仓库管理</h2><p>下面这个是比较重要的：本地仓库连接到远程仓库。新建了远程仓库后，会产生一个地址。这时在你的本地仓库地址输入以下命令即可连接两个仓库：</p><p><strong>为本地仓库添加一个新的远程仓库并给它起一个别名为 origin：</strong><br><code>git remote add origin https://github.com/zerolovesea/Coding-Tips.git</code></p><p><strong>连接了仓库以后，就可以拉取&#x2F;提交&#x2F;推送代码了：</strong><br><code>git pull origin master</code><br><code>git push origin master</code></p><p><strong>设置SSH密钥以后，你可能想把仓库从http协议改为ssh协议。那么你可以更新远程仓库的URL，使用remote set-url命令进行操作：</strong><br><code>git remote set-url origin git@github.com:zerolovesea/Coding-Tips.git</code></p><p><strong>在推送代码时加上-u，可以将本地和远程仓库建立连接。</strong>这样未来就可以通过<code>git push</code>直接推送代码。下面这个示例中，working-pc是本地分支，origin是远程名称，-u代表建立联系：<br><code>git push -u origin working-pc</code></p><p><strong>而未建立联系的时候，在提交推送时就需要写上两边的仓库：</strong><br><code>git push origin working-pc</code></p><h3 id="远程仓库构建main分支的完整流程："><a href="#远程仓库构建main分支的完整流程：" class="headerlink" title="远程仓库构建main分支的完整流程："></a>远程仓库构建main分支的完整流程：</h3><ol><li>本地创建main：<br><code>git switch -c main</code></li><li>新分支推送到远程：<br><code>git push -u origin main</code></li></ol><h2 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h2><p><strong>如果想把本地分支转移关联至不同的远程分支，可以按照以下的步骤操作：</strong></p><ol><li>查看当前关联分支：<br><code>git branch -vv</code></li><li>解除当前关联（本地的main与远程的关联）：<br><code>git branch --unset-upstream main</code></li><li>关联至新的远程分支（本地main关联远程分支newbranch）：<br><code>git branch -u origin/your-newbranch main</code></li></ol><p><strong>同样，可以通过加上<code>-d</code>来删除本地分支：</strong><br><code>git branch -d branch_name</code></p><p><strong>总结一下，本地工作流的整体流程如下：</strong></p><ol><li>克隆仓库：<br><code>git clone</code></li><li>创建新分支：<br><code>git switch -c new_branch</code></li><li>本地提交工作：<br><code>git add. /git commit</code></li><li>推送新分支到远程仓库：<br><code>git push -u origin new_feature</code></li></ol><p><strong>远程的main分支合并两个远程分支：</strong></p><ol><li>切换到main:<br><code>git switch main</code></li><li>拉最新的main：<br><code>git pull origin main</code></li><li>合并两个远程分支到main：<br><code>git merge origin/branch1</code><br><code>git merge origin/branch2</code></li><li>在解决冲突后，将合并后的main推送：<br><code>git push origin main</code></li></ol><p><strong>有的时候，本地改了一大堆代码，发现坑越来越大，还不如直接放弃本地所有修改：</strong><br><code>git reset --hard</code><br><strong>放弃特定文件的修改：</strong><br><code>git checkout -- &lt;filename&gt;</code></p><h2 id="Git变基操作："><a href="#Git变基操作：" class="headerlink" title="Git变基操作："></a>Git变基操作：</h2><p>变基可以将多个提交合并成一个，依次放在最新提交后，从而减少了冗余的提交记录。这有助于保持项目历史的清晰和易读。</p><ol><li>更新仓库：<br><code>git pull origin your_branch_name</code></li><li>切换分支：<br><code>git checkout your_branch_name</code></li><li>将本地的分支变基到远程的main：<br><code>git rebase main</code></li><li>将本地更改推送到仓库：<br><code>git push origin your_branch_name --force</code></li></ol><p><strong>在本地分支编辑，推送时rebase合并到main：</strong></p><ol><li>切换到本地分支：<br><code>git switch branch_name</code></li><li>编辑文件</li><li>提交和commit</li><li>拉取main的最新更改：<br><code>git pull origin main</code></li><li>变基：<br><code>git rebase main</code></li><li>推送：<br><code>git push origin branch_name</code></li></ol><h1 id="服务器安装git-lfs："><a href="#服务器安装git-lfs：" class="headerlink" title="服务器安装git lfs："></a>服务器安装git lfs：</h1><p>最后顺带讲一下在服务器上下载大文件时需要的操作。使用curl指令下载git-lfs并进行安装：</p><p><code>curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash</code></p><p><code>sudo apt-get install git-lfs</code></p><p>有时候会出现Git clone GnuTLS recv error (-110)报错，只需要输入以下命令即可解决：</p><p><code>git config --global --unset http.https://github.com.proxy</code></p><p>2023&#x2F;12&#x2F;29 于昆山</p>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>项目协同开发-配置SSH</title>
    <link href="/2023/12/28/%E9%A1%B9%E7%9B%AE%E5%8D%8F%E5%90%8C%E5%BC%80%E5%8F%91-%E9%85%8D%E7%BD%AESSH/"/>
    <url>/2023/12/28/%E9%A1%B9%E7%9B%AE%E5%8D%8F%E5%90%8C%E5%BC%80%E5%8F%91-%E9%85%8D%E7%BD%AESSH/</url>
    
    <content type="html"><![CDATA[<p>如果你是GitHub&#x2F;Gitee的个人开发者用户，你一定用过Git clone。当然，你可能见过SSH clone，但不一定常用到。但如果你是一个算法工程师，或是已经参加一些大型项目，需要频繁登录远程服务器，那你一定曾为输入密码而苦恼——为了确保服务器的安全，每次登录服务器都需要手动输入密码。这时候，就需要SSH的帮助了。</p><p>漫漫开发长路，恭喜你，了解SSH，这是你从象牙塔走入实际开发的第一步。</p><h2 id="什么是SSH？"><a href="#什么是SSH？" class="headerlink" title="什么是SSH？"></a>什么是SSH？</h2><p>庞大的互联网如同一个黑暗森林，里面有无数虎视眈眈的坏人盯着你的服务器&#x2F;数据。为了保护自己的宝贵财产，你需要一个强大的安全机制，在防止外人随意进出你的服务器的同时，又能让你信任的人可以不那么费劲的进来。这个安全机制就是SSH(Secure Shell)。</p><p>SSH允许两台电脑之间通过安全连接进行数据交换，并通过加密来保证数据的保密性和完整性。它最常用的场景是远程登录和文件传输。现在你可能可以理解GitHub中提供的两种clone方式：Git clone是任何人都可以使用的克隆指令，但SSH clone只有项目拥有者才能使用，因为需要添加SSH Key。</p><h2 id="什么是SSH-Key？"><a href="#什么是SSH-Key？" class="headerlink" title="什么是SSH Key？"></a>什么是SSH Key？</h2><p>SSH通过公钥和私钥来进行加密。Github上，我们把公钥保存在服务器上，这样我们需要克隆文件的时候，文件会被公钥加密。当我们将代码拉到本地时，使用私钥进行解密。</p><p><img src="https://pic1.zhimg.com/80/v2-36ad882e79e96fc67fda66e3f613b878_720w.webp"></p><h2 id="使用SSH进行免密登录"><a href="#使用SSH进行免密登录" class="headerlink" title="使用SSH进行免密登录"></a>使用SSH进行免密登录</h2><p>前面提到SSH最常用在远程登录和文件传输，这也是算法工程师在远程服务器训练时必备的登录方式。通过密钥认证，就不需要每次手动输入密码。</p><p>它的原理是将客户端和服务器交换密钥，当发起登录请求时，双方动态生成一个会话的密钥和会话的ID，建立一个加密通道。远程服务器使用公钥加密一个随机数，发送至本地客户端。客户端使用自己的私钥进行解密后，再用保存的服务器的公钥加密后发回服务器。服务端接到信息后再用服务端私钥解密，如果解密的随机数与自己发送的随机数相同，则验证通过。</p><p>这个过程像是乒乓球一样你来我往。</p><p><img src="https://pic1.zhimg.com/80/v2-ad1496bf71ffa3b0cc28a8833a7c781c_720w.webp"></p><h2 id="在GitHub中配置SSH"><a href="#在GitHub中配置SSH" class="headerlink" title="在GitHub中配置SSH"></a>在GitHub中配置SSH</h2><p>要实现在GitHub中配置SSH，需要现在本地创建公钥-私钥对：</p><p>在命令行中输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa<br></code></pre></td></tr></table></figure><p>随后需要进行三次回车</p><p><img src="/images/2.png"></p><p>可以看到密钥被保存在&#x2F;.ssh&#x2F;路径下</p><p>我们输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> ~/.ssh/id_rsa.pub<br></code></pre></td></tr></table></figure><p>就可以查看rsa密钥，也就是公钥。接下来我们就可以复制这个密钥，将它添加到代码仓库中。OK，大功告成！</p><h2 id="使用VSCode配置SSH免密登录"><a href="#使用VSCode配置SSH免密登录" class="headerlink" title="使用VSCode配置SSH免密登录"></a>使用VSCode配置SSH免密登录</h2><ol><li><p>首先需要安装Remote-SSH插件</p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20210916200211959.png"></p></li><li><p>点击左下角绿色箭头&#x3D;&#x3D;&gt;Connect to Host&#x3D;&#x3D;&gt;Add New SSH Host</p></li><li><p>需要将本地的密钥发送到远程服务器。以autodl的服务器为例：如<code>connect.southb.gpuhub.com</code>，端口号： 29967  账户：root</p></li></ol><p>在Git Bash输入</p>   <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">ssh-copy-id -<span class="hljs-selector-tag">i</span> ~/.ssh/id_rsa<span class="hljs-selector-class">.pub</span> -<span class="hljs-selector-tag">p</span> <span class="hljs-number">29967</span> root@connect<span class="hljs-selector-class">.southb</span><span class="hljs-selector-class">.gpuhub</span>.com<br></code></pre></td></tr></table></figure><p>这将会把本地公钥发送至服务器。</p><ol start="4"><li>确认之后需要输入服务器密码，输入的时候不会显示密码</li></ol><p><img src="/images/3.png"></p><ol start="5"><li>在VSCode-<code>远程资源管理器</code>-<code>SSH</code>-<code>新建远程</code> 输入<code>ssh -p 29967 root@connect.southb.gpuhub.com</code> 并回车，服务器配置将被保存在VSCode的配置文件。</li><li>现在刷新一下，你就可以在远程资源管理器中见到这个服务器了。未来登陆时也不再需要重复输入密码。</li></ol><p><img src="/images/4.png"></p><h2 id="配置SSH端口映射"><a href="#配置SSH端口映射" class="headerlink" title="配置SSH端口映射"></a>配置SSH端口映射</h2><p>有的时候在服务器上部署服务时，想要在本地调用服务，那就需要进行端口映射了。我们以<code>ssh -p 46206 root@connect.westb.seetacloud.com</code>为例，如果设置的服务器端口是8501，只需要在命令行中输入以下代码，即可将服务器的端口映射到本地的8501端口。此时运行localhost:8501即可启动服务。</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh -L 8501:172.17.0.2:8501 -p 46206 root@connect.westb.seetacloud.com<br></code></pre></td></tr></table></figure><p>2023&#x2F;12&#x2F;28 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>工程实践</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>SSH</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>写在第一天</title>
    <link href="/2023/12/27/%E5%86%99%E5%9C%A8%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <url>/2023/12/27/%E5%86%99%E5%9C%A8%E7%AC%AC%E4%B8%80%E5%A4%A9/</url>
    
    <content type="html"><![CDATA[<p>今天是2023&#x2F;12&#x2F;27。距离2024年还有四天。回国以后的第三个月，也是工作的第三个月。</p><p>工作以后接触了很多新的项目和新的知识，加上很早以前就有没事写随笔的习惯，因此写博客的欲望愈发强烈。在此之前花了几个小时研究了一下搭博客的框架，原先打算用Django搭，但是看到很多人在安利Hexo，瞅了一眼确实很方便（不得不提现在的框架实在是太强大了，记得读本科那会我就想写博客来着，发现需要从零开始写服务，遂作罢:&#x2F;）。</p><p>Anyway，今天正式开始我的博客生涯。希望这个习惯能够保持到我死掉。</p><p>2023&#x2F;12&#x2F;27 于苏州家中</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
