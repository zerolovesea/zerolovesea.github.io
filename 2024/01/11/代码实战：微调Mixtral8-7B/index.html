

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;600;700;900&display=swap" rel="stylesheet">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/logo.png">
  <link rel="icon" href="/img/logo.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Yang Zhou">
  <meta name="keywords" content="">
  
    <meta name="description" content="åŸºäºTransformeråº“å®ç°çš„Mixtral8x7Bçš„å¾®è°ƒä»£ç ã€‚">
<meta property="og:type" content="article">
<meta property="og:title" content="ä»£ç å®æˆ˜ï¼šå¾®è°ƒMixtral8*7B">
<meta property="og:url" content="http://example.com/2024/01/11/%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98%EF%BC%9A%E5%BE%AE%E8%B0%83Mixtral8-7B/index.html">
<meta property="og:site_name" content="æˆ‘ä¸æ˜¯ç®—æ³•å·¥ç¨‹å¸ˆ">
<meta property="og:description" content="åŸºäºTransformeråº“å®ç°çš„Mixtral8x7Bçš„å¾®è°ƒä»£ç ã€‚">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images.zerolovesea.top/blog/mixtral.jpg">
<meta property="article:published_time" content="2024-01-11T12:12:14.000Z">
<meta property="article:modified_time" content="2025-05-28T14:16:31.769Z">
<meta property="article:author" content="Yang Zhou">
<meta property="article:tag" content="ä»£ç å®æˆ˜">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://images.zerolovesea.top/blog/mixtral.jpg">
  
  
  
  <title>ä»£ç å®æˆ˜ï¼šå¾®è°ƒMixtral8*7B - æˆ‘ä¸æ˜¯ç®—æ³•å·¥ç¨‹å¸ˆ</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/custom.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":60,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"wHpSTH8j8vF1pDJWJtnFXbzc-gzGzoHsz","app_key":"L2ZYyCM9mJIfR5Nxm7ktn3tU","server_url":"https://whpsth8j.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>æˆ‘ä¸æ˜¯å·¥ç¨‹å¸ˆ</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>é¦–é¡µ</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>å½’æ¡£</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>åˆ†ç±»</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>æ ‡ç­¾</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/databases/" target="_self">
                <i class="iconfont icon-books"></i>
                <span>ä¹¦å•</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/quote/" target="_self">
                <i class="iconfont icon-pen"></i>
                <span>å†™ç»™è‡ªå·±</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>å…³äº</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/168691.webp') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ä»£ç å®æˆ˜ï¼šå¾®è°ƒMixtral8*7B"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-01-11 20:12" pubdate>
          2024å¹´1æœˆ11æ—¥ æ™šä¸Š
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          1.1k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          10 åˆ†é’Ÿ
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> æ¬¡
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">ä»£ç å®æˆ˜ï¼šå¾®è°ƒMixtral8*7B</h1>
            
            
              <div class="markdown-body">
                
                <p>è¿™ç¯‡æ˜¯Mixtral8x7Bçš„å¾®è°ƒä»£ç å®æˆ˜ï¼Œä¹‹å‰çš„åšæ–‡ä¸­æœ‰å†™è¿‡ï¼Œä¸è¿‡å†™çš„ä¸æ˜¯å¾ˆå¥½ï¼Œè¿™æ¬¡å•ç‹¬å†å¼€ä¸€ç¯‡ã€‚</p>
<p>æ³¨æ„ï¼šå¾®è°ƒéœ€è¦A100çš„æ˜¾å¡ã€‚</p>
<h1 id="å®‰è£…ä¾èµ–"><a href="#å®‰è£…ä¾èµ–" class="headerlink" title="å®‰è£…ä¾èµ–"></a>å®‰è£…ä¾èµ–</h1><p>é¦–å…ˆå®‰è£…ä¾èµ–åŒ…ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">!pip install transformers trl accelerate torch bitsandbytes peft datasets -qU<br>!pip install flash-attn --no-build-isolation<br></code></pre></td></tr></table></figure>

<p>è¿™é‡Œçš„flash attentionæ˜¯ä¸€ä¸ªé‡è¦çš„ä¸œè¥¿ï¼Œå…ˆæŒ–ä¸ªå‘ï¼Œä¹‹åç ”ç©¶ä¸€ä¸‹ã€‚</p>
<h1 id="å¯¼å…¥æ•°æ®é›†"><a href="#å¯¼å…¥æ•°æ®é›†" class="headerlink" title="å¯¼å…¥æ•°æ®é›†"></a>å¯¼å…¥æ•°æ®é›†</h1><p>æˆ‘ä»¬éœ€è¦å¯¼å…¥æ•°æ®é›†ï¼Œè¿™é‡Œæ•°æ®é›†æ¥è‡ªHugging Faceã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>instruct_tune_dataset = load_dataset(<span class="hljs-string">&quot;mosaicml/instruct-v3&quot;</span>)<br>instruct_tune_dataset<br></code></pre></td></tr></table></figure>

<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs css">DatasetDict(&#123;<br>    train: <span class="hljs-built_in">Dataset</span>(&#123;<br>        features: [<span class="hljs-string">&#x27;prompt&#x27;</span>, <span class="hljs-string">&#x27;response&#x27;</span>, <span class="hljs-string">&#x27;source&#x27;</span>],<br>        num_rows: <span class="hljs-number">56167</span><br>    &#125;)<br>    test: <span class="hljs-built_in">Dataset</span>(&#123;<br>        features: [<span class="hljs-string">&#x27;prompt&#x27;</span>, <span class="hljs-string">&#x27;response&#x27;</span>, <span class="hljs-string">&#x27;source&#x27;</span>],<br>        num_rows: <span class="hljs-number">6807</span><br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>

<p>å¯ä»¥çœ‹åˆ°ï¼Œæ•°æ®é›†ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼špromptï¼Œresponseï¼Œsourceã€‚æ„¿æ„çš„è¯å¯ä»¥æ‰“å°ä¸€ä¸‹çœ‹çœ‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):<br>  <span class="hljs-built_in">print</span>(instruct_tune_dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-string">&#x27;prompt&#x27;</span>][i])<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;---&#x27;</span>*<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure>

<h1 id="æ•°æ®é¢„å¤„ç†"><a href="#æ•°æ®é¢„å¤„ç†" class="headerlink" title="æ•°æ®é¢„å¤„ç†"></a>æ•°æ®é¢„å¤„ç†</h1><p>å¯¹äºMixtralæ¨¡å‹ï¼Œæ•°æ®é›†éœ€è¦æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å‡†å¤‡ï¼š</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs verilog">&lt;s&gt;[INST] Use the provided <span class="hljs-keyword">input</span> to create an instruction that could have been used to <span class="hljs-keyword">generate</span> the response <span class="hljs-keyword">with</span> an LLM.<br><br>&#123;<span class="hljs-keyword">input</span>&#125; [/INST]<br><br>&#123;response&#125;&lt;/s&gt;<br></code></pre></td></tr></table></figure>

<p>è€Œæˆ‘ä»¬å·²æœ‰çš„æ•°æ®é›†é•¿è¿™æ ·ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">instruct_tune_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs delphi"><span class="hljs-comment">&#123;&#x27;prompt&#x27;: &#x27;Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction\nWhat are different types of grass?\n\n### Response\n&#x27;,</span><br><span class="hljs-comment"> &#x27;response&#x27;: &#x27;There are more than 12,000 species of grass. The most common is Kentucky Bluegrass, because it grows quickly, easily, and is soft to the touch. Rygrass is shiny and bright green colored. Fescues are dark green and shiny. Bermuda grass is harder but can grow in drier soil.&#x27;,</span><br><span class="hljs-comment"> &#x27;source&#x27;: &#x27;dolly_hhrlhf&#x27;&#125;</span><br></code></pre></td></tr></table></figure>

<p>å®šä¹‰ä¸€ä¸ªå¤„ç†çš„å‡½æ•°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_prompt</span>(<span class="hljs-params">sample</span>):<br>    bos_token = <span class="hljs-string">&quot;&lt;s&gt;&quot;</span><br>    original_system_message = <span class="hljs-string">&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.&quot;</span><br>    system_message = <span class="hljs-string">&quot;[INST]Use the provided input to create an instruction that could have been used to generate the response with an LLM.&quot;</span><br>    response = sample[<span class="hljs-string">&quot;prompt&quot;</span>].replace(original_system_message, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;\n\n### Instruction\n&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;\n### Response\n&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).strip()<br>    <span class="hljs-built_in">input</span> = sample[<span class="hljs-string">&quot;response&quot;</span>]<br>    eos_token = <span class="hljs-string">&quot;&lt;/s&gt;&quot;</span><br>    full_prompt = bos_token + system_message + <span class="hljs-string">&quot;\n&quot;</span> + <span class="hljs-built_in">input</span> + <span class="hljs-string">&quot;[/INST]&quot;</span> + response + eos_token<br><br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;full_prompt&quot;</span>: full_prompt&#125;<br></code></pre></td></tr></table></figure>

<p>æ‹¿ä¹‹å‰çš„æ•°æ®æµ‹è¯•ä¸€ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">create_prompt(instruct_tune_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>

<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vbnet"><span class="hljs-comment">&#x27;&lt;s&gt;[INST]Use the provided input to create an instruction that could have been used to generate the response with an LLM.\nThere are more than 12,000 species of grass. The most common is Kentucky Bluegrass, because it grows quickly, easily, and is soft to the touch. Rygrass is shiny and bright green colored. Fescues are dark green and shiny. Bermuda grass is harder but can grow in drier soil.[/INST]What are different types of grass?&lt;/s&gt;&#x27;</span><br></code></pre></td></tr></table></figure>

<p>æœ€åå¯¹æ•°æ®é›†åšä¸ªæ˜ å°„ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mapped_data = instruct_tune_dataset.<span class="hljs-built_in">map</span>(create_prompt)<br></code></pre></td></tr></table></figure>

<h1 id="åŠ è½½æ¨¡å‹"><a href="#åŠ è½½æ¨¡å‹" class="headerlink" title="åŠ è½½æ¨¡å‹"></a>åŠ è½½æ¨¡å‹</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">model_id = <span class="hljs-string">&quot;mistralai/Mixtral-8x7B-v0.1&quot;</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig<br><span class="hljs-keyword">import</span> torch<br><br>nf4_config = BitsAndBytesConfig(<br>   load_in_4bit=<span class="hljs-literal">True</span>,<br>   bnb_4bit_quant_type=<span class="hljs-string">&quot;nf4&quot;</span>,<br>   bnb_4bit_use_double_quant=<span class="hljs-literal">True</span>,<br>   bnb_4bit_compute_dtype=torch.bfloat16<br>) <span class="hljs-comment"># é‡åŒ–å‚æ•°</span><br><br>model = AutoModelForCausalLM.from_pretrained(<br>    model_id,<br>    device_map=<span class="hljs-string">&#x27;auto&#x27;</span>,<br>    quantization_config=nf4_config,<br>    use_cache=<span class="hljs-literal">False</span>,<br>    attn_implementation=<span class="hljs-string">&quot;flash_attention_2&quot;</span><br><br>) <br><br>tokenizer = AutoTokenizer.from_pretrained(model_id)<br><br>tokenizer.pad_token = tokenizer.eos_token<br>tokenizer.padding_side = <span class="hljs-string">&quot;right&quot;</span><br></code></pre></td></tr></table></figure>

<p>å…ˆå†™ä¸€ä¸ªç”Ÿæˆå›å¤çš„æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_response</span>(<span class="hljs-params">prompt, model</span>):<br>    encoded_input = tokenizer(prompt,  return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, add_special_tokens=<span class="hljs-literal">True</span>)<br>    model_inputs = encoded_input.to(<span class="hljs-string">&#x27;cuda&#x27;</span>)<br><br>    generated_ids = model.generate(<br>  **model_inputs,<br>  max_new_tokens=<span class="hljs-number">512</span>,<br>  do_sample=<span class="hljs-literal">True</span>, <br>  pad_token_id=tokenizer.eos_token_id)<br><br>    decoded_output = tokenizer.batch_decode(generated_ids)<br><br>    <span class="hljs-keyword">return</span> decoded_output[<span class="hljs-number">0</span>].replace(prompt, <span class="hljs-string">&quot;&quot;</span>)<br>  <br>  <br>prompt=<span class="hljs-string">&quot;&quot;&quot;[INST]Use the provided input to create an instruction that could have been used to generate the response with an LLM. \nThere are more than 12,000 species of grass. The most common is Kentucky Bluegrass, because it grows quickly, easily, and is soft to the touch. Rygrass is shiny and bright green colored. Fescues are dark green and shiny. Bermuda grass is harder but can grow in drier soil.[\INST]&quot;&quot;&quot;</span><br><br>generate_response(prompt, model)<br></code></pre></td></tr></table></figure>
<h1 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h1><p>ä¸‹é¢éœ€è¦å¯¹è¾“å…¥çš„è®­ç»ƒæ•°æ®é›†åšåˆ†è¯ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_prompts</span>(<span class="hljs-params">prompt</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(prompt)<br><br>tokenized_train_dataset = mapped_data[<span class="hljs-string">&quot;train&quot;</span>].<span class="hljs-built_in">map</span>(tokenize_prompts)<br>tokenized_val_dataset = mapped_data[<span class="hljs-string">&quot;test&quot;</span>].<span class="hljs-built_in">map</span>(tokenize_prompts)<br></code></pre></td></tr></table></figure>

<h1 id="æ¨¡å‹æ¶æ„"><a href="#æ¨¡å‹æ¶æ„" class="headerlink" title="æ¨¡å‹æ¶æ„"></a>æ¨¡å‹æ¶æ„</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure>

<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs routeros">MixtralForCausalLM(<br>  (model): MixtralModel(<br>    (embed_tokens): Embedding(32000, 4096)<br>    (layers): ModuleList(<br>      (0-31): 32 x MixtralDecoderLayer(<br>        (self_attn): MixtralFlashAttention2(<br>          (q_proj): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (k_proj): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (v_proj): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (o_proj): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (rotary_emb): MixtralRotaryEmbedding()<br>        )<br>        (block_sparse_moe): MixtralSparseMoeBlock(<br>          (gate): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=8, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (experts): ModuleList(<br>            (0-7): 8 x MixtralBLockSparseTop2MLP(<br>              (w1): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=14336, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>              (w2): Linear4bit(<span class="hljs-attribute">in_features</span>=14336, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>              (w3): Linear4bit(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=14336, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>              (act_fn): SiLU()<br>            )<br>          )<br>        )<br>        (input_layernorm): MixtralRMSNorm()<br>        (post_attention_layernorm): MixtralRMSNorm()<br>      )<br>    )<br>    (norm): MixtralRMSNorm()<br>  )<br>  (lm_head): Linear(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=32000, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>)<br></code></pre></td></tr></table></figure>

<h1 id="è®¾ç½®è®­ç»ƒå‚æ•°"><a href="#è®¾ç½®è®­ç»ƒå‚æ•°" class="headerlink" title="è®¾ç½®è®­ç»ƒå‚æ•°"></a>è®¾ç½®è®­ç»ƒå‚æ•°</h1><p>éœ€è¦è®¾ç½®ä¸€ä¸‹è®­ç»ƒå¿…é¡»çš„å‚æ•°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraConfig, get_peft_model, prepare_model_for_kbit_training<br><br>peft_config = LoraConfig(<br>    lora_alpha=<span class="hljs-number">16</span>,<br>    lora_dropout=<span class="hljs-number">0.1</span>,<br>    r=<span class="hljs-number">64</span>,<br>    bias=<span class="hljs-string">&quot;none&quot;</span>,<br>    target_modules=[<br>        <span class="hljs-string">&quot;q_proj&quot;</span>,<br>        <span class="hljs-string">&quot;k_proj&quot;</span>,<br>        <span class="hljs-string">&quot;v_proj&quot;</span>,<br>        <span class="hljs-string">&quot;o_proj&quot;</span>,<br>        <span class="hljs-string">&quot;gate_proj&quot;</span>,<br>        <span class="hljs-string">&quot;up_proj&quot;</span>,<br>        <span class="hljs-string">&quot;down_proj&quot;</span>,<br>        <span class="hljs-string">&quot;lm_head&quot;</span>,<br>    ],<br>    task_type=<span class="hljs-string">&quot;CAUSAL_LM&quot;</span><br>)<br><br>model = prepare_model_for_kbit_training(model) <span class="hljs-comment"># ç”¨æ¥ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè®­ç»ƒåœ¨4Bitsç²¾åº¦</span><br>model = get_peft_model(model, peft_config)<br></code></pre></td></tr></table></figure>

<p>æ‰“å°ä¸€ä¸‹å¯è®­ç»ƒå‚æ•°æ•°é‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_trainable_parameters</span>(<span class="hljs-params">model</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Prints the number of trainable parameters in the model.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    trainable_params = <span class="hljs-number">0</span><br>    all_param = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> _, param <span class="hljs-keyword">in</span> model.named_parameters():<br>        all_param += param.numel()<br>        <span class="hljs-keyword">if</span> param.requires_grad:<br>            trainable_params += param.numel()<br>    <span class="hljs-built_in">print</span>(<br>        <span class="hljs-string">f&quot;trainable params: <span class="hljs-subst">&#123;trainable_params&#125;</span> || all params: <span class="hljs-subst">&#123;all_param&#125;</span> || trainable%: <span class="hljs-subst">&#123;<span class="hljs-number">100</span> * trainable_params / all_param&#125;</span>&quot;</span><br>    )<br>    <br>print_trainable_parameters(model)<br></code></pre></td></tr></table></figure>

<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">trainable</span> params: <span class="hljs-number">56836096</span> || <span class="hljs-literal">all</span> params: <span class="hljs-number">23539437568</span> || trainable%: <span class="hljs-number">0</span>.<span class="hljs-number">24145052674182907</span><br></code></pre></td></tr></table></figure>

<h1 id="è®¾ç½®è®­ç»ƒè¶…å‚æ•°"><a href="#è®¾ç½®è®­ç»ƒè¶…å‚æ•°" class="headerlink" title="è®¾ç½®è®­ç»ƒè¶…å‚æ•°"></a>è®¾ç½®è®­ç»ƒè¶…å‚æ•°</h1><p>è¿˜å¯ä»¥è®¾ç½®ä¸€äº›è®­ç»ƒè¶…å‚æ•°ï¼š</p>
<p><code>num_train_epochs/max_steps</code>: æ•°æ®è¿­ä»£æ¬¡æ•°ï¼Œå¦‚æœè¿‡é«˜ä¼šé€ æˆè¿‡æ‹Ÿåˆã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> torch.cuda.device_count() &gt; <span class="hljs-number">1</span>: <span class="hljs-comment"># If more than 1 GPU</span><br>    <span class="hljs-built_in">print</span>(torch.cuda.device_count())<br>    model.is_parallelizable = <span class="hljs-literal">True</span><br>    model.model_parallel = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments<br><br>args = TrainingArguments(<br>  output_dir = <span class="hljs-string">&quot;Mixtral_Alpace_v2&quot;</span>,<br>  <span class="hljs-comment">#num_train_epochs=5,</span><br>  max_steps = <span class="hljs-number">1000</span>, <span class="hljs-comment"># å¯ä»¥é€‰æ‹©num_train_epochsæˆ–è€…æŒ‰stepsè¿›è¡Œè®­ç»ƒ</span><br>  per_device_train_batch_size = <span class="hljs-number">32</span>,<br>  warmup_steps = <span class="hljs-number">0.03</span>,<br>  logging_steps=<span class="hljs-number">10</span>,<br>  save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>  <span class="hljs-comment">#evaluation_strategy=&quot;epoch&quot;,</span><br>  evaluation_strategy=<span class="hljs-string">&quot;steps&quot;</span>,<br>  eval_steps=<span class="hljs-number">10</span>, <span class="hljs-comment"># é»˜è®¤æ˜¯æ¯è½®éƒ½ä¼šè¯„ä¼°ï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰è®¾ç½®</span><br>  learning_rate=<span class="hljs-number">2.5e-5</span>,<br>  bf16=<span class="hljs-literal">True</span>,<br>  <span class="hljs-comment"># lr_scheduler_type=&#x27;constant&#x27;,</span><br>)<br></code></pre></td></tr></table></figure>

<p>æœ€åè®¾ç½®ä¸€ä¸‹SFTTrainerã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> trl <span class="hljs-keyword">import</span> SFTTrainer<br><br>max_seq_length = <span class="hljs-number">1024</span><br><br>trainer = SFTTrainer(<br>  model=model,<br>  peft_config=peft_config,<br>  max_seq_length=max_seq_length,<br>  tokenizer=tokenizer,<br>  packing=<span class="hljs-literal">True</span>,<br>  formatting_func=create_prompt, <span class="hljs-comment"># è¿™ä¸ªä¼šè‡ªåŠ¨å¯¹åŸå§‹æ•°æ®é›†åšæ˜ å°„å¤„ç†ï¼Œä¹Ÿå°±æ˜¯ä¹‹å‰çš„æ“ä½œå¯ä»¥çœç•¥</span><br>  args=args,<br>  train_dataset=instruct_tune_dataset[<span class="hljs-string">&quot;train&quot;</span>],<br>  eval_dataset=instruct_tune_dataset[<span class="hljs-string">&quot;test&quot;</span>]<br>)<br><br>trainer.train() <span class="hljs-comment"># å¼€å§‹è®­ç»ƒ</span><br></code></pre></td></tr></table></figure>

<p>è®­ç»ƒå®Œæ¯•åè®°å¾—ä¿å­˜æ¨¡å‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">trainer.save_model(<span class="hljs-string">&quot;Mixtral_V2&quot;</span>)<br></code></pre></td></tr></table></figure>

<h1 id="æ¨¡å‹åˆå¹¶"><a href="#æ¨¡å‹åˆå¹¶" class="headerlink" title="æ¨¡å‹åˆå¹¶"></a>æ¨¡å‹åˆå¹¶</h1><p>å¯ä»¥é€šè¿‡<code>merge_and_unload</code>æ–¹æ³•è¿›è¡Œåˆå¹¶ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">merged_model = model.merge_and_unload()<br></code></pre></td></tr></table></figure>

<p>æœ€åå¯ä»¥å†ä½¿ç”¨æ–°æ¨¡å‹æ¨ç†ä¸€ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">&quot;[INST]Use the provided input to create an instruction that could have been used to generate the response with an LLM.\nThere are more than 12,000 species of grass. The most common is Kentucky Bluegrass, because it grows quickly, easily, and is soft to the touch. Rygrass is shiny and bright green colored. Fescues are dark green and shiny. Bermuda grass is harder but can grow in drier soil.[/INST]&quot;</span><br><br>generate_response(prompt, merged_model)<br></code></pre></td></tr></table></figure>

<p>2024&#x2F;1&#x2F;11 äºè‹å·å®¶ä¸­</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/LLM/" class="category-chain-item">LLM</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98/" class="print-no-link">#ä»£ç å®æˆ˜</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
        <a href="/tags/NLP/" class="print-no-link">#NLP</a>
      
    </div>
  
</div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/01/13/%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9A%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%B8%95%E7%B4%AF%E6%89%98%E6%9C%80%E4%BC%98%EF%BC%9F/" title="åšå¼ˆè®ºï¼šå¦‚ä½•ç†è§£å¸•ç´¯æ‰˜æœ€ä¼˜ï¼Ÿ">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">åšå¼ˆè®ºï¼šå¦‚ä½•ç†è§£å¸•ç´¯æ‰˜æœ€ä¼˜ï¼Ÿ</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/01/08/%E6%8F%90%E9%AB%98Python%E5%8F%AF%E8%AF%BB%E6%80%A7%EF%BC%9A%E7%B1%BB%E5%9E%8B%E6%8F%90%E7%A4%BA%E5%92%8CEnum/" title="æé«˜Pythonå¯è¯»æ€§ï¼šType Hintsçš„åº”ç”¨">
                        <span class="hidden-mobile">æé«˜Pythonå¯è¯»æ€§ï¼šType Hintsçš„åº”ç”¨</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            <!-- Remark42 è¯„è®ºç³»ç»Ÿ -->
<div id="remark42"></div>

<script>
  var remark_config = {
    host: 'https://comments.zerolovesea.top',
    site_id: 'zerolovesea.top',
    url: window.location.origin + window.location.pathname,
  };
</script>

<script>
  (function(c) {
    for (var i = 0; i < c.length; i++) {
      var d = document, s = d.createElement('script');
      s.src = remark_config.host + c[i];
      s.defer = true;
      (d.head || d.body).appendChild(s);
    }
  })(['/web/embed.js']);
</script>
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        æ€»è®¿é—®é‡ 
        <span id="leancloud-site-pv"></span>
         æ¬¡
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        æ€»è®¿å®¢æ•° 
        <span id="leancloud-site-uv"></span>
         äºº
      </span>
    
    

  
</div>

  
  
  
  
  <!-- æ—¶é—´æ˜¾ç¤ºéƒ¨åˆ† -->
  <div>
    <span id="timeDate">è½½å…¥å¤©æ•°...</span>
    <span id="times">è½½å…¥æ—¶åˆ†ç§’...</span>
    <script>
      var now = new Date();
      function createtime(){
        var grt= new Date("12/27/2023 00:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24;
        dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
        hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){
          hnum = "0" + hnum;
        }
        minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes);
        if(String(mnum).length ==1 ){
          mnum = "0" + mnum;
        }
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds);
        if(String(snum).length ==1 ){
          snum = "0" + snum;
        }
        document.getElementById("timeDate").innerHTML = "ğŸš€ for&nbsp"+dnum+"&nbspdays";
        document.getElementById("times").innerHTML = hnum + "&nbsphr&nbsp" + mnum + "&nbspmin&nbsp" + snum + "&nbspsec";
      }
      setInterval("createtime()",250);
    </script>
  </div>
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
</body>
</html>
